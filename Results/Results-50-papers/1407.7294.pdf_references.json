[
    {
        "title": "Learning from revealed preference",
        "author": [
            "Eyal Beigman",
            "Rakesh Vohra"
        ],
        "venue": "In Proceedings of the 7th ACM Conference on Electronic Commerce, EC",
        "citeRegEx": "1",
        "shortCiteRegEx": "1",
        "year": 2006,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " The problem of finding a utility function that is both consistent and predictive was first considered by Beigman and Vohra [1], who formalize the statement that \u201cAfriat\u2019s Theorem Learners\u201d [1] studies a PAC-like learning model in which they assume a distribution over observations and seek to find a hypothesis that performs well on future observations drawn from the same distribution. We represent a bundle of goods x \u2208 [0, 1]n by a vector specifying what fraction of each of the n goods is purchased. The consumer has an unknown utility function u : [0, 1]n \u2192 R specifying her utility for each possible bundle. The merchant has the power to set prices (one for each good), also represented by a vector p \u2208 [0, 1]n (we normalize so that the price of every good i is pi \u2264 1). The merchant\u2019s goal is to obtain profit close to the maximum possible profit OPT = maxp\u2208[0,1]n maxx\u2208X(u,p,B) x \u00b7 (p\u2212 c) = maxp\u2208[0,1]n maxx\u2208X(u,p,B)B \u2212 x \u00b7 c. The merchant\u2019s goal is to obtain profit close to the maximum possible profit OPT = maxp\u2208[0,1]n maxx\u2208X(u,p,B) x \u00b7 (p\u2212 c) = maxp\u2208[0,1]n maxx\u2208X(u,p,B)B \u2212 x \u00b7 c. The key to the algorithm\u2019s efficiency will stem from the observation that there exists a restricted family of pricing vectors P \u2282 [0, 1]n containing a (nearly) profit-maximizing vector p\u2217. Thus, we should search for the critical \u03b1\u2217(k) over the interval [0, 1] in increments of this size. The algorithm maintains the set of valuation vectors v consistent with the observations seen thus far: initially this feasible set is simply C0 = [0, 1] n. Initialize the fixed coordinates, initially none C0 = {z \u2208 [0, 1]n | 0 \u2264 zi \u2264 1 \u2200i} . Fix each determined coordinate Fix(i) Ct+1 = {z \u2208 [0, 1]n\u2212|Fixed| | 0 \u2264 zi \u2264 1 \u2200i 6\u2208 Fixed} . Note that each of the random variables Mi is independent and bounded in [0, 1].",
        "context": null
    },
    {
        "title": "The empirical implications of privacy-aware choice",
        "author": [
            "Rachel Cummings",
            "Federico Echenique",
            "Adam Wierman"
        ],
        "venue": "In Proceedings of the Fifteenth ACM Conference on Economics and Computation, EC",
        "citeRegEx": "2",
        "shortCiteRegEx": "2",
        "year": 2014,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Cummings, Echenique, and Wierman [2] consider the revealed preferences problem when the consumer can strategically choose bundles to subvert the merchant\u2019s learning.",
        "context": null
    },
    {
        "title": "A random polynomial-time algorithm for approximating the volume of convex bodies",
        "author": [
            "Martin Dyer",
            "Alan Frieze",
            "Ravi Kannan"
        ],
        "venue": "Journal of the ACM (JACM),",
        "citeRegEx": "3",
        "shortCiteRegEx": "3",
        "year": 1991,
        "abstract": "",
        "full_text": "",
        "sentence": " The only computationally challenging step is sampling a point uniformly at random from the consistent set Ct, which can be done in polynomial time using the technique of [3].",
        "context": null
    },
    {
        "title": "Learning quickly when irrelevant attributes abound: a new linear-threshold algorithm",
        "author": [
            "Nick Littlestone"
        ],
        "venue": "Machine Learning,",
        "citeRegEx": "4",
        "shortCiteRegEx": "4",
        "year": 1988,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Our results in the second model are inspired by the classic halving algorithm for the online learning setting, which is credited to Littlestone [4].",
        "context": null
    },
    {
        "title": "Lecture notes in microeconomic theory: the economic agent",
        "author": [
            "Ariel Rubinstein"
        ],
        "venue": null,
        "citeRegEx": "6",
        "shortCiteRegEx": "6",
        "year": 2012,
        "abstract": "",
        "full_text": "",
        "sentence": " textbook treatments in [5] and [6]). For a textbook introduction to the standard model, see [5] and [6], and for a survey of recent work, see [8].",
        "context": null
    },
    {
        "title": "A note on the pure theory of consumers",
        "author": [
            "Paul A. Samuelson"
        ],
        "venue": "behavior. Economica,",
        "citeRegEx": "7",
        "shortCiteRegEx": "7",
        "year": 1938,
        "abstract": "",
        "full_text": "",
        "sentence": " , (pT , xT ) the revealed preferences problem (introduced by [7]; see [8] for a survey) is to determine whether the observations are consistent with a consumer optimizing any utility function u, subject to some mild constraints (e. There is a long line of work on the revealed preference problem, which was first introduced by Samuelson [7].",
        "context": null
    },
    {
        "title": "Revealed preference",
        "author": [
            "Hal R. Varian"
        ],
        "venue": "Samuelsonian economics and the twenty-first century,",
        "citeRegEx": "8",
        "shortCiteRegEx": "8",
        "year": 2006,
        "abstract": "",
        "full_text": "",
        "sentence": " , (pT , xT ) the revealed preferences problem (introduced by [7]; see [8] for a survey) is to determine whether the observations are consistent with a consumer optimizing any utility function u, subject to some mild constraints (e. For a textbook introduction to the standard model, see [5] and [6], and for a survey of recent work, see [8].",
        "context": null
    },
    {
        "title": "Efficiently learning from revealed preference",
        "author": [
            "Morteza Zadimoghaddam",
            "Aaron Roth"
        ],
        "venue": "In Proceedings of the 8th International Conference on Internet and Network Economics,",
        "citeRegEx": "9",
        "shortCiteRegEx": "9",
        "year": 2012,
        "abstract": "In this paper, we consider the revealed preferences problem from a learning\nperspective. Every day, a price vector and a budget is drawn from an unknown\ndistribution, and a rational agent buys his most preferred bundle according to\nsome unknown utility function, subject to the given prices and budget\nconstraint. We wish not only to find a utility function which rationalizes a\nfinite set of observations, but to produce a hypothesis valuation function\nwhich accurately predicts the behavior of the agent in the future. We give\nefficient algorithms with polynomial sample-complexity for agents with linear\nvaluation functions, as well as for agents with linearly separable, concave\nvaluation functions with bounded second derivative.",
        "full_text": "arXiv:1211.4150v1  [cs.GT]  17 Nov 2012\nEf\ufb01ciently Learning from Revealed Preference\nMorteza Zadimoghaddam\u2217\nAaron Roth\u2020\nSeptember 6, 2018\nAbstract\nIn this paper, we consider the revealed preferences problem from a learning perspective. Every day,\na price vector and a budget is drawn from an unknown distribution, and a rational agent buys his most\npreferred bundle according to some unknown utility function, subject to the given prices and budget\nconstraint. We wish not only to \ufb01nd a utility function which rationalizes a \ufb01nite set of observations, but\nto produce a hypothesis valuation function which accurately predicts the behavior of the agent in the\nfuture. We give ef\ufb01cient algorithms with polynomial sample-complexity for agents with linear valuation\nfunctions, as well as for agents with linearly separable, concave valuation functions with bounded second\nderivative.\n1\nIntroduction\nConsider the problem of a market-researcher attempting to divine the preferences of a population of con-\nsumers merely by observing their past buying behavior. Suppose, for example, that the researcher may\nobserve a consumer each day: every day, the consumer is faced with the choice to buy some subset of\ngoods, each of which may have a different price. The consumer is facing an optimization problem \u2013 each\nday he attempts to buy the subset of goods that maximizes his utility function, given his budget constraints.\nThe market-researcher, on the other hand, is facing a learning problem. Based on his observations of the\nconsumer, he would like to learn a model for the agent\u2019s utility function that can explain his behavior, and\nthat can be used to predict (and therefore optimally exploit) his future behavior.\nThis is the \u201crevealed preferences\u201d problem, and it has received a great deal of attention in the economics\nliterature (see, e.g., [Var06] for a nice survey). Typically, however, the work on the revealed preferences\nproblem has focused on determining whether a set of observations is rationalizable or not \u2013 i.e. whether\nit is consistent with any utility function that is monotone increasing in each good. A classic result in this\nliterature is Afriat\u2019s Theorem, which roughly states that any \ufb01nite set of observations is rationalizable if and\nonly if it is rationalizable by a monotone increasing, piecewise linear, concave utility function.\nNote, however, that the problem of rationalizing is easier than the problem of learning. To rationalize a\nset of observations, it is suf\ufb01cient to \ufb01nd a utility function which explains past behavior. Learning, however,\nrequires \ufb01nding a utility function which not only explains past behavior, but also will be predictive of future\nbehavior! In particular, Afriat\u2019s theorem can be taken as showing that attempting to learn from the set of all\nmonotone increasing, piecewise linear, concave utility functions is as hard (and as hopeless) as learning from\nthe set of all utility functions. Indeed, Beigman and Vohra [BV06] have shown that this class of functions has\n\u2217MIT, CSAIL, morteza@csail.mit.edu\n\u2020University of Pennsylvania, aaroth@cis.upenn.edu.\n1\nin\ufb01nite fat-shattering dimension, and so without further restricting the set of allowable utility functions, no\naccurate predictions can in general be made after any \ufb01nite set of observations, even by inef\ufb01cient learning\nalgorithms!\nIn this paper, we initiate the study of ef\ufb01ciently (in terms of both computational complexity and sample\ncomplexity) learning utility functions which can accurately predict future purchases of a utility-maximizing\nagent, given access to past purchase behavior. We necessarily restrict the class of agent utility functions,\nand consider both linear utility functions, and linearly separable concave utility functions with bounded\n2nd derivative. We give polynomial upper and lower bounds on the sample complexity (i.e. the number\nof observations) required for learning, as well as ef\ufb01cient algorithms that can learn predictive models from\npolynomially many observations.\n1.1\nOur Results\nWe consider a model in which an agent has an unknown utility function over a set of n divisible goods. We\nget to observe the behavior of the agent, who every day faces a set of prices for each good, together with\na budget constraint, which is drawn from a \ufb01xed but unknown probability distribution. The agent selects a\nbundle of goods to buy so as to maximize his utility function subject to his budget constraint, and the goal\nof a learning algorithm is to impute a model for his utility function that correctly predicts his behavior with\nhigh probability on future price/budget instances drawn from the same distribution.\nWe consider both linear utility functions, and then more generally, linearly separable concave utility\nfunctions with bounded derivatives. For both of these cases, we give ef\ufb01cient learning algorithms with poly-\nnomially bounded sample complexity. We then consider a relaxed model in which our algorithm receives\nexpanded feedback from the agent during the learning stage, and is permitted to predict bundles that are\nwithin a small additive error of the agent\u2019s optimal bundle. In this relaxed model, we give a polynomial time\nlearning algorithm with improved sample complexity bounds.\n1.2\nRelated Work\nWork on the \u201crevealed preferences problem\u201d has a long history in economics, beginning with the seminal\nwork of Samuelson [Sam38]. Modern work on revealed preferences, in which explanatory utility func-\ntions are constructively generated from \ufb01nitely many agent price/purchase observations began with Afriat\n[Afr65, Afr67] who showed (via an algorithmic construction) that any \ufb01nite sequence of observations is\nrationalizable if and only if it is rationalizable by a piecewise linear, monotone, concave utility function. We\nwill not attempt to review the extremely large body of work on revealed preferences, and instead refer the\nreader to an excellent survey of Varian [Var06].\nAlgorithms that constructively generate utility functions given a \ufb01nite set of observations can be viewed\nas learning algorithms for the set of all monotone increasing utility functions. These algorithms typically\ncome with a caveat, however, that the hypothesis utility functions they generate have the same descrip-\ntion length as the set of observations that they were generated from, and so tend to over\ufb01t the data \u2013 this\nobservation is related to a recent paper of Echenique, Golovin, and Wierman [EGW11], who gave a thought-\nprovoking result: that any set of rationalizable observations can in fact be rationalized by a utility function\nwhich is computationally easy to optimize. However, such a utility function clearly cannot be predictive of\nthe future behavior of an agent who is in fact making his decisions based on an intractable utility function,\nbecause the hypothesis produced by the learning algorithm would itself be witness to the existence of a\npolynomially sized circuit for optimizing the purportedly intractable utility function of the agent.\n2\nMost related to our work is the work of Beigman and Vohra [BV06] who \ufb01rst pose the revealed pref-\nerences problem in the model of computational learning theory, with a distribution over observations and\nthe explicit goal of producing a predictive hypothesis. They show that the set of all monotone utility func-\ntions has in\ufb01nite fat-shattering dimension, and therefore prove that (without restricting the class of allowable\nutility functions), there does not exist any algorithm (independent of computational ef\ufb01ciency) which can\nprovide any non-trivial predictive guarantees from any \ufb01nite number of samples, over every distribution over\nobservations. They also show that if the agent utility functions satisfy a certain bounded-jump condition,\nthen the resulting class in fact has \ufb01nite fat-shattering dimension, and that predictive learning is therefore\npossible using a \ufb01nite number of samples. We continue this line of work by considering speci\ufb01c, simple\nclasses of utility functions, and give ef\ufb01cient learning algorithms together with small polynomial upper and\nlower bounds on the sample complexity necessary for learning.\nA very nice recent line of work by Balcan and Harvey, and Balcan et al. [BH11, BCIW12] considers\na related problem of learning valuation functions. This is similar in motivation, but is orthogonal to the\nrevealed preference setting considered here because it uses direct access to the valuation function evaluated\non bundles, rather than only the \u201crevealed\u201d preference of the user, which is the maximum value bundle\nselected subject to some cost constraint.\n2\nPreliminaries\nWe consider the revealed preferences problem for an agent who when faced with a set of prices over n goods\n[n] buys the most valued bundle available to him. A bundle of goods is a vector of quantities x \u2208[0, 1]n,\none for each good: xi represents the fraction of the good i that is in the bundle. The goods are divisible: i.e.\nbundles can be arbitrary real valued vectors x \u2208[0, 1]n.\nThe agent has a value function v : [0, 1]n \u2192R. His value for a bundle x \u2208[0, 1]n is simply v(x). Goods\ncan also be paired with vectors of non-negative prices p \u2208Rn\n+, where pi is the price for good i. The price\nof a bundle is linear in the goods in the bundle. The price of a bundle x with respect to prices p is therefore\nsimply x \u00b7 p. Prices are important, because the agent may be faced with a budget constraint B: he can only\nbuy bundles x such that x \u00b7 p \u2264B.\nThe agent is a utility maximizer. When faced with a price vector p and a budget B, he will choose to\nbuy the bundle that maximizes his value subject to his budget constraint: That is, he will choose the bundle:\nx\u2217(v, p, B) =\nargmax\nx\u2208[0,1]n:x\u00b7p\u2264B\nv(x)\nWe will consider several types of value functions in this paper. A linear value function v is de\ufb01ned by a\nvector v \u2208Rn\n+, where vi is the marginal value of good i. In this case, v(x) = v \u00b7 x. More generally, we can\nconsider linearly separable concave utility functions. A value function v is linearly separable and concave\nif it can be described using concave functions v1, . . . , vn where each vi : [0, 1] \u2192R+ is a one-dimensional\nreal valued function, and we can evaluate v(x) = Pn\ni=1 vi(xi).\nThe revealed preferences problem is to recover a value function that can explain a sequence of choices\nthat the agent was observed to make. In this paper, we wish to recover a value function that can not only\nrationalize observed behavior, but can help predict future behavior. In order for this to be a meaningful task,\nwe must assume that the choices presented to the agent are drawn from some distribution.\nDe\ufb01nition 2.1. An example is a price vector p \u2208Rn\n+ paired with a budget B \u2208R+. A distribution over\nexamples D is simply a distribution over (p, B) \u223c[0, 1]n \u00d7 R+.\n3\nDe\ufb01nition 2.2. An observation of an agent with value function v, (p, B, x\u2217(p, B, v)) \u2208Rn\n+ \u00d7 R+ \u00d7 Rn\n+\nis simply a triple consisting of a price vector p, a budget B, and a bundle x\u2217(p, B, v) chosen by the agent\ngiven p and B: i.e. a bundle x that maximizes v(x) subject to x \u00b7 p \u2264B.\nDe\ufb01nition 2.3. An algorithm A \u03b4-learns a class of value functions V from m = m(\u03b4) observations if for\nevery distribution D over examples and for every value function v \u2208V, given a set of m observations\n{(pi, Bi, x\u2217(pi, Bi, v))}m\ni=1 where examples (pi, Bi) are drawn i.i.d. from D, with probability 1 \u2212\u03b4 it\nproduces a hypothesis \u02c6v such that:\nPr\n(p,B)\u223cD[v(x\u2217(p, B, v)) = v(x\u2217(p, B, \u02c6v))] \u22651 \u2212\u03b4.\nWe say that A is ef\ufb01cient if both its run-time and its sample complexity m(\u03b4) are bounded by some polyno-\nmial p(n, 1/\u03b4). We say that the sample complexity of learning V is at most m\u2217= m\u2217(\u03b4) if there is some\nalgorithm A which \u03b4-learns V from m(\u03b4) \u2264m\u2217(\u03b4) observations.\nRemark 2.4. Note that a learning algorithm must with high probability (over the choice of observations and\ncoins of the mechanism) produce a value function which most of the time (over draws of examples) selects\na bundle which is equal to the bundle that the agent would have selected.\nIn section 5 we relax our de\ufb01nition of learning to allow our learning algorithm to predict bundles which\nare only approximately optimal to the agent, rather than requiring that it select the exactly correct bundle.\nNote that such approximately optimal bundles might look very different from exactly optimal bundles, and\nso we will also need to allow our learning algorithms to receive richer feedback from the agent.\nDe\ufb01nition 2.5. An algorithm A (\u01eb, \u03b4)-learns a class of value functions V from m = m(\u03b4) observations if\nfor every distribution D over examples and for every value function v \u2208V, given a set of m observations\n{(pi, Bi, x\u2217(pi, Bi, v))}m\ni=1 where examples (pi, Bi) are drawn i.i.d. from D, with probability 1 \u2212\u03b4 it\nproduces a hypothesis \u02c6v such that:\nPr\n(p,B)\u223cD[v(x\u2217(p, B, v)) \u2265v(x\u2217(p, B, \u02c6v)) \u2212\u01eb] \u22651 \u2212\u03b4.\nFor this notion of additive approximation to be meaningful, we will typically normalize the target utility\nfunction v to lie in the range [0, 1].\n3\nAll Pairs Comparisons Algorithm: Learning Linear Valuation Functions\nIn this section, we present an algorithm that ef\ufb01ciently \u03b4-learns the class of all linear valuation functions\ngiven a set of m = O(n2 ln(n2/\u03b4)\n\u03b4\n) observations. In particular, this provides a quadratic upper bound on the\noptimal sample complexity m\u2217(\u03b4) for learning linear valuation functions. We note that a linear \u2126(m) lower\nbound is immediate in this setting. We start by characterizing the optimal bundle for an agent maximizing a\nlinear utility function, and give intuition for our learning algorithm.\nLet v\u2217and p denote some \ufb01xed value and price vectors respectively, and let B denote some \ufb01xed budget.\nWe denote the optimal bundle (according to the linear utility function de\ufb01ned by value vector v\u2217, price vector\np, and budget B) by x\u2217. Recall that the value of the optimal bundle is v\u2217\u00b7 x\u2217, and its cost p \u00b7 x\u2217is at most\nthe budget B. Observe that in choosing bundle x\u2217, the agent is solving a divisible knapsack problem, and\nso the following structural lemma is immediate.\n4\nLemma 3.1. For any pair of goods i, j \u2208[n] with x\u2217\ni > x\u2217\nj, it must be that:\nv\u2217\ni\npi\n\u2265\nv\u2217\nj\npj\nEquivalently, for any pair of goods with v\u2217\ni\nv\u2217\nj \u2265pi\npj , the optimal bundle \u201cprefers\u201d good i over good j (It\nwill never buy any of good j until it has exhausted the supply of good i). Our algorithm is based on this\nstructural characterization, and operates by maintaining upper and lower bounds on each of the n2 ratios v\u2217\ni\nv\u2217\nj\nfor i \u0338= j \u2208[n]. Based on this transitive relation, we can sort the goods, and \ufb01nd the optimal bundle by\nbuying the goods one by one starting from high priority goods until the budget B is spent completely. In this\noptimal bundle, we have at most one fractional item. In our algorithm, we try to learn ratios vi\nvj accurately\nfor all pair of goods with high probability.\nAllPairsLearn(\u03b4):\nTraining Phase:\n1. Let E be a set of m = O\n\u0010\nn2 ln(n2/\u03b4)\n\u03b4\n\u0011\nobservations (p, B, x\u2217(p, B, v)).\n2. Initialize bounds (Li,j, Ui,j) for each i \u0338= j \u2208[n]. Initially Li,j = 0 and Ui,j = \u221efor all i, j.\n3. For each (p, B, x\u2217) \u2208E:\n(a) For each i \u0338= j \u2208[n]:\ni. If x\u2217\ni > x\u2217\nj, Let Li,j = max(Li,j, pi\npj )\nii. If x\u2217\nj > x\u2217\ni , Let Ui,j = min(Ui,j, pi\npj )\nClassi\ufb01cation Phase:\n1. On a new example (p, B) let v\u2032 \u2208[0, 1]n be any vector such that for all i \u0338= j \u2208[n] v\u2032\ni\nv\u2032\nj \u2208[Li,j, Ui,j].\nPredict bundle x\u2032(p, B, v\u2032) that results from maximizing v\u2032 with respect to prices p and budget con-\nstraint B.\nFigure 1: The All Pairs Comparison Algorithm for Learning Linear Valuation Functions. It takes as input\nan accuracy parameter \u03b4.\nThe intuition is that in order to \ufb01nd the optimal bundle x\u2217, we need only know bounds on the ratios of\nthe values of pairs of goods for which unequal quantities are purchased in the optimal bundle. So if we know\nthat vi\nvj \u2265pi\npj for any pair of goods with x\u2217\ni > x\u2217\nj, we can \ufb01nd the optimal bundle x\u2217. We need not know the\nvalues themselves \u2013 it is suf\ufb01cient to bound these ratios. For example, if the lower bound Li,j is at least pi\npj ,\nwe can infer that good i is preferred to good j. If we can infer all these preferences for pairs of goods (i, j)\nwith x\u2217\ni \u0338= x\u2217\nj, we can \ufb01nd the optimal bundle as well. Following we show that with high probability after\nobserving m = O(n2 ln(n2/\u03b4)/\u03b4) i.i.d. examples we can \ufb01nd the optimal bundle.\nTheorem 3.2. AllPairsLearn(\u03b4) ef\ufb01ciently \u03b4-learns the class of linear valuation functions given m =\nO\n\u0010\nn2 ln(n2/\u03b4)\n\u03b4\n\u0011\nobservations.\n5\nProof. For each pair of goods (i, j), we de\ufb01ne ai,j and bi,j as follows:\nai,j\n=\nmin\n\u001a\na|a \u2264vi\nvj\n&\nPr\n\u0012\nx\u2217\ni > x\u2217\nj\n&\npi\npj\n\u2208[a, vi\nvj\n]\n\u0013\n\u2264\u03b4\nn2\n\u001b\nbi,j\n=\nmax\n\u001a\nb|b \u2265vi\nvj\n&\nPr\n\u0012\nx\u2217\nj > x\u2217\ni\n&\npi\npj\n\u2208[ vi\nvj\n, b]\n\u0013\n\u2264\u03b4\nn2\n\u001b\nwhere p is the price vector drawn from the distribution D, and x\u2217is its optimal bundle. Every time an\ni.i.d. example is drawn, with probability \u03b4/n2, the lower bound Li,j becomes at least ai,j, and the upper\nbound Ui,j becomes at most bi,j for every pair (i, j). For each pair (i, j) after m observations, Li,j is less\nthan ai,j with probability at most (1 \u2212\u03b4/n2)m \u2264e\u2212ln(n2/\u03b4) \u2264\u03b4/n2. A similar argument holds for Ui,j.\nUsing union bound, we can have that with probability 1 \u2212\u03b4, every Li,j is at least ai,j, and every Ui,j is at\nmost bi,j.\nNow when a new example (p\u2032, B\u2032, x\u2032(p\u2032, B\u2032, v)) arrives (x\u2032 is the optimal bundle), the probability that\nx\u2032\ni \u0338= x\u2032\nj and we can not imply which of these two items are preferred over the other one, i.e. pi\npj \u2208[Li,j, Ui,j]\nis at most 2\u03b4/n2, because we know that [Li,j, Ui,j] \u2286[ai,j, bi,j]. Using union bound, with probability 1 \u2212\u03b4\nwe can derive all preference relations for items with unequal fractions in the optimal bundle x\u2032. In the other\nwords, with probability 1 \u2212\u03b4, we can \ufb01nd the optimal bundle x\u2032.\n4\nLearning Linearly Separable Concave Utility Function\nIn this section, we modify the algorithm presented in section 3 to learn the class of linearly separable\nconcave utility functions. Recall that agents with linearly separable utility functions have a separate function\nvi : [0, 1] \u2192R+ for each 1 \u2264i \u2264n, and their utility for bundle x is Pn\ni=1 vi(xi). We assume that\neach utility function vi is a concave function with bounded second derivative. Concavity corresponds to a\ndecreasing marginal utility condition: that buying an additional \u01eb fraction of item i increases agent utility\nmore when we have less of item i: vi(a + \u01eb) \u2212vi(a) \u2265vi(b + \u01eb) \u2212vi(b) for any a \u2264b. Our bounded second\nderivative assumption states that the second derivative of each utility function has some supremum strictly\nless than \u221e.\nWe \ufb01rst characterize optimal bundles, and then adapt our learning algorithm for linear valuation func-\ntions to apply to the class of linearly separable concave utility functions.\nFix a utility function v\u2217= {v\u2217\ni : [0, 1] \u2192R+} and a price/budget pair (p, B). The corresponding\noptimal bundle can be characterized as follows. For any threshold \u03c4 \u22650, de\ufb01ne x\u03c4\ni to be Max{f|f \u2208\n[0, 1]& v\u2032\ni(f)\npi\n\u2265\u03c4} where v\u2032\ni(f) is the \ufb01rst derivative of function vi at point f. We can now de\ufb01ne p\u03c4 to be\nPn\ni=1 pix\u03c4\ni . We will show that the optimal bundle x\u2217for v\u2217in the face of price/budget pair (p, B) is the\nvector such that x\u2217\ni = x\u03c4\ni for each 1 \u2264i \u2264n where \u03c4 is the maximum value such that this bundle does not\nexceed the budget constraint. The following lemma is proved in Appendix A.\nLemma 4.1. The optimal bundle x\u2217for pair (p, B) is equal to x\u03c4 where \u03c4 is Max{\u03c4|p\u03c4 \u2264B}.\nThe intuition for our algorithm now follows from the linear utility case. From each observation con-\nsisting of an example and its optimal bundle, we may infer some constraints on the derivatives of utility\nfunctions at various points. Just as in the linear utility case, these are the only pieces of information we need\nto infer the optimal bundle.\n6\nLinearSeparableLearn(\u01eb, \u03b4):\nTraining Phase:\n1. Let E be a set of m = O\n\u0010\n(n(k+2))2 ln((n(k+2))2/\u03b4)\n\u03b4\n\u0011\nobservations (p, B, x\u2217(p, B, v)).\n2. Initialize bounds (L(i, r, j, s), U(i, r, j, s)) for each i \u0338= j \u2208[n] and r, s \u2208[k] de\ufb01ned in De\ufb01ni-\ntion 4.2. Initially L(i, r, j, s) = 0 and U(i, r, j, s) = \u221e.\n3. For each (p, B, x\u2217) \u2208E:\n(a) For each i \u0338= j \u2208[n]:\ni. If x\u2217\ni > x\u2217\nj, Let L(i, \u230akx\u2217\ni \u230b, j, \u2308kx\u2217\nj\u2309) = max(L(i, \u230akx\u2217\ni \u230b, j, \u2308kx\u2217\nj\u2309), pi\npj )\nii. If x\u2217\ni > x\u2217\nj, Let U(i, \u2308kx\u2217\ni \u2309, j, \u230akx\u2217\nj\u230b) = min(U(i, \u2308kx\u2217\ni \u2309, j, \u230akx\u2217\nj\u230b), pi\npj )\nClassi\ufb01cation Phase:\n1. On a new example (p, B) \ufb01nd thresholds {li}n\ni=1 such that\nv\u2032\ni(li/k)\nv\u2032\nj((lj+1)/k) \u2265pi\npj for each pair i, j \u2208[n],\nand Pn\ni=1\npiMax{li,0}\nk\n\u2264B \u2264Pn\ni=1\npiMin{li+1,k}\nk\n. Buy li/k fraction of object i for every i \u2208[n],\nand spend the remaining budget to buy equal fraction of all objects.\nFigure 2: The Learning Algorithm for Linearly Separable Valuation Functions. It takes as input an accuracy\nparameter \u03b4, and an error parameter \u01eb.\nUnlike the linear utility setting, however, it is not possible to maintain bounds on all ratios of derivatives\nof utility functions at all relevant points, because there are a continuum of points and the derivatives may\ntake a distinct value at each point. Instead, we discretize the interval [0, 1] with k+1 equally distanced points\n0, 1/k, 2/k, \u00b7 \u00b7 \u00b7 , 1 for some positive integer value of k, and maintain bounds on the ratios of the derivatives\nat these points.\nDe\ufb01nition 4.2. We let k to be an integer at least\n\u0002\n(2Q/\u01eb) \u00b7 max(p,B)\u223cD,1\u2264j\u2264n{ B\npj }\n\u0003\nwhere Q is an upper\nbound on v\u2032\u2032\ni (x) over all i and x \u2208[0, 1], and \u01eb is the error with which we are happy learning to. We de\ufb01ne\nV (i, l) = v\u2032\ni(l/k) for item i, 1 \u2264i \u2264n and discretization step l, 0 \u2264l \u2264k. For convenience, we de\ufb01ne\nV (i, k + 1) = 0. For any pairs 1 \u2264i, j \u2264n, and 0 \u2264r, s \u2264l, we de\ufb01ne L(i, r, j, s) and U(i, r, j, s) to\nbe the lower and upper bounds on the ratio V (i,r)\nV (j,s). The lower and upper bounds are intialized to zero and \u221e\nrespectively.\nAnalogously to the linear case, our algorithm will maintain upper and lower bounds on the pairwise\nratios between each of these these n(k + 2) variables. Since the utilities are concave, we will also maintain\nthe constraint that V (i, l) \u2264V (i, l \u22121) for any 1 \u2264i \u2264n and 1 \u2264l \u2264k + 1 throughout the course of the\nalgorithm.\nIn the training phase, the algorithm selects m = O((n(k + 2))2log((n(k + 2))2/\u03b4)/\u03b4) observations.\nNote the similarity in the number of examples here as compared to the linear case: this is no coincidence.\nInstead of maintaining bounds on the pairwise ratios of n derivatives we are maintaining bounds on the\npairwise ratios between n(k + 2) derivatives.\nConsider the inequalities we can infer from each observation (p, B, x\u2217). By our optimality characteri-\nzation, we know that for any pair of items i and j with x\u2217\ni > 0 and x\u2217\nj < 1, we must have: v\u2032\ni(x\u2217\ni )\npi\n\u2265\nv\u2032\nj(x\u2217\nj )\npj\n.\n7\nWe therefore can obtain the following inequality:\nV (i, \u230akx\u2217\ni \u230b)\npi\n\u2265v\u2032\ni(x\u2217\ni )\npi\n\u2265\nv\u2032\nj(x\u2217\nj)\npj\n\u2265\nV (j, \u2308kx\u2217\nj\u2309)\npj\nThe above inequality de\ufb01nes the update step that we can impose on the lower bound L(i, l\u2032, j, l\u2032\u2032) and\nupper bound U(i, l\u2032, j, l\u2032\u2032) on the ratios\nV (i,l\u2032)\nV (j,l\u2032\u2032) where l\u2032 = \u230akx\u2217\ni \u230b, and l\u2032\u2032 = \u2308kx\u2217\nj\u2309, analogously to our\nalgorithms update for the linear case. For each example, we update these bounds appropriately.\nAfter the training phase completes, our algorithm uses these bounds to predict a bundle for a new ex-\nample (p, B). The algorithm attempts to \ufb01nd some threshold \u22121 \u2264li \u2264k for each item i such that the\nfollowing two properties hold. We de\ufb01ne V (i, \u22121) = \u221efor each 1 \u2264i \u2264n.\n\u2022 For each pair of items i \u0338= j \u2208[n], upper and lower bounds imply that V (i,li)\npi\n\u2265V (j,lj+1)\npj\n.\n\u2022 We have that: Pn\ni=1\npiMax{li,0}\nk\n\u2264B \u2264Pn\ni=1\npiMin{li+1,k}\nk\n. In other words, there is enough budget\nto buy max{li, 0}/k fraction of object i for all 1 \u2264i \u2264n, and the total cost of buying min{li+1, k}/k\nfraction of each item i is at least B.\nAfter \ufb01nding these thresholds l1, l2, \u00b7 \u00b7 \u00b7 , ln, our algorithm selects a bundle that contains max{li, 0}/k\nunits of item i for each i, and then spend the rest of the budget (if there is any remaining) to buy an equal\nfraction of all objects with 0 \u2264li < k, i.e. if B\u2032 of the budget remains after the \ufb01rst step, we buy\nB\u2032\nP\n1\u2264i\u2264n, 0\u2264li<k pi units of each object i with 0 \u2264li < k. Intuitively, the objects with li = 0, represent\nvery expensive objects (in comparison to their values) which we prefer not to buy at all. On the other hand,\nwe have already exhausted the supply of objects with li = 1.\nIn the rest of this section, we show in Lemma 4.3 (proved in Appendix A) how to \ufb01nd these thresholds\n(the sequence li for 1 \u2264i \u2264n) based on the learned upper and lower bounds on ratios if such thresholds\nexist. Then, we prove in Lemma4.4 that after training on m examples, with high probability (at least 1\u22122\u03b4),\nthis sequence of thresholds indeed exists. Finally we conclude that our algorithm is an (\u01eb, \u03b4)-learner.\nLemma 4.3. Assuming there exists a sequence of thresholds {li}n\ni=1 with the two desired properties in our\nalgorithm, there exists a polynomial time algorithm to \ufb01nd them.\nWe now prove that the required sequence of thresholds {li}n\ni=1 exist with high probability. The proof is\nvery similar to Lemma 3.2, and included in Appendix A.\nLemma 4.4. After updating the algorithm\u2019s upper and lower bounds using m = O((n(k + 2))2log((n(k +\n2))2/\u03b4)/\u03b4) observations, when considering a new example (p, B), the sequence of thresholds {li}n\ni=1 exists\nwith probability at least 1 \u22122\u03b4.\nTo conclude, we just need to show that if we \ufb01nd the thresholds with the desired properties, the returned\nbundle is a good approximation of the optimum bundle. The proof can be found in Appendix A.\nTheorem 4.5. For any \u01eb > 0, we can \ufb01nd some k (the discretization factor) such that with probability at\nleast 1 \u22122\u03b4 over the choice of example (p, B), the bundle \u02c6x = \u02c6x(p, B) returned by our mechanism admits\nat least one of the following properties:\n1. For each item 1 \u2264i \u2264n, we have that \u02c6xi \u2265x\u2217\ni \u2212\u01eb,\n2. v\u2217(\u02c6x) \u2265v\u2217(x\u2217) \u2212\u01eb\nIn other words, have that our mechanism is an ef\ufb01cient (\u01eb, \u03b4)-learning algorithm for the class of linearly\nseparable concave utility functions with bounded range v : [0, 1]n \u2192[0, 1].\n8\n5\nA Learning Algorithm based on Sampling from a Convex Polytope\nIn this section, we present another learning algorithm for (\u01eb, \u03b4)-learning linear cost functions. We introduce\na new model, that gets a stronger form of feedback from the agent, and as a result achieve an improved\nsample complexity bound that requires only m = \u02dcO\n\u0010\nnpolylog(n)\n\u03b43\n\u0011\nobservations.\nDuring the training phase of our algorithm, it will interact with the agent by adding constraints to a\nlinear program and given a new example, propose a candidate bundle to the agent. The agent will either\naccept the candidate bundle (if it is approximately optimal), or else return to the algorithm a set of linear\nconstraints witnessing the suboptimality of the proposed bundle. The main idea is that for each new example\neither our algorithm\u2019s bundle is almost optimal, or we receive a set of linear constraints to add to our linear\nprogram that substantially reduce the volume of the feasible polytope. If the set of constraints are restrictive\nenough, with high probability, we achieve an approximately optimum bundle on all new examples, and\nwe can end the training phase. Otherwise each new example cuts off some constant fraction of the linear\nprogram polytope with high probability. After feeding a polynomial number of examples, and using some\narguments to upper bound the volume of the polytope at the beginning and lower bound its volume at the\nend, we can prove with high probability, the algorithm \ufb01nds an almost optimal bundle for future examples.\nFirst we explain the model, and then we present our algorithm.\nModel: We consider agents with linear utility functions, here bounded so that v \u2208[0, 1]n . If we have\nthat v\u00b7\u02c6x \u2265v\u00b7x\u2212\u01eb, we say bundle \u02c6x is an \u01eb-additive approximation to the optimal bundle x\u2217= x\u2217(v\u2217, p, B),\nand it will be accepted by the agent if it is proposed. If a proposed bundle \u02c6x is not \u01eb-approximately optimal,\nthe agent rejects the bundle if proposed, and instead returns a set of inequalities which are witness to the\nsub-optimality of our solution. The agent returns all valid inequalities of the following form for different\npairs of objects i, j \u2208[n]: vi\u2212\u01eb\u2032\npi\n> vj+\u01eb\u2032\npj\nwhere \u01eb\u2032 = \u01eb/nM, and M is the maximum ratio of two different\nprices in the domain of the price distribution (D).\nIntuitively, for these pairs we have that vi\npi is greater than vj\npj by some non-negligible margin. In the\nfollowing, we show that for any suboptimal bundle (not an \u01eb-additive approximation) resulted from a value\nvector \u02c6v, there exists at least one of these inequalities for which we have that \u02c6vi\npi \u2264\n\u02c6vj\npj . In other words,\nthese set of inequalities that our algorithm returns could be seen as some evidence of suboptimality for any\nsuboptimal bundle for example (p, B).\nLemma 5.1. For any pair of price vector and budget (p, B), and a suboptimal sampled value vector \u02c6v (that\ndoes not generate an \u01eb-approximately optimal bundle \u02c6x), there exists at least one pair of items (i, j) such\nthat we have vi\u2212\u01eb\u2032\npi\n> vj+\u01eb\u2032\npj , and \u02c6vi\npi \u2264\u02c6vj\npj .\nProof. Let x\u2217and \u02c6x be the optimal bundle and the returned bundle based on \u02c6v respectively. We note that\nsince all objects have non-negative values, we have that x\u2217\u00b7 p = \u02c6x \u00b7 p = B unless the budget B is enough to\nbuy all objects in which case both x\u2217and \u02c6x are equal to (1, 1, \u00b7 \u00b7 \u00b7 , 1) which is a contradiction because we\nassumed \u02c6x is suboptimal.\nWe can exchange v/pi units of object i with v/pj units of item j and vice versa without violating the\nbudget constraint. We show that all the differences in entries of x\u2217and \u02c6x can be seen as the sum of at most n\nof these simple exchanges between pairs of objects as follows. We take two entries i and j such that x\u2217\ni > \u02c6xi\nand x\u2217\nj < \u02c6xj. We note that as long as two vectors x\u2217and \u02c6x are not the same, we can \ufb01nd such a pair because\nwe also have that v \u00b7 p = \u02c6v \u00b7 p. Without loss of generality, assume that (x\u2217\ni \u2212\u02c6xi)pi \u2264(\u02c6xj \u2212x\u2217\nj)pj. Now we\nbuy x\u2217\ni \u2212\u02c6xi more units of item i in bundle \u02c6x to make the two entries associated with object i in bundles x\u2217\nand \u02c6x equal. Instead we buy (x\u2217\ni \u2212\u02c6xi)pi/pj fewer units of object j to obey the budget limit B. This way,\nwe decrease the number of different entries in x\u2217and \u02c6x, so after at most n exchanges we make \u02c6x equal to\n9\nx\u2217. By assumption, v\u2217(\u02c6x) \u2264v\u2217(x\u2217) \u2212\u01eb. Therefore, in at least one of these exchanges, the value of \u02c6x is\nincreased by more than \u01eb/n.\nAssume this increase happened in exchange of objects i and j. Let r be (x\u2217\ni \u2212\u02c6xi)pi. We bought r/pi\nmore units of i, and r/pj fewer units of j. The increase in value is r(vi/pi \u2212vj/pj) = (x\u2217\ni \u2212\u02c6xi)(vi \u2212\nvjpi/pj) \u2265\u01eb/n. Since x\u2217\ni \u2212\u02c6xi is at most 1, we also have that vi \u2212vjpi/pj > \u01eb/n which can be rewritten\nas: vi \u2212\u01eb/2n > vjpi/pj + \u01eb/2n. This is equivalent to vi\u2212\u01eb/2n\npi\n> vj+(\u01eb/2n)(pj/pi)\npj\n. We can conclude that\nvi\u2212\u01eb/(2nM)\npi\n> vj+(\u01eb/2nM)\npj\nwhich is by de\ufb01nition of \u01eb\u2032: vi\u2212\u01eb\u2032\npi\n> vj+\u01eb\u2032\npj .\nWe also note that \u02c6xi < 1 and \u02c6xj > 0, so we can infer that \u02c6vi\npi \u2264\u02c6vj\npj . Otherwise one could exchange some\nfraction of j with some fraction of i and gain more value with respect to value vector \u02c6v. This completes the\nproof of both inequalities claimed in this lemma.\nAlgorithm: We maintain a linear program with n variables representing a hypothesis value vector \u02c6v.\nSince v is in [0, 1]n, we initially have the constraints: 0 \u2264vi \u22641 for any 1 \u2264i \u2264n. At any given time, our\nset of constraints forms a convex body K.\nOur algorithm loops until we reach a desired property. At each step of the loop we sample C log(n) log(1/\u03b4)\n\u03b42\nexamples, and for each of them we sample uniformly at random a vector \u02c6v from the convex body K, and\npredict the optimal bundle based on this sampled vector. (Note that uniform sampling from a convex body\ncan be done in polynomial time by [DFK91]). At the end of the loop, we add the linear constraints that we\nobtained as feedback from the agent to our linear program, and get a more restricted version of K which we\ncall K\u2032.\nIf the volume of K\u2032 is greater than 1 \u2212\u03b4 times the volume of K, we stop the learning algorithm, and\nreturn K as the candidate convex body. Otherwise, we replace K with the new more constrained body K\u2032,\nand repeat the same loop again. To avoid confusion, we name the \ufb01nal returned convex body \u02c6K. After the\ntraining phase ends, for future examples, our algorithm samples a value vector \u02c6v uniformly at random from\nthis convex body \u02c6K, and predicts the optimal bundle based on \u02c6v. We explain what kinds of constraints we\nadd at the end of each loop to \ufb01nd K\u2032.\nEach iteration of the training phase uses C log(n) log(1/\u03b4)\n\u03b42\nexamples. Recall that for each one, the mech-\nanism proposes a bundle to the agent, who either accepts or rejects it. For each rejected bundle, we are\ngiven a set of pairs of objects (i, j) such that vi\u2212\u01eb\u2032\npi\n> vj+\u01eb\u2032\npj . For each inequality like this, we add the looser\nconstraint vi\npi > vj\npj . At the end, we have a more restricted convex body K\u2032 which is formed by adding all of\nthese constraints to K.\nWe must show that after the training phase of the algorithm terminates, we are left with a hypothesis\nwhich succeeds at predicting valuable bundles with high probability. We must also also bound the number\nof iterations (and therefore the number of examples used by the algorithm) before the training phase of the\nalgorithm terminates. First we bound the total number of iterations of the training phase.\nLemma 5.2. The total number of examples sampled by our algorithm is at most\nm = O\n\u0012n log(n)(log(n) + log(M)) log(1/\u01eb) log(1/\u03b4)\n\u03b43\n\u0013\n.\nFinally, we argue that after the learning phase terminates, the algorithm returns a good hypothesis.\nTheorem 5.3. The algorithm (\u01eb, \u03b4)-learns from the set of linear utility functions.\n10\nProof. Given a new example (p, B), the algorithm samples a value vector \u02c6v uniformly at random from the\nconvex body \u02c6K, and returns an optimal bundle with respect to \u02c6v, p, and B.\nConsider a price vector p and budget B. For some value vectors in \u02c6K, the returned bundle is suboptimal\n(not an \u01eb-additive approximation). We call this subset the set of suboptimal value vectors with respect to\n(p, B), and the fraction of suboptimal value vectors in \u02c6K is the probability that our algorithm does not return\na good bundle, i.e. the error probability of our algorithm. We say a pair (p, B) is unlucky if for more than\n\u03b4 fraction of value vectors in \u02c6K, the returned bundle is suboptimal. We prove that with probability at least\n1 \u2212\u03b4/2, the convex body \u02c6K we return, has this property that with at most probability \u03b4/2, the pair (p, B)\ndrawn from D is unlucky. This way with probability at most \u03b4/2 + \u03b4/2 = \u03b4, the pair (p, B) is unlucky\nwhich proves that our algorithm is (\u01eb, \u03b4)-learner.\nWe prove the claim by contradiction. De\ufb01ne A to be the event that \u201dwith probability more than \u03b4/2, the\npair (p, B) \u223cD is unlucky\u201d. We prove that the probability of event A is at most \u03b4/2. Let Ki be the convex\nbody at the beginning of iteration i, and K\u2032\ni be the more restricted version of Ki that we compute at the end\nof iteration i. Event A holds if for some i we have these two properties: a) the probability that a pair (p, B)\ndrawn i.i.d. from D is unlucky with respect to Ki is more than \u03b4/2, i.e. if we sample the value vector from\nKi, the returned bundle for (p, B) is suboptimal with probability more than \u03b4. b) the volume of K\u2032\ni is not\nless than 1 \u2212\u03b4 times volume of Ki.\nWe bound the probability of having both of these properties at iteration i. In this iteration, for every\nexample we take, with probability more than \u03b4/2, the pair (p, B) is unlucky. For an unlucky pair (p, B),\nwith probability more than \u03b4, we return a suboptimal example, and then we get feedback from the agent.\nUsing lemma 5.1, and the feedback we get from the agent, all of the suboptimal value vectors for pair (p, B)\nwill be removed from Ki and will not exist in K\u2032\ni (by the new constraints we add in this loop). Since (p, B)\nis unlucky, more than \u03b4 fraction of the Ki will be deleted in this case. In other words, for each example\nin loop i with probability at least \u03b42/2, more than \u03b4 fraction of Ki will be removed. Clearly, since K\u2032\ni has\nvolume at least 1 \u2212\u03b4 fraction of Ki, this has not happened for any of the examples of loop i. Since we\nhave C log(n) log(1/\u03b4)\n\u03b42\nexamples in each loop, the probability of holding both these properties at loop i is at\nmost (1 \u2212\u03b42)\nC log(n) log(1/\u03b4)\n\u03b42\n< \u03b4/(2nC) for \u03b4 \u22641/2. Since there are less than nC number of loops for some\nlarge enough constant C, the probability of event A (which might happen in any of the loops) is less than\n\u03b4/2.\n6\nDiscussion\nIn this paper we have considered the problem of ef\ufb01ciently learning predictive classi\ufb01ers from revealed\npreferences. We feel that the revealed preferences problem is much more meaningful when the observed\ndata must be rationalized with a predictive hypothesis, and of course much remains to be done in this study.\nOur work leaves many open questions:\n1. What are tight bounds on the sample complexity for \u03b4-learning linear valuation functions? There is\na simple \u2126(n) lower bound, and here we give an algorithm with sample complexity \u02dcO(n2/\u03b4), but\nwhere does the truth lie?\n2. Is there a general measure of sample complexity, akin to VC-dimension in the classical learning\nsetting, that can be fruitfully applied to the revealed preferences problem? Beigman and Vohra [BV06]\nadapt the notion of fat-shattering dimension to this setting, but applied to the revealed preferences\nproblem, fat shattering dimension is cumbersome and seems ill-suited to proving tight polynomial\nbounds.\n11\nReferences\n[Afr65]\nS.N. Afriat. The equivalence in two dimensions of the strong and weak axioms of reveaded\npreference. Metroeconomica, 17(1-2):24\u201328, 1965.\n[Afr67]\nS.N. Afriat. The construction of utility functions from expenditure data. International Economic\nReview, 8(1):67\u201377, 1967.\n[BCIW12] M.F. Balcan, F. Constantin, S. Iwata, and L. Wang. Learning valuation functions. In COLT,\n2012.\n[BH11]\nM.F. Balcan and N. Harvey. Learning submodular functions. In STOC 2011, pages 793\u2013802,\n2011.\n[BV06]\nE. Beigman and R. Vohra. Learning from revealed preference. In Proceedings of the 7th ACM\nConference on Electronic Commerce, pages 36\u201342. ACM, 2006.\n[DFK91]\nM. Dyer, A. Frieze, and R. Kannan. A random polynomial-time algorithm for approximating\nthe volume of convex bodies. Journal of the ACM (JACM), 38(1):1\u201317, 1991.\n[EGW11]\nF. Echenique, D. Golovin, and A. Wierman. A revealed preference approach to computational\ncomplexity in economics. In ACM Conference on Electronic Commerce, pages 101\u2013110, 2011.\n[Sam38]\nP.A. Samuelson. A note on the pure theory of consumer\u2019s behaviour. Economica, 5(17):61\u201371,\n1938.\n[Var06]\nH.R. Varian. Revealed preference. Samuelsonian economics and the twenty-\ufb01rst century, pages\n99\u2013115, 2006.\nA\nOmitted Proofs\nProof of Lemma 4.1. For each possible pair of items i \u0338= j \u2208[n], we consider three cases:\n\u2022 0 < x\u2217\ni , x\u2217\nj < 1: In this case, v\u2032\ni(x\u2217\ni )\npi\n=\nv\u2032\nj(x\u2217\nj )\npj\n. Otherwise (if for example the expression corresponding\nto item i is greater), we could buy \u01eb\u2032/pi additional units of i, and buy \u01eb\u2032/pj fewer units of j without\nviolating the budget constraint. When \u01eb\u2032 \u21920, this exchange will be bene\ufb01cial for the agent which\nwould contradict optimality.\n\u2022 x\u2217\ni = 1 and x\u2217\nj < 1: In this case, v\u2032\ni(x\u2217\ni )\npi\n\u2265\nv\u2032\nj(x\u2217\nj )\npj\notherwise the agent could buy fewer units of i and\nadditional units of j and thereby increase the value of the bundle, contradicting optimality.\n\u2022 x\u2217\ni > 0 and x\u2217\nj = 0: Identically to above: v\u2032\ni(x\u2217\ni )\npi\n\u2265\nv\u2032\nj(x\u2217\nj )\npj\n.\nTo complete the proof we need now only to select \u03c4. If there exists some 1 \u2264i \u2264n such that 0 <\nx\u2217\ni < 1, setting \u03c4 = v\u2032\ni(x\u2217\ni )\npi\nproves the claim. Otherwise, any value \u03c4 \u2208[maxi|x\u2217\ni =0\nv\u2032\ni(x\u2217\ni )\npi\n, mini|x\u2217\ni =1\nv\u2032\ni(x\u2217\ni )\npi\n]\ncompletes the proof.\nProof of Lemma 4.3. First let us assume that there is a sequence of thresholds with the desired properties.\nIn this case, we may \ufb01nd it as follows. Suppose item i has the maximum value of V (i,li+1)\npi\namong all items:\n12\ni.e. V (i,li+1)\npi\n\u2265V (j,lj+1)\npj\nfor any j \u0338= i. We assume that this item i and threshold li are given, because we\ncan guess their values as there are n(k + 2) possible choices for them. For any item j \u0338= i, we select some\nlj such that it can be inferred from our upper and lower bounds that V (j,lj)\npj\n\u2265V (i,li+1)\npi\n, but it can not be\ninferred that V (j,lj+1)\npj\n\u2265V (i,li+1)\npi\n.\nSince we have V (j, \u22121) = \u221eand V (j, k+1) = 0, we can always \ufb01nd some value for lj. In fact for each\nitem j, we can \ufb01nd two thresholds 0 \u2264t1(j) \u2264t2(j) \u2264k such that a) we can infer that V (j,t1(j))\npj\n\u2265V (i,li+1)\npi\n,\nand b) we can also infer that V (j,t\u2032)\npj\n= V (i,li+1)\npi\nfor any t1(j) < t\u2032 \u2264t2(j), and \ufb01nally, c) we can not infer\nthat V (j,t2(j)+1)\npj\n\u2265V (i,li+1)\npi\n. Variable lj could be any integer in range [t1, t2]. We might sometimes have\nthat t1(j) = t2(j) which means that lj is uniquely de\ufb01ned.\nAssuming object i has the maximum value of V (i,li+1)\npi\n, we know that any solution lj \u2208[t1(j), t2(j)]\n(for all j \u0338= i) satis\ufb01es the \ufb01rst property we are looking for. The second property is a budget constraint: we\nshould be able to buy max{lj, 0}/k units of each item j, and the total cost of buying min{lj + 1, k}/k of\neach item j should be at least B.\nWe start with thresholds lj = t1(j). If these are not feasible (i.e. if the resulting bundle costs more than\nB), there does not exist such a sequence of thresholds with object i as the object with maximum V (i,li+1)\npi\nand li as the threshold of object i. Alternately, if these thresholds are feasible, we increase the thresholds one\nat a time while the cost of the resulting optimal bundle remains below B. We have the freedom to increase\nthreshold lj in the range [t1(j), t2(j)], and we can increase it one unit at a time to a maximum of t2(j).\nWe stop when it is not possible to increase any of the thresholds any more. This process results in a set of\nthresholds lj \u2208[t1(j), t2(j)], and it is not possible to increase any of them.\nIf for some j, lj is strictly less than t2(j), we can infer that budget B is not enough to buy max{lj\u2032, 0}/k\nunits of each object j\u2032 \u0338= j, and (lj+1)/k = Min{lj+1, k}/k units of object j (note that lj+1 \u2264t2(j) \u2264k)\n( Otherwise we could have increased the threshold lj by at least one). Consequently for this sequence of\nthresholds, there is not enough budget to buy min{lj\u2032\u2032 + 1, 0}/k units of item j\u2032\u2032 for all 1 \u2264j\u2032\u2032 \u2264n.\nTherefore, this sequence satis\ufb01es both properties we wanted.\nIn the remaining case, we stop at lj = t2(j) for all j \u0338= i. In this case, if cost of buying min{lj\u2032 +1, k}/k\nunits of all items 1 \u2264j\u2032 \u2264n is at least B, this sequence of thresholds l1, l2, \u00b7 \u00b7 \u00b7 , ln satis\ufb01es both properties\nthat we want. Otherwise, we must try another guess for object i and threshold li to start again. We try all\nn(k + 2) possible guesses exhaustively for pair (i, li), and if in one of them we succeed to \ufb01nd a sequence\nof valid thresholds, we are done, otherwise there does not exist such sequence, and our algorithm simply\nreturns a random bundle. (The probability that this occurs will be folded into the error probability of our\nalgorithm).\nProof of Lemma 4.4. Similar to Lemma 3.2, we de\ufb01ne ai,r,j,s and bi,r,j,s where i and j are two objects, and\n0 \u2264r, s \u2264k as follows:\nai,r,j,s\n=\nmin\n(\na|Pr\n \nr/k \u2264x\u2217\ni < (r + 1)/k & s/k \u2264x\u2217\nj < (s + 1)/k & a \u2264pi\npj\n\u2264v\u2032\ni(x\u2217\ni )\nv\u2032\nj(x\u2217\nj)]\n!\n\u2264\n\u03b4\n(n(k + 2))2\n)\nbi,r,j,s\n=\nmax\n(\nb|Pr\n \nr/k \u2264x\u2217\ni < (r + 1)/k & s/k \u2264x\u2217\nj < (s + 1)/k & v\u2032\ni(x\u2217\ni )\nv\u2032\nj(x\u2217\nj) \u2264pi\npj\n\u2264b]\n!\n\u2264\n\u03b4\n(n(k + 2))2\n)\nEvery time we see an example, with probability\n\u03b4\n(n(k+2))2 , we update the lower bound L(i, r, j, s + 1) to\nsome thing equal to or greater than ai,r,j,s. A similar claim holds for the upper bounds and values of bj,s,i,r.\n13\nSimilar to the proof of Lemma 3.2, one can show that with probability at most (1 \u2212\u03b4/(n(k + 2))2)m \u2264\n\u03b4/(n(k + 2))2 the lower bound L(i, r, j, s + 1) is less than ai,r,j,s after observing all m examples. Using\nthe union bound this does not happen for any pairs of (i, r) and (j, s) with probability at least 1 \u2212\u03b4. So\nwith high probability, we have very accurate bounds on the ratios of different \ufb01rst derivatives at points\n0, 1/k, 2/k, \u00b7 \u00b7 \u00b7 , 1.\nIn the classi\ufb01cation phase of the algorithm, consider a new example is drawn from D. We prove that\nwith probability 1 \u2212\u03b4, we can \ufb01nd the thresholds {li}n\ni=1, if the lower bound Li,r,j,s+1 is at least ai,r,j,s for\ndifferent choices of i, j, r, and s. So we assume these inequalities hold. De\ufb01ne li to be \u230akx\u2217\ni \u230bfor 1 \u2264i \u2264n\nwith x\u2217\ni > 0, if x\u2217\ni is zero, we de\ufb01ne li to be \u22121. We know that Li,li,j,lj+1 is at least ai,li,j,lj, so we can infer\nthat V (i,li)\npi\n\u2265V (j,lj+1)\npj\nunless pi\npj \u2208[ai,r,j,s, v\u2032\ni(x\u2217\ni )\nv\u2032\nj(x\u2217\nj )] which occurs with probability at most \u03b4/(n(k + 2))2.\nTaking a union bound again, and considering all choices of i, j, r, s, we \ufb01nd that this does not happen for\nany 4-tuple (i, j, r, s) except with probability at most \u03b4.\nTherefore we have shown that the thresholds {li}n\ni=1 exist and can be inferred based on our upper and\nlower bounds with probability 1 \u22122\u03b4. Thus our lower bounds are enough to imply the the \ufb01rst property of\nthe thresholds {li}n\ni=1. We also note that the second property is satis\ufb01ed because of the choices of li. Clearly\nmax{li, 0}/k is at most x\u2217\ni , and therefore the total cost of buying max{li, 0}/k of each object i is at most\nthe cost of optimum bundle, which is B. We also know that min{li + 1, k}/k is at least x\u2217\ni which gives us\nthe remaining inequality needed for the second property of the thresholds.\nProof of Theorem 4.5.\nUsing Lemma 4.4, we know that for any example (p, B), our algorithm \ufb01nds\nthresholds {li}n\ni=1 with probability 1 \u22122\u03b4. We prove that our bundle has one of the two properties in the\nstatement of this theorem in these cases (when our algorithm \ufb01nds appropriate thresholds). There are two\ncases:\n\u2022 There exists some item i such that x\u2217\ni \u2265(li + 1)/k. We have that V (j,lj)\npj\n\u2265V (i,li+1)\npi\n\u2265v\u2032\ni(x\u2217\ni )\npi\nfor any\nj \u0338= i. Therefore x\u2217\nj \u2265lj/k for each 1 \u2264j \u2264n.\nTherefore the proposed bundle is completely consistent with the optimum solution up to li\u2032/k fraction\nfor each item 1 \u2264i\u2032 \u2264n. We spend the rest of our budget to buy equal fractions of objects with\n0 \u2264li\u2032\u2032 < k, but the optimum algorithm might do something else. Based on the second property of\nthresholds, the remaining budget is not enough to buy more than 1/k fraction of these objects, so in\nthe second step we buy some fraction \u03c1 \u22641/k of all objects with 0 \u2264li\u2032\u2032 < k to spend our budget\ncompletely.\nTo compare the performance of the optimum algorithm and our algorithm on the remaining budget,\nwe will focus on some small part of the remaining budget. With very small budget \u01eb\u2032 > 0, we might\nbuy some fraction of object j (with 0 \u2264lj < k) to increase its quantity by \u01eb\u2032/pj. We know that\nsince the value function for object j, vj, is concave with bounded second derivative, our increase in\nvalue is at least (v\u2032\nj(lj/k) \u2212Q/k)\u01eb\u2032/pj where Q is an upper bound on all values of second derivatives\nof value functions. Because the fraction of object j, when we are increasing it, lies in the range\n[lj/k, (lj + 1)/k], and clearly has difference at most 1/k from fraction lj/k. Therefore the \ufb01rst\nderivative of the value function of object j can not be less than v\u2032\nj(lj/k)\u2212Q/k, when we are increasing\nit.\nOn the other hand, the optimum solution might use this \u01eb\u2032 budget to buy \u01eb\u2032/pj\u2032 fraction of object j\u2032.\nSince the fraction object j\u2032 is in range [lj\u2032, 1] when the optimum is buying from j\u2032, the increase in\nthe value can not be more than\n\u0000v\u2032\nj\u2032((lj\u2032 + 1)/k) + Q/k\n\u0001\n\u01eb\u2032/pj\u2032. This holds because the fraction of\nobject j\u2032 is at most 1/k less than (lj\u2032 + 1)/k. This means that the optimum solution is gaining at\n14\nmost\n\u0000v\u2032\nj\u2032((lj\u2032 + 1)/k) + Q/k\n\u0001\n/pj\u2032 \u2212(v\u2032\nj(lj/k) \u2212Q/k)/pj more value per each unit of budget in\ncomparison to our algorithm. Since we have that V (j,lj)\npj\n\u2265\nV (j\u2032,lj\u2032+1)\npj\u2032\n, this term (the difference in\nvalues per unit of budget) is at most Q(1/pj + 1/pj\u2032)/k. In order to make the total difference in the\nvalues of the two bundles at most \u01eb, one just needs to set k \u2265\n\u0002\n(2Q/\u01eb) \u00b7 maxp,B\u223cD,1\u2264j\u2264n B\npj\n\u0003\n.\n\u2022 In the second case, for all 1 \u2264i \u2264n, x\u2217\ni < (li + 1)/k, and our fraction for this object is at least li/k,\nfor k > 1/\u01eb, the \ufb01rst property in the statement of this theorem holds.\nProof of Lemma 5.2.\nBy construction, each time we update the convex body K, we reduce its volume by\na factor of 1 \u2212\u03b4 using C log(n) log(1/\u03b4)\n\u03b42\nexamples. So it suf\ufb01ces to show that we will not do these updates\nmore than O([n(log(n) + log(M)) log(1/\u01eb)]/\u03b4) times. We note that the volume of K is 1 at the beginning.\nWe prove a lower bound on the volume of the \ufb01nal convex body \u02c6K by showing that some points will not\nbe deleted in any of the iterations. We say a value vector v\u2032 is close to the actual value vector v, if for any\n1 \u2264i \u2264n, we have that |vi \u2212v\u2032\ni| \u2264\u01eb\u2032. We claim that a vector v\u2032 \u2208[0, 1]n which is close to v will not be\nremoved in any of the loops. We prove by contradiction.\nSuppose v\u2032 has been removed by adding some constraint on pair of objects (i, j) with price vector p.\nWe should have that v\u2032\ni\npi \u2264\nv\u2032\nj\npj . Since we added this constraint, we also should have that vi\u2212\u01eb\u2032\npi\n> vj+\u01eb\u2032\npj .\nBut this is a contradiction since v\u2032\ni \u2265vi \u2212\u01eb\u2032 and v\u2032\nj \u2264vj + \u01eb\u2032. So we never remove points from the set\n(v + [\u2212\u01eb\u2032, \u01eb]n) \u2229[0, 1]n.\nWe note that for each 1 \u2264i \u2264n, the length of interval [vi \u2212\u01eb\u2032, vi + \u01eb\u2032] \u2229[0, 1] is at least \u01eb\u2032, so the\nvolume of the set of points (v + [\u2212\u01eb\u2032, \u01eb]n) \u2229[0, 1]n is at least (\u01eb\u2032)n which is a lower bound on the volume \u02c6K.\nTherefore the number of iterations can not be more than log1\u2212\u03b4\n\u0000 (\u01eb\u2032)n\n1\n\u0001\n= ln((\u01eb\u2032)n)\nln(1\u2212\u03b4) \u2264n ln(1/\u01eb\u2032)\n\u03b4\n. By de\ufb01nition\nof \u01eb\u2032, the number of loops is O(n(log(n)+log(M))log(1/\u01eb)\n\u03b4\n). So the total number of examples we use to learn \u02c6K\nis O(Cn log(n)(log(n)+log(M))log(1/\u01eb) log(1/\u03b4)\n\u03b43\n).\n15\n",
        "sentence": " Roth and Zadimoghaddam [9] extended this line of work by providing computationally efficient learning algorithms for two specific classes of utility functions \u2014 linear and linearly separable and concave utility functions. In particular, we have the following lemma, first observed in [9]. Lemma 6 ([9]).",
        "context": "We consider both linear utility functions, and then more generally, linearly separable concave utility\nfunctions with bounded derivatives. For both of these cases, we give ef\ufb01cient learning algorithms with poly-\nas learning algorithms for the set of all monotone increasing utility functions. These algorithms typically\ncome with a caveat, however, that the hypothesis utility functions they generate have the same descrip-\nclasses of utility functions, and give ef\ufb01cient learning algorithms together with small polynomial upper and\nlower bounds on the sample complexity necessary for learning."
    }
]