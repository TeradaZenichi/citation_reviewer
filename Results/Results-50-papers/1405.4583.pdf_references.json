[
    {
        "title": "A comparative study of energy minimization methods for Markov random fields with smoothness-based priors",
        "author": [
            "R. Szeliski",
            "R. Zabih",
            "D. Scharstein",
            "O. Veksler",
            "V. Kolmogorov",
            "A. Agarwala",
            "M. Tappen",
            "R. Rother"
        ],
        "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 30, no. 6, pp. 1068\u20131080, 2008.",
        "citeRegEx": "1",
        "shortCiteRegEx": null,
        "year": 2008,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " (1) is derived from the ubiquitous MRF model [1]. Recently, the performance of these techniques in minimizing energy functions defined on 4connected grid graphs has been extensively studied [1], [17], [18]. However, minimizing such energy functions is challenging for existing techniques [1], [19]. niques on minimizing sparse energies defined in 4connected grid graphs is well-understood in computer vision [1], [17], as shown in Fig. This is in contrast to their performances for sparse energy functions [1], [18]. Refer to [1], [17] Lower supermodularity Sr \u2248 0 Higher supermodularity Sr > 10%",
        "context": null
    },
    {
        "title": "Fast approximate energy minimization via graph cuts",
        "author": [
            "Y. Boykov",
            "O. Veksler",
            "R. Zabih"
        ],
        "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 23, no. 11, pp. 1222\u20131239, 2001.",
        "citeRegEx": "2",
        "shortCiteRegEx": null,
        "year": 2001,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14]. such as image segmentation [15], [16], stereo [2], [17] and restoration [2], [4]. such as image segmentation [15], [16], stereo [2], [17] and restoration [2], [4].",
        "context": null
    },
    {
        "title": "What energy functions can be minimized via graph cuts?",
        "author": [
            "V. Kolmogorov",
            "R. Zabih"
        ],
        "venue": "IEEE Trans. Pattern Anal. Mach. Intell.,",
        "citeRegEx": "3",
        "shortCiteRegEx": "3",
        "year": 2004,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14]. State-of-the-art methods for binary MRF labeling include BP [6], TRW [9], [10] and graph cuts [3]. An important conclusion is that any submodular QPBF can be exactly minimized by solving an st-mincut problem on a directed graph [3]. Our algorithm is in contrast to the directed graph formulation [3] and QPBO(P,I) [5]. Conclusion 3 directly results from 1 and 2 due to the additivity property of graph characterization [3], [4]. We already know that E(x) can be exactly minimized if it is submodular [3], [26].",
        "context": null
    },
    {
        "title": "Minimizing non-submodular functions with graph cuts \u2013 a review",
        "author": [
            "V. Kolmogorov",
            "C. Rother"
        ],
        "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 29, no. 7, pp. 1274\u20131279, 2007.",
        "citeRegEx": "4",
        "shortCiteRegEx": null,
        "year": 2007,
        "abstract": "",
        "full_text": "",
        "sentence": " Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14]. such as image segmentation [15], [16], stereo [2], [17] and restoration [2], [4]. For nonsubmodular QPBFs, the roof duality [26] is used to find an optimal partial labeling, which is called QPBO and two variants P and I [4], [5]. Conclusion 3 directly results from 1 and 2 due to the additivity property of graph characterization [3], [4]. used in the literature [4], [26]. refers to reparameterizing the original energy function E(x) to E(x) that does not change the optimality of E(x) [4]. Some methods, such as QPBO(P) may produce partial labelings [4], [5]. Compared to the directed graph formulation and QPBO [4], [5], ESSP has half number of vertices in the undirected graph characterization. , BP [6], TRW-S [10] and QPBO(P,I) [4], [5], on minimizing dense and nonsubmodular energy functions.",
        "context": null
    },
    {
        "title": "Optimizing binary MRFs via extended roof duality",
        "author": [
            "C. Rother",
            "V. Kolmogorov",
            "V. Lempitsky",
            "M. Szummer"
        ],
        "venue": "CVPR, 2007.",
        "citeRegEx": "5",
        "shortCiteRegEx": null,
        "year": 2007,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14]. For nonsubmodular QPBFs, the roof duality [26] is used to find an optimal partial labeling, which is called QPBO and two variants P and I [4], [5]. Our algorithm is in contrast to the directed graph formulation [3] and QPBO(P,I) [5]. Some methods, such as QPBO(P) may produce partial labelings [4], [5]. Compared to the directed graph formulation and QPBO [4], [5], ESSP has half number of vertices in the undirected graph characterization. , BP [6], TRW-S [10] and QPBO(P,I) [4], [5], on minimizing dense and nonsubmodular energy functions.",
        "context": null
    },
    {
        "title": "On the optimality of solutions of the max-product belief-propagation algorithm in arbitrary graphs",
        "author": [
            "Y. Weiss",
            "W. Freeman"
        ],
        "venue": "IEEE Trans. Inf. Theory, vol. 47, no. 2, pp. 736\u2013744, 2001.",
        "citeRegEx": "6",
        "shortCiteRegEx": null,
        "year": 2001,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14]. State-of-the-art methods for binary MRF labeling include BP [6], TRW [9], [10] and graph cuts [3]. , BP [6], TRW-S [10] and QPBO(P,I) [4], [5], on minimizing dense and nonsubmodular energy functions.",
        "context": null
    },
    {
        "title": "Generalized belief propagation",
        "author": [
            "J. Yedidia",
            "W. Freeman",
            "Y. Weiss"
        ],
        "venue": "NIPS, 2000.",
        "citeRegEx": "7",
        "shortCiteRegEx": null,
        "year": 2000,
        "abstract": "",
        "full_text": "",
        "sentence": " Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].",
        "context": null
    },
    {
        "title": "Efficient belief propagation for early vision",
        "author": [
            "P. Felzenszwalb",
            "D. Huttenlocher"
        ],
        "venue": "Int\u2019l J. Computer Vision, vol. 70, no. 1, p. 4154, 2006.",
        "citeRegEx": "8",
        "shortCiteRegEx": null,
        "year": 2006,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].",
        "context": null
    },
    {
        "title": "MAP estimation via agreement on trees: Message-passing and linear-programming approaches",
        "author": [
            "M. Wainwright",
            "T. Jaakkola",
            "A. Willsky"
        ],
        "venue": "IEEE Trans. Inf. Theory, vol. 51, no. 11, pp. 3697\u20133717, 2005.",
        "citeRegEx": "9",
        "shortCiteRegEx": null,
        "year": 2005,
        "abstract": "",
        "full_text": "",
        "sentence": " Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14]. State-of-the-art methods for binary MRF labeling include BP [6], TRW [9], [10] and graph cuts [3].",
        "context": null
    },
    {
        "title": "A linear programming approach to max-sum problem: A review",
        "author": [
            "T. Werner"
        ],
        "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 29, no. 7, pp. 1165\u20131179, 2007.",
        "citeRegEx": "11",
        "shortCiteRegEx": null,
        "year": 2007,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].",
        "context": null
    },
    {
        "title": "Exact optimization for Markov random fields with convex priors",
        "author": [
            "H. Ishikawa"
        ],
        "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 25, no. 10, pp. 1333\u20131336, 2003.",
        "citeRegEx": "12",
        "shortCiteRegEx": null,
        "year": 2003,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].",
        "context": null
    },
    {
        "title": "Efficiently solving convex relaxations for MAP estimation",
        "author": [
            "M. Kumar",
            "P. Torr"
        ],
        "venue": "ICML, 2008.",
        "citeRegEx": "13",
        "shortCiteRegEx": null,
        "year": 2008,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].",
        "context": null
    },
    {
        "title": "An analysis of convex relaxations for MAP estimation",
        "author": [
            "M. Kumar",
            "V. Kolmorgorov",
            "P. Torr"
        ],
        "venue": "NIPS, 2007.",
        "citeRegEx": "14",
        "shortCiteRegEx": null,
        "year": 2007,
        "abstract": "",
        "full_text": "",
        "sentence": " Promising algorithms include graph cuts and QPBO [2], [3], [4], [5], belief propagation (BP) [6], [7], [8], treereweighted message passing (TRW) [9], [10], linear programming [11], and convexity-related methods [12], [13], [14].",
        "context": null
    },
    {
        "title": "Self-validated labeling of Markov random fields for image segmentation",
        "author": [
            "W. Feng",
            "J. Jia",
            "Z.-Q. Liu"
        ],
        "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 32, no. 10, pp. 1871\u20131887, 2010.",
        "citeRegEx": "15",
        "shortCiteRegEx": null,
        "year": 1871,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " such as image segmentation [15], [16], stereo [2], [17] and restoration [2], [4].",
        "context": null
    },
    {
        "title": "Region-level image authentication using Bayesian structural content abstraction",
        "author": [
            "W. Feng",
            "Z.-Q. Liu"
        ],
        "venue": "IEEE Trans. Image Process., vol. 17, no. 12, pp. 2413\u20132424, 2008.",
        "citeRegEx": "16",
        "shortCiteRegEx": null,
        "year": 2008,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " such as image segmentation [15], [16], stereo [2], [17] and restoration [2], [4].",
        "context": null
    },
    {
        "title": "Comparison of graph cuts with belief propagation for stereo using identical mrf parameters",
        "author": [
            "M. Tappen",
            "W. Freeman"
        ],
        "venue": "ICCV, 2003.",
        "citeRegEx": "17",
        "shortCiteRegEx": null,
        "year": 2003,
        "abstract": "",
        "full_text": "",
        "sentence": " such as image segmentation [15], [16], stereo [2], [17] and restoration [2], [4]. Recently, the performance of these techniques in minimizing energy functions defined on 4connected grid graphs has been extensively studied [1], [17], [18]. niques on minimizing sparse energies defined in 4connected grid graphs is well-understood in computer vision [1], [17], as shown in Fig. Refer to [1], [17] Lower supermodularity Sr \u2248 0 Higher supermodularity Sr > 10%",
        "context": null
    },
    {
        "title": "Globally optimal solutions for energy minimization in stereo vision using reweighted belief propagation",
        "author": [
            "T. Meltzer",
            "C. Yanover",
            "Y. Weiss"
        ],
        "venue": "ICCV, 2005.",
        "citeRegEx": "18",
        "shortCiteRegEx": null,
        "year": 2005,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Recently, the performance of these techniques in minimizing energy functions defined on 4connected grid graphs has been extensively studied [1], [17], [18]. However, it has also been shown that the optimal labeling proposed by global minimum energy has larger error statistics than other suboptimal solutions for benchmark stereo pairs [18]. Second, as stated in [18], [19], the performance of different methods for real energies depends on both the power of energy models and the efficacy of energy minimization methods. This is in contrast to their performances for sparse energy functions [1], [18].",
        "context": null
    },
    {
        "title": "Comparison of energy minimization algorithms for highly connected graphs",
        "author": [
            "V. Kolmogorov",
            "C. Rother"
        ],
        "venue": "ECCV, 2006.",
        "citeRegEx": "19",
        "shortCiteRegEx": null,
        "year": 2006,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Most recently, some sophisticated models, such as random fields with higher connectivity [19], [20] and with higher-order cliques [21], [22], [23], [24], have shown their impressive potentials in handling difficult visual labeling problems. However, minimizing such energy functions is challenging for existing techniques [1], [19]. For BP and TRW-S, we used the speed-up implementation introduced in [19]. Second, as stated in [18], [19], the performance of different methods for real energies depends on both the power of energy models and the efficacy of energy minimization methods. The difficulty of TRW-S on solving dense energy functions was also found and analyzed in [19].",
        "context": null
    },
    {
        "title": "Fields of experts: A framework for learning image priors",
        "author": [
            "S. Roth",
            "M.J. Black"
        ],
        "venue": "CVPR, 2005.",
        "citeRegEx": "20",
        "shortCiteRegEx": null,
        "year": 2005,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Most recently, some sophisticated models, such as random fields with higher connectivity [19], [20] and with higher-order cliques [21], [22], [23], [24], have shown their impressive potentials in handling difficult visual labeling problems.",
        "context": null
    },
    {
        "title": "Minimizing sparse higher order energy functions of discrete variables",
        "author": [
            "C. Rother",
            "P. Kohli",
            "W. Feng",
            "J. Jia"
        ],
        "venue": "CVPR, 2009.",
        "citeRegEx": "21",
        "shortCiteRegEx": null,
        "year": 2009,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Most recently, some sophisticated models, such as random fields with higher connectivity [19], [20] and with higher-order cliques [21], [22], [23], [24], have shown their impressive potentials in handling difficult visual labeling problems. Despite the very different formulations of these models, they usually rely on minimizing some dense and nonsubmodular energy functions [21], [25]. In practice, however, some recent powerful energy functions of real problems are usually nonsubmodular [21], [25].",
        "context": null
    },
    {
        "title": "Global stereo reconstruction under second order smoothness priors",
        "author": [
            "O. Woodford",
            "P. Torr",
            "I. Reid",
            "A. Fitzgibbon"
        ],
        "venue": "CVPR, 2008.",
        "citeRegEx": "22",
        "shortCiteRegEx": null,
        "year": 2008,
        "abstract": "",
        "full_text": "",
        "sentence": " Most recently, some sophisticated models, such as random fields with higher connectivity [19], [20] and with higher-order cliques [21], [22], [23], [24], have shown their impressive potentials in handling difficult visual labeling problems.",
        "context": null
    },
    {
        "title": "Efficient belief propagation with learned higher-order Markov random fields",
        "author": [
            "X. Lan",
            "S. Roth",
            "D. Huttenlocher",
            "M.J. Black"
        ],
        "venue": "ECCV, 2006.",
        "citeRegEx": "23",
        "shortCiteRegEx": null,
        "year": 2006,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Most recently, some sophisticated models, such as random fields with higher connectivity [19], [20] and with higher-order cliques [21], [22], [23], [24], have shown their impressive potentials in handling difficult visual labeling problems.",
        "context": null
    },
    {
        "title": "Inference for order reduction in Markov random fields",
        "author": [
            "A.C. Gallagher",
            "D. Batra",
            "D. Parikh"
        ],
        "venue": "CVPR, 2012.",
        "citeRegEx": "24",
        "shortCiteRegEx": null,
        "year": 2012,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Most recently, some sophisticated models, such as random fields with higher connectivity [19], [20] and with higher-order cliques [21], [22], [23], [24], have shown their impressive potentials in handling difficult visual labeling problems.",
        "context": null
    },
    {
        "title": "A graph cut algorithm for higher-order Markov random fields",
        "author": [
            "A. Fix",
            "A. Gruber",
            "E. Boros",
            "R. Zabih"
        ],
        "venue": "ICCV, 2011.",
        "citeRegEx": "25",
        "shortCiteRegEx": null,
        "year": 2011,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Despite the very different formulations of these models, they usually rely on minimizing some dense and nonsubmodular energy functions [21], [25]. In practice, however, some recent powerful energy functions of real problems are usually nonsubmodular [21], [25].",
        "context": null
    },
    {
        "title": "Pseudo-boolean optimization",
        "author": [
            "E. Boros",
            "P. Hammer"
        ],
        "venue": "Discrete Applied Mathematics, vol. 123, pp. 155\u2013225, 2002.",
        "citeRegEx": "26",
        "shortCiteRegEx": null,
        "year": 2002,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Our algorithm can also be viewed as a general approximate solution to dense and nonsubmodular QPBF minimization [26]. QPBF minimization has been studied in discrete optimization for decades [26]. For nonsubmodular QPBFs, the roof duality [26] is used to find an optimal partial labeling, which is called QPBO and two variants P and I [4], [5]. We already know that E(x) can be exactly minimized if it is submodular [3], [26]. used in the literature [4], [26]. Thus, the complexity of ESSP algorithm is O(TM), where T is the number of iterations and M is the state-of-theart complexity of maxflow computation on undirected graphs [26], [28], [29].",
        "context": null
    },
    {
        "title": "A submodular-supermodular procedure with applications to discriminative structure learning",
        "author": [
            "M. Narasimhan",
            "J. Bilmes"
        ],
        "venue": "UAI, 2005.",
        "citeRegEx": "27",
        "shortCiteRegEx": null,
        "year": 2005,
        "abstract": "",
        "full_text": "",
        "sentence": " The core of our algorithm is an extended submodularsupermodular procedure (ESSP) that expands the classical submodular-supermodular procedure (SSP) [27] to minimize QPBFs of any type. One of such methods is SSP that is designed to minimize the difference of two submodular functions [27]. In this paper, we use it to extend the classical SSP [27] to optimize QPBFs of any type. SSP is one of such methods and is designed to minimize the sum of a submodular function and a supermodular function [27]. The optimality and efficacy of SSP is highly dependent on the modular approximation of the supermodular function [27]. Refer to [27] for more details about modApproximation(\u00b7) in Algorithm 1. According to the convergence of SSP [27], ESSP is also guaranteed to converge to a local optimum. Our approach is based on an undirected graph characterization of QPBFs, which enables us to extend the classical submodular-supermodular procedure [27] to a general solver for generic binary labeling problems.",
        "context": null
    },
    {
        "title": "Minimizing symmetric submodular functions",
        "author": [
            "M. Queyranne"
        ],
        "venue": "Math. Programming, vol. 82, pp. 3\u201312, 1998.",
        "citeRegEx": "28",
        "shortCiteRegEx": null,
        "year": 1998,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " and (2) it transforms a QPBF to a symmetric set function, thus providing an efficient way to suppress the supermodular part of the QPBF and to apply more efficient graph cut solutions [28], [29]. Besides, if denoting the value of indicator node o as xo, the undirected graph characterization implies that any QPBF E(x) can be converted to a symmetric set function F (x, xo) that represents the cut value of GE(x) [28], Thus, the complexity of ESSP algorithm is O(TM), where T is the number of iterations and M is the state-of-theart complexity of maxflow computation on undirected graphs [26], [28], [29].",
        "context": null
    },
    {
        "title": "Max flows in O(nm) time, or better",
        "author": [
            "J.B. Orlin"
        ],
        "venue": "2012.",
        "citeRegEx": "29",
        "shortCiteRegEx": null,
        "year": 2012,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " and (2) it transforms a QPBF to a symmetric set function, thus providing an efficient way to suppress the supermodular part of the QPBF and to apply more efficient graph cut solutions [28], [29]. Thus, the complexity of ESSP algorithm is O(TM), where T is the number of iterations and M is the state-of-theart complexity of maxflow computation on undirected graphs [26], [28], [29]. Besides, combining ESSP with other recent optimization methods, such as [29], [32], is an interesting direction for future work.",
        "context": null
    },
    {
        "title": "Efficient exact inference in planar Ising models",
        "author": [
            "N. Schraudolph",
            "D. Kamenetsky"
        ],
        "venue": "NIPS, 2006.",
        "citeRegEx": "30",
        "shortCiteRegEx": null,
        "year": 2006,
        "abstract": "We give polynomial-time algorithms for the exact computation of lowest-energy\n(ground) states, worst margin violators, log partition functions, and marginal\nedge probabilities in certain binary undirected graphical models. Our approach\nprovides an interesting alternative to the well-known graph cut paradigm in\nthat it does not impose any submodularity constraints; instead we require\nplanarity to establish a correspondence with perfect matchings (dimer\ncoverings) in an expanded dual graph. We implement a unified framework while\ndelegating complex but well-understood subproblems (planar embedding,\nmaximum-weight perfect matching) to established algorithms for which efficient\nimplementations are freely available. Unlike graph cut methods, we can perform\npenalized maximum-likelihood as well as maximum-margin parameter estimation in\nthe associated conditional random fields (CRFs), and employ marginal posterior\nprobabilities as well as maximum a posteriori (MAP) states for prediction.\nMaximum-margin CRF parameter estimation on image denoising and segmentation\nproblems shows our approach to be efficient and effective. A C++ implementation\nis available from http://nic.schraudolph.org/isinf/",
        "full_text": "E\ufb03cient Exact Inference in Planar Ising Models\nNicol N. Schraudolph\narxiv@schraudolph.org\nDmitry Kamenetsky\ndmitry.kamenetsky@nicta.com.au\nResearch School of Information Sciences and Engineering\nAustralian National University \u2013and\u2013\nNICTA, Locked Bag 8001\nCanberra ACT 2601, Australia\nEditor: unknown\nAbstract\nWe give polynomial-time algorithms for the exact computation of lowest-energy (ground)\nstates, worst margin violators, log partition functions, and marginal edge probabilities in\ncertain binary undirected graphical models. Our approach provides an interesting alterna-\ntive to the well-known graph cut paradigm in that it does not impose any submodularity\nconstraints; instead we require planarity to establish a correspondence with perfect match-\nings (dimer coverings) in an expanded dual graph. We implement a uni\ufb01ed framework\nwhile delegating complex but well-understood subproblems (planar embedding, maximum-\nweight perfect matching) to established algorithms for which e\ufb03cient implementations are\nfreely available. Unlike graph cut methods, we can perform penalized maximum-likelihood\nas well as maximum-margin parameter estimation in the associated conditional random\n\ufb01elds (CRFs), and employ marginal posterior probabilities as well as maximum a posteri-\nori (MAP) states for prediction. Maximum-margin CRF parameter estimation on image\ndenoising and segmentation problems shows our approach to be e\ufb03cient and e\ufb00ective. A\nC++ implementation is available from http://nic.schraudolph.org/isinf/.\nKeywords:\nMarkov random \ufb01elds, spin glasses, plane embedding, blossom shrinking,\nmarginal posterior mode\n1. Introduction\nUndirected graphical models are a popular tool in machine learning; they represent real-\nvalued energy functions of the form\nE\u2032(y) :=\nX\ni\u2208V\nE\u2032\ni(yi)\n+\nX\n(i,j)\u2208E\nE\u2032\nij(yi, yj) ,\n(1)\nwhere the terms in the \ufb01rst sum range over the nodes V = {1, 2, . . . n}, and those in the\nsecond sum over the edges E \u2286V \u00d7 V of an undirected graph G(V, E).\nThe junction tree decomposition provides an e\ufb03cient framework for exact statistical\ninference in graphs that are (or can be turned into) trees of small cliques. The resulting\nalgorithms, however, require time exponential in the clique size, i.e., the treewidth of the\noriginal graph. The treewidth of many graphs of practical interest is prohibitively large \u2014\nfor instance, it grows as O(n) for an n \u00d7 n square lattice. A large number of approximate\narXiv:0810.4401v2  [cs.LG]  17 Dec 2008\nSchraudolph and Kamenetsky\ninference techniques have been developed so as to deal with such graphs, such as pseudo-\nlikelihood (Besag, 1986), mean \ufb01eld approximation, loopy belief propagation (Weiss, 2001;\nYedidia et al., 2003), tree reweighting (Wainwright et al., 2003, 2005), and tree sampling\n(Hamze and de Freitas, 2004).\n1.1 The Ising Model\nE\ufb03cient exact inference is possible in certain graphical models with binary node labels.\nHere we focus on Ising models, whose energy functions have the form E : {0, 1}n \u2192R with\nE(y) :=\nX\n(i,j)\u2208E\n[yi \u0338= yj] Eij,\n(2)\nwhere [\u00b7] denotes the indicator function, i.e., the cost Eij is incurred only in those states y\nwhere yi and yj disagree. Compared to the general model (1) for binary nodes, (2) imposes\ntwo additional restrictions: zero node energies, and edge energies in the form of disagreement\ncosts. At \ufb01rst glance these constraints look severe; for instance, such systems must obey\nthe symmetry E(y) = E(\u00ac y), where \u00ac denotes Boolean negation (ones\u2019 complement).\nHowever, it is well known (e.g., Globerson and Jaakkola, 2007) that adding a single node\nmakes the Ising model (2) as expressive as the general model (1) for binary variables:\nTheorem 1 Every energy function of the form (1) over n binary variables is equivalent to\nan Ising energy function of the form (2) over n + 1 variables, with the additional variable\nheld constant.\nProof by construction: Two energy functions are equivalent if they di\ufb00er only by a con-\nstant. Without loss of generality, denote the additional variable y0 and hold it constant at\ny0 := 0. Given an energy function of the form (1), construct an Ising model with disagree-\nment costs as follows:\n1. For each node energy function E\u2032\ni(yi), add a disagreement cost of E0i := E\u2032\ni(1)\u2212E\u2032\ni(0),\nas shown in Figure 1a. Note that in both states of yi, the energy of the resulting Ising\nmodel is shifted relative to E\u2032\ni(yi) by the same constant amount, namely E\u2032\ni(0):\nyi\ngeneral\nIsing energy\n0\nE\u2032\ni(0)\n0 = E\u2032\ni(0) \u2212E\u2032\ni(0)\n1\nE\u2032\ni(1)\nE0i = E\u2032\ni(1) \u2212E\u2032\ni(0)\n2. For each edge energy function E\u2032\nij(yi, yj), add the three disagreement cost terms\nEij := 1\n2[(E\u2032\nij(0, 1) + E\u2032\nij(1, 0)) \u2212(E\u2032\nij(0, 0) + E\u2032\nij(1, 1))],\nE0i := E\u2032\nij(1, 0) \u2212E\u2032\nij(0, 0) \u2212Eij,\nand\n(3)\nE0j := E\u2032\nij(0, 1) \u2212E\u2032\nij(0, 0) \u2212Eij,\nas shown in Figure 1b. Note that for all states of yi and yj, the energy of the resulting\nIsing model is shifted relative to E\u2032\ni(yi) by the same constant amount, namely E\u2032\nij(0, 0):\n2\nEfficient Exact Inference in Planar Ising Models\nn\ni\nn\n0\nE0i :=\nE\u2032\ni(1)\u2212E\u2032\ni(0)\nn\ni\nn\n0\nn\nj\n\u0000\u0000\u0000\u0000\u0000\u0000@\n@\n@\n@\n@\n@\nE\u2032\nij(1,0)\u2212E\u2032\nij(0,0)\n\u2212Eij\nE\u2032\nij(0,1)\u2212E\u2032\nij(0,0)\n\u2212Eij\nEij :=\n1\n2[(E\u2032\nij(0,1) + E\u2032\nij(1,0))\n\u2212(E\u2032\nij(0,0) + E\u2032\nij(1,1))]\nn\ni\nn\n0\nn\nj\nn\n1\n\u0000\u0000\u0000\u0000\u0000\u0000E0i\nEij\n\u2212E0j\nn\ni\nn\n0\nn\nj\nn\n1\n\u0000\u0000\u0000\t\n\u0000\u0000\u0000\t\n-\nEij +E0i\n2Eij\nEij \u2212E0j\n(a)\n(b)\n(c)\n(d)\nFigure 1: Equivalent Ising model (with disagreement costs) for a given (a) node energy E\u2032\ni,\n(b) edge energy E\u2032\nij in a binary graphical model; (c) equivalent submodular model\nif Eij > 0 and E0i > 0 but E0j < 0; (d) equivalent directed model of Kolmogorov\nand Zabih (2004, Fig. 2d).\nyi\nyj\ngeneral\nIsing energy\n0\n0\nE\u2032\nij(0, 0)\n0 = E\u2032\nij(0, 0) \u2212E\u2032\nij(0, 0)\n0\n1\nE\u2032\nij(0, 1)\nE0j + Eij = E\u2032\nij(0, 1) \u2212E\u2032\nij(0, 0)\n1\n0\nE\u2032\nij(1, 0)\nE0i + Eij = E\u2032\nij(1, 0) \u2212E\u2032\nij(0, 0)\n1\n1\nE\u2032\nij(1, 1)\nE0i + E0j = E\u2032\nij(1, 1) \u2212E\u2032\nij(0, 0)\nSumming the above terms, the total bias of node i (i.e., its disagreement cost with the bias\nnode) is\nE0i = E\u2032\ni(1) \u2212E\u2032\ni(0) +\nX\nj:(i,j)\u2208E\n[E\u2032\nij(1, 0) \u2212E\u2032\nij(0, 0) \u2212Eij] .\n(4)\nThis construction de\ufb01nes an Ising model whose energy in every con\ufb01guration y is shifted,\nrelative to that of the general model we started with, by the same constant amount, namely\nE\u2032(0):\n\u2200y \u2208{0, 1}n :\nE\n\u0012\u0014\n0\ny\n\u0015\u0013\n= E\u2032(y) \u2212\nX\ni\u2208V\nE\u2032\ni(0) \u2212\nX\n(i,j)\u2208E\nE\u2032\nij(0, 0)\n= E\u2032(y) \u2212E\u2032(0).\n(5)\nThe two models\u2019 energy functions are therefore equivalent.\nNote how in the above construction the label symmetry E(y) = E(\u00ac y) of the plain Ising\nmodel (2) is conveniently broken by the introduction of a bias node, through the convention\nthat y0 := 0.\n1.2 Energy Minimization via Graph Cuts\nDe\ufb01nition 2 The cut C of a binary graphical model G(V, E) induced by state y \u2208{0, 1}n\nis the set C(y) := {(i, j) \u2208E : yi \u0338= yj}; its weight |C(y)| is the sum of the weights of its\nedges.\n3\nSchraudolph and Kamenetsky\nAny given state y partitions the nodes of a binary graphical model into two sets: those\nlabeled \u20180\u2019, and those labeled \u20181\u2019. The corresponding graph cut is the set of edges crossing\nthe partition; since only they contribute disagreement costs to the Ising model (2), we\nhave \u2200y : |C(y)| = E(y). The lowest-energy state of an Ising model therefore induces its\nminimum-weight cut. Conversely, the ground state of an Ising model (in absence of a bias\nnode: up to label symmetry) can be determined from its minimum-weight cut via a simple\n(e.g., depth-\ufb01rst) graph traversal (see Algorithm 1).\nMinimum-weight cuts can be computed in polynomial time in graphs whose edge weights\nare all non-negative. Introducing one more node, with the constraint yn+1 := 1, allows us\nto construct an equivalent energy function by replacing each negatively weighted bias edge\nE0i < 0 by an edge to the new node n + 1 with the positive weight Ei,n+1 := \u2212E0i > 0\n(Figure 1c).\nThis still leaves us with the requirement that all non-bias edges be non-\nnegative. This submodularity constraint implies that agreement between nodes must be\nlocally preferable to disagreement \u2014 a severe limitation.\nThe now widespread use of graph cuts in machine learning to \ufb01nd lowest-energy con-\n\ufb01gurations, in particular in image processing, was pioneered by Greig et al. (1989). Our\nconstruction (Figure 1c) di\ufb00ers from that of Kolmogorov and Zabih (2004) (Figure 1d) in\nthat we do not employ the notion of directed edges. (In directed graphs, the weight of a\ncut is the sum of the weights of only those edges crossing the cut in a given direction.)\nWe note that a more elaborate construction can give partial answers in graphs with some\nnegative edge weights (Kolmogorov and Rother, 2007; Rother et al., 2007b), and that a\nsequence of expansion moves (energy minimizations in binary graphs) can e\ufb03ciently yield\nan approximate answer for graphs with discrete but non-binary node labels (Boykov et al.,\n2001).\nThe remainder of this paper is organized as follows: Section 2 describes the planarity\nand connectivity conditions that our approach imposes upon the graphs, and how we handle\nthem. Section 3 describes the construction of an expanded dual graph, and the algorithm\nfor computing optimal (ground) states of the Ising model from it. The calculation of the\npartition function and marginal probabilities is dealt with in Section 4. These algorithms are\nthen used in Section 5 to implement maximum-likelihood and maximum-margin parameter\nestimation in conditional random \ufb01elds (CRFs). Section 6 describes our experiments using\ngrid CRFs for image denoising and boundary detection, and Section 7 concludes with a\ndiscussion and outlook. We are making open source C++ code implementing our algorithms\nfreely available for download from http://nic.schraudolph.org/isinf/.\n2. Planarity and Connectivity\nUnlike graph cut methods, the inference algorithms we will describe do not depend on\nsubmodularity; instead they require that the model graph be planar, and that a planar\nembedding be provided. They may also work only for connected graphs, and be the most\ne\ufb03cient only for biconnected graphs. In this section we review these concepts, discuss their\nimplications for our approach, and describe how to best handle them.\n4\nEfficient Exact Inference in Planar Ising Models\n1\n2\n3\n4\n5\n2\n1\n3\n4\n5\n1\n2\n3\n4\n5\n1\n2\n3\n4\n5\n(a)\n(b)\n(c)\n(d)\nFigure 2: (a) a non-plane drawing of a planar graph; (b) a plane drawing of the same graph;\n(c) a di\ufb00erent plane drawing of same graph, with the same planar embedding as\n(b); (d) a plane drawing of the same graph with a di\ufb00erent planar embedding.\n2.1 Embedding Planar Graphs\nDe\ufb01nition 3 A graph is planar if it can be drawn in the plane R2 without edge inter-\nsections. The regions into which such a plane drawing partitions R2 are the faces of the\ndrawing; the unbounded region is the external face.\nThe operational nature of this de\ufb01nition would suggest that our algorithms must produce\n(or have access to) a plane drawing of the model graph. This is unsatisfactory in that\nsuch a drawing contains much information (such as the precise location of the vertices, and\nthe exact shape of the edges) that we will not need. All we care about is the cyclic (say,\nclockwise) ordering of the edges incident upon each vertex. In topological graph theory,\nthis is formalized in the notion of a rotation system (White and Beineke, 1978, p. 21f):\nDe\ufb01nition 4 Let G(V, E) be an undirected, connected graph. For each vertex i \u2208V, let\nEi denote the set of edges in E incident upon i, considered as being oriented away from i,\nand let \u03c0i be a cyclic permutation of Ei. A rotation system for G is a set of permutations\n\u03a0 = {\u03c0i : i \u2208V}.\nTo de\ufb01ne the sets Ei of oriented edges more formally, construct the directed graph G(V, E\u2032),\nwhere E\u2032 contains a pair of directed edges (known as edgelets) for each undirected edge in\nE, that is, (i, j) \u2208E\u2032 \u21d0\u21d2[(i, j) \u2208E \u2228(j, i) \u2208E]. Then Ei = {(j, k) \u2208E\u2032 : i = j}.\nRotation systems directly correspond to topological graph embeddings in orientable\nsurfaces:\nTheorem 5 Each rotation system determines an embedding of G in some orientable surface\nS such that \u2200i \u2208V, any edge (i, j) \u2208Ei is followed by \u03c0i(i, j) in (say) clockwise orientation,\nand such that the faces F of the embedding, given by the orbits of the mapping (i, j) \u2192\n\u03c0j(j, i), are 2-cells (topological disks).\nProof see White and Beineke (1978, p. 22f).\n5\nSchraudolph and Kamenetsky\nNote that while in graph visualisation \u201cembedding\u201d is often used as a synonym for\n\u201cdrawing\u201d, in modern topological graph theory it stands for \u201crotation system\u201d. We adopt\nthe latter usage, which views embeddings as equivalence classes of graph drawings charac-\nterized by identical cyclic ordering of the edges incident upon each vertex. For instance,\n\u03c04(4, 5) = (4, 3) in Figures 2b and 2c (same embedding) but \u03c04(4, 5) = (4, 1) in Figure 2d\n(di\ufb00erent embedding). A sample face in Figures 2b\u20132d is given by the orbit\n(4, 1) \u2192\u03c01(1, 4) = (1, 2) \u2192\u03c02(2, 1) = (2, 4) \u2192\u03c04(4, 2) = (4, 1).\nThe genus g of the embedding surface S can be determined from the Euler characteristic\n|V| \u2212|E| + |F| = 2 \u22122g,\n(6)\nwhere |F| is found by counting the orbits of the rotation system, as described in Theorem 5.\nSince planar graphs are exactly those that can be embedded on a surface of genus g = 0 (a\ntopological sphere), we arrive at a purely combinatorial de\ufb01nition of planarity:\nDe\ufb01nition 6 A graph G(V, E) is planar i\ufb00it has a rotation system \u03a0 producing exactly\n2 + |E| \u2212|V| orbits. Such a system is called a planar embedding of G, and G(V, E, \u03a0) is\ncalled a plane graph.\nOur inference algorithms require a plane graph as input. In certain domains (e.g., when\nworking with geographic information) a plane drawing of the graph (from which the corre-\nsponding embedding is readily determined) may be available. Where it is not, we employ\nthe algorithm of Boyer and Myrvold (2004) which, given any connected graph G as input,\nproduces in linear time either a planar embedding for G or a proof that G is non-planar.\nSource code for this step is freely available (Boyer and Myrvold, 2004; Windsor, 2007).\n2.2 The Planarity Constraint\nIn Section 1.1 we have mapped a general binary graphical model to an Ising model with\nan additional bias node; now we require that that Ising model be planar. What does that\nimply for the original, general model? If all nodes of the graph are to be connected to the\nbias node without violating planarity, the graph has to be outerplanar, i.e., have a planar\nembedding in which all its nodes lie on the external face \u2014 a very severe restriction.\nThe situation improves, however, if we do not insist that all nodes be connected to the\nbias: If only a subset B \u2282V of nodes have non-zero bias (4), then the graph only needs\nto be B-outerplanar, i.e., have a planar embedding in which all nodes in B lie on the same\nface. Model selection may thus entail the step of picking the face of a suitably embedded\nplanar Ising model whose nodes will be connected to the bias node. In image processing,\nfor instance, where it is common to operate on a square grid of pixels, we can permit bias\nfor all nodes on the perimeter of the grid, which borders the external face.\nIn general, a planar embedding which maximizes a weighted sum over the nodes bor-\ndering a given face can be found in linear time (Gutwenger and Mutzel, 2004); by setting\nnode weights to some measure of their bias, such as the magnitude or square of E0i (4),\nwe can thus e\ufb03ciently obtain the planar Ising model closest (in that measure) to any given\nplanar binary graphical model.\n6\nEfficient Exact Inference in Planar Ising Models\nIn contrast to submodularity, B-outerplanarity is a structural constraint. This has the\nadvantage that once a model obeying the constraint is selected, inference (e.g., parameter\nestimation) can proceed via unconstrained methods (e.g., optimization).\nFinally, we note that all our algorithms can be extended to work for non-planar graphs as\nwell. They then take time exponential in the genus of the embedding though still polynomial\nin the size of the graph; for graphs of low genus this may well be preferable to current\napproximative methods.\n2.3 Connectivity\nAll algorithms in this paper assume that the graph G(V, E) is connected, i.e., that E contains\nat least one path between any two nodes of V. Where this is not the case, one can simply\ndetermine the connected components1 of G in linear time (Hopcroft and Tarjan, 1973),\nthen invoke the algorithm in question separately on each of them. Since each component is\nunconditionally independent of all others (as they have no edges between them), the results\ncan be trivially combined. Speci\ufb01cally,\n\u2022 G is planar i\ufb00all of its connected components are planar; any concatenation of a\nplanar embedding for each connected component is a planar embedding of G.\n\u2022 Any concatenation of a ground state for each connected component of G is a ground\nstate of G.\n\u2022 The log partition function of G is the sum of the log partition functions of its connected\ncomponents.\n\u2022 The edge marginal probabilities of G are the concatenation of edge marginal proba-\nbilities of its connected components.\n2.4 Biconnectivity\nDe\ufb01nition 7 A graph is biconnected i\ufb00it is connected and does not have any articulation\nvertex. An articulation vertex is a vertex whose removal (along with any incident edges)\ndisconnects the graph.\nAlthough the algorithms in this paper do not require G(V, E) to be biconnected, simpler\nand more e\ufb03cient alternatives are applicable when this is not the case. As Figure 3 illus-\ntrates, any graph G can be decomposed into a tree of edge-disjoint biconnected components1\nwhich overlap in the articulation vertices (of G) they share; this decomposition can be per-\nformed in linear time (Hopcroft and Tarjan, 1973). We make the following key observation:\nTheorem 8 Let E1, E2, . . . , En be the edge sets comprising the biconnected components of a\ngraph G(V, E). The probability of cuts induced by the states of a Markov random \ufb01eld (16)\n1. A component of a graph with respect to a given property is a maximal subgraph that has the property.\n7\nSchraudolph and Kamenetsky\nFigure 3: Skeletal chemical structures (images courtesy of Wikipedia) of phosphorus trioxide\n(bottom left), nitroglycerine (left of center), and quinine (right), with decomposi-\ntion into a tree of biconnected components indicated (shaded ovals). Phosphorous\ntrioxide is biconnected (i.e., all one component); nitroglycerine is a tree (i.e., has\nonly trivial biconnected components).\nover an Ising model 2 (2) on G factors into that of its biconnected components:\nP[C(y)] =\nn\nY\nk=1\nP[C(y) \u2229Ek].\n(7)\nProof If G(V, E) is biconnected, n = 1 and E1 = E, making Theorem 8 trivially true. Oth-\nerwise split G into a biconnected component G1(V1, E1) which is a leaf of the decomposition\ntree, and the remainder G\u2032(V\u2032, E\u2032). It is always possible to \ufb01nd such a split. Because it is\na leaf, G1 connects to G\u2032 through a single articulation vertex of G, which we call v1. To\nsummarize:\nV1 \u222aV\u2032 = V,\nV1 \u2229V\u2032 = {v1},\nE1 \u222aE\u2032 = E,\nE1 \u2229E\u2032 = \u2205,\nG1 biconnected.\n(8)\nLet y1 and y\u2032 be the state y of the model restricted to vertices in V1 and V\u2032, respectively.\nBy de\ufb01nition, y1 is independent of y\u2032 when both are conditioned on the state yv1 of the\narticulation vertex connecting them.\nWe now make use of the label symmetry of Ising\nmodels, resp. the fact that it is broken by conditioning on a single node: P[C(y)] = P(y|yi)\nfor any choice of i. We therefore have\nP[C(y)] = P(y|yv1) = P(y1, y\u2032|yv1)\n= P(y1|yv1) P(y\u2032|yv1) = P[C(y) \u2229E1] P[C(y) \u2229E\u2032].\n(9)\n2. Recall that we consider an Ising model to be an undirected graphical model with binary node states, no\nnode potentials, edge potentials in the form of disagreement costs, and an optional bias node.\n8\nEfficient Exact Inference in Planar Ising Models\nRecursively applying this argument to G\u2032 yields Theorem 8.\nThe independence of biconnected components with respect to cuts C(y) stated by The-\norem 8 may come as a surprise, given that the corresponding node states y do correlate\nthrough the articulation vertices. What happens is that label symmetry \u2014 speci\ufb01cally, the\nfact that C(y) = C(\u00acy) \u2014 folds the state space so as to exactly cancel any moments between\nbiconnected components. By decoupling their biconnected components, this facilitates e\ufb03-\ncient inference in graphs that are not biconnected themselves.\n2.4.1 Ising Trees\nNote in Figure 3 how edges which are not part of any cycle of G form trivial biconnected\ncomponents comprising only themselves and the two articulation vertices they connect. At\nthe most extreme, a tree T does not contain any cycles, hence consists entirely of trivial\nbiconnected components (Figure 3, left of center). Theorem 8 then implies that each edge\ncan be considered individually, making inference in an Ising tree T(V, E) very simple:\n\u2022 T is planar; any embedding of T is a planar embedding.\n\u2022 The minimum-weight cut of T is the set E\u2212:= {(i, j) \u2208E : Eij < 0}.\n(Use Algorithm 1 to obtain the corresponding ground state.)\n\u2022 The log partition function of T is\nln Z = ln\nY\n(i,j)\u2208E\n(e0 + e\u2212Eij) =\nX\n(i,j)\u2208E\nln(1 + e\u2212Eij).\n(10)\n\u2022 The marginal probability of any edge (i, j) of T is\nP[(i, j) \u2208C] =\ne\u2212Eij\ne0 + e\u2212Eij\n=\n1\n1 + eEij .\n(11)\n2.4.2 The General Case\nThe most e\ufb03cient way to employ the inference algorithms in this paper on graphs G that\nare neither biconnected nor trees (e.g., Figure 3, right) is to apply them to each nontrivial\nbiconnected component of G in turn, then use Theorem 8 to combine the results, along with\nthe simple solutions given in Section 2.4.1 above for trivial biconnected components, into\na result for the full graph. Letting ET \u2286E denote the set of edges that belong to trivial\nbiconnected components of G, we have:\n\u2022 A planar embedding of G is obtained by arbitrarily combining a planar embedding\nfor each of its nontrivial biconnected components and the edges in ET .\n\u2022 A minimum-weight cut of G is the union between the edges in E\u2212\u2229ET and a minimum-\nweight cut for each of G\u2019s nontrivial biconnected components; Algorithm 1 can be used\nto obtain the corresponding ground state.\n9\nSchraudolph and Kamenetsky\n\u2022 The log partition function of G is the sum of the log partition functions of its nontrivial\nbiconnected components, plus P\n(i,j)\u2208ET ln(1 + e\u2212Eij).\n\u2022 The marginal probability of an edge (i, j) \u2208E is (1 + eEij)\u22121 if (i, j) \u2208ET, or com-\nputed (by the method of Section 4) from the biconnected component it belongs to.\nThis concludes our discussion of conditions on the Ising model graph G. In what follows,\nwe assume that G is connected and planar, and that a plane embedding is provided. We\ndo not require that G is biconnected, though where this is not the case, it is generally more\ne\ufb03cient to decompose G into biconnected components as discussed above.\n3. Computing Ground States via Maximum-Weight Perfect Matching\nDe\ufb01nition 9 A frustrated cycle O \u2286E of a graph G(V, E) with non-zero edge weights E\nis a simple cycle whose product of edge weights is negative, i.e., Q\n(i,j)\u2208O Eij < 0. (A simple\ncycle is a closed path with no repeated edges or vertices.)\nA weighted graph is said to be frustrated if it contains any frustrated cycles. Note that\ntrees can never be frustrated because they do not contain any cycles to begin with.\nThe lowest-energy (ground) state y\u2217:= argminy E(y) of an unfrustrated Ising model is\neasily found via essentially the same method as in a tree (Section 2.4.1): paint nodes as you\ntraverse the graph, \ufb02ipping the binary color of your paintbrush whenever you traverse an\nedge with negative disagreement cost (as done by Algorithm 1 below when invoked on the\ncut C = {(i, j) \u2208E : Eij < 0}). This cannot lead to a contradiction because by De\ufb01nition 9\nyou will \ufb02ip brush color an even number of times along any cycle in the graph, hence always\nend a cycle on the same color you started it with.\nThe presence of frustration unfortunately makes the computation of ground states much\nharder \u2014 in fact, it is known to be NP-hard in general (Barahona, 1982). As shown below,\nthe ground state of a planar Ising model can be computed in polynomial time via maximum-\nweight perfect matching on an expanded dual of its embedded graph.\nA relationship between the states of a planar Ising model and perfect matchings (\u201cdimer\ncoverings\u201d to physicists) was \ufb01rst established by Kasteleyn (1961, 1963, 1967) and Fisher\n(1961, 1966). Perfect matchings in dual graph constructs were used by Bieche et al. (1980)\nand Barahona (1982) to compute Ising ground states; below we generalize a simpler con-\nstruction for triangulated graphs due to Globerson and Jaakkola (2007). For rectangular\nlattices our approach reduces to the construction of Thomas and Middleton (2007), though\ntheir algorithm to compute ground states is somewhat less straightforward. Pardella and\nLiers (2008) apply this construction to very large square lattices (up to 3000\u00d73000 nodes),\nand \ufb01nd it to be more e\ufb03cient than earlier methods (Bieche et al., 1980; Barahona, 1982).\n3.1 The Expanded Dual Graph\nDe\ufb01nition 10 The dual G\u2217(F, E) of an embedded graph G(V, E, \u03a0) has a vertex for each\nface of G, with edges connecting vertices corresponding to faces that are adjacent ( i.e., share\nan edge) in G.\n10\nEfficient Exact Inference in Planar Ising Models\nFigure 4: Left column: Square face of a plane graph (dashed lines) with its ordinary (top)\nresp. expanded (bottom) dual graph (solid lines). Other columns: Binary node\nstates (open and \ufb01lled circles) on the graph, induced cuts (bold blue dashes), and\ncomplementary perfect matchings (bold red lines) of the expanded dual.\nFigure 4 (top left) shows the dual for a square face of our plane graph. Each edge of the dual\ncrosses exactly one edge of the original graph; due to this one-to-one relationship we will\nconsider the dual to have the same set of edges E (with the same energies) as the original.\nSince the nodes in the dual are di\ufb00erent, however, we will (with some abuse of notation) use\na single index for dual edges and their weights, corresponding to the index of the original\nedge in some arbitrary ordering of E. Thus if (i, j) is the kth edge in the (ordered) E, its\ndual will have weight Ek := Eij.\nWe now expand the dual graph by replacing each of its nodes with a q-clique, where q is\nthe degree of the node, as shown in Figure 4 (bottom left) for a dual node with degree q = 4,\nand in Figure 5 for an entire graph. The additional edges internal to each q-clique are given\nzero energy so as to leave the model una\ufb00ected. For large q the introduction of these O(q2)\ninternal edges slows down subsequent computations (solid line in Figure 8, left); this can be\navoided by subdividing the o\ufb00ending q-gonal face of the model graph with chords (which\nare also given zero energy) before constructing the dual. Our implementation performs best\nwhen \u201coctangulating\u201d the graph, i.e., splitting octagons o\ufb00all faces with q > 13; this is\nmore e\ufb03cient than a full triangulation (Figure 8, left).\nIt is easily seen that the expanded dual has 2|E| vertices, two for each edge in the original\ngraph. We therefore give the two vertices connected by the dual of the kth edge in E the\nindices 2k \u22121 and 2k (cf. Section 4.3.1 and Figure 7). This consistent indexing scheme\nallows us to run the inference algorithms described in the remainder of this paper without\nexplicitly constructing an expanded dual graph data structure.\n11\nSchraudolph and Kamenetsky\nbias\nbias\n0\n0\n1\n0\n1\n0\n1\n1\n0\n1\nFigure 5: Example of a planar Ising model with \ufb01ve binary nodes (large, blue) including a\nconstant-valued bias node (top left), and its expanded dual (small nodes, red), in\ntwo di\ufb00erent states (left & right). The graph cut induced by the given state and\nits complementary perfect matching of the expanded dual are shown in bold, as\nare the nodes left unmatched by the complement M\u2032 := E\\C of the cut in the\nexpanded dual.\n3.2 Complementary Perfect Matchings\nDe\ufb01nition 11 A perfect matching of a graph G(V, E) is a subset M \u2286E of edges wherein\nexactly one edge is incident upon each vertex: \u2200v \u2208V, |v| = 1 in G(V, M). Its weight |M|\nis the sum of the weights of its edges.\nFigure 5 shows two perfect matchings (in bold) of the nodes of the expanded dual of an\nIsing model. There is a complementary relationship between such perfect matchings and\ngraph cuts in the original Ising model, characterized by the following two theorems. The\nreader may \ufb01nd it helpful to refer to Figure 5 while going through the proofs.\nTheorem 12 For every cut C of an embedded graph G(V, E, \u03a0) there exists at least one (if\nG is triangulated: exactly one) perfect matching M of its expanded dual complementary to\nC, i.e., E\\M = C.\nProof\nBy construction, the set E of edges of G constitutes a perfect matching of the\nexpanded dual. Any subset of E therefore is a (possibly partial) matching of the expanded\ndual. The complement M\u2032 := E\\C of a cut of G is a subset of E and thus a matching of the\nexpanded dual; it obeys E\\M\u2032 = E\\(E\\C) = C. The nodes that M\u2032 leaves unmatched in\nthe expanded dual (circled bold in Figure 5) are those neighboring the edges C of the cut.\nBy de\ufb01nition, C intersects any cycle of G, and therefore also the perimeters of G\u2019s faces\nF, in an even number of edges. In each clique of the expanded dual, M\u2032 thus leaves an\neven number of nodes unmatched. It can therefore be completed into a perfect matching\nM \u2287M\u2032 using only edges interior to the cliques to pair up unmatched nodes. These edges\n12\nEfficient Exact Inference in Planar Ising Models\nhave no counterpart in the original graph: (M\\M\u2032) \u2229E = \u2205. We thus have\nE\\M = E\\[(M\\M\u2032) \u222aM\u2032] = [E\\(M\\M\u2032)]\\M\u2032 = E\\M\u2032 = C.\n(12)\nIn a 3-clique of the expanded dual, M\u2032 will leave two nodes unmatched or none at all; in\neither case there is only one way to complete the matching, by adding one edge resp. none\nat all. By construction, if G is triangulated all cliques in its expanded dual are 3-cliques,\nand so M is unique.\nIn other words, there exists a surjection from perfect matchings in the expanded dual of G\nto cuts in G. Furthermore, since we have given edges interior to the cliques of the expanded\ndual zero energy (i.e., |M\\M\u2032| = 0), every perfect matching M complementary to a cut C\nof our Ising model (2) obeys the relation\n|M| + |C| = |M\u2032| + |C|\n=\nX\n(i,j)\u2208E\nEij = const.\n(13)\nThis means that instead of a minimum-weight cut in a graph we can look for a maximum-\nweight perfect matching in its expanded dual. But will that matching always be comple-\nmentary to a cut? The following theorem shows that this is true for plane graphs:\nTheorem 13 Every perfect matching M of the expanded dual of a plane graph G(V, E, \u03a0)\nis complementary to a cut C of G, i.e., E\\M = C.\nProof\nBy de\ufb01nition, E\\M is a cut of G i\ufb00it intersects every cycle O \u2286E of G an even\nnumber of times. This can be shown by induction over the faces of the embedding:\nBase case \u2014 let O \u2286E be the perimeter of a face of the embedding, and consider\nthe corresponding clique of the expanded dual: M matches an even number of nodes in\nthe clique via interior edges; all other nodes must be matched by edges crossing O. The\ncomplement of the matching in G thus intersects O an even number of times:\n|(E\\M) \u2229O| \u22610\nmod 2.\n(14)\nInduction \u2014 let O1, O2 \u2286E be cycles in G obeying (14), and consider their symmetric\ndi\ufb00erence O1\u2206O2 := (O1 \u222aO2)\\(O1 \u2229O2):\n|(E\\M) \u2229(O1\u2206O2)| = |[(E\\M) \u2229(O1 \u222aO2)]\\(O1 \u2229O2)|\n= |[(E\\M) \u2229O1] \u222a[(E\\M) \u2229O2]| \u2212|(E\\M) \u2229(O1 \u2229O2)|\n= |(E\\M) \u2229O1| + |(E\\M) \u2229O2| \u22122|(E\\M) \u2229(O1 \u2229O2)|\n\u22610 + 0 \u22122n \u22610\nmod 2.\n(n \u2208N)\n(15)\nWe see that property (14) is preserved under composition of cycles via symmetric di\ufb00erences,\nand thus holds for all cycles that can be composed from face perimeters of the embedding\nof G in this fashion.\nAll cycles in a plane graph G are contractible on its embedding surface (a plane resp.\nsphere) because that surface has zero genus, and is therefore simply connected. All con-\ntractible cycles of G can be constructed by composition of face perimeters via symmetric\ndi\ufb00erences, thus have an even intersection with E\\M, which is therefore a cut.\n13\nSchraudolph and Kamenetsky\nThis is where planarity matters: Surfaces of non-zero genus are not simply connected, and\nthus non-plane graphs may contain non-contractible cycles (e.g., encircling the hole of a\ntorus). In the presence of frustration, our construction does not guarantee that the comple-\nment E\\M of a perfect matching of the expanded dual contains an even number of edges\nalong such cycles. For planar graphs, however, the above theorems allow us to leverage\nknown polynomial-time algorithms for perfect matchings into inference methods for Ising\nmodels. This approach also works for non-planar Ising models that contain no frustrated\nnon-conctractible cycle.\nWe note that if all cliques of the expanded dual are of even size, there is also a direct (non-\ncomplementary) surjection from perfect matchings to cuts in the original graph. In contrast\nto our complementary map, the direct surjection requires the addition of dummy vertices\ninto the expanded dual for faces of G with odd perimeter so as to make the corresponding\ncliques even (Kasteleyn, 1963; Fisher, 1966; Liers and Pardella, 2008).\n3.3 Computing the Ground State\nThe blossom-shrinking algorithm (Edmonds, 1965a,b) is a sophisticated method to e\ufb03-\nciently compute the maximum-weight perfect matching of a graph. It can be implemented\n(Mehlhorn and Sch\u00a8afer, 2002) to run in as little as O(|E| |V| log |V|) time (Galil et al., 1986).\nAlthough the Blossom IV code we are using (Cook and Rohe, 1999) is asymptotically less\ne\ufb03cient \u2014 O(|E| |V|2) \u2014 we have found it to be very fast in practice (Figure 8, left).\nWe can now e\ufb03ciently compute the lowest-energy state of a planar Ising model as follows:\nFind a planar embedding of the model graph (Section 2.1), construct its expanded dual\n(Section 3.1), and run the blossom-shrinking algorithm on that to compute its maximum-\nweight perfect matching. Its complement in the original model is the minimum-weight graph\ncut (Section 3.2). We can identify the state which induces this cut via a depth-\ufb01rst graph\ntraversal (Algorithm 1) that labels nodes as it encounters them, and checks for consistency\non subsequent encounters. The traversal starts by labeling the bias node with its known\nstate y0 := 0.\n4. Computing the Partition Function and Marginal Probabilities\nA Markov random \ufb01eld (MRF) over our Ising model (2) models the distribution\nP(y) =\n1\nZ e\u2212E(y),\nwhere\nZ :=\nX\ny\ne\u2212E(y)\n(16)\nis the MRF\u2019s partition function. As it involves a summation over exponentially many states\ny, calculating the partition function is generally intractable. For planar graphs, however,\nthe generating function for perfect matchings can be calculated in polynomial time via\nthe determinant of a skew-symmetric matrix (Kasteleyn, 1961, 1963, 1967; Fisher, 1961,\n1966), which we call the Kasteleyn matrix K. Due to the close relationship with graph cuts\n(Section 3.2) we can apply this method to calculate Z in (16). We \ufb01rst convert a planar\nembedding of the Ising model graph into a Boolean \u201chalf-Kasteleyn\u201d matrix H, in four\nsteps which will be elaborated below:\n14\nEfficient Exact Inference in Planar Ising Models\nAlgorithm 1 Find State from Corresponding Graph Cut\nInput:\nIsing model graph G(V, E), graph cut C(y) \u2286E\n1.\n\u2200i \u2208{0, 1, 2, . . . n} : yi := unknown;\n2.\ndfs state(0, 0);\nOutput:\nstate vector y\nprocedure\ndfs state(i \u2208{0, 1, 2, . . . n}, s \u2208{0, 1})\nif yi = unknown then\n1. yi := s;\n2. \u2200(i, j) \u2208Ei :\nif (i, j) \u2208C then\ndfs state(j, \u00acs);\nelse dfs state(j, s);\nelse assert yi = s;\n1. Section 4.1, Algorithm 2: plane triangulate the embedded graph so as to make the\nrelationship between cuts and complementary perfect matchings a bijection (cf. Sec-\ntion 3.2);\n2. Section 4.2, Algorithm 3: orient the edges of the graph such that the in-degree of\nevery node is odd;\n3. Section 4.3.3, Algorithm 4: construct the Boolean half-Kasteleyn matrix H from the\noriented graph;\n4. Section 4.4.3: prefactor the triangulation edges (added in Step 1) out of H.\nOur Step 2 simpli\ufb01es equivalent operations in previous constructions (Kasteleyn, 1963, 1967;\nFisher, 1966; Globerson and Jaakkola, 2007), Step 3 di\ufb00ers in that it only sets unit (i.e.,\n+1) entries in a Boolean matrix, and Step 4 can dramatically reduce the size of H for\ncompact storage (as a bit matrix) and faster subsequent computations (Figure 8).\nEdge disagreement costs do not enter into H; they are only taken into account in a\nsecond phase, when the full Kasteleyn matrix K is constructed from H (Section 4.3.2). We\ncan then factor K (Section 4.4) and compute the partition function from its determinant\n(Section 4.4.1; Kasteleyn, 1961; Fisher, 1961). This factorisation can also be used to invert\nK, which is required to obtain marginal probabilities of disagreement on the edges of the\nmodel graph (Section 4.4.2).\nIn what follows, we elaborate in turn on the graph operations of plane triangulation\n(Section 4.1) and odd edge orientation (Section 4.2), and construction (Section 4.3) and\nfactoring (Section 4.4) of the Kasteleyn matrix K resp. H.\n15\nSchraudolph and Kamenetsky\n1\n2\n3\n4\n5\n1\n2\n3\n4\n5\n(a)\n(b)\n(c)\n(d)\nFigure 6: (a) A chordal graph whose external face is not triangulated; (b) a plane trian-\ngulated graph that has a 4-cycle (bold blue) without a chord; (c) proper, (d)\nimproper plane triangulation (dashed) of the plane graph from Figure 2d.\n4.1 Plane Triangulation\nDe\ufb01nition 14 An embedded graph is plane triangulated i\ufb00it is biconnected and each of\nits faces (including the external face) is a triangle.\nNote that plane triangulation is not equivalent to making a graph chordal, though the latter\nprocess is sometimes also called \u201ctriangulation\u201d. For instance, the graph in Figure 6a is\nchordal but not plane triangulated because the external face is not triangular, while that\nin Figure 6b is plane triangulated but not chordal because it contains a 4-cycle (bold blue)\nthat has no chord.\nWe can plane triangulate an embedded graph in linear time by traversing all of its\nfaces, inserting chords as necessary as we go along (Algorithm 2). This may create multiple\nedges between the same two vertices, as shown in Figure 6c. Care must be taken when\nencountering singly connected components with a perimeter of length two, which could\ncause the insertion of a self-loop (see Figure 6d). Algorithm 2 detects and biconnects such\ncomponents, as De\ufb01nition 14 requires.\nThe insert chord(i, j, k) subroutine of Algorithm 2 not only updates E, but also \u03c0i and\n\u03c0k so as to insert the new edge (i, k) in its proper place in the rotation system. In order\nto leave the distribution (16) modeled by the graph unchanged, the new edge is given zero\nenergy. Repeated traversals of the same face in Algorithm 2 can be avoided by the obvious\nuse of \u201cdone\u201d \ufb02ags, omitted here for the sake of clarity.\nNote that plane triangulation is not strictly necessary for the computation of partition\nfunction or marginal probabilities; it merely simpli\ufb01es subsequent steps in the construc-\ntion. Previously (Fisher, 1966; Globerson and Jaakkola, 2007) this convencience came at\na computational price: the edges added during plane triangulation can make factoring and\ninversion of K (Section 4.4) signi\ufb01cantly (up to 20 times) more expensive. We avoid this\ncost by removing the triangulation edges again before constructing K, during prefactoring\nof the half-Kasteleyn bit matrix H (Section 4.4.3).\n16\nEfficient Exact Inference in Planar Ising Models\nAlgorithm 2 Plane Triangulation\nInput: plane graph G(V, E, \u03a0) with |V| \u22653\n\u2200i \u2208V :\n\u2200(i, j) \u2208Ei :\n1. (j, k) := \u03c0j(j, i);\n2. (k, l) := \u03c0k(k, j);\n3. while l \u0338= i \u2228\u03c0l(l, k) \u0338= (l, j)\n(a) if i = k then\n(avoid self-loop)\ni := j;\nj := k;\nk := l;\n(k, l) := \u03c0k(k, j);\n(b) insert chord(i, j, k);\n(c) i := k; j := l;\n(d) (j, k) := \u03c0j(j, i);\n(e) (k, l) := \u03c0k(k, j);\nOutput:\nplane triangulated graph G(V, E, \u03a0)\nprocedure\ninsert chord(i, j, k \u2208V)\n1. E := E \u222a{(i, k)};\n2. \u03c0k(k, i) := \u03c0k(k, j);\n3. \u03c0k(k, j) := (k, i);\n4. \u03c0i(\u03c0\u22121\ni\n(i, j)) := (i, k);\n5. \u03c0i(i, k) := (i, j);\n6. Eik := 0;\n4.2 Odd Edge Orientation\nTo calculate the generating function for perfect matchings, the graph in question (namely,\nthe expanded dual of our model graph) must be given a clockwise odd orientation.\nDe\ufb01nition 15 An orientation of an undirected graph G(V, E) is a set E\u2032 of oriented edges\nwith |E\u2032| = |E| such that \u2200(i, j) \u2208E, E\u2032 contains either (i, j) or (j, i).\nDe\ufb01nition 16 (Kasteleyn, 1963) An orientation of an embedded graph is clockwise odd\ni\ufb00the number of edges oriented clockwise around each face (except possibly the external\nface) is odd.\nConsider Figure 7: by giving all interior edges of the 3-cliques of the expanded dual\na clockwise orientation (small red arrows), we ensure that (a) the interior faces of the\n3-cliques have clockwise odd orientation, and (b) all interior edges of the 3-cliques are\noriented counterclockwise wrt. all faces exterior to the 3-cliques, hence do not a\ufb00ect the\n17\nSchraudolph and Kamenetsky\n1\n2\n3\n4\n6\n5\n7\n8\n9\n10\n15\n18\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n12\n11\n13\n14\n16\n17\n19\n20\nFigure 7: Clockwise odd orientation (Section 4.2) and indexing scheme (Section 4.3.1) for\nthe expanded dual (red, small nodes) of the model graph (blue, large nodes).\nlatters\u2019 clockwise odd orientation status. It remains to consider the orientation of edges\nexternal to the 3-cliques (large red arrows). What does a clockwise odd orientation of these\nedges correspond to in the original model graph? To map these edges back into the model\ngraph, rotate them clockwise by 90 degrees. A face with clockwise odd orientation of its\nperimeter in the dual thus maps to a vertex with an odd in-degree, i.e., an odd number\nof edges oriented towards it. This facilitates a drastic simpli\ufb01cation of this step in our\nconstruction:\nTo establish a clockwise odd orientation of the expanded dual, simply orient the edges of the\nmodel graph such that all vertices, except possibly one, have an odd in-degree.\nAlgorithm 3 achieves this in linear time by orienting edges appropriately upon return from\na depth-\ufb01rst traversal of the graph. In contrast to earlier constructions (Kasteleyn, 1963;\nFisher, 1966; Globerson and Jaakkola, 2007), it does not require following orbits around\nfaces, and in fact does not refer to an embedding \u03a0 or dual graph G\u2217at all.\nAny vertex can be chosen to be the exceptional vertex s, since the choice of external face\nof a plane drawing is arbitrary \u2014 it is an artifact of the drawing, not an intrinsic property\nof the embedding: a planar graph embedded on a sphere has no external face.\n4.3 Constructing the Kasteleyn Matrix\nThe Kasteleyn matrix K is a skew-symmetric, 2|E|\u00d72|E| matrix constructed from the Ising\nmodel graph whose determinant is the square of the partition function. Our construction\nimproves upon the work of Globerson and Jaakkola (2007) in a number of ways:\n18\nEfficient Exact Inference in Planar Ising Models\nAlgorithm 3 Construct Odd Edge Orientation\nInput:\nundirected graph G(V, E)\n1.\n\u2200v \u2208V : v.visited = false;\n2.\npick arbitrary edge (r, s) \u2208E;\n3.\nE\u2032 := {(r, s)};\n4.\nmake odd(r, s);\nOutput:\norientation E\u2032 of E : \u2200v \u2208V\\{s},\nin-degree(v) \u22611 mod 2 in G(V, E\u2032)\nfunction\nmake odd: (u, v \u2208V) \u2192{true, false}\n1.\nE := E\\(u, v);\n2.\nif v.visited then return true;\n3.\nv.visited := true;\n4.\nodd := false;\n5.\n\u2200w \u2208V : {v, w} \u2208E\nif make odd(v, w) then\n(a)\nE\u2032 := E\u2032 \u222a{(w, v)};\n(b)\nodd := \u00ac odd;\nelse\nE\u2032 := E\u2032 \u222a{(v, w)};\n6.\nreturn odd;\n\u2022 We employ an indexing scheme that obviates any need to refer to the expanded dual\nof the model graph (which we consequently never explicitly construct at all);\n\u2022 We break construction of the Kasteleyn matrix into two phases, the \ufb01rst of which is\ninvariant with respect to the model\u2019s disagreement costs;\n\u2022 We make the \u201chalf-Kasteleyn\u201d matrix H computed in the \ufb01rst phase very compact\nby prefactoring out the triangulation edges (see Section 4.4.3) and storing it as a bit\nmatrix.\n4.3.1 Indexing Scheme\nWithout loss of generality, let E = {e1, e2, . . . e|E|}. Note that the expanded dual has 2|E|\nvertices, one lying to either side of every edge in the model graph. When viewing edge\nek along its direction in E\u2032, we label the dual node to its right 2k \u22121 and that to its\nleft 2k; see Figure 7 for an example (cf. Section 3.1). One bene\ufb01t of this scheme is that\nquantities relating to the edges of the model graph (as opposed to internal edges of the\ncliques of the expanded dual) will always be found on the superdiagonal of K. We also\nnotationally extend the rotation system from Section 2.1 to support this indexing scheme:\nek = (i, j) \u21d0\u21d2e\u03c0i(k) = \u03c0i(i, j).\n19\nSchraudolph and Kamenetsky\n10\n100\n1e3\n1e4\n1e5\n1\n0.1\n0.01\n1e-3\n1e-4\nCPU time  (seconds)\noriginal\ntriang.\noctang.\n10\n100\n1000\n0.001\n0.01\n0.1\n1\n10\nCPU time  (seconds)\nno prefact.\nprefactored\n10\n100\n1000\n1e3\n1e6\n1e9\nmemory  (bytes)\nK\nH\nuncompressed\ncompressed\nring size (nodes)\nring size (nodes)\nring size (nodes)\nFigure 8: Cost of planar Ising inference methods on a ring graph, plotted against ring size.\nLeft & center: CPU time on Apple MacBook with 2.2 GHz Intel Core2 Duo\nprocessor, averaged over 100 repetitions. Left: MAP state calculated via Blos-\nsom IV (Cook and Rohe, 1999) on original, triangulated, and octangulated ring.\nCenter: marginal edge probabilities with vs. without prefactoring. Right: size of\nK (double precision, no prefactoring) vs. prefactored bit matrix H, in uncom-\npressed (solid lines) vs. compressed form (dashed lines), using row-compressed\nsparse matrix storage for K and bzip2 compression for H.\n4.3.2 Two-Phase Construction\nIn a \ufb01rst phase we process the Ising model graph\u2019s structure into a Boolean \u201chalf-Kasteleyn\u201d\nmatrix H which does not yet include disagreement costs. For a given set of edge disagree-\nment costs Ek, k = {1, 2, , . . . |E|}, we then build from H the conventional, real-valued\nKasteleyn matrix K by adding the exponentiated disagreement costs along the superdiag-\nonal and skew-symmetrizing:\n1. K := H;\n2. \u2200k \u2208{1, 2, , . . . |E|} : K2k\u22121,2k := K2k\u22121,2k + eEk;\n3. K := K \u2212K\u22a4.\nThis two-phase approach holds a number of advantages:\n\u2022 When working with a large number of isomorphic graphs (as we do in Section 6), the\ncorresponding half-Kasteleyn matrix is identical for all of them, hence needs to be\nconstructed just once.\n\u2022 During maximum likelihood parameter estimation, partition function and/or marginals\nhave to be recomputed many times for the same graph, with disagreement costs vary-\ning due to the ongoing adaptation of the model parameters. H remains valid when\ndisagreement costs change, so we can compute it just once upfront, then re-use it in\nthe parameter estimation loop.\n\u2022 H can be stored very compactly as a prefactored bit matrix. As Figure 8 (right)\nshows, the uncompressed H can be several orders of magnitude smaller than the\n20\nEfficient Exact Inference in Planar Ising Models\ncorresponding Kasteleyn matrix K. Row-compressed sparse storage of K (which has\nexactly 3 non-zero entries in each row and column) is more e\ufb03cient, but applying the\nbzip2 compressor3 to the prefactored bit matrix H yields by far the most compact\nstorage format. Such memory e\ufb03ciency becomes very important when working with\nlarge data sets of non-isomorphic graphs.\nAlgorithm 4 Construct Half-Kasteleyn Bit Matrix\nInput:\noriented, embedded,\ntriangulated graph G(V, E\u2032, \u03a0)\n1.\nH := 0 \u2208{0, 1}2|E\u2032|\u00d72|E\u2032|\n2.\n\u2200v \u2208V :\n(a) es := any edge incident on v;\n(b) if es = (\u00b7, v)\n(edge points to v)\nthen \u03b1 := 2s;\nelse \u03b1 := 2s \u22121;\n(c) i := \u03c0v(s);\n(d) repeat\nif ei = (\u00b7, v)\n(edge points to v)\nthen\nH2i\u22121,\u03b1 := 1;\n\u03b1 := 2i;\nif ei was created by Algorithm 2 (plane triangulation)\nthen H2i\u22121,2i := 1;\nelse\nH2i,\u03b1 := 1;\n\u03b1 := 2i \u22121;\ni := \u03c0v(i);\nuntil i = \u03c0v(s);\nOutput:\nHalf-Kasteleyn bit matrix H\n4.3.3 Algorithm for Constructing H\nUsing the above indexing scheme, Algorithm 4 constructs H in linear time, cycling once\nthrough the edges incident upon each vertex of the model graph.\nIt deviates from the\nclassical construction of K (Kasteleyn, 1961; Fisher, 1961; Globerson and Jaakkola, 2007)\nin that it makes only positive entries, and only those corresponding to edges with zero\ndisagreement cost, i.e., added during plane triangulation or internal to the cliques of the\n3. http://www.bzip.org/\n21\nSchraudolph and Kamenetsky\nexpanded dual. All such entries have the value e0 = 1, making H a Boolean matrix, which\ncan be stored compactly as a bit matrix.\n4.4 Factoring Kasteleyn Matrices\nStandard approaches such as LU-factorization can be used to factor the Kasteleyn matrix\nK, but do not exploit its skew symmetry. Here we develop a numerically stable Cholesky-\nlike factorization for even-sized skew-symmetric matrices, which can be used to factor K\nas well as to prefactor H (see below). Begin by writing the Kasteleyn matrix as\nK =\n\uf8ee\n\uf8f0\n0\nc\na\u22a4\n\u2212c\n0\nb\u22a4\n\u2212a \u2212b\nC\n\uf8f9\n\uf8fb,\n(17)\nfor some scalar c, vectors a and b, and a matrix C which is either empty or again of the\nsame form. We factor (17) into (cf. Bunch, 1982; Benner et al., 2000)\nK =\n\uf8ee\n\uf8f0\n0 \u22121\n0\u22a4\n1\n0\n0\u22a4\na/c b/c\nI\n\uf8f9\n\uf8fb\n\uf8ee\n\uf8f0\n0\nc\n0\u22a4\n\u2212c\n0\n0\u22a4\n0\n0\nC\u2032\n\uf8f9\n\uf8fb\n\uf8ee\n\uf8f0\n0\n1\na\u22a4/c\n\u22121\n0\nb\u22a4/c\n0\n0\nI\n\uf8f9\n\uf8fb,\n(18)\nwhere C\u2032 is the Schur complement\nC\u2032 := C + (ba\u22a4\u2212ab\u22a4)/c.\n(19)\nIterated application of (18) to the Schur complement ultimately yields K = R\u22a4JR, where\nR :=\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n0\n1\na\u22a4\n1/c1\n\u22121\n0\nb\u22a4\n1/c1\n0\n0\n0\n1\na\u22a4\n2/c2\n0\n\u22121\n0\nb\u22a4\n2/c2\n...\n...\n...\n...\n0\n0\n0\n1\n0\n\u00b7 \u00b7 \u00b7\n0\n\u22121\n0\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n(20)\nand\nJ :=\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n0\nc1\n0\n\u00b7 \u00b7 \u00b7\n0\n\u2212c1 0\n0\n0\n0\n0\n0\nc2\n...\n...\n0\n\u2212c2 0\n0\n...\n...\n...\n0\n0\n0\n0\n0\nc|E|\n0\n\u00b7 \u00b7 \u00b7\n0\n\u2212c|E| 0\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n.\n(21)\nTo prevent small pivots ci from causing numerical instability, pivoting is required. Since\nKasteleyn matrices have at least two entries of unit magnitude in each row and column,\npartial pivoting su\ufb03ces.\n22\nEfficient Exact Inference in Planar Ising Models\n4.4.1 Partition Function\nThe partition function for perfect matchings is\np\n|K| (Kasteleyn, 1961; Fisher, 1961). Our\nfactoring gives |R| = 1 and |J| = Q\ni c2\ni , so we have\np\n|K| =\nq\n|R\u22a4| |J| |R| =\np\n|J| =\n|E|\nY\ni=1\n|ci|.\n(22)\nCalculation of the product in (22) is prone to numerical over\ufb02ow; this is easily avoided by\nworking with logarithms instead. Using the complementary relationship (13) with graph\ncuts in planar Ising models, we obtain the log partition function for the latter as\nln Z := ln\nX\ny\ne\u2212P\nk\u2208C(y) Ek = ln\nX\ny\ne\u2212(P\nk\u2208E Ek\u2212P\nk /\u2208C(y) Ek)\n(23)\n= ln(e\u2212P\nk\u2208E Ek X\ny\ne\nP\nk /\u2208C(y) Ek) = ln\np\n|K| \u2212\nX\nk\u2208E\nEk =\n|E|\nX\ni=1\n(ln |ci| \u2212Ei).\n4.4.2 Marginal Probabilities\nThe marginal probability of disagreement along an edge equals the negative gradient of the\nlog partition function (23) with respect to the disagreement costs. Computing this involves\nthe inverse of K:\nP(k \u2208C) =\nX\ny: k\u2208C(y)\nP(y) =\n1\nZ\nX\ny: k\u2208C(y)\ne\u2212E(y) =\n\u22121\nZ\n\u2202Z\n\u2202Ek\n=\n\u2212\u2202ln Z\n\u2202Ek\n= 1 \u2212\n1\n2|K|\n\u2202|K|\n\u2202Ek\n= 1 \u22121\n2 tr\n\u0012\nK\u22121 \u2202K\n\u2202Ek\n\u0013\n= 1 + K\u22121\n2k\u22121,2k K2k\u22121,2k,\n(24)\nwhere tr denotes the matrix trace, and we have used the fact that K\u22121 is skew-symmetric\nas well. To invert K, observe from (20) resp. (21) that R and J are essentially triangular\nresp. diagonal (simply swap rows 2k\u22121 and 2k, k = 1, 2, . . . |E|), and thus easily inverted.\nThen use K\u22121 = R\u22121J\u22121R\u2212\u22a4to obtain\n[K\u22121]2k\u22121,2k =\n2|E|\nX\ni=1\n2|E|\nX\nj=1\n[R\u22121]2k\u22121,i[J\u22121]i,j[R\u2212\u22a4]j,2k\n=\n\u22121\nck\n+\n|E|\nX\ni=k+1\ndik,\n(25)\nwhere\ndik := [R\u22121]2k\u22121,2i[R\u22121]2k,2i\u22121 \u2212[R\u22121]2k\u22121,2i\u22121[R\u22121]2k,2i\nci\n.\n4.4.3 Prefactoring\nConsider the rows and columns of K corresponding to an edge added during plane trian-\ngulation (Section 4.1). Re-order K to bring those rows and columns to the top left, so that\nthey form the a, b, and c of (17). Since the disagreement cost of a triangulation edge is\nzero, we now have a unity pivot: c = e0 = 1. This has two advantageous consequences:\nSize reduction: The unity pivot does not a\ufb00ect the value of the partition function.\nSince we are not interested in the marginal probability of triangulation edges (which after all\n23\nSchraudolph and Kamenetsky\nare not part of the original model), we do not need a or b either, once we have computed the\nSchur complement (19). We can therefore discard the \ufb01rst two rows and \ufb01rst two columns\nof K after factoring (17). Factoring out all triangulation edges in this fashion reduces the\nsize of K (resp. R and J) to range only over the edges of the original Ising model graph.\nThis reduces storage requirements and speeds up subsequent computation of the inverse\n(Figure 8, center).\nBoolean closure: The unity pivot eliminates the division from the Schur complement\n(19); in fact we show below that applying (18) to prefactor H \u2212H\u22a4yields a Schur com-\nplement that can be expressed as H\u2032 \u2212H\u2032\u22a4, where H\u2032 is again a Boolean matrix. This\nclosure property allows us to simply prefactor triangulation edges directly out of H without\nexplicitly constructing K.\nSpeci\ufb01cally, let K := H \u2212H\u22a4for a half-Kasteleyn matrix H with elements in {0, 1}.\nWithout loss of generality, assume that H and its transpose are disjoint, i.e., have no\nnon-zero element in common: H \u2299H\u22a4= 0, where \u2299denotes Hadamard (element-wise)\nmultiplication. Algorithm 4 respects this condition; violations would cancel in the con-\nstruction of K anyway. Expressing H as\nH =\n\uf8ee\n\uf8ef\uf8ef\uf8f0\n0\n1\na\u22a4\n1\n0\n0\nb\u22a4\n1\na2 b2\nC1\n\uf8f9\n\uf8fa\uf8fa\uf8fb,\n(26)\nwe can write K = H \u2212H\u22a4as (17) with a = a1 \u2212a2, b = b1 \u2212b2, c = 1, and C = C1 \u2212C\u22a4\n1.\nThe Schur complement (19) then becomes\nC\u2032 = C1 \u2212C\u22a4\n1 + (b1 \u2212b2)(a1 \u2212a2)\u22a4\u2212(a1 \u2212a2)(b1 \u2212b2)\u22a4\n= (C1 + b1a\u22a4\n1 + b2a\u22a4\n2 + a1b\u22a4\n2 + a2b\u22a4\n1 ) \u2212(C\u22a4\n1 + a1b\u22a4\n1 + a2b\u22a4\n2 + b2a\u22a4\n1 + b1a\u22a4\n2 )\n=: H\u2032 \u2212H\u2032\u22a4,\n(27)\nwhere\nH\u2032 = C1 + b1a\u22a4\n1 + b2a\u22a4\n2 + a1b\u22a4\n2 + a2b\u22a4\n1 .\n(28)\nIt remains to show that all elements of H\u2032 are in {0, 1}.\nBy de\ufb01nition of H (26), all\nelements of C1, a1, a2, b1, b2 are in {0, 1}, and by closure of multiplication in {0, 1} so are\ntheir products. Thus an element of H\u2032 will be in {0, 1} i\ufb00it is non-zero in at most one term\non the right-hand side of (28), or (equivalently) i\ufb00all pairs formed from the \ufb01ve terms in\nquestion are disjoint. This can indeed be shown to be the case:\n\u2022 Because H \u2299H\u22a4= 0, we know that neither a1 and a2 nor b1 and b2 can have any\nnon-zero elements in common, so b1a\u22a4\n1 and b2a\u22a4\n2 are disjoint, as are a1b\u22a4\n2 and a2b\u22a4\n1 .\n\u2022 By construction of H (Algorithm 4), a1 and b1 (resp. a2 and b2) can only have\nan element in common if the dual nodes on both sides of the corresponding edge are\nmembers of the same clique. This cannot happen because we explicitly ensure that\nthe graph becomes biconnected during plane triangulation (Section 4.1), so that an\nedge cannot border the same face of the model graph on both sides. Thus all four\nouter products in (28) are pairwise disjoint.\n24\nEfficient Exact Inference in Planar Ising Models\n\u2022 Finally, each outer product in (28) is disjoint from C1 as long as the edges being\nfactored out do not form a cut of the model graph (i.e., cycle of the dual).\nWe\nare prefactoring only edges added during triangulation; for these to form a cut the\nmodel graph would have to have been disconnected prior to triangulation. This can-\nnot happen here because we deal with (and eliminate) this possibility during earlier\npreprocessing (Section 2.3).\nIn summary, all \ufb01ve terms on the right-hand side of (28) are pairwise disjoint. Thus the\nSchur complement H\u2032 is a Boolean matrix as well, and can be computed from H (26) very\ne\ufb03ciently by replacing the additions and multiplications in (28) with bitwise OR and AND\noperations, respectively. As long as further triangulation edges remain in H\u2032, we then set\nH := H\u2032 and iteratively apply (26) and (28) so as to prefactor them out as well.\n5. Application to CRF Parameter Estimation\nOur algorithms can be applied to regularized maximum likelihood and maximum margin\nparameter estimation in conditional random \ufb01elds (CRFs). In a standard planar Ising CRF,\nthe disagreement costs in (2) are computed as Ek := \u03b8\u22a4xk, i.e., as inner products between\nlocal features (su\ufb03cient statistics) xk of the modeled data at each edge k, and corresponding\nparameters \u03b8 of the model. The conditional distribution P(y|x, \u03b8) (where x represents the\nunion of all local features) is then modeled as a Markov random \ufb01eld (16).\n5.1 Maximum Likelihood\nMaximum-likelihood (ML) CRF parameter estimation seeks to minimize wrt. \u03b8 the L2-\nregularized negative log likelihood\nLML(\u03b8) :=\n1\n2 \u03bb\u2225\u03b8\u22252 \u2212ln P(y\u2217|x, \u03b8)\n=\n1\n2 \u03bb\u2225\u03b8\u22252 + E(y\u2217|x, \u03b8) + ln Z(\u03b8|x)\n(29)\nof a given target labeling y\u2217,4 with regularization parameter \u03bb. This is a smooth, convex,\nnon-negative objective that can be optimized via gradient methods such as LBFGS, either\nin conventional batch mode (Nocedal, 1980; Liu and Nocedal, 1989) or online (Schraudolph\net al., 2007). The gradient of (29) with respect to the parameters \u03b8 is given by\n\u2202\n\u2202\u03b8LML(\u03b8) = \u03bb\u03b8 +\nX\nk\u2208E\n\u0010\n[k \u2208C(y\u2217)] \u2212P(k \u2208C(y|x, \u03b8))\n\u0011\nxk.\n(30)\nThe contribution of each edge k to the gradient (30) is given by the product between its\nlocal features xk and the di\ufb00erence between the indicator function for membership of k in\nthe cut induced by the target state y\u2217and the marginal probability of k being contained in\na cut, given x and \u03b8. We compute the latter via the inverse of the Kasteleyn matrix (24).\n4. For notational clarity we suppress here the fact that we are usually modeling a collection of data items;\nthe objective function for such a set is simply the sum of objectives for each individual item in it.\n25\nSchraudolph and Kamenetsky\n5.2 Maximum Margin\nFor maximum-margin (MM) parameter estimation (Taskar et al., 2004) we instead minimize\nLMM(\u03b8) :=\n1\n2 \u03bb\u2225\u03b8\u22252 + E(y\u2217|x, \u03b8) \u2212min\ny M(y|y\u2217, x, \u03b8)\n(31)\n=\n1\n2 \u03bb\u2225\u03b8\u22252 + E(y\u2217|x, \u03b8) \u2212E(\u02c6y|x, \u03b8) + d(\u02c6y|y\u2217),\nwhere \u02c6y := argminy M(y|y\u2217, x, \u03b8) is the worst margin violator, i.e., the state that minimizes,\nrelative to a given target state y\u2217,4 the margin energy\nM(y|y\u2217) := E(y) \u2212d(y|y\u2217),\n(32)\nwhere d(\u00b7|\u00b7) is a measure of divergence in state space.\nIf d(\u00b7|\u00b7) is a weighted Hamming\ndistance between induced cuts:\nd(y|y\u2217) :=\nX\nk\u2208E\n[[k \u2208C(y)] \u0338= [k \u2208C(y\u2217)]] vk,\n(33)\nwhere the vk > 0 are constant weighting factors (in the simplest case: all ones) on the edges\nof our Ising model, then it is easily veri\ufb01ed that the margin energy (32) is implemented (up\nto a shift that depends only on y\u2217) by an isomorphic Ising model with disagreement costs\nEk + (2[k \u2208C(y\u2217)] \u22121) vk.\n(34)\nWe can thus use our algorithm of Section 3.3 to e\ufb03ciently \ufb01nd the worst margin violator.5\nThe maximum-margin objective (31) is convex but non-smooth; its gradient is\n\u2202\n\u2202\u03b8LMM(\u03b8) = \u03bb\u03b8 +\nX\nk\u2208E\n\u0010\n[k \u2208C(y\u2217)] \u2212[k \u2208C(\u02c6y)]\n\u0011\nxk,\n(35)\ni.e., local features xk are multiplied by one of {\u22121, 0, 1}, depending on the membership of\nedge k in the cuts induced by y\u2217and \u02c6y, respectively. We can minimize (31) via bundle\nmethods, such as the BT bundle trust algorithm (Schramm and Zowe, 1992), making use\nof the convenient lower bound \u2200\u03b8: LMM(\u03b8) \u22650, which holds because\nmin\ny M(y|y\u2217, x, \u03b8) \u2264M(y\u2217|y\u2217, x, \u03b8) = E(y\u2217|x, \u03b8) \u2212d(y\u2217|y\u2217) = E(y\u2217|x, \u03b8).\n(36)\n6. Experiments\nWe now demonstrate the scalability of our approach to CRF parameter estimation (Sec-\ntion 5) on two simple computer vision problems: the synthetic binary image denoising task\nof Kumar and Hebert (2004, 2006), and the detection of segmentation boundaries in noisy\nmasks from the GrabCut Ground Truth image segmentation database (Rother et al., 2007a).\n5. Thomas and Middleton (2007) employ a similar approach to obtain the ground state from a given state\ny\u2217by setting up an isomorphic Ising model with disagreement costs (1 \u22122 [k \u2208C(y\u2217)])Ek.\n26\nEfficient Exact Inference in Planar Ising Models\n6.1 Synthetic Binary Image Denoising\nKumar and Hebert (2004, 2006) developed an image denoising benchmark problem for\nbinary random \ufb01elds based on four hand-drawn 64\u00d764 pixel images (Figure 9, top row).\nWe created 50 instances of each image corrupted with pink noise, produced by convolving a\nwhite noise image (all pixels i.i.d. uniformly random) with a Gaussian density of one pixel\nstandard deviation. Original and pink noise images were linearly mixed using signal-to-\nnoise (S/N) amplitude ratios of 1:n, n \u2208N. Figure 9 shows samples of the resulting noisy\ninstances for S/N ratios of 1:5 (second row) and 1:6 (fourth row).\nWe then employed square grid planar Ising CRFs to denoise the images, with edge\nenergies set to Eij := \u27e8[1, |xi \u2212xj|], \u03b8\u27e9, where xi is the pixel intensity at node i.\nThe\nperimeter of the grid was connected to a bias node with constant input and label: x0 =\ny0 = 0. Bias edges had their own parameters, yielding CRFs with four parameters and up\nto (for a 64\u00d764 grid) 4097 nodes and 8316 edges.\nThese systems were trained by maximum margin (MM) and maximum likelihood (ML)\nparameter estimation (Section 5) on the 50 noisy instances derived from the \ufb01rst image\n(Figure 9, left column) only. The gradient (35) resp. (30) was computed by adding the\ncontributions from all 50 training instances to that of the regularizer, with \u03bb = 100. We as-\nsessed the quality of the obtained parameters by determining (via the method of Section 3.3)\nthe maximum a posteriori (MAP) states\ny\u2217:= argmax\ny\nP(y|x, \u03b8) = argmin\ny\nE(y|x, \u03b8)\n(37)\nof the trained CRF for all 150 noisy instances of the other three images. Interpreting these\nMAP states as attempted reconstructions of the original images, we then calculated the\nprediction error rates for both nodes and edges of the model.\nAll experiments were carried out on a Linux PC with 3 GB RAM and dual Intel Pentium\n4 processors running at 3.6 GHz, each with 2 MB of level 2 cache.\n6.1.1 Noise Level\nWe \ufb01rst explored the limit of the ability of a full-size (64\u00d764) MM-trained Ising grid CRF\nto reconstruct the test images as the noise level increases. Rows 3 and 5 of Figure 9 show\nthe reconstructions obtained from the noisy instances shown in rows 2 and 4, respectively.\nAt low noise levels (n < 5) we obtained perfect reconstruction of the original images. At\nan S/N ratio of 1:5 the \ufb01rst subtle errors do creep in (Figure 9, third row), though less\nthan 0.5% of the nodes (0.3% of the edges) are predicted incorrectly. At the 1:6 S/N ratio,\nthese \ufb01gures increase to 2.1% for nodes and 1.15% for edges, and the errors become far\nmore noticeable (Figure 9, bottom row). For higher noise levels (n > 6) the reconstructions\nrapidly deteriorate as the noise \ufb01nally overwhelms the signal. At these noise levels our\nhuman visual system was no longer able to accurately reconstruct the images either.\n6.1.2 Maximum Margin vs. Maximum Likelihood Parameter Estimation\nNext we compared MM and ML parameter estimation at the S/N ratio of 1:6 (fourth row\nof Figure 9), where reconstruction begins to break down and any di\ufb00erences in performance\nshould be evident.\nTo make ML training computationally feasible, we subdivided each\n27\nSchraudolph and Kamenetsky\n(used for\ntraining)\n(used for\ntraining)\nFigure 9: Denoising of binary images by maximum-margin training of planar Ising grids;\nfrom top to bottom: original images (Kumar and Hebert, 2004, 2006), images\nmixed with pink noise in a 1:5 ratio, reconstruction via MAP state of 64\u00d764\nIsing grid CRF from those noisy instances, images mixed with pink noise in a 1:6\nratio, and reconstruction from those noisy instances. Only the left-most image\nwas used for training (max-margin CRF parameter estimation, \u03bb = 100), the\nothers for reconstruction.\n28\nEfficient Exact Inference in Planar Ising Models\nTable 1: Performance comparison of parameter estimation methods on the denoising task;\nimage reconstruction via MAP on the full (64\u00d764) model and images. The mini-\nmum in each result column is boldfaced.\nTrain Method\nPatch Size\nTrain Time\nEdge Error\nNode Error\nMM\n64 \u00d7 64\n490.4 s\n1.15 %\n2.10 %\n32 \u00d7 32\n174.7 s\n1.16 %\n2.15 %\n16 \u00d7 16\n91.4 s\n1.12 %\n1.98 %\n8 \u00d7 8\n78.1 s\n1.10 %\n1.83 %\nML\n5468.2 s\n1.11 %\n1.93 %\ntraining image into 64 8\u00d78 patches, then trained an 8\u00d78 grid CRF on those patches. For\nMM training we used the full (64\u00d764) images and model, as well as 32\u00d732, 16\u00d716, and 8\u00d78\npatches, so as to assess how this subdividision impacts the quality of the model. Testing\nalways employed the MAP state of the full model on the full images.\nTable 1 reports the edge and node errors obtained under each experimental condition.\nTo assess statistical signi\ufb01cance, we performed binomial pairwise comparison tests at a 95%\ncon\ufb01dence level against the null hypothesis that each of the two algorithms being compared\nhas an equal (50%) chance of outperforming the other on a given test image.\nWe found no statistically signi\ufb01cant di\ufb00erence here between 8\u00d78 CRFs trained by MM\nvs. ML. However, ML training took 70 times as long to achieve this, so MM training is\nmuch preferable on computational grounds.\nCounter to our expectations, the node and edge errors suggest that MM training actually\nworks better on small (8\u00d78 and 16\u00d716) image patches. We surmise that this is because\nsmall patches have a relatively larger perimeter, leading to better training of the bias edges.\nPairwise comparison tests, however, only found the node error for the 32\u00d732 patch-trained\nCRF to be signi\ufb01cantly worse than for the smaller patches; all other di\ufb00erences were below\nthe signi\ufb01cance threshold. What we can con\ufb01dently state is that subdividing the images\ninto small patches did not hurt performance, and yielded much shorter training times.\n6.1.3 Maximum A Posteriori vs. Marginal Posterior Reconstruction\nFox and Nicholls (2001) have argued that the MAP state does not summarize well the\ninformation in the posterior distribution of an Ising model of noisy binary images, and\nproposed reconstruction via the marginal posterior mode (MPM) instead. For binary labels,\nthe MPM is simply obtained by thresholding the marginal posterior node probabilities:\n(\u2200i \u2208V) yi := [P(yi = 1 | x, \u03b8) > 0.5]. In our Ising models, however, we have marginal\nposterior probabilities for edges (Section 4.4.2), and infer node states from graph cuts\n(Algorithm 1). Here implementing the MPM runs into a di\ufb03culty: since the edge set\n{k \u2208E : P(k \u2208C(y|x, \u03b8)) > 0.5}\n(38)\nmay not be a cut of the model graph, hence may not unambiguously induce a node state.\nWhat we really need is the cut closest (in some given sense) to (38). For this purpose we\n29\nSchraudolph and Kamenetsky\nTable 2: Comparison of reconstruction methods on the denoising task, using the parameters\nof an MM-trained 8\u00d78 CRF. The minimum in each result column is boldfaced;\n\u201ctest time\u201d is the time required to reconstruct all 150 images.\nTest Method\nPatch Size\nTest Time\nEdge Error\nNode Error\nMAP\n64\u00d764\n3.7 s\n1.10 %\n1.83 %\n8\u00d78\n3.2 s\n1.96 %\n5.21 %\nM3P\n397.5 s\n1.95 %\n3.32 %\nformulate the state y+ with the maximal minimum marginal posterior (M3P):\ny+ := argmax\ny\u2032\nmin\nk\u2208E\n\u001a\nP(k \u2208C(y|x, \u03b8))\nif k \u2208C(y\u2032),\n1 \u2212P(k \u2208C(y|x, \u03b8))\notherwise.\n(39)\nIn other words, the M3P state (39) is induced by the cut whose edges (and those of its\ncomplement) have the largest minimum marginal probability. We can e\ufb03ciently compute\ny+ as follows:\n1. Find the minimum-weight spanning tree E+ \u2286E of the model graph G(V, E) with\nedge weights \u2212|P(k \u2208C(y|x, \u03b8)) \u22120.5|. (This can be done in O(|E| log |E|) time.)\n2. Run Algorithm 1 on G(V, E+) to \ufb01nd y+ as the state induced in the spanning tree\nby the MPM edge set (38).\nSince G(V, E+) is a tree, it contains no cycles, and Algorithm 1 will therefore unambiguously\nidentify the M3P state.\nTable 2 lists the reconstruction errors achieved on the denoising task via MAP vs. M3P\nstates, using the parameters of the MM-trained 8\u00d78 CRF which gave the best performance\nin Section 6.1.2. (We obtained comparable results for ML training on 8\u00d78 patches and MM\ntraining on full images.) Figure 10 shows representative sample reconstructions.\nWhen reconstructing 8\u00d78 patches, both MAP and M3P states appear to achieve virtu-\nally the same edge error. The binomial pairwise comparison test, however, reveals M3P to\nconsistently outperform MAP here, even at a 99 % con\ufb01dence level. This trend is con\ufb01rmed\nby M3P\u2019s substantially lower node error. For comparison, an oracle that always picks the\nbetter of the two label-symmetric node states would yield a node error of 2.8 % here; the\nexcess node error relative to that baseline is almost 5 times lower for M3P than for MAP.\nThis does con\ufb01rm the limitations of the MAP state for reconstruction, as argued by Fox\nand Nicholls (2001).\nSince the M3P state (39) requires calculation of the edge marginals, however, it takes\nover two order of magnitude longer to obtain than the MAP state on an 8\u00d78 patch, and is\ncomputationally infeasible for us to compute for the entire 64\u00d764 image. The MAP state\non the entire image clearly outperforms any reconstruction from 8\u00d78 patches in terms of\nboth edge and node error. The impressive scalability of the MAP state computation via\nblossom-shrinking (Section 3.3) thus in practice overrules here the theoretical advantage of\nreconstruction based on marginal probabilities.\n30\nEfficient Exact Inference in Planar Ising Models\nFigure 10: Image reconstructions on the denoising task; columns from left to right: Noisy\n64\u00d764 image, MAP reconstruction of full image, MAP reconstruction of 8\u00d78\npatches, and M3P reconstruction of 8\u00d78 patches.\n6.2 Boundary Detection\nTo further scale up our approach, we designed a simple boundary detection task based\non images from the GrabCut Ground Truth image segmentation database (Rother et al.,\n2007a). We took 100\u00d7100 pixel subregions of images that depicted a segmentation bound-\nary, and corrupted the segmentation mask with pink noise, produced by convolving a white\nnoise image (all pixels i.i.d. uniformly random) with a Gaussian density with one pixel\nstandard deviation.\nWe then employed a planar Ising model to recover the original boundary \u2014 namely,\na 100\u00d7100 square grid with one additional edge pegged to a high energy, encoding prior\nknowledge that the bottom left and top right corners of the grid depict di\ufb00erent regions.\nAs before, the energy of the other edges was set to Eij := \u27e8[1, |xi \u2212xj|], \u03b8\u27e9, where xi is the\npixel intensity at node i. We did not employ a bias node for this task, and simply set the\nregularization constant to \u03bb = 1.\nNote that this is a huge model: 10 000 nodes and 19 801 edges. Computing the partition\nfunction or marginals would require inverting a Kasteleyn matrix with over 1.5\u00b7109 entries;\nminimizing (29) is therefore computationally infeasible for us. Computing a ground state\n31\nSchraudolph and Kamenetsky\nFigure 11: Boundary detection by maximum-margin training of planar Ising grids; columns\nfrom left to right: original image, original segmentation mask, noisy mask for\nS/N ratio of 1:8 (top two rows) resp. 1:7 (bottom two rows), and MAP segmen-\ntation obtained from the Ising grid CRF trained on the noisy mask.\nvia the algorithm described in Section 3, by contrast, takes only 0.3 CPU seconds on an\nApple MacBook with 2.2 GHz Intel Core2 Duo processor.6\nWe can therefore e\ufb03ciently\nminimize (31) to obtain the MM parameter vector \u03b8\u2217, then compute the CRF\u2019s MAP (i.e.,\nground) state for rapid prediction.\nAs before, we titrated for the smallest S/N ratio of the form 1:n for which we obtained\na good segmentation; depending on the image this occurred for n = 7 or 8. Figure 11 (right\n6. In scalability tests our code was able to compute the MAP state of a 400\u00d7400 grid in 0.85 CPU seconds.\n32\nEfficient Exact Inference in Planar Ising Models\ncolumn) shows that at these noise levels our approach is capable of recovering the original\nsegmentation boundary quite well, with less than 1% of nodes mislabeled. For S/N ratios\nof 1:9 and lower the system was unable to locate the boundary; for S/N ratios of 1:6 and\nhigher we obtained perfect reconstruction. Again this corresponded closely to our human\nability to visually locate the segmentation boundary accurately.\n7. Discussion and Outlook\nWe have proposed an alternative algorithmic framework for e\ufb03cient exact inference in\nbinary graphical models, which replaces the submodularity constraint of graph cut methods\nwith a planarity constraint. Besides proving e\ufb03cient and e\ufb00ective in \ufb01rst experiments, our\napproach opens up a number of interesting research directions to be explored:\nOur algorithms can all be extended to nonplanar graphs, at a cost exponential in the\ngenus of the embedding. We are currently developing these extensions, which may prove of\ngreat practical value for graphs that are \u201calmost\u201d planar; examples include road networks\n(where edge crossings arise from overpasses without on-ramps) and graphs describing the\ntertiary structure of proteins (Vishwanathan et al., 2007).\nOur algorithms also provide a foundation for e\ufb00orts to develop e\ufb03cient approximate\ninference methods for nonplanar Ising models.\nOur method for calculating the ground\nstate (Section 3) actually works for nonplanar graphs whose ground state does not contain\nfrustrated non-contractible cycles. The QPBO graph cut method (Kolmogorov and Rother,\n2007) \ufb01nds ground states that do not contain any frustrated cycles, and otherwise yields a\npartial labeling. Can we likewise obtain a partial labeling of ground states with frustrated\nnon-contractible cycles?\nThe existence of two distinct tractable frameworks for inference in binary graphical\nmodels implies a more powerful hybrid: Consider a graph each of whose biconnected com-\nponents is either planar or submodular. In its entirety, this graph may be neither planar nor\nsubmodular, yet e\ufb03cient exact inference in it is clearly possible by applying the appropriate\nframework to each component, then combining the results (Section 2.4.2). Can this hybrid\napproach be extended to cover less obvious situations?\nAcknowledgments\nEarlier drafts of this paper have appeared on the arXiv preprint server (Schraudolph and\nKamenetsky, 2008) and (in condensed form) at the 2008 NIPS conference (Schraudolph and\nKamenetsky, 2009). We thank the anonymous NIPS reviewers for their valuable feedback.\nNICTA is a national research institute with a charter to build Australia\u2019s pre-eminent\ncentre of excellence for information and communications technology (ICT). NICTA is build-\ning capabilities in ICT research, research training and commercialisation for the generation\nof national bene\ufb01t. NICTA is funded by the Australian Government as represented by the\nDepartment of Broadband, Communications and the Digital Economy and the Australian\nResearch Council through the ICT Centre of Excellence program.\n33\nSchraudolph and Kamenetsky\nReferences\nFrancisco Barahona. On the computational complexity of Ising spin glass models. Journal\nof Physics A: Mathematical, Nuclear and General, 15(10):3241\u20133253, 1982.\nPeter Benner, Ralph Byers, Heike Fassbender, Volker Mehrmann, and David Watkins.\nCholesky-like factorizations of skew-symmetric matrices. Electronic Transactions on Nu-\nmerical Analysis, 11:85\u201393, 2000.\nJ. Besag. On the statistical analysis of dirty pictures. Journal of the Royal Statistical Society\nB, 48(3):259\u2013302, 1986.\nI. Bieche, R. Maynard, R. Rammal, and J. P. Uhry. On the ground states of the frustration\nmodel of a spin glass by a matching method of graph theory. Journal of Physics A:\nMathematical, Nuclear and General, 13:2553\u20132576, 1980.\nJohn M. Boyer and Wendy J. Myrvold.\nOn the cutting edge:\nSimpli\ufb01ed O(n) pla-\nnarity by edge addition. Journal of Graph Algorithms and Applications, 8(3):241\u2013273,\n2004.\nReference implementation (C source code):\nhttp://jgaa.info/accepted/2004/\nBoyerMyrvold2004.8.3/planarity.zip.\nYuri Boykov, Olga Veksler, and Ramin Zabih. Fast approximate energy minimization via\ngraph cuts. IEEE Transactions on Pattern Analysis and Machine Intelligence, 23(11):\n1222\u20131239, 2001.\nJames R. Bunch. A note on the stable decomposition of skew-symmetric matrices. Mathe-\nmatics of Computation, 38(158):475\u2013479, April 1982.\nWilliam Cook and Andr\u00b4e Rohe. Computing minimum-weight perfect matchings. INFORMS\nJournal on Computing, 11(2):138\u2013148, 1999. C source code available at http://www.isye.\ngatech.edu/~wcook/blossom4/.\nJack Edmonds. Maximum matching and a polyhedron with 0,1-vertices. Journal of Research\nof the National Bureau of Standards, 69B:125\u2013130, 1965a.\nJack Edmonds. Paths, trees, and \ufb02owers. Canadian Journal of Mathematics, 17:449\u2013467,\n1965b.\nMichael E. Fisher. Statistical mechanics of dimers on a plane lattice. Physical Review, 124\n(6):1664\u20131672, 1961.\nMichael E. Fisher. On the dimer solution of planar Ising models. Journal of Mathematical\nPhysics, 7(10):1776\u20131781, 1966.\nC. Fox and G. K. Nicholls. Exact map states and expectations from perfect sampling: Greig,\nPorteous and Seheult revisited. In A. Mohammad-Djafari, editor, Bayesian Inference and\nMaximum Entropy Methods in Science and Engineering, volume 568 of American Institute\nof Physics Conference Series, pages 252\u2013263, 2001.\n34\nEfficient Exact Inference in Planar Ising Models\nZvi Galil, Silvio Micali, and Harold N. Gabow. An O(EV logV ) algorithm for \ufb01nding a\nmaximal weighted matching in general graphs. SIAM Journal of Computing, 15:120\u2013130,\n1986.\nAmir Globerson and Tommi Jaakkola. Approximate inference using planar graph decompo-\nsition. In B. Sch\u00a8olkopf, J. Platt, and T. Hofmann, editors, Advances in Neural Information\nProcessing Systems 19, pages 473\u2013480, Cambridge, MA, 2007. MIT Press.\nD. M. Greig, B. T. Porteous, and A. H. Seheult. Exact maximum a posteriori estimation\nfor binary images. Journal of the Royal Statistical Society B, 51(2):271\u2013279, 1989.\nCarsten Gutwenger and Petra Mutzel. Graph embedding with minimum depth and max-\nimum external face. In G. Liotta, editor, Graph Drawing 2003, volume 2912 of Lecture\nNotes in Computer Science, pages 259\u2013272. Springer Verlag, 2004.\nF. Hamze and N. de Freitas. From \ufb01elds to trees. In Uncertainty in Arti\ufb01cial Intelligence\n(UAI), 2004.\nJohn E. Hopcroft and Robert E. Tarjan. Algorithm 447: E\ufb03cient algorithms for graph\nmanipulation. Communications of the ACM, 16(6):372\u2013378, 1973.\nPieter W. Kasteleyn. The statistics of dimers on a lattice: I. the number of dimer arrange-\nments on a quadratic lattice. Physica, 27(12):1209\u20131225, 1961.\nPieter W. Kasteleyn.\nDimer statistics and phase transitions.\nJournal of Mathematical\nPhysics, 4(2):287\u2013293, 1963.\nPieter W. Kasteleyn. Graph theory and crystal physics. In Frank Harary, editor, Graph\nTheory and Theoretical Physics, chapter 2, pages 43\u2013110. Academic Press, London and\nNew York, 1967.\nVladimir Kolmogorov and Carsten Rother. Minimizing nonsubmodular functions with graph\ncuts \u2013 a review. IEEE Trans. Pattern Analysis and Machine Intelligence, 29(7):1274\u20131279,\nJuly 2007.\nVladimir Kolmogorov and Ramin Zabih. What energy functions can be minimized via graph\ncuts? IEEE Trans. Pattern Analysis and Machine Intelligence, 26(2):147\u2013159, Feb. 2004.\nSanjiv Kumar and Martial Hebert. Discriminative \ufb01elds for modeling spatial dependencies\nin natural images. In S. Thrun, L. Saul, and B. Sch\u00a8olkopf, editors, Advances in Neural\nInformation Processing Systems 16, 2004.\nSanjiv Kumar and Martial Hebert. Discriminative random \ufb01elds. International Journal of\nComputer Vision, 68(2):179\u2013201, 2006. http://www-2.cs.cmu.edu/~skumar/DRF_IJCV.pdf.\nFrauke Liers and Gregor Pardella. A simple max-cut algorithm for planar graphs. Technical\nReport zaik2008-579, Zentrum f\u00a8ur Angewandte Informatik, Universit\u00a8at K\u00a8oln, September\n2008. http://www.zaik.uni-koeln.de/~paper/preprints.html?show=zaik2008-579.\nDong C. Liu and Jorge Nocedal. On the limited memory BFGS method for large scale\noptimization. Mathematical Programming, 45(3):503\u2013528, 1989.\n35\nSchraudolph and Kamenetsky\nKurt Mehlhorn and Guido Sch\u00a8afer. Implementation of O(nm log n) weighted matchings in\ngeneral graphs: The power of data structures. ACM Journal of Experimental Algorithms,\n7:138\u2013148, 2002.\nArticle and C source code (requires LEDA 4.2 or higher) at http:\n//www.jea.acm.org/2002/MehlhornMatching/.\nJorge Nocedal.\nUpdating quasi-Newton matrices with limited storage.\nMathematics of\nComputation, 35:773\u2013782, 1980.\nGregor Pardella and Frauke Liers. Exact ground states of huge two-dimensional planar ising\nspin glasses. Technical Report 0801.3143, arXiv, January 2008. http://aps.arxiv.org/\nabs/0801.3143, to appear in Phys Rev E.\nC. Rother, V. Kolmogorov, A. Blake, and M. Brown. GrabCut ground truth database. http:\n//research.microsoft.com/vision/cambridge/i3l/segmentation/GrabCut.htm, 2007a.\nCarsten Rother, Vladimir Kolmogorov, Victor Lempitsky, and Martin Szummer. Optimiz-\ning binary MRFs via extended roof duality. In Proc. IEEE Conf. Computer Vision and\nPattern Recognition, Minneapolis, MN, June 2007b.\nHelga Schramm and Jochem Zowe. A version of the bundle idea for minimizing a non-\nsmooth function: Conceptual idea, convergence analysis, numerical results.\nSIAM J.\nOptimization, 2:121\u2013152, 1992.\nNicol N. Schraudolph and Dmitry Kamenetsky. E\ufb03cient exact inference in planar Ising\nmodels. Technical Report 0810.4401, arXiv, October 2008. http://aps.arxiv.org/abs/\n0810.4401.\nNicol N. Schraudolph and Dmitry Kamenetsky. E\ufb03cient exact inference in planar Ising\nmodels. In Advances in Neural Information Processing Systems 21, Cambridge, MA, to\nappear 2009. MIT Press.\nNicol N. Schraudolph, Jin Yu, and Simon G\u00a8unter. A stochastic quasi-Newton method for\nonline convex optimization. In Proc. 11th Intl. Conf. Arti\ufb01cial Intelligence and Statistics\n(AIstats), San Juan, Puerto Rico, March 2007. Society for Arti\ufb01cial Intelligence and\nStatistics. http://nic.schraudolph.org/pubs/SchYuGue07.pdf.\nB. Taskar, C. Guestrin, and D. Koller. Max-margin Markov networks. In S. Thrun, L. Saul,\nand B. Sch\u00a8olkopf, editors, Advances in Neural Information Processing Systems 16, pages\n25\u201332, Cambridge, MA, 2004. MIT Press.\nCreighton K. Thomas and A. Alan Middleton. Matching Kasteleyn cities for spin glass\nground states. Physical Review B, 76(22):22406, 2007.\nS. V. N. Vishwanathan, Karsten Borgwardt, and Nicol N. Schraudolph. Fast computation\nof graph kernels. In B. Sch\u00a8olkopf, J. Platt, and T. Hofmann, editors, Advances in Neural\nInformation Processing Systems 19, Cambridge MA, 2007. MIT Press.\nMartin J. Wainwright, Tommi S. Jaakkola, and Alan S. Willsky. Tree-based reparameteri-\nzation framework for analysis of sum-product and related algorithms. IEEE Transactions\non Information Theory, 49(5):1120\u20131146, 2003.\n36\nEfficient Exact Inference in Planar Ising Models\nMartin J. Wainwright, Tommi S. Jaakkola, and Alan S. Willsky. A new class of upper\nbounds on the log partition function. IEEE Transactions on Information Theory, 51(7):\n2313\u20132335, 2005.\nYair Weiss.\nComparing the mean \ufb01eld method and belief propagation for approximate\ninference in MRFs. In David Saad and Manfred Opper, editors, Advanced Mean Field\nMethods. MIT Press, 2001.\nArthur T. White and Lowell W. Beineke. Topological graph theory. In Lowell W. Beineke\nand Robin J. Wilson, editors, Selected Topics in Graph Theory, chapter 2, pages 15\u201349.\nAcademic Press, 1978.\nAaron Windsor. Planar graph functions for the boost graph library. C++ source code, boost\n\ufb01le vault: http://boost-consulting.com/vault/index.php?directory=Algorithms/graph,\n2007.\nJ.S. Yedidia, W.T. Freeman, and Y. Weiss. Understanding belief propagation and its gen-\neralizations. In Exploring Arti\ufb01cial Intelligence in the New Millennium, chapter 8, pages\n239\u2013236. Science & Technology Books, 2003.\n37\n",
        "sentence": " Note that the undirected graph characterization has also been used in exact inference of planar graphs [30].",
        "context": "1. Introduction\nUndirected graphical models are a popular tool in machine learning; they represent real-\nvalued energy functions of the form\nE\u2032(y) :=\nX\ni\u2208V\nE\u2032\ni(yi)\n+\nX\n(i,j)\u2208E\nE\u2032\nij(yi, yj) ,\n(1)\nthe latter usage, which views embeddings as equivalence classes of graph drawings charac-\nterized by identical cyclic ordering of the edges incident upon each vertex. For instance,\n1986.\nAmir Globerson and Tommi Jaakkola. Approximate inference using planar graph decompo-\nsition. In B. Sch\u00a8olkopf, J. Platt, and T. Hofmann, editors, Advances in Neural Information\nProcessing Systems 19, pages 473\u2013480, Cambridge, MA, 2007. MIT Press."
    },
    {
        "title": "Dynamic graph cuts for efficient inference in Markov random fields",
        "author": [
            "P. Kohli",
            "P. Torr"
        ],
        "venue": "IEEE Trans. Pattern Anal. Mach. Intell., vol. 29, no. 12, pp. 2079\u20132088, 2007.",
        "citeRegEx": "31",
        "shortCiteRegEx": null,
        "year": 2007,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Furthermore, if the difference between m(x) and m(x) is only related to a small number of variables, the maxflow computation of last iteration can be efficiently reused [31].",
        "context": null
    },
    {
        "title": "Beyond loose LP-relaxations: Optimizing MRFs by repairing cycles",
        "author": [
            "N. Komodakis",
            "N. Paragios"
        ],
        "venue": "ECCV, 2008.",
        "citeRegEx": "32",
        "shortCiteRegEx": null,
        "year": 2008,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Besides, combining ESSP with other recent optimization methods, such as [29], [32], is an interesting direction for future work.",
        "context": null
    }
]