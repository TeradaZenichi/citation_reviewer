,abstract,faithfulness,precision,recall,semantic_similarity,pdf,pdf-faithfulness,pdf-precision,pdf-recall,pdf-semantic_similarity,precision_recall,pdf-precision_recall
Taming the monster: A fast and simple algorithm for contextual bandits,arxiv Library,0.0,0.15873015873015872,0.5555555555555556,0.899468713449008,arxiv Library,0.0,0.11428571428571428,0.5070422535211268,0.9034556029673104,,
Minimax policies for combinatorial prediction,,,,,,,,,,,,
Regret in online combinatorial optimization,arxiv Library,0.0,0.3,0.06382978723404255,0.7590160644254509,arxiv Library,0.0,0.3,0.1016949152542373,0.8411679310484534,,
The nonstochastic multiarmed bandit problem,crossref,0.0,1.0,0.0,0.7019992385653937,,,,,,,
Contextual bandit algorithms with supervised learning guarantees,arxiv Library,0.0,0.2631578947368421,0.05154639175257732,0.7392249347260454,arxiv Library,0.0,0.631578947368421,0.18181818181818182,0.8760432194265517,,
Counterfactual reasoning and learning systems: The example of computational advertising,,,,,,,,,,,,
Regret analysis of stochastic and nonstochastic multi-armed bandit problems,crossref,0.0,0.0,0.0,0.6714430846825848,,,,,,,
Combinatorial pure exploration of multi-armed bandits,,,,,,,,,,,,
Combinatorial multi-armed bandit: General framework and applications,,,,,,,,,,,,
Contextual bandits with linear payoff functions,,,,,,,,,,,,
Efficient optimal learning for contextual bandits,arxiv Library,0.0,0.16666666666666666,0.08450704225352113,0.730294135230847,arxiv Library,0.0,0.4166666666666667,0.21739130434782608,0.8670812151865555,,
Parametric bandits: The generalized linear case,,,,,,,,,,,,
The on-line shortest path problem under partial monitoring,,,,,,,,,,,,
Non-stochastic bandit slate problems,,,,,,,,,,,,
Matroid bandits: Fast combinatorial optimization with learning,arxiv Library,1.0,1.0,0.0,0.6462451738935487,arxiv Library,0.0,1.0,0.0,0.6727577197432767,,
Tight regret bounds for stochastic combinatorial semi-bandits,,,,,,,,,,,,
The epoch-greedy algorithm for multi-armed bandits with side information,,,,,,,,,,,,
A contextual-bandit approach to personalized news article recommendation,crossref,0.0,1.0,0.0,0.7019992385653937,,,,,,,
Contextual combinatorial bandit and its application on diversified online recommendation,crossref,0.0,1.0,0.0,0.7019992385653937,,,,,,,
The analysis of randomized and nonrandomized AIDS treatment trials using a new approach to causal inference in longitudinal studies,,,,,,,,,,,,
Hanson-wright inequality and sub-gaussian concentration,crossref,0.0,0.0,0.0,0.6797202322494734,,,,,,,
Linearly parameterized bandits,arxiv Library,0.0,1.0,0.0,0.6528385233081975,arxiv Library,0.0,1.0,0.0,0.6827726942191689,,
User-Friendly Tail Bounds for Sums of Random Matrices,crossref,0.0,0.0,0.0,0.677056559020581,,,,,,,
Algorithms for adversarial bandit problems with multiple plays,crossref,0.0,1.0,0.0,0.7019992385653937,,,,,,,
The proof of this theorem is similar in spirit to a related theorem,,,,,,,,,,,,
The first three are fairly straightforward and the proof of the later two are based on the arguments,,,,,,,,,,,,
Freedmanâ€™s Inequality),,,,,,,,,,,,
