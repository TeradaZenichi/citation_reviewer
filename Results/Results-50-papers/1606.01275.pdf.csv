,abstract,faithfulness,precision,recall,semantic_similarity,pdf,pdf-faithfulness,pdf-precision_recall,pdf-semantic_similarity,precision_recall,pdf-precision,pdf-recall
Learning from noisy examples,crossref,0.0,0.0,0.0,0.6779866844303295,,,,,,,
Learning mixtures of arbitrary gaussians,crossref,0.0,0.0,0.0,0.7085914556904208,,,,,,,
Combining labeled and unlabeled data with co-training,crossref,0.0,0.0,0.0,0.6820769539524231,,,,,,,
Learning mixtures of gaussians,crossref,0.0,0.0,0.0,0.7064680424509866,,,,,,,
PAC learning with constant-partition classification noise and applications to decision tree induction,,,,,,,,,,,,
Learningmixtures of product distributions over discrete domains,,,,,,,,,,,,
PAC learning axis-aligned mixtures of Gaussians with no separation assumption,crossref,0.0,0.0,0.0,0.7085914556904208,,,,,,,
Decision theoretic generalizations of the PAC model for neural net and other learning applications,crossref,0.0,1.0,0.0,0.7019992385653937,,,,,,,
Learning mixtures of spherical gaussians: moment methods and spectral decompositions,arxiv Library,0.9,1.0,0.0,0.6499156338650318,arxiv Library,0.0,,0.6791645599455519,,1.0,0.0
Learning boolean formulas,crossref,0.0,0.21428571428571427,0.26373626373626374,0.7963698856517573,,,,,,,
Cryptographic limitations on learning boolean formulae and finite automata,crossref,0.5,0.35,0.12173913043478261,0.8317377566475754,,,,,,,
Efficient noise-tolerant learning from statistical queries,crossref,0.7,0.29411764705882354,0.3191489361702128,0.8318083477364514,,,,,,,
On the learnability of discrete distributions,crossref,0.0,1.0,0.0,0.7019992385653937,,,,,,,
Asymptotic methods in statistical decision theory,crossref,0.0,0.0,0.0,0.6775181401339253,,,,,,,
Prediction-preserving reducibility,crossref,0.0,0.0,0.0,0.6765989087386055,,,,,,,
CN = CPCN,crossref,0.0,0.0,0.0,0.6809078537321118,,,,,,,
The strength of weak learnability,crossref,0.0,0.0,0.0,0.6765989087386055,,,,,,,
A theory of the learnable,crossref,0.0,0.0,0.0,0.6823350134621644,,,,,,,
A spectral algorithm for learning mixture models,crossref,0.0,1.0,0.0,0.7019992385653937,,,,,,,
"Assouad, fano, and le cam",crossref,0.0,1.0,0.0,0.7019680454290691,,,,,,,
"We say that a probability model T is good if err(T ) ≤ 4ε, and bad otherwise. We know that T is guaranteed to contain at least one good model",,,,,,,,,,,,
