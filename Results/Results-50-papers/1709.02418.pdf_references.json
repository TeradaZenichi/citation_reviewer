[
    {
        "title": "Generalization bounds for the area under the ROC curve",
        "author": [
            "S. Agarwal",
            "T. Graepel",
            "R. Herbrich",
            "S. Har-Peled",
            "D. Roth"
        ],
        "venue": "Journal of Machine Learning Research, 393\u2013425.",
        "citeRegEx": "Agarwal et al\\.,? 2005",
        "shortCiteRegEx": "Agarwal et al\\.",
        "year": 2005,
        "abstract": "",
        "full_text": "",
        "sentence": " The AUC has two mathematically equivalent definitions (Tyler and Chen, 2000; Agarwal et al., 2005): (1) the AUC is the Area under the Receiver Operating Characteristics (ROC) curve, which plots the true positive rate against the false positive rate of a classifier on some test set.",
        "context": null
    },
    {
        "title": "The ladder: A reliable leaderboard for machine learning competitions",
        "author": [
            "A. Blum",
            "M. Hardt"
        ],
        "venue": "arXiv preprint arXiv:1502.04585.",
        "citeRegEx": "Blum and Hardt,? 2015",
        "shortCiteRegEx": "Blum and Hardt",
        "year": 2015,
        "abstract": "The organizer of a machine learning competition faces the problem of\nmaintaining an accurate leaderboard that faithfully represents the quality of\nthe best submission of each competing team. What makes this estimation problem\nparticularly challenging is its sequential and adaptive nature. As participants\nare allowed to repeatedly evaluate their submissions on the leaderboard, they\nmay begin to overfit to the holdout data that supports the leaderboard. Few\ntheoretical results give actionable advice on how to design a reliable\nleaderboard. Existing approaches therefore often resort to poorly understood\nheuristics such as limiting the bit precision of answers and the rate of\nre-submission.\n  In this work, we introduce a notion of \"leaderboard accuracy\" tailored to the\nformat of a competition. We introduce a natural algorithm called \"the Ladder\"\nand demonstrate that it simultaneously supports strong theoretical guarantees\nin a fully adaptive model of estimation, withstands practical adversarial\nattacks, and achieves high utility on real submission files from an actual\ncompetition hosted by Kaggle.\n  Notably, we are able to sidestep a powerful recent hardness result for\nadaptive risk estimation that rules out algorithms such as ours under a\nseemingly very similar notion of accuracy. On a practical note, we provide a\ncompletely parameter-free variant of our algorithm that can be deployed in a\nreal competition with no tuning required whatsoever.",
        "full_text": "The Ladder: A Reliable Leaderboard for\nMachine Learning Competitions\nAvrim Blum\nMoritz Hardt\nFebruary 17, 2015\nAbstract\nThe organizer of a machine learning competition faces the problem of maintaining\nan accurate leaderboard that faithfully represents the quality of the best submission of\neach competing team. What makes this estimation problem particularly challenging is its\nsequential and adaptive nature. As participants are allowed to repeatedly evaluate their\nsubmissions on the leaderboard, they may begin to over\ufb01t to the holdout data that supports\nthe leaderboard. Few theoretical results give actionable advice on how to design a reliable\nleaderboard. Existing approaches therefore often resort to poorly understood heuristics such\nas limiting the bit precision of answers and the rate of re-submission.\nIn this work, we introduce a notion of leaderboard accuracy tailored to the format of a\ncompetition. We introduce a natural algorithm called the Ladder and demonstrate that it si-\nmultaneously supports strong theoretical guarantees in a fully adaptive model of estimation,\nwithstands practical adversarial attacks, and achieves high utility on real submission \ufb01les\nfrom an actual competition hosted by Kaggle.\nNotably, we are able to sidestep a powerful recent hardness result for adaptive risk\nestimation that rules out algorithms such as ours under a seemingly very similar notion\nof accuracy. On a practical note, we provide a completely parameter-free variant of our\nalgorithm that can be deployed in a real competition with no tuning required whatsoever.\n1\nIntroduction\nMachine learning competitions have become an extremely popular format for solving prediction\nand classi\ufb01cation problems of all kinds. A number of companies such as Net\ufb02ix have organized\nmajor competitions in the past and some start-ups like Kaggle specialize in hosting machine\nlearning competitions. In a typical competition hundreds of participants will compete for\nprize money by repeatedly submitting classi\ufb01ers to the host in an attempt to improve on their\npreviously best score. The score re\ufb02ects the performance of the classi\ufb01er on some subset of the\ndata, which are typically partitioned into two sets: a training set and a test set. The training set\nis publicly available with both the individual instances and their corresponding class labels. The\ntest set is publicly available as well, but the class labels are withheld. Predicting these missing\nclass labels is the goal of the participant and a valid submission is simply a list of labels\u2014one\nfor each point in the test set.\nThe central component of any competition is the leaderboard which ranks all teams in the\ncompetition by the score of their best submission. This leads to the fundamental problem of\nmaintaining a leaderboard that accurately re\ufb02ects the true strength of a classi\ufb01er. What makes\nthis problem so challenging is that participants may begin to incorporate the feedback from the\n1\narXiv:1502.04585v1  [cs.LG]  16 Feb 2015\nleaderboard into the design of their classi\ufb01er thus creating a dependence between the classi\ufb01er\nand the data on which it is evaluated. In such cases, it is well known that the holdout set\nno longer gives an unbiased estimate of the classi\ufb01er\u2019s true performance. To counteract this\nproblem, existing solutions such as the one used by Kaggle further partition the test set into two\nparts. One part of the test set is used for computing scores on the public leaderboard. The other\nis used to rank all submissions after the competition ended. This \ufb01nal ranking is often referred\nto as the private leaderboard. While this solution increases the quality of the private leaderboard,\nit does not address the problem of maintaining accuracy on the public leaderboard. Indeed,\nnumerous posts on the forums of Kaggle report on the problem of \u201cover\ufb01tting to the holdout\u201d\nmeaning that some scores on the public leaderboard are in\ufb02ated compared to \ufb01nal scores. To\nmitigate this problem Kaggle primarily restricts the rate of re-submission and to some extent\nthe numerical precision of the released scores.\nYet, in spite of its obvious importance, there is relatively little theory on how to design a\nleaderboard with rigorous quality guarantees. Basic questions remain di\ufb03cult to assess, such as,\ncan we a priori quantify how accurate existing leaderboard mechanisms are and can we design\nbetter methods?\nWhile the theory of estimating the true loss of a classi\ufb01er or set of classi\ufb01ers from a \ufb01nite\nsample is decades old, much of theory breaks down due to the sequential and adaptive nature\nof the estimation problem that arises when maintaining a leaderboard. First of all, there is no\na priori understanding of which learning algorithms are going to be used, the complexity of\nthe classi\ufb01ers they are producing, and how many submissions there are going to be. Indeed,\nsubmissions are just a list of labels and do not even specify how these labels were obtained.\nSecond, any submission might incorporate statistical information about the withheld class labels\nthat was revealed by the score of previous submissions. In such cases, the public leaderboard\nmay no longer provide an unbiased estimate of the true score. To make matters worse, very\nrecent results suggest that maintaining accurate estimates on a sequence of many adaptively\nchosen classi\ufb01ers may be computationally intractable [HU, SU].\n1.1\nOur Contributions\nWe introduce a notion of accuracy called leaderboard accuracy tailored to the format of a com-\npetition. Intuitively, high leaderboard accuracy entails that each score represented on the\nleaderboard is close to the true score of the corresponding classi\ufb01er on the unknown distribu-\ntion from which the data were drawn. Our primary theoretical contributions are the following.\n1. We show that there is a simple and natural algorithm we call Ladder that achieves high\nleaderboard accuracy in a fully adaptive model of estimation in which we place no\nrestrictions on the data analyst whatsoever. In fact, we don\u2019t even limit the number of\nsubmissions an analyst can make. Formally, our worst-case upper bound shows that if we\nnormalize scores to be in [0,1] the maximum error of our algorithm on any estimate is\nnever worse than O((log(k)/n)1/3) where k is the number of submissions and n is the size\nof the data used to compute the leaderboard. In contrast, we observe that the error of the\nKaggle mechanism (and similar solutions) scales with the number of submissions as\n\u221a\nk so\nthat our algorithm features an exponential improvement in k.\n2. We also prove an information-theoretic lower bound on the leaderboard accuracy demon-\nstrating that no estimator can achieve error smaller than \u2126((log(k)/n)1/2).\n2\nComplementing our theoretical worst-case upper bound and lower bound, we make a\nnumber of practical contributions:\n1. We provide a parameter-free variant of our algorithm that can be deployed in a real\ncompetition with no tuning required whatsoever.\n2. To demonstrate the strength of our parameter-free algorithm we conduct two opposing\nexperiments. The \ufb01rst is an adversarial\u2014yet practical\u2014attack on the leaderboard that\naims to create as much of a bias as possible with a given number of submissions. We\ncompare the performance of the Kaggle mechanism to that of the Ladder mechanism\nunder this attack. We observe that the accuracy of the Kaggle mechanism diminishes\nrapidly with the number of submissions, while our algorithm encounters only a small bias\nin its estimates.\n3. In a second experiment, we evaluate our algorithm on real submission \ufb01les from a Kaggle\ncompetition. The data set presents a di\ufb03cult benchmark as little over\ufb01tting occurred\nand the errors of the Kaggle leaderboard were generally within the expected statistical\ndeviations given the properties of the data set. Even on this benchmark our algorithm\nproduced a leaderboard that is very close to that computed by Kaggle. Through a sequence\nof signi\ufb01cance tests we assess that the di\ufb00erences between the two leaderboards on this\ncompetition are not statistically signi\ufb01cant.\nIn summary, our algorithm supports strong theoretical results while suggesting a simple and\npractical solution. Importantly, it is one and the same parameter-free algorithm that withstands\nour adversarial attack and simultaneously achieves high utility in a real Kaggle competition.\nAn important aspect of our algorithm is that it only releases a score to the participant if the\nscore presents a statistically signi\ufb01cant improvement over the previously best submission of the\nparticipant. Intuitively, this prevents the participant from exploiting or over\ufb01tting to minor\n\ufb02uctuations in the observed score values.\n1.2\nRelated Work\nThere is a vast literature on preventing over\ufb01tting in the context of model assessment and\nselection. See, for example, Chapter 7 of [HTF] for background. Two particularly popular\npractical approaches are various forms of cross-validation and bootstrapping. It is important to\nnote though that when scoring a submission for the leaderboard, neither of these techniques\napplies. One problem is that participants submit only a list of labels and not the corresponding\nlearning algorithms. In particular, the organizer of the competition has no means of retraining\nthe model on a di\ufb00erent split of the data. Similarly, the natural bootstrap estimate of the\nexpected loss of a classi\ufb01er given a \ufb01nite sample is simply the empirical average of the loss on\nthe \ufb01nite sample, which is what existing solutions release anyway. The other substantial obstacle\nis that even if these methods applied, their theoretical guarantees in the adaptive setting of\nestimation are largely not understood.\nA highly relevant recent work [DFH+], that inspired us, studies a more general question:\nGiven a sequence of adaptively chosen bounded functions f1,...,fk : X \u2192{0,1} over a domain X,\nestimate the expectations of these function Ef1,...,Efk over an unknown distribution D, given\nn samples from this distribution. If we think of each function as expressing the loss of one\n3\nclassi\ufb01er submitted to the leaderboard, then such an algorithm could in principle be used in\nour setting. The main result of [DFH+] is an algorithm that achieves maximum error\nO\n\u0010\nmin\nn\nlog(k)3/7(log|X|)1/7/n2/7,(log|X|log(k)/n)1/4o\u0011\n.\nThis bound readily implies a corresponding result for leaderboard accuracy albeit worse than the\none we show. One issue is that this algorithm requires the entire test set to be withheld and not\njust the labels as is required in the Kaggle application. The bigger obstacle is that the algorithm\nis unfortunately not computationally e\ufb03cient and this is inherent. In fact, no computationally\ne\ufb03cient algorithm can give non-trivial error on k > n2+o(1) adaptively chosen functions as was\nshown recently [HU, SU] under a standard computational hardness assumption.\nMatching this hardness result, there is a computationally e\ufb03cient algorithm in [DFH+] that\nachieves an error bound of O(k1/5 log(k)3/5/n2/5) which implies a bound on leaderboard accuracy\nthat is worse than ours for all k > n1/3. They also give an algorithm (called E\ufb00ectiveRounds) with\naccuracy O(\np\nr log(k)/n) when the number of \u201crounds of adaptivity\u201d is at most r. While we do\nnot have a bound on r in our setting better than k1, the proof technique relies on sample splitting\nand a similar argument could be used to prove our upper bound. However, our argument does\nnot require sample splitting and this is very important for the practical applicability of the\nalgorithm.\nWe sidestep the hardness result by going to a more specialized notion of accuracy that is\nsurprisingly still su\ufb03cient for the leaderboard application. However, it does not resolve the\nmore general question raised in [DFH+]. In particular, we do not always provide a loss estimate\nfor each submitted classi\ufb01er, but only for those that made a signi\ufb01cant improvement over the\nprevious best. This seemingly innocuous change is enough to circumvent the aforementioned\nhardness results.\nAcknowledgments\nWe thank Ben Hamner at Kaggle Inc., for providing us with the submission \ufb01les from the Photo\nQuality competition, as well as many helpful discussions. We are grateful to Aaron Roth for\npointing out an argument similar to that appearing in the proof of Theorem 3.1 in a di\ufb00erent\ncontext. We thank John Duchi for many stimulating discussions.\n1.3\nPreliminaries\nLet X be a data domain and Y be a \ufb01nite set of class labels, e.g., X = Rd and Y = {0,1}. Rather\nthan speaking of the score of a classi\ufb01er we will use the term loss with the understanding that\nsmaller is better. A loss function is a mapping of the form \u2113: Y \u00d7 Y \u2192[0,1] and a classi\ufb01er is a\nmapping f : X \u2192Y. A standard loss function is the 0/1-loss de\ufb01ned as \u211301(y,y\u2032) = 1 if y , y\u2032 and\n0 otherwise.\nWe assume that we are given a sample S = {(x1,y1),...,(xn,yn)} drawn i.i.d. from an unknown\ndistribution D over X \u00d7 Y. We de\ufb01ne the empirical loss of a classi\ufb01er f on the sample S as\nRS(f ) def\n= 1\nn\nn\nX\ni=1\n\u2113(f (xi),yi).\n1The parameter r corresponds to the depth of the adaptive tree we de\ufb01ne in the proof of Theorem 3.1. While we\nbound the size of the tree, the depth could be as large as k.\n4\nThe true loss is de\ufb01ned as\nRD(f ) def\n=\nE\n(x,y)\u223cD[\u2113(f (x),y))] .\nThroughout this paper we assume that S consists of n i.i.d. draws from D and \u2113is a loss function\nwith bounded range.\n2\nSequential and Adaptive Loss Estimation\nIn this section we formally de\ufb01ne the adaptive model of estimation that we work in and present\nour de\ufb01nition of leaderboard accuracy. Given a sequence of classi\ufb01ers f1,...,fk and a \ufb01nite\nsample S of size n, a fundamental estimation problem is to compute estimates R1,...,Rk such\nthat\nPr{\u2203t \u2208[k]: |Rt \u2212RD(ft)| > \u03b5} \u2a7d\u03b4.\n(1)\nThe standard way of estimating the true loss is via the empirical loss. If we assume that all\nfunctions f1,...,fk are \ufb01xed independently of the sample S, then Hoe\ufb00ding\u2019s bound and the\nunion bound imply\nPr{\u2203t \u2208[k]: |RS(ft) \u2212RD(ft)| > \u03b5} \u2a7d2k exp(\u22122\u03b52n).\n(2)\nIn the adaptive setting, however, we assume that the classi\ufb01er ft may be chosen as a function of\nthe previous estimates and the previously chosen classi\ufb01ers. Formally, there exists a mapping A\nsuch that for all t \u2208[k] :\nft = A(f1,R1,...,ft\u22121,Rt\u22121).\nWe will assume for simplicity that A is a deterministic algorithm. The tuple (f1,R1,...,ft\u22121,Rt\u22121)\nis nevertheless a random variable due to the random sample used to compute the estimates.\nUnfortunately, in the case where the choice of ft depends on previous estimates, we may\nno longer apply Hoe\ufb00ding\u2019s bound to control RS(ft). In fact, recent work [HU, SU] shows that\nno computationally e\ufb03cient estimator can achieve error o(1) on more than n2+o(1) adaptively\nchosen functions (under a standard hardness assumption). Since we\u2019re primarily interested\nin a computationally e\ufb03cient algorithm, these hardness results demonstrate that the goal of\nachieving the accuracy guarantee speci\ufb01ed in inequality (1) is too stringent in the adaptive\nsetting when k is large. We will therefore introduce a weaker notion of accuracy called leader-\nboard accuracy under which we can circumvent the hardness results and nevertheless achieve a\nguarantee strong enough for our application.\n2.1\nLeaderboard Accuracy\nThe goal of an accurate leaderboard is to guarantee that at each step t \u2a7dk, the leaderboard\naccurately re\ufb02ects the best classi\ufb01er among those classi\ufb01ers f1,...,fk submitted so far. In other\nwords, while we do not need an accurate estimate for each ft, we wish to maintain that the t-th\nestimate Rt correctly re\ufb02ects the minimum loss achieved by any classi\ufb01er so far. This leads to\nthe following de\ufb01nition.\nDe\ufb01nition 2.1. Given an adaptively chosen sequence of classi\ufb01ers f1,...,fk, we de\ufb01ne the\nleaderboard error of estimates R1,...,Rk as\nlberr(R1,...,Rk) def\n= max\n1\u2a7dt\u2a7dk\n\f\f\f\f\fmin\n1\u2a7di\u2a7dtRD(fi) \u2212Rt\n\f\f\f\f\f\n(3)\n5\nGiven an algorithm that achieves high leaderboard accuracy there are two simple ways to\nextend it to provide a full leaderboard:\n1. Use one instance of the algorithm for each team to maintain the best score achieved by\neach team.\n2. Use one instance of the algorithm for each rank on the leaderboard. When a new submis-\nsion comes in, evaluate it against each instance in descending order to determine its place\non the leaderboard.\nThe \ufb01rst variant is straightforward to implement, but requires the assumption that competitors\ndon\u2019t use several accounts (a practice that is typically against the terms of use of a competition).\nThe second variant is more conservative and does not need this assumption.\n3\nThe Ladder Mechanism\nWe introduce an algorithm called the Ladder Mechanism that achieves small leaderboard\naccuracy. The algorithm is very simple. For each given function, it compares the empirical loss\nestimate of the function to the previously smallest loss. If the estimate is below the previous\nbest by some margin, it releases the estimate and updates the best estimate. Importantly, if the\nestimate is not smaller by a margin, the algorithm releases the previous best loss (rather than\nthe new estimate). A formal description follows in Figure 1.\nInput: Data set S, step size \u03b7 > 0\nAlgorithm:\n\u2013 Assign initial estimate R0 \u2190\u221e.\n\u2013 For each round t \u21901,2... :\n1. Receive function ft : X \u2192Y\n2. If RS(ft) < Rt\u22121 \u2212\u03b7, assign Rt \u2190[RS(ft)]\u03b7. Else assign Rt \u2190Rt\u22121.\n3. Output Rt\nFigure 1: The Ladder Mechanism. We use the notation [x]\u03b7 to denote the number x rounded to the\nnearest integer multiple of \u03b7.\nTheorem 3.1. For any sequence of adaptively chosen classi\ufb01ers f1,...,fk, the Ladder Mechanism\nsatis\ufb01es for all t \u2a7dk and \u03b5 > 0,\nPr\n\u001a\f\f\f\f\fmin\n1\u2a7di\u2a7dtRD(fi) \u2212Rt\n\f\f\f\f\f > \u03b5 + \u03b7\n\u001b\n\u2a7dexp\n\u0010\n\u22122\u03b52n + (1/\u03b7 + 2)log(4t/\u03b7) + 1\n\u0011\n.\n(4)\nIn particular, for some \u03b7 = O(n\u22121/3 log1/3(kn)), the Ladder Mechanism achieves with high probability,\nlberr(R1,...,Rk) \u2a7dO\n log1/3(kn)\nn1/3\n!\n.\nProof. Let A be the adaptive analyst generating the function sequence. Fix t \u2a7dk. The algorithm A\nnaturally de\ufb01nes a rooted tree T of depth t recursively de\ufb01ned as follows:\n6\n1. The root is labeled by f1 = A(\u2205).\n2. Each node at depth 1 < i < t corresponds to one realization (h1,r1,...,hi\u22121,ri\u22121) of the ran-\ndom variable (f1,R1,...,fi\u22121,Ri\u22121) and is labeled by hi = A(h1,r1,...,hi\u22121,ri\u22121). Its children\nare de\ufb01ned by each possible value of the output Ri of Ladder Mechanism on the sequence\nh1,r1,...,ri\u22121,hi.\nClaim 3.2. Let B = (1/\u03b7 + 2)log(4t/\u03b7). Then, |T | \u2a7d2B.\nProof. To prove the claim, we will uniquely encode each node in the tree using B bits of\ninformation. The claim then follows directly. The compression argument is as follows. We use\n\u230alog(t)\u230b\u2a7dlog(2t) bits to specify the depth of the node in the tree. We then specify the index\nof each 1 \u2a7di \u2a7dt for which Ri \u2a7dRi\u22121 \u2212\u03b7 together with the value Ri. Note that since Ri \u2208[0,1]\nthere can be at most \u23081/\u03b7\u2309\u2a7d(1/\u03b7) + 1 many such steps. Moreover, there are at most \u23081/\u03b7\u2309\nmany possible values for Ri = [RS(fi)]\u03b7. Hence, specifying all such indices requires at most\n(1/\u03b7 + 1)(log(2/\u03b7) + log(2t)) bits. It is easy that this uniquely identi\ufb01es each node in the graph,\nsince for every index i not explicitly listed we know that Ri = Ri\u22121. The total number of bits we\nused is:\n(1/\u03b7 + 1)(log(2/\u03b7) + log(2t)) + log(2t) \u2a7d(1/\u03b7 + 2)log(4t/\u03b7) = B.\n\u25a0\nThe theorem now follows by applying a union bound over all nodes in T and using Hoe\ufb00ding\u2019s\ninequality for each \ufb01xed node. Let F be the set of all functions appearing in T .\nPr{\u2203f \u2208F : |RD(f ) \u2212RS(f )| > \u03b5} \u2a7d2|F|exp(\u22122\u03b52n)\n\u2a7d2B+1 exp(\u22122\u03b52n) \u2a7d2exp(\u22122\u03b52n + B).\nIn particular,\nPr\n\u001a\f\f\f\f\fmin\n1\u2a7di\u2a7dtRD(fi) \u2212min\n1\u2a7di\u2a7dtRS(fi)\n\f\f\f\f\f > \u03b5\n\u001b\n\u2a7d2exp(\u22122\u03b52n + B).\nMoreover, it is clear that conditioned on the event that\n\f\f\f\f\fmin\n1\u2a7di\u2a7dtRD(fi) \u2212min\n1\u2a7di\u2a7dtRS(fi)\n\f\f\f\f\f \u2a7d\u03b5,\nat step i\u2217where the minimum of RD(fi) is attained, the Ladder Mechanism must output an\nestimate Ri\u2217which is within \u03b5 + \u03b7 of RD(fi\u2217). This concludes the proof.\n\u25a0\n3.1\nA lower bound on leaderboard accuracy\nWe next show that \u2126(\np\nlog(k)/n) is a lower bound on the best possible leaderboard accuracy that\nwe might hope to achieve. This is true even if the functions are not adaptively chosen but \ufb01xed\nahead of time.\nTheorem 3.3. There are classi\ufb01ers f1,...fk and a bounded loss function for which we have the\nminimax lower bound\ninf\nR sup\nD\nE[lberr(R(x1,...,xn))] \u2a7e\u2126\n\uf8eb\n\uf8ec\uf8ec\uf8ec\uf8ec\uf8ed\nr\nlogk\nn\n\uf8f6\n\uf8f7\uf8f7\uf8f7\uf8f7\uf8f8.\nHere the in\ufb01mum is taken over all estimators R: Xn \u2192[0,1]k that take n samples from a distribution\nD and produce k estimates R1,...,Rk = b\u03b8(x1,...,xn). The expectation is taken over n samples from D.\n7\nProof. We will reduce the problem of mean estimation in a certain high-dimensional distribution\nfamily to that of obtaining small leaderboard error. Our lower bound then follows from lower\nbounds for the corresponding mean estimation problem.\nLet X = Rk and take the functions f1,...,fk to be the k coordinate projections fi(x) = xi, for\n1 \u2a7di \u2a7dk. Let the loss function be the projection onto its \ufb01rst argument \u2113(y\u2032,y) = y\u2032 so that\n\u2113(fi(x),y) = xi. Consider the family of distributions D\u03b5 = {D1,...,Dk} where Di is uniform over\n{0,1}k except that the i-th coordinate satis\ufb01es Ex\u223cDi xi = 1/2 \u2212\u03b5 for some \u03b5 \u2208(0,1/4) that we will\ndetermine later. Now, we have\nRDi(fj) =\n\uf8f1\uf8f4\uf8f4\uf8f2\uf8f4\uf8f4\uf8f3\n1/2\ni , j\n1/2 \u2212\u03b5\no.w.\nDenote the mean of a distribution D by \u03b8(D) = Ex\u223cD [x] and note that \u03b8(D) = (RD(f1),...,RD(fk))\u22a4.\nWe claim that obtaining small leaderboard error on f1,...,fk is at least as hard estimating the\nmeans of an unknown distribution in D\u03b5. Formally,\ninf\nR sup\nD\u2208D\u03b5\nE[lberr(R(x1,...,xn))] \u2a7e1\n3 inf\nb\u03b8\nsup\nD\u2208D\u03b5\nE\nh\r\r\rb\u03b8(x1,...,xn) \u2212\u03b8(D)\n\r\r\r\u221e\ni\n.\n(5)\nIndeed, let R be the estimator that achieves minimax leaderboard accuracy. De\ufb01ne the estimator\nb\u03b8 as follows:\n1. Given x1,...,xn compute R1,...Rk = R(x1,...,xn).\n2. Let i be the \ufb01rst coordinate in the sequence R1,...,Rk which is less than 1/2 \u2212\u03b5/2.\n3. Output the vector b\u03b8(x1,...,xn) which is 1/2 \u2212\u03b5 in the i-th coordinate and 1/2 everywhere\nelse.\nNote that the \u2113\u221e-error of b\u03b8 is always at most \u03b5, since all means parameters in the family D\u03b5\nare \u03b5-close in \u2113\u221e-norm. Suppose then that lberr(R(x1,...,xn)) \u2a7d\u03b5/3 and suppose that Di is the\nunknown distribution for some i \u2208[k]. In this case, we claim that \u2225\u03b8(x1,...,xn) \u2212\u03b8(Di)\u2225\u221e= 0.\nIndeed, the \ufb01rst coordinate for which R(x1,...,xn) is less than 1/2 \u2212\u03b5/2 must be i. This follows\nfrom the de\ufb01nition of leaderboard error and the assumption that R had error \u03b5/3 on x1,...,xn.\nThis establishes inequality (5).\nFinally, it is well known and follows from Fano\u2019s inequality that for some \u03b5 = \u2126(\np\nlog(k)/n),\ninf\nb\u03b8\nsup\nD\u2208D\u03b5\nE\nh\r\r\rb\u03b8(x1,...,xn) \u2212\u03b8(D)\n\r\r\r\u221e\ni\n\u2a7e\u03b5.\nFor completeness we include the argument. Let V be a random index in [k] and assume that\nX is a random sample from Di conditional on V = i. Note that the set P = {\u03b8(Di)}i\u2208[k] forms an\n(\u03b5/2)-packing in the \u2113\u221e-norm. Hence, by Fano\u2019s inequality (see e.g. [Has, Tsy]),\ninf\nb\u03b8\nsup\nD\u2208D\u03b5\nE[\u2225b\u03b8(x1,...,xn) \u2212\u03b8(D)\u2225\u221e] \u2a7e\u03b5\n4\n \n1 \u2212I(V ;Xn) + log2\nlog|P|\n!\n,\nwhere I(V ;X) is the mutual information between V and X. Moreover, it is known that\nI(V ;Xn) \u2a7d\n1\n|P|2\nX\ni,j\u2208[k]\nDkl\n\u0012\nDn\ni\n\r\r\r\rDn\nj\n\u0013\n\u2a7dO(\u03b52n).\n8\nIn the second inequality we used that the Kullback-Leibler divergence between a Bernoulli\nrandom variable with bias 1/2 and another one with bias 1/2\u2212\u03b5 is at most O(\u03b52) for all 0 < \u03b5 < 1/4.\nMoreover, the Kullback-Leibler divergence of n independent samples is at most n times the\ndivergence of a single sample. We conclude that\ninf\nb\u03b8\nsup\nD\u2208D\u03b5\nE\nh\r\r\rb\u03b8(x1,...,xn) \u2212\u03b8(D)\n\r\r\r\u221e\ni\n\u2a7e\u03b5\n4\n \n1 \u2212O(\u03b52n) + log2\nlogk\n!\n.\nSetting \u03b5 = c\np\nlog(k)/n for small enough constant c > 0 completes the proof.\n\u25a0\n4\nA parameter-free Ladder mechanism\nWhen applying the Ladder Mechanism in practice it can be di\ufb03cult to choose a \ufb01xed step\nsize \u03b7 ahead of time that will work throughout an entire competition. We therefore now give a\ncompletely parameter-free version of our algorithm that we will use in our experiments. The\nalgorithm adaptively \ufb01nds a suitable step size based on previous submissions to the algorithm.\nThe idea is to perform a statistical signi\ufb01cance test to judge whether the given submission\nimproves upon the previous one. The test is such that as the best classi\ufb01er gets increasingly\naccurate, the step size shrinks accordingly.\nThe empirical loss of a classi\ufb01er is the average of n bounded numbers and follows a very\naccurate normal approximation for su\ufb03ciently large n so long as the loss is not biased too\nmuch towards 0. In our setting, the typical loss if bounded away form 0 so that the normal\napproximation is reasonable. In order to test whether the empirical loss of one classi\ufb01er is\nsigni\ufb01cantly below the empirical loss of another classi\ufb01er, it is appropriate to perform a one-\nsided paired t-test. A paired test has substantially more statistical power in settings where the\nloss vectors that are being compared are highly correlated as is common in a competition.\nTo recall the de\ufb01nition of the test, we denote the sample standard deviation of an n-dimensional\nvector vector u as std(u) =\nq\n1\nn\u22121\nPn\ni=1(ui \u2212mean(u))2 , where mean(u) denotes the average of the\nentries in u. With this notation, the paired t-test statistic given two vectors u and v is de\ufb01ned as\nt =\n\u221a\nn \u00b7 mean(u \u2212v)\nstd(u \u2212v) .\n(6)\nKeeping this de\ufb01nition in mind, our parameter-free Ladder mechanism in Figure 2 is now very\nnatural. On top of the loss estimate, it also maintains the loss vector of the previously best\nclassi\ufb01er (starting with the trivial all zeros loss vector).\nThe algorithm in Figure 2 releases the estimate of RS(ft) up to an error of 1/n which is\nsigni\ufb01cantly below the typical step size of \u2126(1/\u221an). Looking back at our analysis, this is not a\nproblem since such an estimate only reveals log(n) bits of information which is the same up to\nconstant factors as an estimate that is accurate to within 1/\u221an. The more critical quantity is the\nstep size as it controls how often the algorithm releases a new estimate.\nIn the following sections we will show that the parameter-free Ladder mechanism achieves\nhigh accuracy both under a strong attack as well as on a real Kaggle competition.\n4.1\nRemark on the interpretation of the signi\ufb01cance test\nFor su\ufb03ciently large n, the test statistic on the left hand side of (6) is well approximated by a\nStudent\u2019s t-distribution with n \u22121 degrees of freedom. The test performed in our algorithm at\n9\nInput: Data set S = {(x1,y1),...(xn ...,yn)} of size n\nAlgorithm:\n\u2013 Assign initial estimate R0 \u2190\u221e, and loss vector \u21130 = (0)n\ni=1.\n\u2013 For each round t \u21901,2...,k :\n1. Receive function ft : X \u2192Y.\n2. Compute loss vector lt \u2190(\u2113(ft(xi),yi))n\ni=1\n3. Compute the sample standard deviation s \u2190std(lt \u2212lt\u22121).\n4. If RS(ft) < Rt\u22121 \u2212s/\u221an\n(a) Rt \u2190[RS(ft)]1/n.\n5. Else assign Rt \u2190Rt\u22121 and lt \u2190lt\u22121.\n6. Output Rt\nFigure 2: The parameter-free Ladder Mechanism. We use the notation [x]\u03b7 to denote the number x\nrounded to the nearest integer multiple of \u03b7.\neach step corresponds to refuting the null hypothesis roughly at the 0.15 signi\ufb01cance level.\nIt is important to note, however, that our use of this signi\ufb01cance test is primarily heuristic.\nThis is because for t > 1, due to the adaptive choices of the analyst, the function ft may in\ngeneral not be independent of the sample S. In such a case, the Student approximation is no\nlonger valid. Besides we apply the test many times, but do not control for multiple comparisons.\nNevertheless, the signi\ufb01cance test is an intuitive guide for deciding which improvements are\nstatistically signi\ufb01cant.\n5\nThe boosting attack\nIn this section we describe a new canonical attack that an adversarial analyst might perform in\norder to boost their ranking on the public leaderboard. Besides being practical in some cases,\nthe attack also serves as an analytical tool to assess the accuracy of concrete mechanisms.\nFor simplicity we describe the attack only for the 0/1-loss although it generalizes to other\nreasonable functions such as the clipped logarithmic loss often used by Kaggle. We assume\nthat the hidden solution is a vector y \u2208{0,1}n. The analyst may submit a vector u \u2208{0,1}n and\nobserve (up to small enough error) the loss\n\u211301(y,u) def\n= 1\nn\nn\nX\ni=1\n\u211301(ui,yi)\nThe attack proceeds as follows:\n1. Pick u1,...,uk \u2208{0,1}n uniformly at random.\n2. Observe loss estimates l1,...,lk \u2208[0,1].\n3. Let I = {i : li \u2a7d1/2}.\n4. Output u\u2217= maj({ui : i \u2208I}), where the majority function is applied coordinate-wise.\n10\nThe vector y corresponds to the target set of labels used for the public leaderboard which\nthe analyst does not know. The vectors u1,...,uk represent the labels given by a sequence of k\nclassi\ufb01ers.\nThe next theorem follows from a standard \u201cboosting argument\u201d using properties of the\nmajority function and the fact that each ui for i \u2208I has a somewhat larger than expected\ncorrelation with y.\nTheorem 5.1. Assume that |li \u2212\u211301(y,ui)| \u2a7dn\u22121/2 for all i \u2208[k]. Then, the boosting attack \ufb01nds a\nvector u\u2217\u2208{0,1}n so that with probability 2/3,\n1\nn\nn\nX\ni=1\n\u211301(u\u2217\ni ,yi) \u2a7d1\n2 \u2212\u2126\n\uf8eb\n\uf8ec\uf8ec\uf8ec\uf8ec\uf8ed\nr\nk\nn\n\uf8f6\n\uf8f7\uf8f7\uf8f7\uf8f7\uf8f8.\nThe previous theorem in particular demonstrates that the Kaggle mechanism has poor\nleaderboard accuracy if it is invoked with rounding parameter \u03b1 \u2a7d1/\u221an. The currently used\nrounding parameter is 10\u22125 which satis\ufb01es this assumption for all n \u2a7d1010.\nCorollary 5.2. There is a sequence of adaptively chosen classi\ufb01ers f1,...,fk such that if Ri denotes the\nminimum of the \ufb01rst i loss estimates returned by the Kaggle mechanism (as described in Figure 7)\nwith accuracy \u03b1 \u2a7d1/\u221an where n is the size of the data set, then with probability 2/3 the estimates\nR1,...,Rk have leaderboard error\nlberr(R1,...,Rk) \u2a7e\u2126\n\uf8eb\n\uf8ec\uf8ec\uf8ec\uf8ec\uf8ed\nr\nk\nn\n\uf8f6\n\uf8f7\uf8f7\uf8f7\uf8f7\uf8f8.\n5.1\nExperiments with the boosting attack\nFigure 3 compares the performance of the Ladder mechanism with that of the standard Kaggle\nmechanism under the boosting attack. We chose N = 12000 as the total number of labels of\nwhich n = 4000 labels are used for determining the public leaderboard under either mechanism.\nOther parameter settings lead to a similar picture, but these settings correspond roughly to\nthe properties of the real data set that we will analyze later. The Kaggle mechanism gives\nanswers that are accurate up to a rounding error of 10\u22125. Note that 1/\n\u221a\n4000 \u22480.0158 so that\nthe rounding error is well below the critical level of 1/\u221an. The vector y in the description of\nour attack corresponds to the 4000 labels used for the public leaderboard. Since the answers\ngiven by Kaggle only depend on these labels, the remaining labels play no role in the attack.\nImportantly, the attack does not need to know the indices of the labels used for the public\nleaderboard within the entire vector of labels.\nThe 8000 coordinates not used for the leaderboard remain unbiased random bits throughout\nthe attack as no information is revealed. In particular, the \ufb01nal submission u\u2217is completely\nrandom on those 8000 coordinates and only biased on the other 4000 coordinates used for the\nleaderboard. Therefore, once we evaluate the \ufb01nal submission u\u2217on the test set consisting of\nthe remaining 8000 coordinates, the resulting loss is close to its expected value of 1/2, i.e. the\nexpected loss of a random 0/1-vector. What we observe, however, is that the Kaggle mechanism\ngives a strongly biased estimate of the loss of u\u2217.\nThe blue line in Figure 3 displays the performance of the parameter-free version of the\nLadder mechanism. Instead of selecting all the vectors with loss at most 1/2 we modi\ufb01ed the\nattack to be more e\ufb00ective against the Ladder Mechanism. Speci\ufb01cally, we selected all those\n11\nvectors that successfully lowered the score compared to the previous best. As we have no\ninformation about the correlation of the remaining vectors, there is no bene\ufb01t in including them\nin the boosting step. Even with this more e\ufb00ective attack, the Ladder mechanism gives a result\nthat is correct to within the expected maximum deviation of the score on k random vectors. The\nintuitive reason is that every time a vector lowers the best score seen so far, the probability of a\nsubsequent vector crossing the new threshold drops o\ufb00by a constant factor. In particular there\ncannot be more than O(log(k)) such steps thus creating a bias of at most O(\np\nlog(k)/n) in the\nboosting step.\n\u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\t\u0007\n\u0002\u0005\u0006\u000b\u0005\f\n\r\n\u000e\r\r\n\u000f\r\r\n\u0010\r\r\n\u0011\r\r\n\r\u0012\u0011\u000f\n\r\u0012\u0011\u0011\n\r\u0012\u0011\u0013\n\r\u0012\u0011\u0014\n\r\u0012\u0015\r\n\u0016\u0005\u0017\b\u0006\u0018\u0005\u0019\u0007\u001a\b\f\f\n\u001b\u001c\u0019\u0019\u0005\u0006\u0007\u001d\f\u0007\u001e\u001c\u001f\u001f\u001a\u0005\u0007 !\b\u0006\u0003\u001c\u001a\u0007\u0017\u0006\u0005\"\u000b\f\u000b\b!#\n\u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\t\u0007\n\u0002\u0005\u0006\u000b\u0005\f\n\r\n\u000e\r\r\n\u000f\r\r\n\u0010\r\r\n\u0011\r\r\n\r\u0012\u0011\u000f\n\r\u0012\u0011\u0011\n\r\u0012\u0011\u0013\n\r\u0012\u0011\u0014\n\r\u0012\u0015\r\n\u0016\u0005\u0017\b\u0006\u0018\u0005\u0019\u0007\u001a\b\f\f\n\u001b\u001c\u0019\u0019\u0005\u0006\u0007\u001d\f\u0007\u001e\u001c\u001f\u001f\u001a\u0005\u0007 !\b\u0006\u0003\u001c\u001a\u0007\u0017\u0006\u0005\"\u000b\f\u000b\b!#\nFigure 3: Performance of the parameter free Ladder Mechanism compared with the Kaggle Mechanism.\nTop green line: Independent test set. Middle blue line: Ladder. Bottom red line: Kaggle. Left: Kaggle\nwith large rounding parameter 1/\u221an \u22480.0158. Right: Kaggle with normal rounding parameter 0.00001.\nAll numbers are averaged over 5 independent repetitions of the experiment. Number of labels used is\nn = 4000.\n6\nExperiments on real Kaggle data\nTo demonstrate the utility of the Ladder mechanism we turn to real submission data from\nKaggle\u2019s \u201cPhoto Quality Prediction\u201d challenge2. Here is some basic information about the\ncompetition.\nNumber of test samples\n12000\n\u2013 used for private leaderboard\n8400\n\u2013 used for public leaderboard\n3600\nNumber of submissions\n1830\n\u2013 processed successfully\n1785\nNumber of teams\n200\nOur \ufb01rst experiment is to use the parameter-free Ladder mechanism in place of the Kag-\ngle mechanism across all 1785 submissions and recompute both the public and the private\nleaderboard. The resulting rankings turn out to be very close to those computed by Kaggle. For\nexample, Table 1 shows the only perturbations in the ranking among the top 10 submissions.\n2https://www.kaggle.com/c/PhotoQualityPrediction\n12\nPrivate\nPublic\nKaggle\n6\n8\n5\n6\n7\nLadder\n8\n6\n7\n5\n6\nTable 1: Perturbations in the top 10 leaderboards\nFigure 4 plots the public versus private scores of the leading 50 submissions (w.r.t the private\nleaderboard). The diagonal line indicates an equal private and public score. The plot a small\namount of under\ufb01tting between the public and private scores. That is, the losses on the public\nleaderboard generally tend to be slightly higher than on the private leaderboard. This appears\nto be due random \ufb02uctuations in the proportion of hard examples in the public holdout set.\nTo assess this possibility and gain further insight into the magnitude of statistical deviations\nof the scores, we randomly split the private holdout set into two equally sized parts and\nrecompute the leaderboards on each part. We repeat the process 20 times independently and\nlook at the standard deviations of the scores across these 20 repetitions. Figure 5 shows the\nresults demonstrating that the statistical deviations due to random splitting are large relative to\nthe di\ufb00erence in mean scores. In particular the amount of under\ufb01tting observed on the original\nsplit is within one standard deviation of the mean scores which cluster close to the diagonal line.\nWe also observed that the top 50 scores are highly correlated so that across di\ufb00erent splits the\npoints are either mostly above or mostly below the diagonal line. This must be due to the fact\nthat the best submissions in this competition used related classi\ufb01ers that fail to predict roughly\nthe same label set.\n\u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\u0006\t\n\u000b\n\f\r\u000e\u000f\n\f\r\u000e\u0010\n\f\r\u0011\f\n\f\r\u000e\u0010\n\f\r\u0011\f\n\u0001\n\u0005\u0012\u0013\u0014\u000b\u0007\b\u0006\t\n\u000b\n\u0015\t\u0016\u0007\u0017\f\u0007\u0018\u0013\u0019\u0019\u0004\u000b\u0007\b\u0006\t\n\u000b\b\u0007\t\u001a\u0007\u0016\n\u0005\u0012\u0013\u0014\u000b\u0007\u001b\u0013\u0014\u0013\n\u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\u0006\t\n\u000b\n\f\r\u000e\u000f\n\f\r\u000e\u0010\n\f\r\u0011\f\n\f\r\u000e\u0010\n\f\r\u0011\f\n\u0001\n\u0005\u0012\u0013\u0014\u000b\u0007\b\u0006\t\n\u000b\n\u0015\t\u0016\u0007\u0017\f\u0007\u0018\u0013\u0019\u0019\u000b\n\u0007\b\u0006\t\n\u000b\b\u0007\t\u001a\u0007\u0016\n\u0005\u0012\u0013\u0014\u000b\u0007\u0019\u0013\u0014\u0013\nFigure 4: Private versus public scores for the top 50 submissions. Left: Kaggle. Right: Ladder.\n6.1\nStatistical signi\ufb01cance analysis\nTo get a better sense of the statistical signi\ufb01cance of the di\ufb00erence between the scores of com-\npeting submissions we performed a sequence of signi\ufb01cance tests. Speci\ufb01cally, we considered\nthe top 10 submissions taken from the Kaggle public leaderboard and tested on the private data\n13\n\u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\u0006\t\n\u000b\n\f\r\u000e\u000f\n\f\r\u000e\u0010\n\f\r\u0011\f\n\f\r\u000e\u0010\n\f\r\u0011\f\n\u0001\n\u0005\u0012\u0013\u0014\u000b\u0007\b\u0006\t\n\u000b\n\u0015\u0013\u0016\u0016\u0004\u000b\u0007\u0014\t\u0017\u0007\u0018\f\u0007\b\u0006\t\n\u000b\b\u0007\t\u0019\u0007\u001a\n\u000b\b\u001b\u0007\b\u0017\u0004\u0005\u0014\b\n\u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\u0006\t\n\u000b\n\f\r\u000e\u000f\n\f\r\u000e\u0010\n\f\r\u0011\f\n\f\r\u000e\u0010\n\f\r\u0011\f\n\u0001\n\u0005\u0012\u0013\u0014\u000b\u0007\b\u0006\t\n\u000b\n\u0015\u0013\u0016\u0016\u000b\n\u0007\u0014\t\u0017\u0007\u0018\f\u0007\b\u0006\t\n\u000b\b\u0007\t\u0019\u0007\u001a\n\u000b\b\u001b\u0007\b\u0017\u0004\u0005\u0014\b\nFigure 5: Fluctuations of scores across 20 independent splits of the private data. Dots represent mean\nscores. Error bars indicate a single standard deviation in each direction.\nif the true score of the top submission is signi\ufb01cantly di\ufb00erent from the rank r submission for\nr = 2,3,...,10. A suitable test of signi\ufb01cance is the paired t-test. The score of a submission is\nthe mean of a large number of samples in the interval [0,2] and follows a su\ufb03ciently accurate\nnormal approximation. We chose a paired t-test rather than an unpaired t-test, because it has far\ngreater statistical power in our setting. This is primarily due to the strong correlation between\ncompeting submissions. See Equation 6 for a de\ufb01nition of the test statistic. Note that the data\nthat determined the selection of the top 10 classi\ufb01ers is independent of the data used to perform\nthe signi\ufb01cance tests.\nFigure 6 plots the resulting p-values before and after correction for multiple comparisons.\nWe see that after applying a Bonferroni correction, the only submissions with a signi\ufb01cantly\ndi\ufb00erent mean are 8 and 9.\n\u0001\u0002\u0003\u0004\n\u0005\n\u0006\n\u0007\n\b\n\t\n\n\u000b\n\f\n\r\u000e\n\u000e\u000f\u000e\b\n\u000e\u000f\u0005\u000e\n\u000e\u000f\u0007\u000e\n\u000e\u000f\t\u000e\n\u000e\u000f\u000b\u000e\n\u0010\u0011\u0012\u0002\u0013\u0014\u0015\n\u0001\u0002\u0003\u0004\n\u0005\n\u0006\n\u0007\n\b\n\t\n\n\u000b\n\f\n\r\u000e\n\u000e\u000f\u000e\b\n\u000e\u000f\u0005\u000e\n\u000e\u000f\u0007\u000e\n\u000e\u000f\t\u000e\n\u000e\u000f\u000b\u000e\n\u0010\u0011\u0012\u0002\u0013\u0014\u0015\nFigure 6: Signi\ufb01cance test for the di\ufb00erence between score of top submission and rank r submission.\nLeft: Before multiple comparison correction. Right: After Bonferroni correction.\n14\nThese observations give further evidence that the small perturbations we saw in the top 10\nleaderboard between the Kaggle mechanism and the Ladder mechanism are below the level of\nstatistical signi\ufb01cance.\n7\nConclusion\nWe hope that the Ladder mechanism will be helpful in making machine learning competitions\nmore reliable. Beyond the scope of machine learning competitions, it is conceivable that the\nLadder mechanism could be useful in other domains where over\ufb01tting is currently a concern.\nFor example, in the context of false discovery in the empirical sciences [Ioa, GL], one could\nimagine using the the Ladder mechanism as a way of keeping track of scienti\ufb01c progress on\nimportant public data sets.\nOur algorithm can also be seen as an intuitive explanation for why over\ufb01tting to the holdout\nis sometimes not a major problem even in the adaptive setting. If indeed every analyst only\nuses the holdout set to test if their latest submission is well above the previous best, then they\ne\ufb00ectively simulate our algorithm.\nA beautiful theoretical problem is to resolve the gap between our upper and lower bound. On\nthe practical side, it would be interesting to use the Ladder mechanism in a real competition. One\ninteresting question is if the Ladder mechanism actually encourages higher quality submissions\nby requiring a certain level of statistically signi\ufb01cant improvement over previous submissions.\nReferences\n[DFH+] Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold, and\nAaron Roth. Preserving statistical validity in adaptive data analysis. In Proc. 47th\nSymposium on Theory of Computing (STOC). ACM, 2014.\n[GL]\nAndrew Gelman and Eric Loken. The garden of forking paths: Why multiple compar-\nisons can be a problem, even when there is no \u201c\ufb01shing expedition\u201d or \u201cp-hacking\u201d and\nthe research hypothesis was posited ahead of time, 2013.\n[Has]\nR. Z. Has\u2019minskii. A lower bound on the risks of nonparametric estimates of densities\nin the uniform metric. Theory of Probability and Applications, 23:794\u2013798, 1978.\n[HTF]\nTrevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical\nLearning. Springer, 2001.\n[HU]\nMoritz Hardt and Jonathan Ullman. Preventing false discovery in interactive data\nanalysis is hard. In Proc. 55th Foundations of Computer Science (FOCS), pages 454\u2013463.\nIEEE, 2014.\n[Ioa]\nJohn P. A. Ioannidis. Why Most Published Research Findings Are False. PLoS Medicine,\n2(8):124, August 2005.\n[SU]\nThomas Steinke and Jonathan Ullman. Interactive \ufb01ngerprinting codes and the hard-\nness of preventing false discovery. CoRR, abs/1410.1228, 2014.\n[Tsy]\nAlexandre B. Tsybakov. Introduction to Nonparametric Estimation. Springer, 1st edition,\n2008.\n15\nA\nKaggle reference mechanism\nAs we did for the Ladder Mechanism we describe the algorithm as if the analyst was submitting\nclassi\ufb01ers f : X \u2192Y. In reality the analyst only submits a list of labels. It is easy to see that such\na list of labels is su\ufb03cient to compute the empirical loss which is all the algorithm needs to do.\nThe input set S in the description of our algorithm corresponds to the set of data points (and\ncorresponding labels) that Kaggle uses for the public leaderboard.\nInput: Data set S, rounding parameter \u03b1 > 0 (typically 0.00001)\nAlgorithm:\n\u2013 For each round t \u21901,2...,k :\n1. Receive function ft : X \u2192Y\n2. Output [RS(ft)]\u03b1.\nFigure 7: Kaggle reference mechanism. We use the notation [x]\u03b1 to denote the number x rounded to the\nnearest integer multiple of \u03b1.\n16\n",
        "sentence": " Recent work on privacy-preserving machine learning has considered how datamining competitions such as Kaggle could potentially be \u201chacked\u201d, either intentionally or inadvertently, by using information from an oracle that reports a classifier\u2019s accuracy on the test set (Blum and Hardt, 2015; Hardt and Ullman, 2014; Zheng, 2015; Whitehill, 2016). Recent research on privacy-preserving machine learning (Whitehill, 2016; Blum and Hardt, 2015; Zheng, 2015) has shown how information on the accuracy of a contestant\u2019s guesses, returned to the contestant by an oracle, can divulge information about the test data\u2019s true labels. Recent research on privacy-preserving machine learning (Whitehill, 2016; Blum and Hardt, 2015; Zheng, 2015) has shown how information on the accuracy of a contestant\u2019s guesses, returned to the contestant by an oracle, can divulge information about the test data\u2019s true labels. Such oracles are often provided by the organizers of the competition themselves. For example, in the 2017 Intel & MobileODT Cervical Cancer Screening competition1 hosted by Kaggle, every contestant can submit her/his guesses up to 5 times per day, and for each submission the oracle returns the log-loss of the guesses with respect to the ground-truth values of the entire 512-element test set. The contestant can use the accuracy information to improve (hopefully) the classifier design and then re-submit. AUC: For binary classification problems, one of the most commonly used accuracy metrics is the Area Under the Receiver Operating Characteristics Curve (AUC). In contrast to other accuracy metrics such as log-loss and 0/1 loss, which can be computed as the sum of example-wise losses over each example in the test set, the AUC statistic is computed over all possible pairs of test examples, such that each pair contains one example from each class. In a recent paper, Whitehill (2016) showed that an oracle that provides contestants with information on the AUC of their guesses can inadvertently divulge information on the ground-truth labels of the test examples. Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. The AUC statistic, in particular, has been investigated in the context of privacy: Stoddard, Chen, and Machanavajjhala (2014) proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics. Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. The AUC statistic, in particular, has been investigated in the context of privacy: Stoddard, Chen, and Machanavajjhala (2014) proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics. Matthews and Harel (2013) showed how an attacker who already knows most of the test labels can estimate the remaining labels if he/she gains access to an empirical ROC curve, i. Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. The AUC statistic, in particular, has been investigated in the context of privacy: Stoddard, Chen, and Machanavajjhala (2014) proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics. Matthews and Harel (2013) showed how an attacker who already knows most of the test labels can estimate the remaining labels if he/she gains access to an empirical ROC curve, i.e., a set of classifier thresholds and corresponding true positive and false positive rates. The prior work most similar to ours is by Whitehill (2016). They showed a weak form of lower bound on the number of possible binary ground-truth vectors y \u2208 {0, 1} for which the contestant\u2019s guesses \u0177 achieve any fixed AUC c. Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015). In particular, Blum and Hardt (2015) proposed an algorithm (\u201cLadder\u201d) that can reliably estimate the accuracy of a contestant\u2019s classifier on the true test data distribution, even when the classifier has been adaptively optimized based on the output of an oracle on the empirical test distribution. While the availability of an oracle in datamining contests presents potential problems, it is also useful for helping contestants to focus their efforts on more promising algorithmic approaches. Our research is thus related to privacy-preserving machine learning and differential privacy (e.g., Dwork (2011); Chaudhuri and Monteleoni (2009); Blum, Ligett, and Roth (2013)), which are concerned with how to provide useful aggregate statistics without disclosing private information about particular examples in the dataset. The AUC statistic, in particular, has been investigated in the context of privacy: Stoddard, Chen, and Machanavajjhala (2014) proposed an algorithm for computing \u201cprivate ROC\u201d curves and associated AUC statistics. Matthews and Harel (2013) showed how an attacker who already knows most of the test labels can estimate the remaining labels if he/she gains access to an empirical ROC curve, i.e., a set of classifier thresholds and corresponding true positive and false positive rates. The prior work most similar to ours is by Whitehill (2016). They showed a weak form of lower bound on the number of possible binary ground-truth vectors y \u2208 {0, 1} for which the contestant\u2019s guesses \u0177 achieve any fixed AUC c. Specifically, for every AUC value c = p/q \u2208 (0, 1), there exists an infinite sequence of dataset sizes (n = 4q, 8q, 12q, . . .) such that the number of satisfying ground-truth vectors y \u2208 {0, 1} grows exponentially in n. However, this result does not preclude the possibility that there might be certain pathological cases \u2013 combinations of p, q, n0, and n1 \u2013 for which the number of satisfying ground-truth vectors is actually much smaller. Conceivably, there might be values of n that lie between integer multiples of 4q for which the number of satisfying solutions is small. Moreover, the lower bound in Whitehill (2016) applies only to datasets that contain at least 4q examples and says nothing about smaller (but possibly still substantial) datasets.",
        "context": "may no longer provide an unbiased estimate of the true score. To make matters worse, very\nrecent results suggest that maintaining accurate estimates on a sequence of many adaptively\nchosen classi\ufb01ers may be computationally intractable [HU, SU].\n1.1\nreasonable functions such as the clipped logarithmic loss often used by Kaggle. We assume\nthat the hidden solution is a vector y \u2208{0,1}n. The analyst may submit a vector u \u2208{0,1}n and\nobserve (up to small enough error) the loss\n\u211301(y,u) def\n= 1\nn\nn\nX\ni=1\nthe remaining 8000 coordinates, the resulting loss is close to its expected value of 1/2, i.e. the\nexpected loss of a random 0/1-vector. What we observe, however, is that the Kaggle mechanism\ngives a strongly biased estimate of the loss of u\u2217."
    },
    {
        "title": "A learning theory approach to noninteractive database privacy",
        "author": [
            "A. Blum",
            "K. Ligett",
            "A. Roth"
        ],
        "venue": "Journal of the ACM (JACM) 60(2):12.",
        "citeRegEx": "Blum et al\\.,? 2013",
        "shortCiteRegEx": "Blum et al\\.",
        "year": 2013,
        "abstract": "\n            In this article, we demonstrate that, ignoring computational constraints, it is possible to release synthetic databases that are useful for accurately answering large classes of queries while preserving differential privacy. Specifically, we give a mechanism that privately releases synthetic data useful for answering a class of queries over a\n            discrete\n            domain with error that grows as a function of the size of the smallest net approximately representing the answers to that class of queries. We show that this in particular implies a mechanism for counting queries that gives error guarantees that grow only with the VC-dimension of the class of queries, which itself grows at most logarithmically with the size of the query class.\n          \n          \n            We also show that it is not possible to release even simple classes of queries (such as intervals and their generalizations) over\n            continuous\n            domains with worst-case utility guarantees while preserving differential privacy. In response to this, we consider a relaxation of the utility guarantee and give a privacy preserving polynomial time algorithm that for any halfspace query will provide an answer that is accurate for some small perturbation of the query. This algorithm does not release synthetic data, but instead another data structure capable of representing an answer for each query. We also give an efficient algorithm for releasing synthetic data for the class of interval queries and axis-aligned rectangles of constant dimension over\n            discrete\n            domains.\n          ",
        "full_text": "",
        "sentence": "",
        "context": null
    },
    {
        "title": "Privacy-preserving logistic regression",
        "author": [
            "K. Chaudhuri",
            "C. Monteleoni"
        ],
        "venue": "Advances in Neural Information Processing Systems, 289\u2013296.",
        "citeRegEx": "Chaudhuri and Monteleoni,? 2009",
        "shortCiteRegEx": "Chaudhuri and Monteleoni",
        "year": 2009,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": "",
        "context": null
    },
    {
        "title": "Preserving statistical validity in adaptive data analysis",
        "author": [
            "C. Dwork",
            "V. Feldman",
            "M. Hardt",
            "T. Pitassi",
            "O. Reingold",
            "A.L. Roth"
        ],
        "venue": "Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing, 117\u2013126. ACM.",
        "citeRegEx": "Dwork et al\\.,? 2015",
        "shortCiteRegEx": "Dwork et al\\.",
        "year": 2015,
        "abstract": "A great deal of effort has been devoted to reducing the risk of spurious\nscientific discoveries, from the use of sophisticated validation techniques, to\ndeep statistical methods for controlling the false discovery rate in multiple\nhypothesis testing. However, there is a fundamental disconnect between the\ntheoretical results and the practice of data analysis: the theory of\nstatistical inference assumes a fixed collection of hypotheses to be tested, or\nlearning algorithms to be applied, selected non-adaptively before the data are\ngathered, whereas in practice data is shared and reused with hypotheses and new\nanalyses being generated on the basis of data exploration and the outcomes of\nprevious analyses.\n  In this work we initiate a principled study of how to guarantee the validity\nof statistical inference in adaptive data analysis. As an instance of this\nproblem, we propose and investigate the question of estimating the expectations\nof $m$ adaptively chosen functions on an unknown distribution given $n$ random\nsamples.\n  We show that, surprisingly, there is a way to estimate an exponential in $n$\nnumber of expectations accurately even if the functions are chosen adaptively.\nThis gives an exponential improvement over standard empirical estimators that\nare limited to a linear number of estimates. Our result follows from a general\ntechnique that counter-intuitively involves actively perturbing and\ncoordinating the estimates, using techniques developed for privacy\npreservation. We give additional applications of this technique to our\nquestion.",
        "full_text": "arXiv:1411.2664v3  [cs.LG]  2 Mar 2016\nPreserving Statistical Validity in Adaptive Data Analysis\u2217\nCynthia Dwork\u2020\nVitaly Feldman\u2021\nMoritz Hardt\u00a7\nToniann Pitassi\u00b6\nOmer Reingold\u2225\nAaron Roth\u2217\u2217\nAbstract\nA great deal of e\ufb00ort has been devoted to reducing the risk of spurious scienti\ufb01c discoveries,\nfrom the use of sophisticated validation techniques, to deep statistical methods for controlling\nthe false discovery rate in multiple hypothesis testing. However, there is a fundamental discon-\nnect between the theoretical results and the practice of data analysis: the theory of statistical\ninference assumes a \ufb01xed collection of hypotheses to be tested, or learning algorithms to be ap-\nplied, selected non-adaptively before the data are gathered, whereas in practice data is shared\nand reused with hypotheses and new analyses being generated on the basis of data exploration\nand the outcomes of previous analyses.\nIn this work we initiate a principled study of how to guarantee the validity of statistical\ninference in adaptive data analysis. As an instance of this problem, we propose and investigate\nthe question of estimating the expectations of m adaptively chosen functions on an unknown\ndistribution given n random samples.\nWe show that, surprisingly, there is a way to estimate an exponential in n number of ex-\npectations accurately even if the functions are chosen adaptively. This gives an exponential\nimprovement over standard empirical estimators that are limited to a linear number of esti-\nmates. Our result follows from a general technique that counter-intuitively involves actively\nperturbing and coordinating the estimates, using techniques developed for privacy preservation.\nWe give additional applications of this technique to our question.\n\u2217Preliminary version of this work appears in the proceedings of the ACM Symposium on Theory of Computing\n(STOC), 2015\n\u2020Microsoft Research\n\u2021IBM Almaden Research Center. Part of this work done while visiting the Simons Institute, UC Berkeley\n\u00a7IBM Almaden Research Center\n\u00b6University of Toronto\n\u2225Samsung Research America\n\u2217\u2217Department of Computer and Information Science, University of Pennsylvania\n1\nIntroduction\nThroughout the scienti\ufb01c community there is a growing recognition that claims of statistical signif-\nicance in published research are frequently invalid [Ioa05b, Ioa05a, PSA11, BE12]. The past few\ndecades have seen a great deal of e\ufb00ort to understand and propose mitigations for this problem.\nThese e\ufb00orts range from the use of sophisticated validation techniques and deep statistical methods\nfor controlling the false discovery rate in multiple hypothesis testing to proposals for preregistration\n(that is, de\ufb01ning the entire data-collection and data-analysis protocol ahead of time). The statis-\ntical inference theory surrounding this body of work assumes a \ufb01xed procedure to be performed,\nselected before the data are gathered. In contrast, the practice of data analysis in scienti\ufb01c research\nis by its nature an adaptive process, in which new hypotheses are generated and new analyses are\nperformed on the basis of data exploration and observed outcomes on the same data. This dis-\nconnect is only exacerbated in an era of increased amounts of open access data, in which multiple,\nmutually dependent, studies are based on the same datasets.\nIt is now well understood that adapting the analysis to data (e.g., choosing what variables to\nfollow, which comparisons to make, which tests to report, and which statistical methods to use) is\nan implicit multiple comparisons problem that is not captured in the reported signi\ufb01cance levels\nof standard statistical procedures. This problem, in some contexts referred to as \u201cp-hacking\u201d or\n\u201cresearcher degrees of freedom\u201d, is one of the primary explanations of why research \ufb01ndings are\nfrequently false [Ioa05b, SNS11, GL14].\nThe \u201ctextbook\u201d advice for avoiding problems of this type is to collect fresh samples from the\nsame data distribution whenever one ends up with a procedure that depends on the existing data.\nGetting fresh data is usually costly and often impractical so this requires partitioning the available\ndataset randomly into two or more disjoint sets of data (such as a training and testing set) prior to\nthe analysis. Following this approach conservatively with m adaptively chosen procedures would\nsigni\ufb01cantly (on average by a factor of m) reduce the amount of data available for each procedure.\nThis would be prohibitive in many applications, and as a result, in practice even data allocated for\nthe sole purpose of testing is frequently reused (for example to tune parameters). Such abuse of\nthe holdout set is well known to result in signi\ufb01cant over\ufb01tting to the holdout or cross-validation\nset [Reu03, RF08].\nClear evidence that such reuse leads to over\ufb01tting can be seen in the data analysis competitions\norganized by Kaggle Inc.\nIn these competitions, the participants are given training data and\ncan submit (multiple) predictive models in the course of competition. Each submitted model is\nevaluated on a (\ufb01xed) test set that is available only to the organizers. The score of each solution\nis provided back to each participant, who can then submit a new model. In addition the scores are\npublished on a public leaderboard. At the conclusion of the competition the best entries of each\nparticipant are evaluated on an additional, hitherto unused, test set. The scores from these \ufb01nal\nevaluations are published. The comparison of the scores on the adaptively reused test set and one-\ntime use test set frequently reveals signi\ufb01cant over\ufb01tting to the reused test set (e.g. [Win, Kaga]),\na well-recognized issue frequently discussed on Kaggle\u2019s blog and user forums [Kagb, Kagc].\nDespite the basic role that adaptivity plays in data analysis we are not aware of previous\ngeneral e\ufb00orts to address its e\ufb00ects on the statistical validity of the results (see Section 1.4 for\nan overview of existing approaches to the problem). We show that, surprisingly, the challenges\nof adaptivity can be addressed using insights from di\ufb00erential privacy, a de\ufb01nition of privacy\ntailored to privacy-preserving data analysis. Roughly speaking, di\ufb00erential privacy ensures that\nthe probability of observing any outcome from an analysis is \u201cessentially unchanged\u201d by modifying\n2\nany single dataset element (the probability distribution is over the randomness introduced by the\nalgorithm). Di\ufb00erentially private algorithms permit a data analyst to learn about the dataset as a\nwhole (and, by extension, the distribution from which the data were drawn), while simultaneously\nprotecting the privacy of the individual data elements. Strong composition properties show this\nholds even when the analysis proceeds in a sequence of adaptively chosen, individually di\ufb00erentially\nprivate, steps.\n1.1\nProblem De\ufb01nition\nWe consider the standard setting in statistics and statistical learning theory: an analyst is given\nsamples drawn randomly and independently from some unknown distribution P over a discrete\nuniverse X of possible data points. While our approach can be applied to any output of data\nanalysis, we focus on real-valued functions de\ufb01ned on X. Speci\ufb01cally, for a function \u03c8: X \u2192[0, 1]\nproduced by the analyst we consider the task of estimating the expectation P[\u03c8] = Ex\u223cP[\u03c8(x)] up\nto some additive error \u03c4 usually referred to as tolerance. We require the estimate to be within this\nerror margin with high probability.\nWe choose this setup for three reasons. First, a variety of quantities of interest in data analysis\ncan be expressed in this form for some function \u03c8.\nFor example, true means and moments of\nindividual attributes, correlations between attributes and the generalization error of a predictive\nmodel or classi\ufb01er. Next, a request for such an estimate is referred to as a statistical query in\nthe context of the well-studied statistical query model [Kea98, FGR+13], and it is known that\nusing statistical queries in place of direct access to data it is possible to implement most standard\nanalyses used on i.i.d. data (see [Kea98, BDMN05, CKL+06] for examples). Finally, the problem\nof providing accurate answers to a large number of queries for the average value of a function on\nthe dataset has been the subject of intense investigation in the di\ufb00erential privacy literature.1\nWe address the following basic question: how many adaptively chosen statistical queries can be\ncorrectly answered using n samples drawn i.i.d. from P? The conservative approach of using fresh\nsamples for each adaptively chosen query would lead to a sample complexity that scales linearly\nwith the number of queries m. We observe that such a bad dependence is inherent in the standard\napproach of estimating expectations by the exact empirical average on the samples. This is directly\nimplied by the techniques from [DN03] who show how to make linearly many non-adaptive counting\nqueries to a dataset, and reconstruct nearly all of it. Once the data set is nearly reconstructed it is\neasy to make a query for which the empirical average on the dataset is far from the true expectation.\nNote that this requires only a single round of adaptivity! A simpler and more natural example of\nthe same phenomenon is known as \u201cFreedman\u2019s paradox\u201d [Fre83] and we give an additional simple\nexample in the Appendix. This situation is in stark contrast to the non-adaptive case in which\nn = O\n\u0010\nlog m\n\u03c4 2\n\u0011\nsamples su\ufb03ce to answer m queries with tolerance \u03c4 using empirical averages. Below\nwe refer to using empirical averages to evaluate the expectations of query functions as the na\u00a8\u0131ve\nmethod.\n1.2\nOur Results\nOur main result is a broad transfer theorem showing that any adaptive analysis that is carried\nout in a di\ufb00erentially private manner must lead to a conclusion that generalizes to the underlying\n1The average value of a function \u03c8 on a set of random samples is a natural estimator of P[\u03c8]. In the di\ufb00erential\nprivacy literature such queries are referred to as (fractional) counting queries.\n3\ndistribution. This theorem allows us to draw on a rich body of results in di\ufb00erential privacy and\nto obtain corresponding results for our problem of guaranteeing validity in adaptive data analysis.\nBefore we state this general theorem, we describe a number of important corollaries for the question\nwe formulated above.\nOur primary application is that, remarkably, it is possible to answer nearly exponentially many\nadaptively chosen statistical queries (in the size of the data set n). Equivalently, this reduces the\nsample complexity of answering m queries from linear in the number of queries to polylogarithmic,\nnearly matching the dependence that is necessary for non-adaptively chosen queries.\nTheorem 1 (Informal). There exists an algorithm that given a dataset of size at least n \u2265\nmin(n0, n1), can answer any m adaptively chosen statistical queries so that with high probability,\neach answer is correct up to tolerance \u03c4, where:\nn0 = O\n \n(log m)3/2p\nlog |X|\n\u03c4 7/2\n!\nand\nn1 = O\n\u0012log m \u00b7 log |X|\n\u03c4 4\n\u0013\n.\nThe two bounds above are incomparable. Note that the \ufb01rst bound is larger than the sample\ncomplexity needed to answer non-adaptively chosen queries by only a factor of O\n\u0010p\nlog m log |X|/\u03c4 3/2\u0011\n,\nwhereas the second one is larger by a factor of O\n\u0000log(|X|)/\u03c4 2\u0001\n. Here log |X| should be viewed as\nroughly the dimension of the domain. For example, if the underlying domain is X = {0, 1}d, the\nset of all possible vectors of d-boolean attributes, then log |X| = d.\nThe above mechanism is not computationally e\ufb03cient (it has running time linear in the size of\nthe data universe |X|, which is exponential in the dimension of the data). A natural question raised\nby our result is whether there is an e\ufb03cient algorithm for the task. This question was addressed\nin [HU14, SU14] who show that under standard cryptographic assumptions any algorithm that can\nanswer more than \u2248n2 adaptively chosen statistical queries must have running time exponential\nin log |X|.\nWe show that it is possible to match this quadratic lower bound using a simple and practical\nalgorithm that perturbs the answer to each query with independent noise.\nTheorem 2 (Informal). There exists a computationally e\ufb03cient algorithm for answering m adap-\ntively chosen statistical queries, such that with high probability, the answers are correct up to toler-\nance \u03c4, given a data set of size at least n \u2265n0 for:\nn0 = O\n \u221am(log m)3/2\n\u03c4 5/2\n!\n.\nFinally, we show a computationally e\ufb03cient method which can answer exponentially many\nqueries so long as they were generated using o(n) rounds of adaptivity, even if we do not know\nwhere the rounds of adaptivity lie. Another practical advantage of this algorithm is that it only\npays the price for a round if adaptivity actually causes over\ufb01tting. In other words, the algorithm\ndoes not pay for the adaptivity itself but only for the actual harm to statistical validity that\nadaptivity causes. This means that in many situations it would be possible to use this algorithm\nsuccessfully with a much smaller \u201ce\ufb00ective\u201d r (provided that a good bound on it is known).\n4\nTheorem 3 (Informal). There exists a computationally e\ufb03cient algorithm for answering m adap-\ntively chosen statistical queries, generated in r rounds of adaptivity, such that with high probability,\nthe answers are correct up to some tolerance \u03c4, given a data set of size at least n \u2265n0 for:\nn0 = O\n\u0012r log m\n\u03c4 2\n\u0013\n.\nFormal statements of these results appear in Section 5.\n1.3\nOverview of Techniques\nWe consider a setting in which an arbitrary adaptive data analyst chooses queries to ask (as a\nfunction of past answers), and receives answers from an algorithm referred to as an oracle whose\ninput is a dataset S of size n randomly drawn from Pn. To begin with, the oracles we use will\nonly guarantee accuracy with respect to the empirical average on their input dataset S, but they\nwill simultaneously guarantee di\ufb00erential privacy. We exploit a crucial property about di\ufb00erential\nprivacy, known as its post-processing guarantee: Any algorithm that can be described as the\n(possibly randomized) post-processing of the output of a di\ufb00erentially private algorithm is itself\ndi\ufb00erentially private.\nHence, although we do not know how an arbitrary analyst is adaptively\ngenerating her queries, we do know that if the only access she has to S is through a di\ufb00erentially\nprivate algorithm, then her method of producing query functions must be di\ufb00erentially private\nwith respect to S. We can therefore, without loss of generality, think of the oracle and the analyst\nas a single algorithm A that is given a random data set S and returns a di\ufb00erentially private\noutput query \u03c6 = A(S). Note that \u03c6 is random both due to the internal randomness of A and the\nrandomness of the data S. This picture is the starting point of our analysis, and allows us to study\nthe generalization properties of queries which are generated by di\ufb00erentially private algorithms,\nrather than estimates returned by them.\nOur results then follow from a strong connection we make between di\ufb00erential privacy and\ngeneralization, which will likely have applications beyond those that we explore in this paper. At\na high level, we prove that if A is a di\ufb00erentially private algorithm then the empirical average\nof a function that it outputs on a random dataset will be close to the true expectation of the\nfunction with high probability2 (over the choice of the dataset and the randomness of A). More\nformally, for a dataset S = (x1, . . . , xn) and a function \u03c8 : X \u2192[0, 1], let ES[\u03c8] = 1\nn\nPn\ni=1 \u03c8(xi)\ndenote the empirical average of \u03c8. We denote a random dataset chosen from Pn by S. For any\n\ufb01xed function \u03c8, the empirical average ES[\u03c8] is strongly concentrated around its expectation P[\u03c8].\nHowever, this statement is no longer true if \u03c8 is allowed to depend on S (which is what happens if\nwe choose functions adaptively, using previous estimates on S). However for a hypothesis output\nby a di\ufb00erentially private A on S (denoted by \u03c6 = A(S)), we show that ES[\u03c6] is close to P[\u03c6] with\nhigh probability.\nHigh probability bounds are necessary to ensure that valid answers can be given to an exponen-\ntially large number of queries. To prove these bounds, we show that di\ufb00erential privacy roughly\npreserves the moments of ES[\u03c6] even when conditioned on \u03c6 = \u03c8 for any \ufb01xed \u03c8. Now using strong\nconcentration of the k-th moment of ES[\u03c8] around P[\u03c8]k, we can obtain that ES[\u03c6] is concentrated\naround P[\u03c6]. Such an argument works only for (\u03b5, 0)-di\ufb00erential privacy due to conditioning on\n2A weaker connection that gives closeness in expectation over the dataset and algorithm\u2019s randomness was known\nto some experts and is considered folklore. We give a more detailed comparison in Sec. 1.4 and Sec. 2.1.\n5\nthe event \u03c6 = \u03c8 which might have arbitrarily low probability. We use a more delicate condition-\ning to obtain the extension to (\u03b5, \u03b4)-di\ufb00erential privacy. We note that (\u03b5, \u03b4)-di\ufb00erential privacy is\nnecessary to obtain the stronger bounds that we use for Theorems 1 and 2.\nWe give an alternative, simpler proof for (\u03b5, 0)-di\ufb00erential privacy that, in addition, extends\nthis connection beyond expectations of functions. We consider a di\ufb00erentially private algorithm A\nthat maps a database S \u223cPn to elements from some arbitrary range Z. Our proof shows that if\nwe have a collection of events R(y) de\ufb01ned over databases, one for each element y \u2208Z, and each\nevent is individually unlikely in the sense that for all y, the probability that S \u2208R(y) is small, then\nthe probability remains small that S \u2208R(Y ), where Y = A(S). Note that this statement involves\na re-ordering of quanti\ufb01ers. The hypothesis of the theorem says that the probability of event R(y)\nis small for each y, where the randomness is taken over the choice of database S \u223cPn, which is\nindependent of y. The conclusion says that the probability of R(Y ) remains small, even though\nY is chosen as a function of S, and so is no longer independent. The upshot of this result is that\nadaptive analyses, if performed via a di\ufb00erentially private algorithm, can be thought of (almost) as\nif they were non-adaptive, with the data being drawn after all of the decisions in the analysis are\n\ufb01xed.\nTo prove this result we note that it would su\ufb03ce to establish that for every y \u2208Z, P[S \u2208\nR(y) | Y = y] is not much larger than P[S \u2208R(y)]. By Bayes\u2019 rule, for every dataset S,\nP[S = S | Y = y]\nP[S = S]\n= P[Y = y | S = S]\nP[Y = y]\n.\nTherefore, to bound the ratio of P[S \u2208R(y) | Y = y] to P[S \u2208R(y)] it is su\ufb03cient to bound\nthe ratio of P[Y = y | S = S] to P[Y = y] for most S \u2208R(y).\nDi\ufb00erential privacy implies\nthat P[Y = y | S = S] does not change fast as a function of S. From here, using McDiarmid\u2019s\nconcentration inequality, we obtain that P[Y = y | S = S] is strongly concentrated around its\nmean, which is exactly P[Y = y].\n1.4\nRelated Work\nNumerous techniques have been developed by statisticians to address common special cases of\nadaptive data analysis. Most of them address a single round of adaptivity such as variable selection\nfollowed by regression on selected variables or model selection followed by testing and are optimized\nfor speci\ufb01c inference procedures (the literature is too vast to adequately cover here, see Ch. 7 in\n[HTF09] for a textbook introduction and [TT15] for a survey of some recent work). In contrast,\nour framework addresses multiple stages of adaptive decisions, possible lack of a predetermined\nanalysis protocol and is not restricted to any speci\ufb01c procedures.\nThe traditional perspective on why adaptivity in data analysis invalidates the signi\ufb01cance levels\nof statistical procedures given for the non-adaptive case is that one ends up disregarding all the\nother possible procedures or tests that would have been performed had the data been di\ufb00erent\n(see e.g. [SNS11]). It is well-known that when performing multiple tests on the same data one\ncannot use signi\ufb01cance levels of individual tests and instead it is necessary to control measures\nsuch as the false discovery rate [BH95]. This view makes it necessary to explicitly account for all\nthe possible ways to perform the analysis in order to provide validity guarantees for the adaptive\nanalysis. While this approach might be possible in simpler studies, it is technically challenging and\noften impractical in more complicated analyses [GL14].\n6\nThere are procedures for controlling false discovery in a sequential setting in which tests arrive\none-by-one [FS08, ANR11, AR14]. However the analysis of such tests crucially depends on tests\nmaintaining their statistical properties despite conditioning on previous outcomes. It is therefore\nunsuitable for the problem we consider here, in which we place no restrictions on the analyst.\nThe classical approach in theoretical machine learning to ensure that empirical estimates gen-\neralize to the underlying distribution is based on the various notions of complexity of the set of\nfunctions output by the algorithm, most notably the VC dimension (see [KV94] or [SSBD14] for a\ntextbook introduction). If one has a sample of data large enough to guarantee generalization for\nall functions in some class of bounded complexity, then it does not matter whether the data ana-\nlyst chooses functions in this class adaptively or non-adaptively. Our goal, in contrast, is to prove\ngeneralization bounds without making any assumptions about the class from which the analyst can\nchoose query functions. In this case the adaptive setting is very di\ufb00erent from the non-adaptive\nsetting.\nAn important line of work [BE02, MNPR06, PRMN04, SSSSS10] establishes connections be-\ntween the stability of a learning algorithm and its ability to generalize. Stability is a measure of\nhow much the output of a learning algorithm is perturbed by changes to its input. It is known that\ncertain stability notions are necessary and su\ufb03cient for generalization. Unfortunately, the stability\nnotions considered in these prior works are not robust to post-processing, and so the stability of\na query answering procedure would not guarantee the stability of the query generating procedure\nused by an arbitrary adaptive analyst. They also do not compose in the sense that running mul-\ntiple stable algorithms sequentially and adaptively may result in a procedure that is not stable.\nDi\ufb00erential privacy is stronger than these previously studied notions of stability, and in particular\nenjoys strong post-processing and composition guarantees. This provides a calculus for building up\ncomplex algorithms that satisfy stability guarantees su\ufb03cient to give generalization. Past work has\nconsidered the generalization properties of one-shot learning procedures. Our work can in part be\ninterpreted as showing that di\ufb00erential privacy implies generalization in the adaptive setting, and\nbeyond the framework of learning.\nDi\ufb00erential privacy emerged from a line of work [DN03, DN04, BDMN05], culminating in the\nde\ufb01nition given by [DMNS06]. It de\ufb01nes a stability property of an algorithm developed in the\ncontext of data privacy. There is a very large body of work designing di\ufb00erentially private algorithms\nfor various data analysis tasks, some of which we leverage in our applications. Most crucially, it is\nknown how to accurately answer exponentially many adaptively chosen queries on a \ufb01xed dataset\nwhile preserving di\ufb00erential privacy [RR10, HR10], which is what yields the main application in\nour paper, when combined with our main theorem. See [Dwo11] for a short survey and [DR14] for\na textbook introduction to di\ufb00erential privacy.\nFor di\ufb00erentially private algorithms that output a hypothesis it has been known as folklore that\ndi\ufb00erential privacy implies stability of the hypothesis to replacing (or removing) an element of the\ninput dataset. Such stability is long known to imply generalization in expectation (e.g. [SSSSS10]).\nSee Section 2.1 for more details. Our technique can be seen as a substantial strengthening of this\nobservation: from expectation to high probability bounds (which is crucial for answering many\nqueries), from pure to approximate di\ufb00erential privacy (which is crucial for our improved e\ufb03cient\nalgorithms), and beyond the expected error of a hypothesis.\nFurther Developments: Our work has attracted substantial interest to the problem of statistical\nvalidity in adaptive data analysis and its relationship to di\ufb00erential privacy. Hardt and Ullman\n[HU14] and Steinke and Ullman [SU14] have proven complementary computational lower bounds\n7\nfor the problem formulated in this work. They show that, under standard cryptographic assump-\ntions, the exponential running time of the algorithm instantiating our main result is unavoidable.\nSpeci\ufb01cally, that the square-root dependence on the number of queries in the sample complexity\nof our e\ufb03cient algorithm is nearly optimal, among all computationally e\ufb03cient mechanisms for\nanswering arbitrary statistical queries.\nIn [DFH+15a] we discuss approaches to the problem of adaptive data analysis more generally.\nWe demonstrate how di\ufb00erential privacy and description-length-based analyses can be used in\nthis context. In particular, we show that the bounds on n1 obtained in Theorem 1 can also be\nobtained by analyzing the transcript of the median mechanism for query answering [RR10] (even\nwithout adding noise). Further, we de\ufb01ne a notion of approximate max-information between the\ndataset and the output of the analysis that ensures generalization with high probability, composes\nadaptively and uni\ufb01es (pure) di\ufb00erential privacy and description-length-based analyses. We also\ndemonstrate an application of these techniques to the problem of reusing the holdout (or testing)\ndataset. An overview of this work and [DFH+15a] intended for a broad scienti\ufb01c audience appears\nin [DFH+15b].\nBlum and Hardt [BH15] give an algorithm for reusing the holdout dataset specialized to the\nproblem of maintaining an accurate leaderboard for a machine learning competition (such as those\norganized by Kaggle Inc. and discussed earlier).\nTheir generalization analysis is based on the\ndescription length of the algorithm\u2019s transcript.\nOur results for approximate (\u03b4 > 0) di\ufb00erential privacy apply only to statistical queries (see\nThm. 10). Bassily, Nissim, Smith, Steinke, Stemmer and Ullman [BNS+15] give a novel, elegant\nanalysis of the \u03b4 > 0 case that gives an exponential improvement in the dependence on \u03b4 and gen-\neralizes it to arbitrary low-sensitivity queries. This leads to stronger bounds on sample complexity\nthat remove an O(\np\nlog(m)/\u03c4) factor from the bounds on n0 we give in Theorems 1 and 2. It also\nimplies a similar improvement and generalization to low-sensitivity queries in the reusable holdout\napplication [DFH+15a].\nAnother implication of our work is that composition and post-processing properties (which are\ncrucial in the adaptive setting) can be ensured by measuring the e\ufb00ect of data analysis on the\nprobability space of the analysis outcomes. Several additional techniques of this type have been\nrecently analyzed. Bassily et al. [BNS+15] show that generalization in expectation (as discussed\nin Cor. 7) can also be obtained from two additional notions of stability: KL-stability and TV-\nstability that bound the KL-divergence and total variation distance between output distributions\non adjacent datasets, respectively. Russo and Zou [RZ15] show that generalization in expectation\ncan be derived by bounding the mutual information between the dataset and the output of analysis.\nThey give applications of their approach to analysis of adaptive feature selection procedures. We\nnote that these techniques do not imply high-probability generalization bounds that we obtain here\nand in [DFH+15a].\n2\nPreliminaries\nLet P be a distribution over a discrete universe X of possible data points. For a function \u03c8: X \u2192\n[0, 1] let P[\u03c8] = Ex\u223cP[\u03c8(x)]. Given a dataset S = (x1, . . . , xn), a natural estimator of P[\u03c8] is the\nempirical average 1\nn\nPn\ni=1 \u03c8(xi). We let ES denote the empirical distribution that assigns weight\n1/n to each of the data points in S and thus ES[\u03c8] is equal to the empirical average of \u03c8 on S.\nDe\ufb01nition 4. A statistical query is de\ufb01ned by a function \u03c8 : X \u2192[0, 1] and tolerance \u03c4. For\n8\ndistribution P over X a valid response to such a query is any value v such that |v \u2212P(\u03c8)| \u2264\u03c4.\nThe standard Hoe\ufb00ding bound implies that for a \ufb01xed query function (chosen independently\nof the data) the probability over the choice of the dataset that ES[\u03c8] has error greater than \u03c4 is\nat most 2 \u00b7 exp(\u22122\u03c4 2n). This implies that an exponential in n number of statistical queries can be\nevaluated within \u03c4 as long as the hypotheses do not depend on the data.\nWe now formally de\ufb01ne di\ufb00erential privacy. We say that datasets S, S\u2032 are adjacent if they di\ufb00er\nin a single element.\nDe\ufb01nition 5. [DMNS06, DKM+06] A randomized algorithm A with domain X n is (\u03b5, \u03b4)-di\ufb00erentially\nprivate if for all O \u2286Range(A) and for all pairs of adjacent datasets S, S\u2032 \u2208X n:\nP[A(S) \u2208O] \u2264exp(\u03b5) P[A(S\u2032) \u2208O] + \u03b4,\nwhere the probability space is over the coin \ufb02ips of the algorithm A.\nThe case when \u03b4 = 0 is\nsometimes referred to as pure di\ufb00erential privacy, and in this case we may say simply that A is\n\u03b5-di\ufb00erentially private.\nAppendix B contains additional background that we will need later on.\n2.1\nReview of the known connection between privacy and generalization\nWe now brie\ufb02y summarize the basic connection between di\ufb00erential privacy and generalization that\nis considered folklore. This connection follows from an observation that di\ufb00erential privacy implies\nstability to replacing a single sample in a dataset together with known connection between stability\nand on-average generalization. We \ufb01rst state the form of stability that is immediately implied by\nthe de\ufb01nition of di\ufb00erential privacy. For simplicity, we state it only for [0, 1]-valued functions. The\nextension to any other bounded range is straightforward.\nLemma 6. Let A be an (\u01eb, \u03b4)-di\ufb00erentially private algorithm ranging over functions from X to\n[0, 1]. For any pair of adjacent datasets S and S\u2032 and x \u2208X:\nE [A(S)(x)] \u2264e\u03b5 \u00b7 E\n\u0002\nA(S\u2032)(x)\n\u0003\n+ \u03b4,\nand, in particular,\n\f\fE [A(S)(x)] \u2212E\n\u0002\nA(S\u2032)(x)\n\u0003\f\f \u2264e\u03b5 \u22121 + \u03b4.\n(1)\nAlgorithms satisfying equation (1) are referred to as strongly-uniform-replace-one stable with\nrate (e\u03b5 \u22121 + \u03b4) by Shalev-Schwartz et al. [SSSSS10]. It is easy to show and is well-known that\nreplace-one stability implies generalization in expectation, referred to as on-average generalization\n[SSSSS10, Lemma 11]. In our case this connection immediately gives the following corollary.\nCorollary 7. Let A be an (\u01eb, \u03b4)-di\ufb00erentially private algorithm ranging over functions from X\nto [0, 1], let P be a distribution over X and let S be an independent random variable distributed\naccording to Pn. Then\n| E[ES[A(S)]] \u2212E[P[A(S)]]| \u2264e\u03b5 \u22121 + \u03b4.\n9\nThis corollary was observed in the context of functions expressing the loss of the hypothesis\noutput by a (private) learning algorithm, that is, \u03c6(x) = L(h(x), x), where x is a sample (possibly\nincluding a label), h is a hypothesis function and L is a non-negative loss function. When applied\nto such a function, Corollary 7 implies that the expected true loss of a hypothesis output by an\n(\u03b5, \u03b4)-di\ufb00erentially private algorithm is at most e\u03b5 \u22121 + \u03b4 larger than the expected empirical loss of\nthe output hypothesis, where the expectation is taken over the random dataset and the randomness\nof the algorithm. A special case of this corollary is stated in a recent work of Bassily et al. [BST14].\nMore recently, Wang et al. [WLF15] have similarly used the stability of di\ufb00erentially private learning\nalgorithms to show a general equivalence of di\ufb00erentially private learning and di\ufb00erentially private\nempirical loss minimization.\nA standard way to obtain a high-probability bound from a bound on expectation in Corollary\n7 is to use Markov\u2019s inequality. Using this approach, a bound that holds with probability 1 \u2212\u03b2\nwill require a polynomial dependence of the sample size on 1/\u03b2. While this might lead to a useful\nbound when the expected empirical loss is small it is less useful in the common scenario when\nthe empirical loss is relatively large. In contrast, our results in Sections 3 and 4 directly imply\ngeneralization bounds with logarithmic dependence of the sample size on 1/\u03b2. For example, in\nTheorem 9 we show that for any \u03b5, \u03b2 > 0 and n \u2265O(ln(1/\u03b2)/\u03b52), the output of an \u03b5-di\ufb00erentially\nprivate algorithm A satis\ufb01es P [|P[A(S)] \u2212ES[A(S)]| > 2\u03b5] \u2264\u03b2.\n3\nDi\ufb00erential Privacy and Preservation of Moments\nWe now prove that if a function \u03c6 is output by an (\u03b5, \u03b4)-di\ufb00erentially private algorithm A on input\nof a random dataset S drawn from Pn, then the average of \u03c6 on S, that is, ES[\u03c6], is concentrated\naround its true expectation P[\u03c6].\nThe statement we wish to prove is nontrivial due to the apparent dependency between the\nfunction \u03c6 and the dataset S that arises because \u03c6 = A(S). If instead \u03c6 was evaluated on a fresh\ndataset T drawn independently of \u03c6, then indeed we would have E ET [\u03c6] = P[\u03c6]. At a high level,\nour goal is therefore to resolve the dependency between \u03c6 and S by relating the random variable\nES[\u03c6] to the random variable ET [\u03c6]. To argue that these random variables are close with high\nprobability we relate the moments of ES[\u03c6] to the moments of ET [\u03c6]. The moments of ET [\u03c6] are\nrelatively easy to bound using standard techniques.\nOur proof is easier to execute when \u03b4 = 0 and we start with this case for the sake of exposition.\n3.1\nSimpler case where \u03b4 = 0\nOur main technical tool relates the moments of the random variables that we are interested in.\nLemma 8. Assume that A is an (\u01eb, 0)-di\ufb00erentially private algorithm ranging over functions from\nX to [0, 1]. Let S, T be independent random variables distributed according to Pn. For any function\n\u03c8 : X \u2192[0, 1] in the support of A(S),\nE\nh\nES[\u03c6]k \f\f\f \u03c6 = \u03c8\ni\n\u2264ek\u03b5 \u00b7 E\nh\nET [\u03c8]ki\n.\n(2)\nProof. We use I to denote a k-tuple of indices (i1, . . . , ik) \u2208[n]k and use I to denote a k-tuple\nchosen randomly and uniformly from [n]k. For a data set T = (y1, . . . , yn) we denote by \u03a0I\nT (\u03c8) =\n10\nQ\nj\u2208[k] \u03c8(yij). We \ufb01rst observe that for any \u03c8,\nET [\u03c8]k = E[\u03a0I\nT (\u03c8)].\n(3)\nFor two datasets S, T \u2208X n, let SI\u2190T denote the data set in which for every j \u2208[k], element ij\nin S is replaced with the corresponding element from T. We \ufb01x I. Note that the random variable\nSI\u2190T is distributed according to Pn and therefore\nE\n\u0002\n\u03a0I\nS(\u03c6) | \u03c6 = \u03c8\n\u0003\n= E\n\u0002\n\u03a0I\nSI\u2190T (A(SI\u2190T )) | A(SI\u2190T ) = \u03c8\n\u0003\n= E\n\u0002\n\u03a0I\nT (A(SI\u2190T )) | A(SI\u2190T ) = \u03c8\n\u0003\n=\nZ 1\n0\nP\n\u0002\n\u03a0I\nT (A(SI\u2190T )) \u2265t and A(SI\u2190T ) = \u03c8\n\u0003\nP [A(SI\u2190T ) = \u03c8]\ndt\n=\nZ 1\n0\nP\n\u0002\n\u03a0I\nT (A(SI\u2190T )) \u2265t and A(SI\u2190T ) = \u03c8\n\u0003\nP [\u03c6 = \u03c8]\ndt\n(4)\nNow for any \ufb01xed t, S and T consider the event \u03a0I\nT (A(S)) \u2265t and A(S) = \u03c8 (de\ufb01ned on the\nrange of A). Data sets S and SI\u2190T di\ufb00er in at most k elements. Therefore, by the \u03b5-di\ufb00erential\nprivacy of A and Lemma 24, the distribution A(S) and the distribution A(SI\u2190T ) satisfy:\nP\n\u0002\n\u03a0I\nT (A(SI\u2190T )) \u2265t and A(SI\u2190T) = \u03c8\n\u0003\n\u2264ek\u03b5 \u00b7 P\n\u0002\n\u03a0I\nT (A(S)) \u2265t and A(S) = \u03c8\n\u0003\n.\nTaking the probability over S and T we get:\nP\n\u0002\n\u03a0I\nT (A(SI\u2190T )) \u2265t and A(SI\u2190T ) = \u03c8\n\u0003\n\u2264ek\u03b5 \u00b7 P\n\u0002\n\u03a0I\nT (\u03c6) \u2265t and \u03c6 = \u03c8\n\u0003\n.\nSubstituting this into eq. (4) we get\nE\n\u0002\n\u03a0I\nS(\u03c6) | \u03c6 = \u03c8\n\u0003\n\u2264ek\u03b5\nZ 1\n0\nP\n\u0002\n\u03a0I\nT (\u03c6) \u2265t and \u03c6 = \u03c8\n\u0003\nP [\u03c6 = \u03c8]\ndt\n= ek\u03b5 E\n\u0002\n\u03a0I\nT (\u03c6) | \u03c6 = \u03c8\n\u0003\n= ek\u03b5 E\n\u0002\n\u03a0I\nT (\u03c8) | \u03c6 = \u03c8\n\u0003\n= ek\u03b5 E\n\u0002\n\u03a0I\nT (\u03c8)\n\u0003\nTaking the expectation over I and using eq. (3) we obtain that\nE\nh\nES[\u03c6]k \f\f\f \u03c6 = \u03c8\ni\n\u2264ek\u03b5 E\nh\nET [\u03c8]ki\n,\ncompleting the proof of the lemma.\nWe now turn our moment inequality into a theorem showing that ES[\u03c6] is concentrated around\nthe true expectation P[\u03c6].\nTheorem 9. Let A be an \u03b5-di\ufb00erentially private algorithm that given a dataset S outputs a function\nfrom X to [0, 1]. For any distribution P over X and random variable S distributed according to\nPn we let \u03c6 = A(S). Then for any \u03b2 > 0, \u03c4 > 0 and n \u226512 ln(4/\u03b2)/\u03c4 2, setting \u03b5 \u2264\u03c4/2 ensures\nP [|P[\u03c6] \u2212ES[\u03c6]| > \u03c4] \u2264\u03b2, where the probability is over the randomness of A and S.\n11\nProof. Consider an execution of A with \u03b5 = \u03c4/2 on a data set S of size n \u226512 ln(4/\u03b2)/\u03c4 2. By\nLemma 29 we obtain that RHS of our bound in Lemma 8 is at most e\u03b5kMk[B(n, P[\u03c8])]. We use\nLemma 31 with \u03b5 = \u03c4/2 and k = 4 ln(4/\u03b2)/\u03c4 (noting that the assumption n \u226512 ln(4/\u03b2)/\u03c4 2\nensures the necessary bound on n) to obtain that\nP [ES[\u03c6] \u2265P[\u03c8] + \u03c4 | \u03c6 = \u03c8] \u2264\u03b2/2.\nThis holds for every \u03c8 in the range of A and therefore,\nP [ES[\u03c6] \u2265P[\u03c6] + \u03c4] \u2264\u03b2/2.\nWe can apply the same argument to the function 1 \u2212\u03c6 to obtain that\nP [ES[\u03c6] \u2264P[\u03c6] \u2212\u03c4] \u2264\u03b2/2.\nA union bound over the above inequalities implies the claim.\n3.2\nExtension to \u03b4 > 0\nWe now extend our proof to the case when A satis\ufb01es (\u03b5, \u03b4)-di\ufb00erential privacy for su\ufb03ciently\nsmall but nonzero \u03b4 > 0. The main di\ufb03culty in extending the previous proof is that the condition\n{\u03c6 = \u03c8} appearing in Lemma 8 may have arbitrarily small probability. A simple extension of the\nprevious proof would lead to an error of \u03b4/ P[\u03c6 = \u03c8]. We avoid this issue by using a more carefully\nchosen condition. Speci\ufb01cally, instead of restricting \u03c6 to be equal to a particular function \u03c8, we\nonly constrain P[\u03c6] to be in a certain interval of length \u03c4. This conditioning still gives us enough\ninformation about \u03c6 in order to control ET [\u03c6], while allowing us to ignore events of exceedingly\nsmall probability.\nTheorem 10. Let A be an (\u03b5, \u03b4)-di\ufb00erentially private algorithm that given a dataset S outputs\na function from X to [0, 1]. For any distribution P over X and random variable S distributed\naccording to Pn we let \u03c6 = A(S). Then for any \u03b2 > 0, \u03c4 > 0 and n \u226548 ln(4/\u03b2)/\u03c4 2, setting\n\u03b5 \u2264\u03c4/4 and \u03b4 = exp(\u22124 \u00b7 ln(8/\u03b2)/\u03c4) ensures P [|P[\u03c6] \u2212ES[\u03c6]| > \u03c4] \u2264\u03b2, where the probability is\nover the randomness of A and S.\nProof. We use the notation from the proof of Theorem 9 and consider an execution of A with \u03b5\nand \u03b4 satisfying the conditions of the theorem.\nLet L = \u23081/\u03c4\u2309. For a value \u2113\u2208[L] we use B\u2113to denote the interval set [(\u2113\u22121)\u03c4, \u2113\u03c4].\nWe say that \u2113\u2208[L] is heavy if P [P[\u03c6] \u2208B\u2113] \u2265\u03b2/(4L) and we say that \u2113is light otherwise. The\nkey claim that we prove is an upper bound on the k-th moment of ES[\u03c6] for heavy \u2113\u2019s:\nE\nh\nES[\u03c6]k \f\f\f P[\u03c6] \u2208B\u2113\ni\n\u2264ek\u03b5 \u00b7 Mk[B(n, \u03c4\u2113)] + \u03b4e(k\u22121)\u03b5 \u00b7 4L/\u03b2.\n(5)\nWe use the same decomposition of the k-th moment as before:\nE\nh\nES[\u03c6]k \f\f\f P[\u03c6] \u2208B\u2113\ni\n= E\n\u0002\n\u03a0I\nS(\u03c6)\n\f\f P[\u03c6] \u2208B\u2113\n\u0003\n.\nNow for a \ufb01xed I \u2208[n]k, exactly as in eq. (4), we obtain\nE\n\u0002\n\u03a0I\nS(\u03c6) | P[\u03c6] \u2208B\u2113\n\u0003\n=\nZ 1\n0\nP\n\u0002\n\u03a0I\nT (A(SI\u2190T )) \u2265t and P[A(SI\u2190T )] \u2208B\u2113\n\u0003\nP [P[\u03c6] \u2208B\u2113]\ndt\n(6)\n12\nNow for \ufb01xed values of t, S and T we consider the event \u03a0I\nT (A(S)) \u2265t and P[A(S)] \u2208B\u2113de\ufb01ned\non the range of A. Datasets S and SI\u2190T di\ufb00er in at most k elements. Therefore, by the (\u03b5, \u03b4)-\ndi\ufb00erential privacy of A and Lemma 24, the distribution over the output of A on input S and the\ndistribution over the output of A on input SI\u2190T satisfy:\nP\n\u0002\n\u03a0I\nT (A(SI\u2190T)) \u2265t and P[A(SI\u2190T )] \u2208B\u2113\n\u0003\n\u2264ek\u03b5 \u00b7 P\n\u0002\n\u03a0I\nT (A(S)) \u2265t and P[A(S)] \u2208B\u2113\n\u0003\n+ e(k\u22121)\u03b5\u03b4.\nTaking the probability over S and T and substituting this into eq. (6) we get\nE\n\u0002\n\u03a0I\nS(\u03c6) | P[\u03c6] \u2208B\u2113\n\u0003\n\u2264ek\u03b5\nZ 1\n0\nP\n\u0002\n\u03a0I\nT (\u03c6) \u2265t and P[\u03c6] \u2208B\u2113\n\u0003\nP [P[\u03c6] \u2208B\u2113]\ndt +\ne(k\u22121)\u03b5\u03b4\nP [P[\u03c6] \u2208B\u2113]\n= ek\u03b5 E\n\u0002\n\u03a0I\nT (\u03c6) | P[\u03c6] \u2208B\u2113\n\u0003\n+\ne(k\u22121)\u03b5\u03b4\nP [P[\u03c6] \u2208B\u2113]\nTaking the expectation over I and using eq. (3) we obtain:\nE\nh\nES[\u03c6]k \f\f\f P[\u03c6] \u2208B\u2113\ni\n\u2264ek\u03b5 E\nh\nET [\u03c6]k \f\f\f P[\u03c6] \u2208B\u2113\ni\n+\ne(k\u22121)\u03b5\u03b4\nP [P[\u03c6] \u2208B\u2113].\n(7)\nConditioned on P[\u03c6] \u2208B\u2113, P[\u03c6] \u2264\u03c4\u2113and therefore by Lemma 29,\nE\nh\nET [\u03c6]k \f\f\f P[\u03c6] \u2208B\u2113\ni\n\u2264Mk[B(n, \u03c4\u2113)].\nIn addition, by our assumption, \u2113is heavy, that is P [P[\u03c6] \u2208B\u2113] \u2265\u03b2/(4L). Substituting these\nvalues into eq. (7) we obtain the claim in eq. (5).\nAs before, we use Lemma 31 with \u03b5 = \u03c4/2 and k = 4(\u03c4\u2113) ln(4/\u03b2)/\u03c4 = 4\u2113ln(4/\u03b2) (noting that\ncondition n \u226512 ln(4/\u03b2)/\u03c4 2 ensures the necessary bound on n) to obtain that\nP [ES[\u03c6] \u2265\u03c4\u2113+ \u03c4 | P[\u03c6] \u2208B\u2113] \u2264\u03b2/2 + \u03b4e(k\u22121)\u03b5 \u00b7 4L\n\u03b2(\u03c4\u2113+ \u03c4)k ,\n(8)\nUsing condition \u03b4 = exp(\u22122 \u00b7 ln(4/\u03b2)/\u03c4) and inequality ln(x) \u2264x/e (for x > 0) we obtain\n\u03b4e(k\u22121)\u03b5 \u00b7 4L\n\u03b2((\u2113+ 1)\u03c4)k \u2264\n\u03b4 \u00b7 e2 ln(4/\u03b2) \u00b7 4/\u03c4\n\u03b2e4 ln((\u2113+1)\u03c4)\u00b7\u2113ln(4/\u03b2)\n\u2264\n\u03b4 \u00b7 e4 ln(4/\u03b2)\n\u03c4 \u00b7 e4 ln((\u2113+1)\u03c4)\u00b7\u2113ln(4/\u03b2) \u00b7 \u03b2\n4\n\u2264\u03b4 \u00b7 exp (4 ln(1/((\u2113+ 1)\u03c4)) \u00b7 \u2113ln(4/\u03b2) + 4 ln(4/\u03b2) + ln(1/\u03c4)) \u00b7 \u03b2\n4\n\u2264\u03b4 \u00b7 exp\n\u00124\ne \u00b7\n1\n(\u2113+ 1)\u03c4 \u00b7 \u2113ln(4/\u03b2) + 4 ln(4/\u03b2) + ln(1/\u03c4)\n\u0013\n\u00b7 \u03b2\n4\n\u2264\u03b4 \u00b7 exp\n\u00124\ne \u00b7 ln(4/\u03b2)/\u03c4 + 4 ln(4/\u03b2) + ln(1/\u03c4)\n\u0013\n\u00b7 \u03b2\n4\n\u2264\u03b4 \u00b7 exp (2 \u00b7 ln(4/\u03b2)/\u03c4) \u00b7 \u03b2\n4 \u2264\u03b2/4.\n13\nSubstituting this into eq. (8) we get\nP [ES[\u03c6] \u2265\u03c4\u2113+ \u03c4 | P[\u03c6] \u2208B\u2113] \u22643\u03b2/4.\nNote that, conditioned on P[\u03c6] \u2208B\u2113, P[\u03c6] \u2265\u03c4(\u2113\u22121), and therefore\nP [ES[\u03c6] \u2265P[\u03c6] + 2\u03c4 | P[\u03c6] \u2208B\u2113] \u22643\u03b2/4.\nThis holds for every heavy \u2113\u2208[L] and therefore,\nP [ES[\u03c6] \u2265P[\u03c6] + 2\u03c4] \u22643\u03b2/4 +\nX\n\u2113\u2208[L] is light\nP [P[\u03c6] \u2208B\u2113]\n\u22643\u03b2/4 + L\u03b2/(4L) = \u03b2.\nApply the same argument to 1 \u2212\u03c6 and use a union bound. We obtain the claim after rescaling \u03c4\nand \u03b2 by a factor 2.\n4\nBeyond statistical queries\nThe previous section dealt with statistical queries. A di\ufb00erent way of looking at our results is to\nde\ufb01ne for each function \u03c8 a set R(\u03c8) containing all datasets S such that \u03c8 is far from the correct\nvalue P[\u03c8] on S. Formally, R(\u03c8) = {S : |ES[\u03c8] \u2212P[\u03c8]| > \u03c4}. Our results showed that if \u03c6 = A(S)\nis the output of a di\ufb00erentially private algorithm A on a random dataset S, then P[S \u2208R(\u03c6)] is\nsmall.\nHere we prove a broad generalization that allows the di\ufb00erentially private algorithm to have an\narbitrary output space Z. The same conclusion holds for any collection of sets R(y) where y \u2208Z\nprovided that P[S \u2208R(y)] is small for all y \u2208Z.\nTheorem 11. Let A be an (\u03b5, 0)-di\ufb00erentially private algorithm with range Z. For a distribution\nP over X, let S be a random variable drawn from Pn. Let Y = A(S) be the random variable\noutput by A on input S. For each element y \u2208Z let R(y) \u2286X n be some subset of datasets and\nassume that maxy P[S \u2208R(y)] \u2264\u03b2. Then, for \u03b5 \u2264\nq\nln(1/\u03b2)\n2n\nwe have P[S \u2208R(Y )] \u22643\u221a\u03b2.\nProof. Fix y \u2208Z. We \ufb01rst observe that by Jensen\u2019s inequality,\nE\nS\u223cPn[ln(P[Y = y | S = S])] \u2264ln\n\u0012\nE\nS\u223cPn[P[Y = y | S = S]]\n\u0013\n= ln(P[Y = y]).\nFurther, by de\ufb01nition of di\ufb00erential privacy, for two databases S, S\u2032 that di\ufb00er in a single element,\nP[Y = y | S = S] \u2264e\u03b5 \u00b7 P[Y = y | S = S\u2032].\nNow consider the function g(S) = ln\n\u0010\nP[Y =y | S=S]\nP[Y =y]\n\u0011\n. By the properties above we have that\nE[g(S)] \u2264ln(P[Y = y])\u2212ln(P[Y = y]) = 0 and |g(S)\u2212g(S\u2032)| \u2264\u03b5. This, by McDiarmid\u2019s inequality\n(Lemma 28), implies that for any t > 0,\nP[g(S) \u2265\u03b5t] \u2264e\u22122t2/n.\n(9)\n14\nFor an integer i \u22651 let\nBi .=\n\u001a\nS\n\f\f\f\f \u03b5\nq\nn ln(2i/\u03b2)/2 \u2264g(S) \u2264\u03b5\nq\nn ln(2i+1/\u03b2)/2\n\u001b\nand let B0 .= {S | g(S) \u2264\u03b5\np\nn ln(2/\u03b2)/2}.\nBy inequality (9) we have that for i \u22651, P[g(S) \u2265\u03b5\np\nn ln(2i/\u03b2)/2] \u2264\u03b2/2i. Therefore, for all\ni \u22650,\nP[S \u2208Bi \u2229R(y)] \u2264\u03b2/2i,\nwhere the case of i = 0 follows from the assumptions of the lemma.\nBy Bayes\u2019 rule, for every S \u2208Bi,\nP[S = S | Y = y]\nP[S = S]\n= P[Y = y | S = S]\nP[Y = y]\n= exp(g(S)) \u2264exp\n\u0012\n\u03b5\nq\nn ln(2i+1/\u03b2)/2\n\u0013\n.\nTherefore,\nP[S \u2208Bi \u2229R(y) | Y = y] =\nX\nS\u2208Bi\u2229R(y)\nP[S = S | Y = y]\n\u2264exp\n\u0012\n\u03b5\nq\nn ln(2i+1/\u03b2)/2\n\u0013\n\u00b7\nX\nS\u2208Bi\u2229R(y)\nP[S = S]\n= exp\n\u0012\n\u03b5\nq\nn ln(2i+1/\u03b2)/2\n\u0013\n\u00b7 P[S \u2208Bi \u2229R(y)]\n\u2264exp\n\u0012\n\u03b5\nq\nn ln(2i+1/\u03b2)/2 \u2212ln(2i/\u03b2)\n\u0013\n.\n(10)\nThe condition \u03b5 \u2264\nq\nln(1/\u03b2)\n2n\nimplies that\n\u03b5\nr\nn ln(2i+1/\u03b2)\n2\n\u2212ln(2i/\u03b2) \u2264\nr\nln(1/\u03b2) ln(2i+1/\u03b2)\n4\n\u2212ln(2i/\u03b2)\n\u2264ln(2(i+1)/2/\u03b2)\n2\n\u2212ln(2i/\u03b2) = \u2212ln\n \n2(3i\u22121)/4\n\u221a\u03b2\n!\nSubstituting this into inequality (10), we get\nP[S \u2208Bi \u2229R(y) | Y = y] \u2264\n\u221a\u03b2\n2(3i\u22121)/4 .\nClearly, \u222ai\u22650Bi = X [n]. Therefore\nP[S \u2208R(y) | Y = y] =\nX\ni\u22650\nP[S \u2208Bi \u2229R(y) | Y = y] \u2264\nX\ni\u22650\n\u221a\u03b2\n2(3i\u22121)/4 =\np\n\u03b2 \u00b7\n21/4\n1 \u22122\u22123/4 \u22643\np\n\u03b2.\nFinally, let Y denote the distribution of Y . Then,\nP[S \u2208R(Y )] = E\ny\u223cY[P[S \u2208R(y) | Y = y]] \u22643\np\n\u03b2.\n15\nOur theorem gives a result for statistical queries that achieves the same bound as our earlier\nresult in Theorem 9 up to constant factors in the parameters.\nCorollary 12. Let A be an \u03b5-di\ufb00erentially private algorithm that outputs a function from X to\n[0, 1]. For a distribution P over X, let S be a random variable distributed according to Pn and\nlet \u03c6 = A(S). Then for any \u03c4 > 0, setting \u03b5 \u2264\np\n\u03c4 2 \u2212ln(2)/2n ensures P [|P[\u03c6] \u2212ES[\u03c6]| > \u03c4] \u2264\n3\n\u221a\n2e\u2212\u03c4 2n.\nProof. By the Cherno\ufb00bound, for any \ufb01xed query function \u03c8 : X \u2192[0, 1],\nP[|P[\u03c8] \u2212ES[\u03c8]| \u2265\u03c4] \u22642e\u22122\u03c4 2n.\nNow, by Theorem 11 for R(\u03c8) = {S \u2208X n | |P[\u03c8] \u2212ES[\u03c8]| > \u03c4}, \u03b2 = 2e\u22122\u03c4 2n and any \u03b5 \u2264\np\n\u03c4 2 \u2212ln(2)/2n,\nP [|P[\u03c6] \u2212ES[\u03c6]| > \u03c4] \u22643\n\u221a\n2e\u2212\u03c4 2n.\n5\nApplications\nTo obtain algorithms for answering adaptive statistical queries we \ufb01rst note that if for a query\nfunction \u03c8 and a dataset S, |P[\u03c8] \u2212ES[\u03c8]| \u2264\u03c4/2 then we can use an algorithm that outputs a\nvalue v that is \u03c4/2-close to ES[\u03c8] to obtain a value that is \u03c4-close to P[\u03c8]. Di\ufb00erentially private\nalgorithms that for a given dataset S and an adaptively chosen sequence of queries \u03c61, . . . , \u03c6m\nproduce a value close to ES[\u03c6i] for each query \u03c6i : X \u2192[0, 1] have been the subject of intense\ninvestigation in the di\ufb00erential privacy literature (see [DR14] for an overview). Such queries are\nusually referred to as (fractional) counting queries or linear queries in this context. This allows\nus to obtain statistical query answering algorithms by using various known di\ufb00erentially private\nalgorithms for answering counting queries.\nThe results in Sections 3 and 4 imply that |P[\u03c8] \u2212ES[\u03c8]| \u2264\u03c4 holds with high probability when-\never \u03c8 is generated by a di\ufb00erentially private algorithm M. This might appear to be inconsistent\nwith our application since there the queries are generated by an arbitrary (possibly adversarial)\nadaptive analyst and we can only guarantee that the query answering algorithm is di\ufb00erentially\nprivate. The connection comes from the following basic fact about di\ufb00erentially private algorithms:\nFact 13 (Postprocessing Preserves Privacy (see e.g. [DR14])). Let M : X n \u2192O be an (\u01eb, \u03b4)\ndi\ufb00erentially private algorithm with range O, and let F : O \u2192O\u2032 be an arbitrary randomized\nalgorithm. Then F \u25e6M : X n \u2192O\u2032 is (\u01eb, \u03b4)-di\ufb00erentially private.\nHence, an arbitrary adaptive analyst A is guaranteed to generate queries in a manner that is\ndi\ufb00erentially private in S so long as the only access that she has to S is through a di\ufb00erentially\nprivate query answering algorithm M.\nWe also note that the bounds we state here give the\nprobability of correctness for each individual answer to a query, meaning that the error probability\n\u03b2 is for each query \u03c6i and not for all queries at the same time. The bounds we state in Section 1.2\nhold with high probability for all m queries and to obtain them from the bounds in this section,\nwe apply the union bound by setting \u03b2 = \u03b2\u2032/m for some small \u03b2\u2032.\nWe now highlight a few applications of di\ufb00erentially private algorithms for answering counting\nqueries to our problem.\n16\n5.1\nLaplacian Noise Addition\nThe Laplacian Mechanism on input of a dataset S answers m adaptively chosen queries \u03c61, . . . , \u03c6m\nby responding with \u03c6i(S) + Lap(0, \u03c3) when given query \u03c6i. Here, Lap(0, \u03c3) denotes a Laplacian\nrandom variable of mean 0 and scale \u03c3. For suitably chosen \u03c3 the algorithm has the following\nguarantee.\nTheorem 14 (Laplace). Let \u03c4, \u03b2, \u01eb > 0 and de\ufb01ne\nnL(\u03c4, \u03b2, \u01eb, m) = m log(1/\u03b2)\n\u01eb\u03c4\n.\nn\u03b4\nL(\u03c4, \u03b2, \u01eb, \u03b4, m) =\np\nm log(1/\u03b4) log(1/\u03b2)\n\u01eb\u03c4\n.\nThere is computationally e\ufb03cient algorithm called Laplace which on input of a data set S of size\nn accepts any sequence of m adaptively chosen functions \u03c61, . . . , \u03c6m \u2208X [0,1] and returns estimates\na1, . . . , am such that for every i \u2208[m] we have P [|ES[\u03c6i] \u2212ai| > \u03c4] \u2264\u03b2. To achieve this guarantee\nunder (\u01eb, 0)-di\ufb00erential privacy, it requires n \u2265CnL(\u03c4, \u03b2, \u01eb, m), and to achieve this guarantee under\n(\u01eb, \u03b4)-di\ufb00erential privacy, it requires n \u2265Cn\u03b4\nL(\u03c4, \u03b2, \u01eb, \u03b4, m) for su\ufb03ciently large constant C.\nApplying our main generalization bound for (\u01eb, 0)-di\ufb00erential privacy directly gives the following\ncorollary.\nCorollary 15. Let \u03c4, \u03b2 > 0 and de\ufb01ne\nnL(\u03c4, \u03b2, m) = m log(1/\u03b2)\n\u03c4 2\n.\nThere is a computationally e\ufb03cient algorithm which on input of a data set S of size n sampled\nfrom Pn accepts any sequence of m adaptively chosen functions \u03c61, . . . , \u03c6m \u2208X [0,1] and returns\nestimates a1, . . . , am such that for every i \u2208[m] we have P [|P[\u03c6i] \u2212ai| > \u03c4] \u2264\u03b2 provided that\nn \u2265CnL(\u03c4, \u03b2, m) for su\ufb03ciently large constant C.\nProof. We apply Theorem 9 with \u01eb = \u03c4/2 and plug this choice of \u01eb into the de\ufb01nition of nL in\nTheorem 14.\nWe note that the stated lower bound on n implies the lower bound required by\nTheorem 9.\nThe corollary that follows the (\u01eb, \u03b4) bound gives a quadratic improvement in m compared with\nCorollary 15 at the expense of a slightly worse dependence on \u03c4 and 1/\u03b2.\nCorollary 16. Let \u03c4, \u03b2 > 0 and de\ufb01ne\nn\u03b4\nL(\u03c4, \u03b2, m) =\n\u221am log1.5(1/\u03b2)\n\u03c4 2.5\n.\nThere is a computationally e\ufb03cient algorithm which on input of a data set S of size n sampled\nfrom Pn accepts any sequence of m adaptively chosen functions \u03c61, . . . , \u03c6m \u2208X [0,1] and returns\nestimates a1, . . . , am such that for every i \u2208[m] we have P [|P[\u03c6i] \u2212ai| > \u03c4] \u2264\u03b2 provided that\nn \u2265Cn\u03b4\nL(\u03c4, \u03b2, m) for su\ufb03ciently large constant C.\nProof. We apply Theorem 10 with \u01eb = \u03c4/2 and \u03b4 = exp(\u22124 ln(8/\u03b2)/\u03c4). Plugging these parameters\ninto the de\ufb01nition of n\u03b4\nL in Theorem 14 gives the stated lower bound on n. We note that the stated\nlower bound on n implies the lower bound required by Theorem 10.\n17\n5.2\nMultiplicative Weights Technique\nThe private multiplicative weights algorithm [HR10] achieves an exponential improvement in m\ncompared with the Laplacian mechanism. The main drawback is a running time that scales linearly\nwith the domain size in the worst case and is therefore not computationally e\ufb03cient in general.\nTheorem 17 (Private Multiplicative Weights). Let \u03c4, \u03b2, \u01eb > 0 and de\ufb01ne\nnMW(\u03c4, \u03b2, \u01eb) = log(|X|) log(1/\u03b2)\n\u01eb\u03c4 3\n.\nn\u03b4\nMW(\u03c4, \u03b2, \u01eb, \u03b4) =\np\nlog(|X|) log(1/\u03b4) log(1/\u03b2)\n\u01eb\u03c4 2\n.\nThere is algorithm called PMW which on input of a data set S of size n accepts any sequence of m\nadaptively chosen functions \u03c61, . . . , \u03c6m \u2208X [0,1] and with probability at least 1\u2212(n log |X|)\u03b2 returns\nestimates a1, . . . , am such that for every i \u2208[m] we have P [|ES[\u03c6i] \u2212ai| > \u03c4] \u2264\u03b2. To achieve this\nguarantee under (\u01eb, 0) di\ufb00erential privacy, it requires that n \u2265CnMW(\u03c4, \u03b2, \u01eb) and to achieve it\nunder (\u01eb, \u03b4)-di\ufb00erential privacy it requires n \u2265Cn\u03b4\nMW(\u03c4, \u03b2, \u01eb, \u03b4) for su\ufb03ciently large constant C.\nCorollary 18. Let \u03c4, \u03b2 > 0 and de\ufb01ne\nnMW(\u03c4, \u03b2) = log(|X|) log(1/\u03b2)\n\u03c4 4\n.\nThere is an algorithm which on input of a data set S of size n sampled from Pn accepts any sequence\nof m adaptively chosen functions \u03c61, . . . , \u03c6m \u2208X [0,1] and with probability at least 1 \u2212(n log |X|)\u03b2\nreturns estimates a1, . . . , am such that for every i \u2208[m] we have P [|P[\u03c6i] \u2212ai| > \u03c4] \u2264\u03b2 provided\nthat n \u2265CnMW(\u03c4, \u03b2) for su\ufb03ciently large constant C.\nProof. We apply Theorem 9 with \u01eb = \u03c4/2 and plug this choice of \u01eb into the de\ufb01nition of nMW\nin Theorem 17. We note that the stated lower bound on n implies the lower bound required by\nTheorem 9.\nUnder (\u01eb, \u03b4) di\ufb00erential privacy we get the following corollary that improves the dependence on\n\u03c4 and log |X| in Corollary 18 at the expense of a slightly worse dependence on \u03b2.\nCorollary 19. Let \u03c4, \u03b2 > 0 and de\ufb01ne\nn\u03b4\nMW(\u03c4, \u03b2) =\np\nlog(|X|) log(1/\u03b2)3/2\n\u03c4 3.5\n.\nThere is an algorithm which on input of a data set S of size n sampled from Pn accepts any sequence\nof m adaptively chosen functions \u03c61, . . . , \u03c6m \u2208X [0,1] and with probability at least 1 \u2212(n log |X|)\u03b2\nreturns estimates a1, . . . , am such that for every i \u2208[m] we have P [|P[\u03c6i] \u2212ai| > \u03c4] \u2264\u03b2 provided\nthat n \u2265Cn\u03b4\nMW(\u03c4, \u03b2) for su\ufb03ciently large constant C.\nProof. We apply Theorem 10 with \u01eb = \u03c4/2 and \u03b4 = exp(\u22124 ln(8/\u03b2)/\u03c4). Plugging these parameters\ninto the de\ufb01nition of n\u03b4\nMW in Theorem 17 gives the stated lower bound on n. We note that the\nstated lower bound on n implies the lower bound required by Theorem 10.\n18\n5.3\nSparse Vector Technique\nIn this section we give a computationally e\ufb03cient technique for answering exponentially many\nqueries \u03c61, . . . , \u03c6m in the size of the data set n so long as they are chosen using only o(n) rounds\nof adaptivity. We say that a sequence of queries \u03c61, . . . , \u03c6m \u2208X [0,1], answered with numeric values\na1, . . . , am is generated with r rounds of adaptivity if there are r indices i1, . . . , ir such that the\nprocedure that generates the queries as a function of the answers can be described by r+1 (possibly\nrandomized) algorithms f0, f1, . . . , fr satisfying:\n(\u03c61, . . . , \u03c6i1\u22121) = f0(\u2205)\n(\u03c6i1, . . . , \u03c6i2\u22121) = f1((\u03c61, a1), . . . , (\u03c6i1\u22121, ai1\u22121))\n(\u03c6i2, . . . , \u03c6i3\u22121) = f2((\u03c61, a1), . . . , (\u03c6i2\u22121, ai2\u22121))\n...\n(\u03c6ir, . . . , \u03c6m) = fr((\u03c61, a1), . . . , (\u03c6ir\u22121, air\u22121))\nWe build our algorithm out of a di\ufb00erentially private algorithm called SPARSE that takes\nas input an adaptively chosen sequence of queries together with guesses of the answers to those\nqueries. Rather than always returning numeric valued answers, it compares the error of our guess\nto a threshold T and returns a numeric valued answer to the query only if (a noisy version of) the\nerror of our guess was above the given threshold. SPARSE is computationally e\ufb03cient, and has the\nremarkable property that its accuracy has polynomial dependence only on the number of queries\nfor which the error of our guesses are close to being above the threshold.\nTheorem 20 (Sparse Vector (\u01eb, 0)). Let \u03c4, \u03b2, \u01eb > 0 and de\ufb01ne\nnSV (\u03c4, \u03b2, \u01eb) = 9r (ln(4/\u03b2))\n\u03c4\u01eb\n.\nn\u03b4\nSV (\u03c4, \u03b2, \u01eb, \u03b4) =\n\u0000\u221a\n512 + 1\n\u0001 p\nr ln(2/\u03b4) (ln(4/\u03b2))\n\u03c4\u01eb\n.\nThere is an algorithm called SPARSE parameterized by a real valued threshold T, which on input of\na data set S of size n accepts any sequence of m adaptively chosen queries together with guesses\nat their values gi \u2208R: (\u03c61, g1), . . . , (\u03c6m, gm) and returns answers a1, . . . , am \u2208{\u22a5} \u222aR. It has\nthe property that for all i \u2208[m], with probability 1 \u2212\u03b2: if ai = \u22a5then |ES[\u03c6i] \u2212gi| \u2264T + \u03c4\nand if ai \u2208R, |ES[\u03c6i] \u2212ai| \u2264\u03c4.\nTo achieve this guarantee under (\u01eb, 0)-di\ufb00erential privacy it\nrequires n \u2265nSV (\u03c4, \u03b2, \u01eb) and to achieve this guarantee under (\u01eb, \u03b4)-di\ufb00erential privacy, it requires\nn \u2265n\u03b4\nSV (\u03c4, \u03b2, \u01eb, \u03b4). In either case, the algorithm also requires that |{i : |ES[\u03c6i] \u2212gi| \u2265T \u2212\u03c4}| \u2264r.\n(If this last condition does not hold, the algorithm may halt early and stop accepting queries)\nWe observe that the na\u00a8\u0131ve method of answering queries using their empirical average allows us\nto answer each query up to accuracy \u03c4 with probability 1\u2212\u03b2 given a data set of size n0 \u2265ln(2/\u03b2)/\u03c4 2\nso long as the queries are non-adaptively chosen. Thus, with high probability, problems only arise\nbetween rounds of adaptivity.\nIf we knew when these rounds of adaptivity occurred, we could\nrefresh our sample between each round, and obtain total sample complexity linear in the number\nof rounds of adaptivity.\nThe method we present (using (\u01eb, 0)-di\ufb00erential privacy) lets us get a\n19\ncomparable bound without knowing where the rounds of adaptivity appear. Using (\u01eb, \u03b4) privacy\nwould allow us to obtain constant factor improvements if the number of queries was large enough,\nbut does not get an asymptotically better dependence on the number of rounds r (it would allow\nus to reuse the round testing set quadratically many times, but we would still potentially need to\nrefresh the training set after each round of adaptivity, in the worst case).\nThe idea is the following: we obtain r di\ufb00erent estimation samples S1, . . . , Sr each of size\nsu\ufb03cient to answer non-adaptively chosen queries to error \u03c4/8 with probability 1 \u2212\u03b2/3, and a\nseparate round detection sample Sh of size nSV (\u03c4/8, \u03b2/3, \u01eb) for \u01eb = \u03c4/16, which we access only\nthrough a copy of SPARSE we initialize with threshold T = \u03c4/4. As queries \u03c6i start arriving, we\ncompute their answers at\ni = ES1[\u03c6i] using the na\u00a8\u0131ve method on estimation sample S1 which we\nuse as our guess of the correct value on Sh when we feed \u03c6i to SPARSE. If the answer SPARSE\nreturns is ah\ni = \u22a5, then we know that with probability 1 \u2212\u03b2/3, at\ni is accurate up to tolerance\nT + \u03c4/8 = 3\u03c4/8 with respect to Sh, and hence statistically valid up to tolerance \u03c4/2 by Theorem 9\nwith probability at least 1 \u22122\u03b2/3. Otherwise, we discard our estimation set S1 and continue with\nestimation set S2. We know that with probability 1 \u2212\u03b2/3, ah\ni is accurate with respect to Sh up to\ntolerance \u03c4/8, and hence statistically valid up to tolerance \u03c4/4 by Theorem 9 with probability at\nleast 1 \u22122\u03b2/3. We continue in this way, discarding and incrementing our estimation set whenever\nour guess gi is incorrect. This succeeds in answering every query so long as our guesses are not\nincorrect more than r times in total. Finally, we know that except with probability at most m\u03b2/3,\nby the accuracy guarantee of our estimation set for non-adaptively chosen queries, the only queries\ni for which our guesses gi will deviate from ESh[\u03c6i] by more than T \u2212\u03c4/8 = \u03c4/8 are those queries\nthat lie between rounds of adaptivity. There are at most r of these by assumption, so the algorithm\nruns to completion with probability at least 1 \u2212m\u03b2/3. The algorithm is given in \ufb01gure 1.\nAlgorithm E\ufb00ectiveRounds\nInput: A database S of size |S| \u2265\n1156r ln( 12\n\u03b2 )\n\u03c4 2\n.\nInitialization: Randomly split S into r+1 sets: r sets S1, . . . , Sr with size |Si| \u2265\n4 ln( 12\n\u03b2 )\n\u03c4 2\n, and one\nset Sh with size |Sh| =\n1152\u00b7r\u00b7ln( 12\n\u03b2 )\n\u03c4 2\n. Instantiate SPARSE with input Sh and parameters T = \u03c4/4,\n\u03c4 \u2032 = \u03c4/8, \u03b2\u2032 = \u03b2/3, and \u01eb = \u03c4/16. Let c \u21901.\nQuery stage For each query \u03c6i do:\n1. Compute at\ni = ESc[\u03c6i]. Let gi = at\ni and feed (\u03c6i, gi) to sparse and receive answer ah\ni .\n2. If ah\ni = \u22a5then return answer ai = at\ni.\n3. Else return answer ai = ah\ni . Set c \u2190c + 1.\n4. If c > r HALT.\nFigure 1: The E\ufb00ectiveRounds algorithm\nThis algorithm yields the following theorem:\nTheorem 21. Let \u03c4, \u03b2 > 0 and de\ufb01ne\nnSV (\u03c4, \u03b2) =\nr ln( 1\n\u03b2)\n\u03c4 2\n.\n20\nThere is an algorithm which on input of a data set S of size n sampled from Pn accepts any sequence\nof m adaptively chosen queries \u03c61, . . . , \u03c6m generated with at most r rounds of adaptivity. With\nprobability at least 1 \u2212m\u03b2 the algorithm runs to completion and returns estimates a1, . . . , am for\neach query. These estimates have the property that for all i \u2208[m] we have P [|P[\u03c6i] \u2212ai| > \u03c4] \u2264\u03b2\nprovided that n \u2265CnSV (\u03c4, \u03b2) for su\ufb03ciently large constant C.\nRemark 22. Note that the accuracy guarantee of SPARSE depends only on the number of incorrect\nguesses that are actually made. Hence, E\ufb00ectiveRounds does not halt until the actual number of\ninstances of over-\ufb01tting to the estimation samples Si is larger than r. This could be equal to the\nnumber of rounds of adaptivity in the worst case (for example, if the analyst is running the Dinur-\nNissim reconstruction attack within each round [DN03]), but in practice might achieve a much better\nbound (if the analyst is not fully adversarial).\nAcknowledgements\nWe would like to thank Sanjeev Arora, Nina Balcan, Avrim Blum, Dean\nFoster, Michael Kearns, Jon Kleinberg, Sasha Rakhlin, and Jon Ullman for enlightening discussions\nand helpful comments. We also thank the Simons Institute for Theoretical Computer Science at\nBerkeley where part of this research was done.\nReferences\n[ANR11]\nEhud Aharoni, Hani Neuvirth, and Saharon Rosset. The quality preserving database: A\ncomputational framework for encouraging collaboration, enhancing power and control-\nling false discovery. IEEE/ACM Trans. Comput. Biology Bioinform., 8(5):1431\u20131437,\n2011.\n[AR14]\nEhud Aharoni and Saharon Rosset. Generalized a-investing: de\ufb01nitions, optimality\nresults and application to public databases. Journal of the Royal Statistical Society:\nSeries B (Statistical Methodology), 76(4):771\u2013794, 2014.\n[BDMN05] Avrim Blum, Cynthia Dwork, Frank McSherry, and Kobbi Nissim. Practical privacy:\nthe SuLQ framework. In PODS, pages 128\u2013138, 2005.\n[BE02]\nOlivier Bousquet and Andr\u00b4e Elissee\ufb00. Stability and generalization. JMLR, 2:499\u2013526,\n2002.\n[BE12]\nC. Glenn Begley and Lee Ellis. Drug development: Raise standards for preclinical\ncancer research. Nature, 483:531\u2013533, 2012.\n[BH95]\nYoav Benjamini and Yosef Hochberg. Controlling the false discovery rate \u2013 a practical\nand powerful approach to multiple testing. Journal of the Royal Statistics Society:\nSeries B (Statistical Methodology), 57:289\u2013300, 1995.\n[BH15]\nAvrim Blum and Moritz Hardt. The ladder: A reliable leaderboard for machine learn-\ning competitions. CoRR, abs/1502.04585, 2015.\n[BNS+15]\nRaef Bassily,\nKobbi Nissim,\nAdam D. Smith, Thomas Steinke,\nUri Stemmer,\nand Jonathan Ullman.\nAlgorithmic stability for adaptive data analysis.\nCoRR,\nabs/1511.02513, 2015.\n21\n[BST14]\nRaef Bassily, Adam Smith, and Abhradeep Thakurta. Private empirical risk minimiza-\ntion, revisited. CoRR, abs/1405.7085, 2014.\n[CKL+06]\nC. Chu, S. Kim, Y. Lin, Y. Yu, G. Bradski, A. Ng, and K. Olukotun. Map-reduce for\nmachine learning on multicore. In Proceedings of NIPS, pages 281\u2013288, 2006.\n[DFH+15a] Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold, and\nAaron Roth.\nGeneralization in adaptive data analysis and holdout reuse.\nCoRR,\nabs/1506, 2015.\n[DFH+15b] Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold, and\nAaron Roth.\nThe reusable holdout: Preserving validity in adaptive data analysis.\nScience, 349(6248):636\u2013638, 2015.\n[DKM+06] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and Moni\nNaor. Our data, ourselves: Privacy via distributed noise generation. In EUROCRYPT,\npages 486\u2013503, 2006.\n[DMNS06]\nCynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise\nto sensitivity in private data analysis.\nIn Theory of Cryptography, pages 265\u2013284.\nSpringer, 2006.\n[DN03]\nIrit Dinur and Kobbi Nissim. Revealing information while preserving privacy. In PODS,\npages 202\u2013210. ACM, 2003.\n[DN04]\nCynthia Dwork and Kobbi Nissim. Privacy-preserving datamining on vertically parti-\ntioned databases. In CRYPTO, pages 528\u2013544, 2004.\n[DR14]\nCynthia Dwork and Aaron Roth. The algorithmic foundations of di\ufb00erential privacy.\nFoundations and Trends in Theoretical Computer Science, 9(34):211\u2013407, 2014.\n[Dwo11]\nCynthia Dwork.\nA \ufb01rm foundation for private data analysis.\nCACM, 54(1):86\u201395,\n2011.\n[FGR+13]\nVitaly Feldman, Elena Grigorescu, Lev Reyzin, Santosh Vempala, and Ying Xiao.\nStatistical algorithms and a lower bound for planted clique. In STOC, pages 655\u2013664.\nACM, 2013.\n[Fre83]\nDavid A. Freedman. A note on screening regression equations. The American Statis-\ntician, 37(2):152\u2013155, 1983.\n[FS08]\nD. Foster and R. Stine. Alpha-investing: A procedure for sequential control of ex-\npected false discoveries. J. Royal Statistical Soc.: Series B (Statistical Methodology),\n70(2):429\u2013444, 2008.\n[GL14]\nAndrew Gelman and Eric Loken.\nThe statistical crisis in science.\nThe American\nStatistician, 102(6):460, 2014.\n[HR10]\nMoritz Hardt and Guy N. Rothblum. A multiplicative weights mechanism for privacy-\npreserving data analysis. In 51st IEEE FOCS 2010, pages 61\u201370, 2010.\n22\n[HTF09]\nTrevor Hastie, Robert Tibshirani, and Jerome H. Friedman. The Elements of Statis-\ntical Learning: Data Mining, Inference, and Prediction. Springer series in statistics.\nSpringer, 2009.\n[HU14]\nMoritz Hardt and Jonathan Ullman. Preventing false discovery in interactive data\nanalysis is hard. In FOCS, pages 454\u2013463, 2014.\n[Ioa05a]\nJohn A. Ioannidis. Contradicted and initially stronger e\ufb00ects in highly cited clinical\nresearch. The Journal of American Medical Association, 294(2):218\u2013228, 2005.\n[Ioa05b]\nJohn P. A. Ioannidis.\nWhy Most Published Research Findings Are False.\nPLoS\nMedicine, 2(8):124, August 2005.\n[Kaga]\nFive\nlessons\nfrom\nKaggle\u2019s\nevent\nrecommendation\nengine\nchallenge.\nhttp://www.rouli.net/2013/02/five-lessons-from-kaggles-event.html.\nAc-\ncessed: 2014-10-07.\n[Kagb]\nKaggle blog: No free hunch. http://blog.kaggle.com/. Accessed: 2014-10-07.\n[Kagc]\nKaggle user forums. https://www.kaggle.com/forums. Accessed: 2014-10-07.\n[Kea98]\nMichael Kearns. E\ufb03cient noise-tolerant learning from statistical queries. Journal of\nthe ACM (JACM), 45(6):983\u20131006, 1998.\n[KV94]\nMichael J Kearns and Umesh Virkumar Vazirani. An introduction to computational\nlearning theory. MIT press, 1994.\n[MNPR06]\nSayan Mukherjee, Partha Niyogi, Tomaso Poggio, and Ryan Rifkin. Learning theory:\nstability is su\ufb03cient for generalization and necessary and su\ufb03cient for consistency of\nempirical risk minimization. Advances in Computational Mathematics, 25(1-3):161\u2013\n193, 2006.\n[PRMN04]\nTomaso Poggio, Ryan Rifkin, Sayan Mukherjee, and Partha Niyogi. General conditions\nfor predictivity in learning theory. Nature, 428(6981):419\u2013422, 2004.\n[PSA11]\nFlorian Prinz, Thomas Schlange, and Khusru Asadullah. Believe it or not: how much\ncan we rely on published data on potential drug targets? Nature Reviews Drug Dis-\ncovery, 10(9):712\u2013712, 2011.\n[Reu03]\nJuha Reunanen. Over\ufb01tting in making comparisons between variable selection methods.\nJournal of Machine Learning Research, 3:1371\u20131382, 2003.\n[RF08]\nR. Bharat Rao and Glenn Fung. On the dangers of cross-validation. an experimental\nevaluation. In International Conference on Data Mining, pages 588\u2013596. SIAM, 2008.\n[RR10]\nAaron Roth and Tim Roughgarden. Interactive privacy via the median mechanism. In\n42nd ACM STOC, pages 765\u2013774. ACM, 2010.\n[RZ15]\nDaniel Russo and James Zou. Controlling bias in adaptive data analysis using infor-\nmation theory. CoRR, abs/1511.05219, 2015.\n23\n[SNS11]\nJoseph P. Simmons, Leif D. Nelson, and Uri Simonsohn. False-positive psychology:\nUndisclosed \ufb02exibility in data collection and analysis allows presenting anything as\nsigni\ufb01cant. Psychological Science, 22(11):1359\u20131366, 2011.\n[SSBD14]\nShai Shalev-Shwartz and Shai Ben-David. Understanding Machine Learning: From\nTheory to Algorithms. Cambridge University Press, 2014.\n[SSSSS10]\nShai Shalev-Shwartz, Ohad Shamir, Nathan Srebro, and Karthik Sridharan. Learn-\nability, stability and uniform convergence. The Journal of Machine Learning Research,\n11:2635\u20132670, 2010.\n[SU14]\nThomas Steinke and Jonathan Ullman. Interactive \ufb01ngerprinting codes and the hard-\nness of preventing false discovery. arXiv preprint arXiv:1410.1228, 2014.\n[TT15]\nJonathan Taylor and Robert J. Tibshirani. Statistical learning and selective inference.\nProceedings of the National Academy of Sciences, 112(25):7629\u20137634, 2015.\n[Win]\nDavid Wind. Learning from the best. http://blog.kaggle.com/2014/08/01/learning-from-the-b\nAccessed: 2014-10-07.\n[WLF15]\nYu-Xiang Wang, Jing Lei, and Stephen E. Fienberg. Learning with di\ufb00erential pri-\nvacy: Stability, learnability and the su\ufb03ciency and necessity of ERM principle. CoRR,\nabs/1502.06309, 2015.\nA\nAdaptivity in \ufb01tting a linear model\nIn this section, we give a very simple example to illustrate how a data analyst could end up\nover\ufb01tting to a dataset by asking only a small number of (adaptively) chosen queries to the dataset,\nif they are answered using the na\u00a8\u0131ve method.\nThe data analyst has n samples D = {x1, . . . , xn} over d real-valued attributes sampled from\nan unknown distribution D. The analyst\u2019s goal is to \ufb01nd a linear model \u2113that maximizes the\naverage correlation with the unknown distribution. Formally, the goal is to \ufb01nd a unit vector that\nmaximizes the function\nf(u) = E\nx\u223cD[\u27e8u, x\u27e9] .\nNot knowing the distribution the analyst decides to solve the corresponding optimization problem\non her \ufb01nite sample:\n\u02dcfD(u) = 1\nn\nX\nx\u2208D\n\u27e8u, x\u27e9.\nThe analyst attempts to solve the problem using the following simple but adaptive strategy:\n1. For i = 1, . . . , d, determine si = sign\n\u0010 P\nx\u2208D xi\n\u0011\n.\n2. Let \u02dcu =\n1\n\u221a\nd(s1, . . . , sd).\nIntuitively, this natural approach \ufb01rst determines for each attribute whether it is positively or\nnegatively correlated. It then aggregates this information across all d attributes into a single linear\nmodel.\n24\nThe next lemma shows that this adaptive strategy has a terrible generalization performance\n(if d is large). Speci\ufb01cally, we show that even if there is no linear structure whatsoever in the\nunderlying distribution (namely it is normally distributed), the analyst\u2019s strategy falsely discovers\na linear model with large objective value.\nLemma 23. Suppose D = N(0, 1)d. Then, every unit vector u \u2208Rd satis\ufb01es f(u) = 0. However,\nED[ \u02dcfD(\u02dcu)] =\np\n2/\u03c0 \u00b7\np\nd/n.\nProof. The \ufb01rst claim follows because \u27e8u, x\u27e9for x \u223cN(0, 1)d is distributed like a Gaussian random\nvariable N(0, 1). Let us now analyze the objective value of \u02dcu.\n\u02dcfD(\u02dcu) = 1\nn\nX\nx\u2208D\nsi\n\u221a\nd\nd\nX\ni=1\nxi =\n1\n\u221a\nd\nd\nX\ni=1\n\f\f\f\f\f\n1\nn\nX\nx\u2208D\nxi\n\f\f\f\f\f\nHence,\nE\nD[ \u02dcfD(\u02dcu)] =\nd\nX\ni=1\n1\n\u221a\nd\nE\nD\n\"\f\f\f\f\f\n1\nn\nX\nx\u2208D\nxi\n\f\f\f\f\f\n#\n.\nNow, (1/n) P\nx\u2208D xi is distributed like a gaussian random variable g \u223cN(0, 1/n), since each xi is\na standard gaussian. It follows that\nE\nD\n\u02dcfD(\u02dcu) =\nr\n2d\n\u03c0n.\nNote that all the operations performed by the analyst are based on empirical averages of real-\nvalued functions. To determine the bias, the function is just \u03c6i(x) = xi and to determine the \ufb01nal\ncorrelation it is \u03c8(x) = \u27e8u, x\u27e9. These functions are not bounded to the range [0, 1] as required by\nthe formal de\ufb01nition of our model. However, it is easy to see that this is a minor issue. Note that\nboth xi and \u27e8u, x\u27e9are distributed according to N(0, 1) whenever x \u223cN(0, 1)d. This implies that\nfor every query function \u03c6 we used, P[|\u03c6(x)| \u2265B] \u22641/poly(n, d) for some B = O(log(dn)). We\ncan therefore truncate and rescale each query as \u03c6\u2032(x) = PB(\u03c6(x))/(2B) + 1/2, where PB is the\ntruncation of the values outside [\u2212B, B]. This ensures that the range of \u03c6\u2032(x) is [0, 1]. It is easy to\nverify that using these [0, 1]-valued queries does not a\ufb00ect the analysis in any signi\ufb01cant way (aside\nfrom scaling by a logarithmic factor) and we obtain over\ufb01tting in the same way as before (for large\nenough d).\nB\nBackground on Di\ufb00erential Privacy\nWhen applying (\u01eb, \u03b4)-di\ufb00erential privacy, we are typically interested in values of \u03b4 that are very\nsmall compared to n. In particular, values of \u03b4 on the order of 1/n yield no meaningful de\ufb01nition\nof privacy as they permit the publication of the complete records of a small number of data set\nparticipants\u2014a violation of any reasonable notion of privacy.\nTheorem 24. Any (\u03b5, \u03b4)-di\ufb00erentially private mechanism A satis\ufb01es for all pairs of data sets S, S\u2032\ndi\ufb00ering in at most k elements, and all O \u2286Range(A):\nP[A(S) \u2208O] \u2264exp(k\u03b5) P[A(S\u2032) \u2208O] + e\u01eb(k\u22121)\u03b4,\nwhere the probability space is over the coin \ufb02ips of the mechanism A.\n25\nDi\ufb00erential privacy also degrades gracefully under composition.\nIt is easy to see that the\nindependent use of an (\u03b51, 0)-di\ufb00erentially private algorithm and an (\u03b52, 0)-di\ufb00erentially private\nalgorithm, when taken together, is (\u03b51 + \u03b52, 0)-di\ufb00erentially private. More generally, we have\nTheorem 25. Let Ai : X n \u2192Ri be an (\u03b5i, \u03b4i)-di\ufb00erentially private algorithm for i \u2208[k]. Then if\nA[k] : X n \u2192Qk\ni=1 Ri is de\ufb01ned to be A[k](S) = (A1(S), . . . , Ak(S)), then A[k] is (Pk\ni=1 \u03b5i, Pk\ni=1 \u03b4i)-\ndi\ufb00erentially private.\nA more sophisticated argument yields signi\ufb01cant improvement when \u03b5 < 1:\nTheorem 26. For all \u03b5, \u03b4, \u03b4\u2032 \u22650, the composition of k arbitrary (\u03b5, \u03b4)-di\ufb00erentially private mech-\nanisms is (\u03b5\u2032, k\u03b4 + \u03b4\u2032)-di\ufb00erentially private, where\n\u03b5\u2032 =\np\n2k ln(1/\u03b4\u2032)\u03b5 + k\u03b5(e\u03b5 \u22121),\neven when the mechanisms are chosen adaptively.\nTheorems 25 and 26 are very general. For example, they apply to queries posed to overlapping,\nbut not identical, data sets. Nonetheless, data utility will eventually be consumed: the Fundamental\nLaw of Information Recovery states that overly accurate answers to too many questions will destroy\nprivacy in a spectacular way (see [DN03] et sequelae). The goal of algorithmic research on di\ufb00erential\nprivacy is to stretch a given privacy \u201cbudget\u201d of, say, \u03b50, to provide as much utility as possible, for\nexample, to provide useful answers to a great many counting queries. The bounds a\ufb00orded by the\ncomposition theorems are the \ufb01rst, not the last, word on utility.\nC\nConcentration and moment bounds\nC.1\nConcentration inequalities\nWe will use the following statement of the multiplicative Cherno\ufb00bound:\nLemma 27 (Cherno\ufb00\u2019s bound). Let Y1, Y2, . . . , Yn be i.i.d. Bernoulli random variables with expec-\ntation p > 0. Then for every \u03b3 > 0,\nP\n\uf8ee\n\uf8f0X\ni\u2208[n]\nYi \u2265(1 + \u03b3)np\n\uf8f9\n\uf8fb\u2264exp (\u2212np((1 + \u03b3) ln(1 + \u03b3) \u2212\u03b3)) .\nLemma 28 (McDiarmid\u2019s inequality). Let X1, X2, . . . , Xn be independent random variables taking\nvalues in the set X.\nFurther let f : X n \u2192R be a function that satis\ufb01es, for all i \u2208[n] and\nx1, x2, . . . , xn, x\u2032\ni \u2208X,\nf(x1, . . . , xi, . . . , xn) \u2212f(x1, . . . , x\u2032\ni, . . . , xn) \u2264c.\nThen for all \u03b1 > 0, and \u00b5 = E [f(X1, . . . , Xn)],\nP [f(X1, . . . , Xn) \u2212\u00b5 \u2265\u03b1] \u2264exp\n\u0012\u22122\u03b12\nn \u00b7 c2\n\u0013\n.\n26\nC.2\nMoment Bounds\nLemma 29. Let Y1, Y2, . . . , Yn be i.i.d. Bernoulli random variables with expectation p. We denote\nby Mk[B(n, p)] .= E\n\u0014\u0010\n1\nn\nP\ni\u2208[n] Yi\n\u0011k\u0015\n. Let X1, X2, . . . , Xn be i.i.d. random variables with values in\n[0, 1] and expectation p. Then for every k > 0,\nE\n\uf8ee\n\uf8ef\uf8f0\n\uf8eb\n\uf8ed1\nn\nX\ni\u2208[n]\nXi\n\uf8f6\n\uf8f8\nk\uf8f9\n\uf8fa\uf8fb\u2264Mk[B(n, p)].\nProof. We use I to denote a k-tuple of indices (i1, . . . , ik) \u2208[n]k (not necessarily distinct). For I\nlike that we denote by {\u21131, . . . , \u2113k\u2032} the set of distinct indices in I and let k1, . . . , kk\u2032 denote their\nmultiplicities. Note that P\nj\u2208[k\u2032] kj = k. We \ufb01rst observe that\nE\n\uf8ee\n\uf8ef\uf8f0\n\uf8eb\n\uf8ed1\nn\nX\ni\u2208[n]\nXi\n\uf8f6\n\uf8f8\nk\uf8f9\n\uf8fa\uf8fb=\nE\nI\u223c[n]k\n\uf8ee\n\uf8f0E\n\uf8ee\n\uf8f0Y\nj\u2208[k]\nXij\n\uf8f9\n\uf8fb\n\uf8f9\n\uf8fb=\nE\nI\u223c[n]k\n\uf8ee\n\uf8f0E\n\uf8ee\n\uf8f0Y\nj\u2208[k\u2032]\nXkj\n\u2113j\n\uf8f9\n\uf8fb\n\uf8f9\n\uf8fb=\nE\nI\u223c[n]k\n\uf8ee\n\uf8f0Y\nj\u2208[k\u2032]\nE\nh\nXkj\n\u2113j\ni\n\uf8f9\n\uf8fb,\n(11)\nwhere the last equality follows from independence of Xi\u2019s. For every j, the range of X\u2113j is [0, 1]\nand thus\nE\nh\nXkj\n\u2113j\ni\n\u2264E\n\u0002\nX\u2113j\n\u0003\n= p.\nMoreover the value p is achieved when X\u2113j is Bernoulli with expectation p. That is\nE\nh\nXkj\n\u2113j\ni\n\u2264E\nh\nY kj\n\u2113j\ni\n,\nand by using this in equality (11) we obtain that\nE\n\uf8ee\n\uf8ef\uf8f0\n\uf8eb\n\uf8ed1\nn\nX\ni\u2208[n]\nXi\n\uf8f6\n\uf8f8\nk\uf8f9\n\uf8fa\uf8fb\u2264E\n\uf8ee\n\uf8ef\uf8f0\n\uf8eb\n\uf8ed1\nn\nX\ni\u2208[n]\nYi\n\uf8f6\n\uf8f8\nk\uf8f9\n\uf8fa\uf8fb= Mk[B(n, p)].\nLemma 30. For all integers n \u2265k \u22651 and p \u2208[0, 1],\nMk[B(n, p)] \u2264pk + (k ln n + 1) \u00b7\n\u0012k\nn\n\u0013k\n.\nProof. Let U denote 1\nn\nP\ni\u2208[n] Xi, where Xi\u2019s are i.i.d. Bernoulli random variables with expectation\np > 0 (the claim is obviously true if p = 0). Then\nE[U k] \u2264pk +\nZ 1\npk P[U k \u2265t]dt.\n(12)\n27\nWe substitute t = (1 + \u03b3)kpk and observe that Lemma 27 gives:\nP[U k \u2265t] = P[U k \u2265((1 + \u03b3)p)k] = P[U \u2265(1 + \u03b3)p] \u2264exp (\u2212np((1 + \u03b3) ln(1 + \u03b3) \u2212\u03b3)) .\nUsing this substitution in eq.(12) together with dt\nd\u03b3 = k(1 + \u03b3)k\u22121 \u00b7 pk we obtain\nE[U k] \u2264pk +\nZ 1/p\u22121\n0\nexp (\u2212np((1 + \u03b3) ln(1 + \u03b3) \u2212\u03b3)) \u00b7 k(1 + \u03b3)k\u22121d\u03b3\n= pk + pkk\nZ 1/p\u22121\n0\n1\n1 + \u03b3 \u00b7 exp (k ln(1 + \u03b3) \u2212np((1 + \u03b3) ln(1 + \u03b3) \u2212\u03b3)) d\u03b3\n\u2264pk + pkk\nmax\n\u03b3\u2208[0,1/p\u22121] {exp (k ln(1 + \u03b3) \u2212np((1 + \u03b3) ln(1 + \u03b3) \u2212\u03b3))} \u00b7\nZ 1/p\u22121\n0\n1\n1 + \u03b3 d\u03b3\n= pk + pkk ln(1/p) \u00b7\nmax\n\u03b3\u2208[0,1/p\u22121] {exp (k ln(1 + \u03b3) \u2212np((1 + \u03b3) ln(1 + \u03b3) \u2212\u03b3))} .\n(13)\nWe now \ufb01nd the maximum of g(\u03b3) .= k ln(1 + \u03b3) \u2212np((1 + \u03b3) ln(1 + \u03b3) \u2212\u03b3).\nDi\ufb00erentiating\nthe expression we get\nk\n1+\u03b3 \u2212np ln(1 + \u03b3) and therefore the function attains its maximum at the\n(single) point \u03b30 which satis\ufb01es: (1 + \u03b30) ln(1 + \u03b30) =\nk\nnp. This implies that ln(1 + \u03b30) \u2264ln\n\u0010\nk\nnp\n\u0011\n.\nNow we observe that (1 + \u03b3) ln(1 + \u03b3) \u2212\u03b3 is always non-negative and therefore g(\u03b30) \u2264k ln\n\u0010\nk\nnp\n\u0011\n.\nSubstituting this into eq.(13) we conclude that\nE[U k] \u2264pk + pkk ln(1/p) \u00b7 exp\n\u0012\nk ln\n\u0012 k\nnp\n\u0013\u0013\n= pk + k ln(1/p) \u00b7\n\u0012k\nn\n\u0013k\n.\nFinally, we observe that if p \u22651/n then clearly ln(1/p) \u2264ln n and the claim holds. For any p < 1/n\nwe use monotonicity of Mk[B(n, p)] in p and upper bound the probability by the bound for p = 1/n\nthat equals\n\u0012 1\nn\n\u0013k\n+ (k ln n) \u00b7\n\u0012k\nn\n\u0013k\n\u2264(k ln n + 1) \u00b7\n\u0012k\nn\n\u0013k\n.\nLemma 31. Let n > k > 0, \u03b5 > 0, p > 0, \u03b4 \u22650 and let V be a non-negative random variable that\nsatis\ufb01es E[V k] \u2264e\u03b5kMk[B(n, p)] + \u03b4. Then for any \u03c4 \u2208[0, 1/3], \u03b2 \u2208(0, 2/3] if\n\u2022 \u03b5 \u2264\u03c4/2,\n\u2022 k \u2265max{4p ln(2/\u03b2)/\u03c4, 2 log log n},\n\u2022 n \u22653k/\u03c4 then\nP[V \u2265p + \u03c4] \u2264\u03b2 + \u03b4/(p + \u03c4)k.\nProof. Observe that by Markov\u2019s inequality:\nP[V \u2265p + \u03c4] = P[V k \u2265(p + \u03c4)k] \u2264\nE[V k]\n(p + \u03c4)k \u2264e\u03b5kMk[B(n, p)]\npk(1 + \u03c4/p)k\n+\n\u03b4\n(p + \u03c4)k .\n28\nUsing Lemma 30 we obtain that\nP[V \u2265p + \u03c4] \u2264pk + (k ln n + 1) \u00b7\n\u0000 k\nn\n\u0001k\ne\u2212\u03b5kpk(1 + \u03c4/p)k\n+\n\u03b4\n(p + \u03c4)k =\n1 + (k ln n + 1) \u00b7\n\u0010\nk\npn\n\u0011k\n(e\u2212\u03b5(1 + \u03c4/p))k\n+\n\u03b4\n(p + \u03c4)k .\n(14)\nUsing the condition \u03b5 \u2264\u03c4/2 and \u03c4 \u22641/3 we \ufb01rst observe that\ne\u2212\u03b5(1 + \u03c4/p) \u2265(1 \u2212\u03b5)(1 + \u03c4/p) = 1 + \u03c4/p \u2212\u03b5 \u2212\u03b5\u03c4/p \u22651 + \u03c4/(3p).\nHence, with the condition that k \u22654p ln(2/\u03b2)/\u03c4 we get\n(e\u2212\u03b5(1 + \u03c4/p))k \u2265(1 + \u03c4/(3p))k \u2265ek\u03c4/(4p) \u22652\n\u03b2 .\n(15)\nUsing the condition n \u22653k/\u03c4.\ne\u2212\u03b5\u03c4/p \u22653e\u2212\u03b5k/(np) > 2k/(np).\nTogether with the condition k \u2265max{4 ln(2/\u03b2)/\u03c4, 2 log log n}, we have\nlog(2/\u03b2) + log(k ln n + 1) \u2264log(2/\u03b2) + log(k + 1) + log log n \u2264k\nsince k/2 \u2265log log n holds by assumption and for k \u226512 ln(2/\u03b2), k/6 \u2265log(2/\u03b2) and k/3 \u2265\nlog(k + 1) (whenever \u03b2 < 2/3). Therefore we get\n(e\u2212\u03b5(1 + \u03c4/p))k \u2265(e\u2212\u03b5\u03c4/p)k \u22652k \u00b7\n\u0012 k\npn\n\u0013k\n\u22652\n\u03b2 \u00b7 (k ln n + 1) \u00b7\n\u0012 k\npn\n\u0013k\n.\n(16)\nCombining eq.(15) and (16) we obtain that\n1 + (k ln n + 1) \u00b7\n\u0010\nk\npn\n\u0011k\n(e\u2212\u03b5(1 + \u03c4/p))k\n\u2264\u03b2/2 + \u03b2/2 = \u03b2.\nSubstituting this into eq.(14) we obtain the claim.\n29\n",
        "sentence": " Related work: Over the past few years there has been growing theoretical and practical interest in the statistical validity of scientific results that are obtained from adaptive data analyses, in which the results of one experiment inform the design of the next (Dwork et al., 2015; Hardt and Ullman, 2014).",
        "context": "Further Developments: Our work has attracted substantial interest to the problem of statistical\nvalidity in adaptive data analysis and its relationship to di\ufb00erential privacy. Hardt and Ullman\nand reused with hypotheses and new analyses being generated on the basis of data exploration\nand the outcomes of previous analyses.\nIn this work we initiate a principled study of how to guarantee the validity of statistical\narXiv:1411.2664v3  [cs.LG]  2 Mar 2016\nPreserving Statistical Validity in Adaptive Data Analysis\u2217\nCynthia Dwork\u2020\nVitaly Feldman\u2021\nMoritz Hardt\u00a7\nToniann Pitassi\u00b6\nOmer Reingold\u2225\nAaron Roth\u2217\u2217\nAbstract"
    },
    {
        "title": "Differential privacy",
        "author": [
            "C. Dwork"
        ],
        "venue": "van Tilborg, H., and Jajodia, S., eds., Encyclopedia of Cryptography and Security. Springer US. 338\u2013340.",
        "citeRegEx": "Dwork,? 2011",
        "shortCiteRegEx": "Dwork",
        "year": 2011,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": "",
        "context": null
    },
    {
        "title": "Preventing false discovery in interactive data analysis is hard",
        "author": [
            "M. Hardt",
            "J. Ullman"
        ],
        "venue": "Foundations of Computer Science (FOCS), 2014 IEEE 55th Annual Symposium on, 454\u2013463. IEEE.",
        "citeRegEx": "Hardt and Ullman,? 2014",
        "shortCiteRegEx": "Hardt and Ullman",
        "year": 2014,
        "abstract": "We show that, under a standard hardness assumption, there is no\ncomputationally efficient algorithm that given $n$ samples from an unknown\ndistribution can give valid answers to $n^{3+o(1)}$ adaptively chosen\nstatistical queries. A statistical query asks for the expectation of a\npredicate over the underlying distribution, and an answer to a statistical\nquery is valid if it is \"close\" to the correct expectation over the\ndistribution.\n  Our result stands in stark contrast to the well known fact that exponentially\nmany statistical queries can be answered validly and efficiently if the queries\nare chosen non-adaptively (no query may depend on the answers to previous\nqueries). Moreover, a recent work by Dwork et al. shows how to accurately\nanswer exponentially many adaptively chosen statistical queries via a\ncomputationally inefficient algorithm; and how to answer a quadratic number of\nadaptive queries via a computationally efficient algorithm. The latter result\nimplies that our result is tight up to a linear factor in $n.$\n  Conceptually, our result demonstrates that achieving statistical validity\nalone can be a source of computational intractability in adaptive settings. For\nexample, in the modern large collaborative research environment, data analysts\ntypically choose a particular approach based on previous findings. False\ndiscovery occurs if a research finding is supported by the data but not by the\nunderlying distribution. While the study of preventing false discovery in\nStatistics is decades old, to the best of our knowledge our result is the first\nto demonstrate a computational barrier. In particular, our result suggests that\nthe perceived difficulty of preventing false discovery in today's collaborative\nresearch environment may be inherent.",
        "full_text": "Preventing False Discovery in\nInteractive Data Analysis is Hard\nMoritz Hardt\u2217\nJonathan Ullman\u2020\nAugust 8, 2014\nAbstract\nWe show that, under a standard hardness assumption, there is no computationally e\ufb03-\ncient algorithm that given n samples from an unknown distribution can give valid answers\nto n3+o(1) adaptively chosen statistical queries. A statistical query asks for the expectation\nof a predicate over the underlying distribution, and an answer to a statistical query is valid\nif it is \u201cclose\u201d to the correct expectation over the distribution.\nOur result stands in stark contrast to the well known fact that exponentially many\nstatistical queries can be answered validly and e\ufb03ciently if the queries are chosen non-\nadaptively (no query may depend on the answers to previous queries). Moreover, a recent\nwork [DFH+14] shows how to accurately answer exponentially many adaptively chosen sta-\ntistical queries via a computationally ine\ufb03cient algorithm; and how to answer a quadratic\nnumber of adaptive queries via a computationally e\ufb03cient algorithm. The latter result im-\nplies that our result is tight up to a linear factor in n.\nConceptually, our result demonstrates that achieving statistical validity alone can be\na source of computational intractability in adaptive settings. For example, in the mod-\nern large collaborative research environment, data analysts typically choose a particular\napproach based on previous \ufb01ndings. False discovery occurs if a research \ufb01nding is sup-\nported by the data but not by the underlying distribution. While the study of preventing\nfalse discovery in Statistics is decades old, to the best of our knowledge our result is the \ufb01rst\nto demonstrate a computational barrier. In particular, our result suggests that the perceived\ndi\ufb03culty of preventing false discovery in today\u2019s collaborative research environment may\nbe inherent.\n\u2217IBM Research Almaden. Email: mhardt@us.ibm.com\n\u2020Harvard University School of Engineering and Applied Sciences and Center for Research on Computation and\nSociety. Supported by NSF grant CNS-1237235. Email: jullman@seas.harvard.edu\n1\narXiv:1408.1655v1  [cs.LG]  6 Aug 2014\nContents\n1\nIntroduction\n3\n1.1\nProof overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n5\n1.2\nConnection to privacy and reconstruction attacks . . . . . . . . . . . . . . . . . .\n6\n1.3\nRelated work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n7\n2\nPreliminaries\n8\n2.1\nFingerprinting codes\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n3\nLower bound for natural oracles\n10\n3.1\nAnalysis of the recovery phase . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n11\n3.2\nAnalysis of the Attack Phase . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n13\n3.3\nPutting it together . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n4\nLower bound for all computationally bounded oracles\n15\n4.1\nEncryption schemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n15\n4.2\nDescription of the attack . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n4.3\nAnalysis of the recovery phase . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n16\n4.4\nAnalysis of the attack phase\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n21\n4.5\nPutting it together . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n23\n4.6\nAn information-theoretic lower bound . . . . . . . . . . . . . . . . . . . . . . . .\n23\n5\nLower bounds for avoiding blatant non-privacy\n24\n5.1\nBlatant non-privacy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n24\n5.2\nLower bounds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n25\nA Security reductions from Section 4\n29\n2\n1\nIntroduction\nEmpirical research is commonly done by testing multiple hypotheses on a \ufb01nite sample. A test\noutcome is deemed statistically sign\ufb01cant if it is unliked to have occured by chance alone. False\ndiscovery arises if the analyst incorrectly declares an observation as statistically signi\ufb01cant.\nFor decades statisticians have been devising methods for preventing false discovery, such as\nthe widely used and highly in\ufb02uential method for controlling the false discovery rate due to\nBenjamini and Hochberg [BH95].\nNevertheless the problem of false discovery persists across all empirical sciences today.\nPopular articles report on an increasing number of invalid research \ufb01ndings. Why is it seem-\ningly so di\ufb03cult to prevent false discovery? Today\u2019s practice of data analysis diverges from\nclassical statistics in its massive scale, heavy use of sophisticated algorithms, and large number\nof participants in any given project. Importantly, the way modern data analysts interact with\nthe data set is inherently adaptive\u2014many design choices, including the choice and tuning of\nthe algorithm itself, depend on previous interactions with the data set. An extreme example\nare data science competitions, in which hundreds of data scientists analyze the same data set\nand repeatedly evaluate their approach against the same data. This level of adaptivity makes\nit nearly impossible to give a precise a priori description of the experimental setup.\nWe formalize the way in which data analysts may interact with a data set using the statistical-\nquery model (SQ model) of Kearns [Kea93]. In the statistical query model, there is an algorithm\ncalled the oracle that gets access to n samples from an unknown distribution D over some \ufb01nite\nuniverse X . We will assume throughout that X = {0,1}d where we think of the parameter d as\nthe dimensionality of the data. A statistical query q is speci\ufb01ed by a predicate p: X \u2192{0,1}\nand the answer to a statistical query is de\ufb01ned as q(D) = Ex\u223cD p(x). The goal of the oracle is to\ngive an answer a to the query that is accurate (or statistically valid) in the sense that |a\u2212q(D)| \u2264\u03b1\nwith high probability. Throughout our work we only require \u03b1 to be a small constant. Put\ndi\ufb00erently, the goal of the oracle is to provide answers that generalize to the underlying distri-\nbution rather than answers that are speci\ufb01c to the sample. The latter is always easy to achieve\nby outputting the empirical average of the query predicate on the sample.\nThe SQ model has a number of advantages for our purposes. First, almost all natural ma-\nchine learning algorithms can be compiled into a sequence of statistical queries. Hence, the\nmodel does not give up much generality. Second, it makes it convenient to formalize adaptiv-\nity. In the adaptive/interactive setting, the analyst is modeled as an e\ufb03cient algorithm that\ngiven a sequence of queries and answers q1,a1,q2,a2,...,qi,ai (previously exchanged with the\noracle) produces a new query qi+1. We say that an oracle is accurate given n samples for k adap-\ntively chosen queries, if for every distribution D, given n samples from D the oracle accurately\nresponds to any computationally e\ufb03cient adaptive analyst that makes at most k queries. A\ncomputationally e\ufb03cient oracle should run time polynomial in n and d on input of each query.\nA recent work by Dwork, Feldman, Hardt, Pitassi, Reingold and Roth [DFH+14] addresses\nthe problem of answering adaptive statistical queries. Their main result implies that there is\na computationally ine\ufb03cient oracle that accurately answers even an exponential number of\nadaptively chosen statistical queries. Moreover, they show that a quadratic number of queries\ncan be answered accurately and e\ufb03ciently. Our main theorem shows that these results are\nessentially as far as it goes. Under a standard cryptographic hardness assumption, we show\nthat there is no e\ufb03cient oracle that is accurate on more than a cubic number of adaptively\nchosen queries.\n3\nTheorem 1.1. Assuming one-way functions exist, there is no computationally e\ufb03cient oracle that\ngiven n samples is accurate on n3+o(1) adaptively chosen queries.\nAn intuitive interpretation of the theorem is that if an e\ufb03cient oracle attempts to answer\nmore than n3 statistical queries it cannot in general maintain that its answers are statistically\nvalid with respect to the underlying distribution. Of course, the oracle can always report the\nexact answer of the query on its data set. However, this strategy does not maintain accuracy on\nadaptive queries in general and\u2014as our theorem shows\u2014neither does any other computation-\nally e\ufb03cient approach. From a technical perspective our result gives a strong computational\nlower bound in the statistical query model. Lower bounds in the statistical query model have\nbeen studied for more than two decades. But more broadly speaking, we interpret our result\nas pointing at an inherent computational obstruction to preventing false discovery in collabo-\nrative science.\nNote that Theorem 1.1 stands in sharp contrast to the non-adaptive setting. If we \ufb01x queries\nq1,...,qk and then sample n items from the distribution D, the observed empirical answer to\neach query on the data set will be close to the correct answer with high probability so long as\nk = 2o(n). This guarantee follows from a Hoe\ufb00ding bound together with the union bound.\nOur hardness result applies when the dimensionality of the data grows with the sample size\nmore than logarithmically so that 2d is no longer polynomial in n.1 This requirement is rather\nmild, and is also necessary. If n \u226b2d then the empirical distribution of the n samples will\nbe close to the underlying distribution in statistical distance, and thus every statistical query\ncan be answered accurately given the sample. More generally, as we discuss in Section 1.2,\nthere are algorithms that run in time polynomial in n and 2d and provide accuracy even on\nan exponential number of adaptively chosen queries [DFH+14]. Thus, our results show that\nthe dimensionality of the data has a major e\ufb00ect on the hardness of the problem. In fact, we\nprovide a second theorem that shows that if the dimensionality is polynomially large in n, then\nwe cannot even hope for a computationally unbounded oracle that provides accuracy on adaptive\nqueries.\nTheorem 1.2. There is no computationally unbounded oracle that given n samples of dimension\nd = n3+o(1) is accurate on n3+o(1) adaptively chosen queries.\nWhile the dimension in the previous theorem has to be large, there are important data sets\nthat exhibit this trade-o\ufb00between sample size and dimension. A good example are genome\nwide association studies (GWAS). Here, the sample size corresponds to patients with a certain\n(possibly rare disease) and is often in the hundreds. The dimensionality corresponds to the\nnumber of relevent positions in the human genome and is often in the millions. Moreover, the\ngenome resolution is increasing rapidly with new technology whereas the number of available\npatients is not.\nConclusion.\nTo conclude this discussion of our results, we believe that adaptivity is an essen-\ntial element of modern data analysis that ought to be taken into account by theoretical models.\nAt the same time, our theorems demonstrate the intrinsic di\ufb03culty of coping with adaptivity.\n1This is under the stronger but standard assumption that exponentially hard one-way-functions exist.\n4\n1.1\nProof overview\nThe intuition for our proof is rather simple. We will design a challenge distribution D and\na computationally e\ufb03cient adaptive analyst A so that the following is true. If any compua-\ntionally e\ufb03cient oracle O is given n samples S = {x1,...,xn} drawn from D then our adaptive\nanalyst A is able to reconstruct n\u2032 = n \u2212O(1) samples {y1,...,yn\u2032} \u2286S. In other words, the an-\nalyst is able to \ufb01nd all but a constant number of samples that the oracle is using. While the\nanalyst has a priori information about the distribution D it has no information whatsoever\nabout which sample O received. Nevertheless, the analyst can reconstruct essentially all of\nthe hidden sample. Quantitatively, the analyst proceeds in n \u2212O(1) rounds and each round\nconsists of roughly n2 queries. In each round the analyst successfully recovers one data item\nfrom the oracle provided that the oracle continues to give accurate answers. After the analyst\nhas recovered almost all samples, the e\ufb00ective sample size of the oracle has shrunk down to a\nconstant size. At this point it is easy for the analyst to \ufb01nd queries on which the oracle gives\nblatantly inaccurate answers.\nThe \ufb01rst problem is to recover even a single data point inside the oracle\u2019s sample. To solve\nthis problem we rely on a cryptographic primitive known as a \ufb01ngerprinting code. Fingerprint-\ning codes were introduced by Boneh and Shaw [BS98] for the problem of watermarking digital\ncontent. A \ufb01ngerprinting code has two components. The \ufb01rst component generates a set of\n\u201cchallenge queries.\u201d The second component is a \u201ctracing algorithm\u201d which takes answers to\nthese queries and returns a data item. The \ufb01ngerprinting code gives the guarantee that if the\nchallenge queries are answered accurately, and by looking only at how each challenge query is\nde\ufb01ned on S, then the tracing algorithm will successfully recover one element in S. Unfortu-\nnately, in general nothing prevents the oracle from evaluating the queries at points outside of S.\nIn fact, information-theoretically the challenge queries used in our attack reveal information\nabout the unknown distribution D that the oracle didn\u2019t have previously. Evaluating the query\noutside the sample S is somewhat unnatural. For example, if the oracle simply outputs an em-\npirical quantity that only depends on the sample this situation will not arise. For such natural\noracles our proof is somewhat easier and does not require any cryptographic assumptions. We\ntherefore present this illustrative special case in Section 3.\nTo obtain a result for all computationally bounded oracles, we need to hide from the oracle\nthe additional information that\u2019s revealed by the query de\ufb01nition outside the sample. To do\nso, we use an encryption scheme to e\ufb00ectively hide the de\ufb01nition of the query on points out-\nside of S from the oracle. The encryption is su\ufb03cient to show that, assuming that the oracle\nis computationally bounded, the tracing algorithm of the \ufb01ngerprinting code will succeed. We\nnote that encryption schemes suitable for our purpose exist under the standard assumption\nthat one-way functions exist. With this one-round approach in mind, we can proceed itera-\ntively. In the next round we exclude the previously learned data item from the de\ufb01nition of\nthe challenge queries, which ensures that the analyst learns a new item in each round.\nThere is one important subtlety. The tracing algorithm of the \ufb01ngerprinting code will only\nsucceed if the oracle answers the challenge queries accurately with respect to its sample S.\nHowever, our assumption is that the oracle is accurate with respect to the underlying distribu-\ntion D rather than the sample S. We need to worry that eventually the sample and the distribu-\ntion disagree on the challenge queries. In this case the oracle may be inaccurate on its sample\n(and hence tracing fails), yet still accurate on the distribution. To rule out this pathological sit-\nuation we use a measure concentration property of our speci\ufb01c choice of \ufb01ngerprinting code.\nSpeci\ufb01cally, we the fact that the challenge queries of the code are essentially random predicates\n5\nwith a certain bias. This property allows us to use the randomness of the challenge queries to\nargue that the sample S approximately agrees with the distribution D on these queries with\nsu\ufb03ciently high probability so long as there are at least O(1) elements in the sample that we\nhaven\u2019t reconstructed yet. Due to the approximation error incurred here, we also need to use\na somewhat stronger primitive called a robust \ufb01ngerprinting code that was just recently pro-\nvided in work by Bun, Ullman and Vadhan [BUV14], which also satis\ufb01es the necessary measure\nconcentration property.\n1.2\nConnection to privacy and reconstruction attacks\nOur work builds on a close connection to the problem of designing privacy-preserving oracles.\nHere, the goal is to provide answers to statistical queries in such a way that the analyst does\nnot learn the speci\ufb01cs of individual data records but rather global properties of the underlying\ndistribution. A successful approach for formalizing this desideratum is the notion of di\ufb00eren-\ntial privacy [DMNS06]. Di\ufb00erential privacy requires that the answers given by the oracle are\nrandomized in such a way that the presence or absence of any single data item in the sample\ncannot be detected. It is known that di\ufb00erential privacy prevents so-called reconstruction at-\ntacks. A reconstruction attack is an algorithm that is able to reconstruct most entries of a data\nset by interacting with the oracle. Such an attack demonstrates that the oracle is blatantly non-\nprivate (it fails to satisfy not only di\ufb00erential privacy, but any reasonable notion of privacy).\nOur work can be considered an e\ufb03cient reconstruction attack as we give an e\ufb03cient adaptive\nanalyst that reconstructs almost all of the data points that the oracle uses if the oracle provides\naccuracy on n3+o(1) queries. An immediate consequence of our work is therefore the following\nresult.\nTheorem 1.3. Assuming one-way functions exist, any computationally e\ufb03cient oracle that given n\nsamples is accurate on n3+o(1) adaptively chosen queries must be blatantly non-private.\nThis result should be compared with recent work of Ullman [Ull13], which showed that or-\nacles satisfying di\ufb00erential privacy cannot answer even n2+o(1) non-adaptively chosen queries.\nHere we show that if the queries are chosen adaptively, then the same conclusion holds even\nfor oracles that merely thwart blatant non-privacy, up to a factor of n loss in the number of\nqueries.\nAn important di\ufb00erence to the privacy setting is how accuracy is de\ufb01ned. In the privacy\nsetting, accuracy is de\ufb01ned with respect to the oracle\u2019s sample. It is trivial to maintain accu-\nracy with respect to the sample by answering each query with the sample mean, which suc-\nceeds even when the oracle is blatantly non-private. In the setting of false discovery, we de\ufb01ne\naccuracy with respect to the underlying distribution and show that achieving this notion of\naccuracy is hard for the oracle.\nUpper bounds for answering adaptive queries.\nDi\ufb00erential privacy is also useful in estab-\nlishing upper bounds in our setting. At a high-level, di\ufb00erential privacy is a stability con-\ndition on an algorithm requiring that the output varies only slightly with the addition or\ndeletion of a sample point. On the other hand, it is known that stability implies general-\nization [BE02]. Hence, we can think of the interaction between an oracle and an analyst as\na single algorithm that satis\ufb01es a stability guarantee strong enough to imply generalization\nbounds with respect to the underlying distribution. This approach was formalized by Dwork\n6\net al. [DFH+14] leading to upper bounds in the adaptive setting when combined with algo-\nrithms from the di\ufb00erential privacy literature. Speci\ufb01cally, work of Roth-Roughgarden [RR10]\nand Hardt-Rothblum [HR10] addresses di\ufb00erential privacy in the interactive setting. The latter\nwork shows that 2 \u02dc\u2126(n/\n\u221a\nd) statistical queries can be answered with constant error under di\ufb00er-\nential privacy. However, the running time is exponential in d. Using the results of [DFH+14]\nthis leads to the same upper bound in the adaptive statistical query setting. Similarly, there\nis an e\ufb03cient di\ufb00erentially private mechanism that gives constant accuracy for \u02dc\u2126(n2) queries.\nThis leads to a computationally e\ufb03cient upper bound in our setting. To summarize we state\nthe following theorem.\nTheorem 1.4 ([DFH+14]). There is an ine\ufb03cient algorithm that accurately answers 2 \u02dc\u2126(n/\n\u221a\nd) adap-\ntively chosen statistical queries. Moreover, there is an e\ufb03cient algorithm that accurately answers\n\u02dc\u2126(n2) adaptively chosen queries.\nWe emphasize that exponential running time was known to be inherent for di\ufb00erentially\nprivate algorithms that answer n2+o(1) statistical queries [Ull13], but prior to our results it\nwas possible that there was an e\ufb03cient oracle that accurately answered exponentially many\nadaptively chosen statistical queries via a di\ufb00erent approach.\n1.3\nRelated work\nThe combination of \ufb01ngerprinting codes and encryption in our one-round approach is a com-\nmon technique in the construction of \u201ctraitor-tracing schemes.\u201d Traitor-tracing schemes were\nintroduced by Chor, Fiat, and Naor [CFN94], also for the problem of secure distribution of dig-\nital content. Dwork et al. [DNR+09] were the \ufb01rst to show that traitor-tracing schemes can be\nused to prove computational hardness results for di\ufb00erential privacy. Ullman [Ull13] showed\nthat traitor-tracing schemes with certain non-standard security properties can be used to prove\nstrong computational hardness results for di\ufb00erential privacy, and showed how to construct\nsuch a scheme. In fact, the one-round approach described above closely mirrors the traitor-\ntracing scheme constructed in [Ull13]. See [Ull13] for a more detailed discussion of prior work\non traitor-tracing and the issues that arise when using traitor-tracing schemes in the context of\ndi\ufb00erential privacy.\nOur work was also inspired by recent work of Hardt and Woodru\ufb00[HW13], which showed\nthat no low-dimensional linear sketch can give valid answers to even a polynomial number\nof adaptively chosen queries. Technically our results are largely orthogonal to theirs, since\nwe consider arbitrary computationally e\ufb03cient statistical query oracles, rather than linear\nsketches. However, their work also noted the connection between di\ufb00erential privacy and\nvalidly answering adaptively chosen queries. On the technical side, our iterative approach\nwas inspired by their results.\nThere is also a large body of work on the computational hardness of certain learning prob-\nlems. Many of these results have a similar \ufb02avor to ours in showing that any computationally\ne\ufb03cient algorithm requires either large running time or a large number of samples from the\ndistribution in order to learn a valid hypothesis. However, we are not aware of any result\nshowing a hardness result speci\ufb01c to adaptively chosen queries.\n7\nAcknowledgments\nWe are extremely grateful to Aaron Roth for raising the issue of adaptivity in false discovery\ncontrol at the Simons Workshop on Di\ufb00erential Privacy. We thank Cynthia Dwork and Omer\nReingold for introducing us to the area of False Discovery Control. We also thank Salil Vad-\nhan for helpful discussions. We acknowledge the Simons Institute for Theoretical Computer\nScience at Berkeley where this work started.\n2\nPreliminaries\nLet D be a distribution over {0,1}d, for some parameter d \u2208N. We are interested in answer-\ning statistical queries about the distribution D. A statistical query on {0,1}d is speci\ufb01ed by a\npredicate q : {0,1}d \u2192{0,1} and is de\ufb01ned to be\nq(D) =\nE\nx\u2190RD[q(x)].\nThe goal is to design an oracle O that answers statistical queries about the unknown distribution\nD, given only iid samples x1,...,xn from D. In this work, we are interested in the case where\nthe queries may be adaptively and adversarially chosen.\nSpeci\ufb01cally, O is a stateful algorithm that holds a tuple of samples x1,x2,\u00b7\u00b7\u00b7 \u2208{0,1}\u2217, takes a\nstatistical query q as input, and returns a real-valued answer a \u2208[0,1]. We require that when x\nconsists of iid samples from D, the answer a is close to q(D), and moreover that this condition\nholds for every query in an adaptively chosen sequence q1,q2,.... Formally, we de\ufb01ne the\naccuracy guarantee using the following game with a stateful adversary A.\nA chooses a distribution D over {0,1}d\nSample x1,...,xn \u2190R D, let x = (x1,...,xn)\nFor j = 1,...,k\nA(q1,a1,...,qj\u22121,aj\u22121) outputs a query qj\nO(x,qj) outputs aj\nFigure 1: Accn,d,k[O,A]\nDe\ufb01nition 2.1 (Accurate Oracle). An oracle O is (\u03b1,\u03b2)-accurate for k adaptively chosen queries\ngiven n samples in {0,1}d if for every adversary A,\nPr\nAccn,d,k[O,A]\nh\n\u2200j \u2208[k]\n\f\f\fO(x,qj) \u2212qj(D)\n\f\f\f \u2264\u03b1\ni\n\u22651 \u2212\u03b2 .\nAs a shorthand, we will say that O is \u03b1-accurate for k queries if for every n,d \u2208N, O is (\u03b1,on(1))-\naccurate for k queries given n samples in {0,1}d. Here, k may depend on n and d and on(1) is a\nfunction of n that tends to 0.\nWe are interested in oracles that are both accurate and computationally e\ufb03cient. We say\nthat an oracle O is computationally e\ufb03cient if when given samples x1,...,xn \u2208{0,1}d and a query\nq : {0,1}d \u2192{0,1} it runs in time poly(n,d,|q|). Here q will be represented as a circuit that\nevaluates q(x) and |q| denotes the size of this circuit.\n8\n2.1\nFingerprinting codes\nCollusion-resilient \ufb01ngerprinting codes were introduced by Boneh and Shaw [BS98] for the\nproblem of watermarking digital content. A \ufb01ngerprinting code is a pair of e\ufb03cient algorithms\n(FPC.Gen,FPC.Trace). The code generator FPC.Gen takes a number of users p as input and\noutputs a matrix F \u2208{0,1}p\u00d7\u2113FPC(p), for some function \u2113FPC : N \u2192N. We think of F as consisting\nof p codewords, one for each user i \u2208[p], with each codeword being of length \u2113FPC = \u2113FPC(p). For\na subset of users S \u2286[p], we use FS to denote the |S| \u00d7 \u2113FPC matrix consisting of the subset of\ncodewords belonging to users in S.\nThe security property says that any codeword can be \u201ctraced\u201d to its corresponding user.\nMoreover, the code is fully collusion-resilient\u2014if any subset of users S \u2286[p] \u201ccombines\u201d their\ncodewords in an arbitrary manner, then the combined codeword a \u2208{0,1}\u2113FPC can also be traced\nto one of the users in S, provided that the combined codeword is \u201cconsistent\u201d with FS in a\nvery weak sense. For the standard de\ufb01nition of \ufb01ngerprinting codes, the consistency condition\nwould require that for every column j of FS, if every entry of the j-th column shares the same\nbit b, then the j-th entry of a is also b. Formally, we will use the condition that for every j,\n|aj \u2212Ei\u2208S [FS(i,j)]| \u22641/3. For our results we require a stronger, error-robust \ufb01ngerprinting code,\nthat can trace combined codewords that only respect a relaxed consistency condition, in which\nthe above constraint on a is only required to hold for 99% of columns j.\nSpeci\ufb01cally, for any set of codewords FS, we de\ufb01ne\nCon(FS) =\n\u001a\na \u2208{0,1}\u2113FPC\n\f\f\f\f\ffor .99\u2113FPC choices of j,\n\f\f\f\f\faj \u2212E\ni\u2208S [FS(i,j)]\n\f\f\f\f\f \u22641/3\n\u001b\nWe can now formally de\ufb01ne error-robust \ufb01ngerprinting codes\nDe\ufb01nition 2.2. For a function \u2113FPC : N \u2192N, a pair of e\ufb03cient algorithms (FPC.Gen,FPC.Trace)\nis an error-robust \ufb01ngerprinting code of length \u2113FPC if\n1. for every p \u2208N, FPC.Gen(1p) outputs a matrix F \u2208{0,1}p\u00d7\u2113FPC(p) and\n2. for every (possibly randomized) adversary AFPC and every S \u2286[p], if a \u2190R AFPC(FS), then\nPr\nF\u2190RFPC.Gen(1p)[a \u2208Con(FS) \u2227FPC.Trace(F,a) < S] \u2264negl(p).\nBun, Ullman, and Vadhan [BUV14] introduced error-robust \ufb01ngerprinting codes. They\ngave a construction with nearly-optimal length, building on the nearly-optimal construction\nof standard (non-robust) \ufb01ngerprinting codes by Tardos [Tar08].\nTheorem 2.3 ([BUV14], building on [Tar08]). For every p \u2208N, there exists an error-robust \ufb01nger-\nprinting code of length \u2113FPC(p) = \u02dc\u0398(p2).\nFor our results, we will need an additional technical lemma about the \ufb01ngerprinting code\nin [BUV14] that we will use for our results. The lemma states that if |S| is at least a su\ufb03ciently\nlarge constant, then for most columns j, the mean of the j-th column of F and that of FS are\nclose. In order to prove the lemma, we need to partially describe the algorithm FPC.Gen.\nLemma 2.4. For every p \u2265500, and every S \u2286[p] such that |S| \u2265500, we have\nPr\nF\u2190RFPC.Gen\n\"\nfor .99\u2113FPC choices of j,\n\f\f\f\f\f\f E\ni\u2208[p][F(i,j)] \u2212E\ni\u2208S [FS(i,j)]\n\f\f\f\f\f\f \u22641/6\n#\n\u22651 \u2212negl(p)\n9\nChoose parameters p1,...,p\u2113FPC \u2208[0,1]. (The parameters pj must be chosen from a partic-\nular distribution, which is not relevant for our purposes)\nFor every i \u2208[p],j \u2208[\u2113FPC], let F(i,j) = 1 with probability pj, independently\nFigure 2: FPC.Gen\nProof. Fix any p1,...,p\u2113FPC \u2208[0,1] and any j \u2208[\u2113FPC]. Then for every i \u2208[S], F(i,j) is an indepen-\ndent Bernoulli random variable with success probability pj. Thus, by a Hoe\ufb00ding bound2\nPr\n\"\f\f\f\f\f\f E\ni\u2208[p][F(i,j)] \u2212pj\n\f\f\f\f\f\f > 1/12\n#\n\u22642exp(\u2212p/72) \u22641/400\nand\nPr\n\u0014\f\f\f\f\f E\ni\u2208S [F(i,j)] \u2212pj\n\f\f\f\f\f > 1/12\n\u0015\n\u22642exp(\u2212|S|/72) \u22641/400.\nThus, by a triangle inequality, it holds that\nPr\n\"\f\f\f\f\f\f E\ni\u2208S [F(i,j)] \u2212E\ni\u2208[p][F(i,j)]\n\f\f\f\f\f\f > 1/6\n#\n\u22641/200\nIf we let Bj be the indicator variable of the event\nn\n|Ei\u2208S [F(i,j)] \u2212Ei\u2208[p] [F(i,j)]| > 1/6\no\n, then\nE\nhP\u2113FPC\ni=1 Bj\ni\n\u2264\u2113FPC/200. Since the parameters pj are \ufb01xed, the events Bj are independent. Thus,\nby a Hoe\ufb00ding bound, Pr\nhP\u2113FPC\ni=1 Bj > \u2113FPC/100\ni\n\u2264exp(\u2212\u2113FPC/20000) \u2264negl(p). The \ufb01nal in-\nequality holds because \u2113FPC = \u2113FPC(p) = \u02dc\u0398(p2). Since the conclusion holds for every \ufb01xed choice\nof parameters pj, it also holds when the parameters pj are chosen randomly as in FPC.Gen.\n3\nLower bound for natural oracles\nIn this section we prove our main result in the special case where the oracle satis\ufb01es a natural\ncondition, roughly speaking, that it does not evaluate a given query outside its sample. The\nproof is technically simpler in this case as it is unconditional and does not rely on any crypto-\ngraphic constructions. Nevertheless, the proof outline is essentially the same as in the general\ncase and so it is instructive to begin with this special case.\nDe\ufb01nition 3.1. An oracle O is natural if for every input sample S and every two queries q and\nq\u2032 such that q(x) = q\u2032(x) for all x \u2208S, the answers a and a\u2032 that the oracle gives on queries q\nand q\u2032, respectively, are identical if the oracle is deterministic and identically distributed if the\noracle is randomized. If the oracle is stateful, then this condition should hold when the oracle\nis in any of its possible states.\nWe will now show that there is no natural oracle that is accurate for a su\ufb03ciently large\nnumber of adaptively chosen queries. To do so, we will construct an adversary that chooses a\ndistribution D, and then issues queries to the oracle in such a way that any computationally\ne\ufb03cient oracle that is given samples from D will fail to answer all queries correctly.\n2For independent random variables X1,...,Xm \u2208[0,1], if X = 1\nm\nPm\ni=1 Xi, then Pr[X > E[X] + \u03c4] \u2264exp(\u22122\u03c42m)\nand Pr[|X \u2212E[X]| > \u03c4] \u22642exp(\u22122\u03c42m).\n10\nThe adversary is described in Figure 4 and proceeds in three phases. In the \ufb01rst phase the\nadversary chooses the distribution D randomly. Then the oracle is given samples from D and\nthe adversary performs a recovery phase in order to identify (most of) the samples the oracle\nreceived. Finally, the adversary uses knowledge of (most of) the samples to \ufb01nd a query that\nthe oracle cannot answer accurately. In the \ufb01gure, (FPC.Gen,FPC.Trace) is a \ufb01ngerprinting code\nof length \u2113FPC(p).\nGiven a parameter n, let p = 2000n and R = n \u2212500.\nLet D be the uniform distribution over {1,...,p}.\nChoose samples x1,...,xn \u2190R D, let x = (x1,...,xn).\nLet S \u2286[p] be the set of unique numbers appearing in x.\nRecovery phase:\nSample \ufb01ngerprinting codes F1,...,FR \u2190R FPC.Gen(1p) of length \u2113FPC = \u2113FPC(p).\nLet T 0 = \u2205\nFor round r = 1 to R:\nFor j = 1,...,\u2113FPC :\nDe\ufb01ne the query qr\nj(i) to be Fr(i,j) if i < T r\u22121 and 0 otherwise.\nLet ar\nj = O(x;qr\nj)\nLet ar = (ar\n1,...,ar\n\u2113FPC)\nLet ir = FPC.Trace(Fr,ar), and let T r = T r\u22121 \u222a{ir}\nAttack phase:\nLet \u03c6 = 0 with probability 1/2 and \u03c6 = 1/500 with probability 1/2\nSample a random subset B \u2286[p] of size \u03c6 \u00b7 p.\nLet mi = 1 for all i \u2208B and 0 for all i \u2208[p] \\ B.\nDe\ufb01ne the query q\u2217(i) to be mi if i < T R and 0 otherwise.\nLet a\u2217= O(x,q\u2217).\nFigure 3: Attackn[O]\n3.1\nAnalysis of the recovery phase\nThe goal of the recovery phase of the algorithm is to identify most of the samples x1,...,xn that\nare held by the oracle. Once the attacker has this information, he can use it to \ufb01nd queries that\ndistinguish the oracle\u2019s samples from the population and force the oracle to be inaccurate.\nIn order to recover samples, the attacker will force the oracle to give answers that are con-\nsistent with the \ufb01ngerprinting codes F1,...,FR, which are then given to FPC.Trace to recover an\nelement of the sample. Our \ufb01rst claim establishes that an accurate oracle will indeed force the\noracle to give answers consistent with the \ufb01ngerprinting codes.\nClaim 3.2. If O is (1/12)-accurate for n \u00b7 \u2113FPC(2000n) + 1 adaptively chosen queries, then\nPr\nAttackn[O]\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u2200r \u2208[R], for .99\u2113FPC choices of j \u2208[\u2113FPC],\n\f\f\f\fO(x,qr\nj) \u2212Ei\u2208S\\T r\u22121 [Fr(i,j)]\n\f\f\f\f \u22641/3\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\u22651 \u2212o(1).\n11\nProof. First we show that,\nPr\nAttack\n\"\n\u2200r \u2208[R],j \u2208[\u2113FPC]\n\f\f\f\f\f\fO(x,qr\nj) \u2212E\ni\u2208[p][Fr(i,j)]\n\f\f\f\f\f\f \u22641/6\n#\n\u22651 \u2212o(1).\nObserve that by de\ufb01nition, for every r,j,\nE\n(i,ski)\u2190RD\nh\nqr\nj(i)\ni\n= 1\np\nX\ni\u2208[p]\\T r\u22121\nFr(i,j).\nSince |T r\u22121| \u2264n and Fr(i,j) \u2208{0,1}, for every r,j,\n\f\f\f\f\f\f E\ni\u2190RD\nh\nqr\nj(i)\ni\n\u2212E\ni\u2208[p][Fr(i,j)]\n\f\f\f\f\f\f \u2264n\np \u22641\n12 .\n(1)\nThe oracle\u2019s input x consists of n samples from D. Moreover, the total number of queries issued\nto the oracle is at most k = n \u00b7\u2113FPC(2000n)+1. Since the oracle is assumed to be (1/12)-accurate\nfor k queries given n samples in {0,1}d,\nPr\nAttack\n\"\n\u2200r,j\n\f\f\f\f\f\fO(x,qr\nj) \u2212\nE\n(i,ski)\u2190RD\nh\nqr\nj(i,ski)\ni\f\f\f\f\f\f \u22641\n12\n#\n\u22651 \u2212o(1).\n(2)\nApplying the triangle inequality to (1) and (2), this shows\nPr\nAttack\n\"\n\u2200r,j\n\f\f\f\f\f\fO(x,qr\nj) \u2212E\ni\u2208[p][Fr(i,j)]\n\f\f\f\f\f\f \u22641/6\n#\n\u22651 \u2212o(1).\n(3)\nBy Lemma 2.4, since |S \\ T r\u22121| \u2265500, for every r,\nPr\n\"\nfor .99\u2113FPC choices of j,\n\f\f\f\f\f\f E\ni\u2208[p][Fr(i,j)] \u2212E\ni\u2208S\nh\nFr\nS(i,j)\ni\f\f\f\f\f\f \u22641/6\n#\n\u22651 \u2212negl(n).\nwhere the probability is taken over the choice of Fr \u2190R FPC.Gen. By a union bound over\nr = 1,...,R, where R = n \u2212500, if F1,...,FR \u2190R FPC.Gen, then\nPr\n\"\n\u2200r, for .99\u2113FPC choices of j,\n\f\f\f\f\f\f E\ni\u2208[p][Fr(i,j)] \u2212E\ni\u2208S\nh\nFr\nS(i,j)\ni\f\f\f\f\f\f \u22641/6\n#\n\u22651 \u2212negl(n).\n(4)\nThe claim now follows by combining (3) and (4).\nNow that we have established Claim 4.1, we know that in every round r, the oracle O\nholding x returns a set of answers that are consistent with the \ufb01ngerprinting code Fr\nS\\T r\u22121.\nHowever, this fact alone is not enough to guarantee that FPC.Trace returns a user in S \\ T r\u22121,\nbecause the queries to the oracle depend on rows of Fr for users outside of S \\T r\u22121, whereas the\nsecurity of the \ufb01ngerprinting code applies only to algorithms that only have access to the rows\nof Fr for users in S \\T r\u22121. However, if we assume that the oracle is natural, then its answers do\nnot depend on information about the query at points outside of the sample S.\n12\nLemma 3.3. If O is a natural oracle and is (1/12)-accurate for n\u00b7\u2113FPC(2000n)+1 adaptively chosen\nqueries, then\nPr\nAttackn,d[O]\nh\n|S \\ T R| > 500\ni\n= o(1)\nProof. Fix any round r \u2208{1,...,|S| \u2212500} and let U = S \\T r\u22121. By the security of the \ufb01ngerprint-\ning code, we have that for every algorithm A\nPr\nFr\u2190RFPC.Gen(1p)\nh\n(A(Fr\nU) \u2208Con(Fr\nU)) \u2227(FPC.Trace(Fr,A(Fr\nU)) < U)\ni\n\u2264negl(n)\nObserve that the oracle O is natural and therefore the answer it gives on any query cannot\ndepend on rows of Fr that belong to users outside of S. Moreover, the query is 0 on points in\nT r\u22121 and The queries issued in rounds r\u2032 , r depend only on Fr\u2032, which is independent from\nFr. Hence, the answer of the oracle depends only on points in U. We therefore have\nPr\nFr\u2190RFPC.Gen(1p)\nh\n(ar \u2208Con(Fr\nU)) \u2227(FPC.Trace(Fr,ar) < U)\ni\n\u2264negl(n).\n(5)\nBy a union bound over r = 1,...,|S| \u2212500, we also have\nPr\nF1,...,F|S|\u2212500\u2190RFPC.Gen(1p)\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u2203r\n\u0010\nar \u2208Con(Fr\nS\\T r\u22121)\n\u0011\n\u2227\n\u0010\nFPC.Trace(Fr,ar) < S \\ T r\u22121\u0011\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\u2264negl(n)\n(6)\nBy Claim 3.2, we have that with probability at least 1\u2212o(1), it holds that for all r \u2208{1,...,|S| \u2212500}\nand for .99\u2113FPC choices of j \u2208[\u2113FPC]\n\f\f\f\f\far\nj \u2212E\ni\u2208U [Fr(i,j)]\n\f\f\f\f\f \u22641/3\nNote that in order to apply Claim 3.2 we have used the fact that when r \u2208{1,...,|S| \u2212500},\n|S \\ T r\u22121| \u2265500. If this condition is satis\ufb01ed, then indeed ar \u2208Con(Fr\nU). Therefore, combining\nwith (6), we have\nPr\nF1,...,F|S|\u2212500\u2190RFPC.Gen(1p)\nh\n\u2203r,FPC.Trace(Fr,ar) < S \\ T r\u22121i\n\u2264o(1).\nNow the claim follows by observing that\nPr\nAttack\nh\n|S \\ T R| > 500\ni\n\u2264\nPr\nAttack\nh\n\u2203r \u2208{1,...,|S| \u2212500} FPC.Trace(Fr,ar) < S \\ T r\u22121i\n\u2264o(1).\n3.2\nAnalysis of the Attack Phase\nAt this point we know that if the oracle is natural and accurately answers all the queries in\nthe recovery phase, then with high probability |S \\ T R| \u2264500. Next we show that if this event\noccurs, then the probability that the oracle answers q\u2217accurately in the attack phase is bounded\naway from 1 by a constant. Since an accurate oracle is required to answer each query accurately\nwith probability at least 1 \u2212o(1), we will obtain a contradiction.\nTo begin with we show that the population answer q\u2217(D) is close to the value \u03c6 in the attack.\n13\nClaim 3.4. In Attackn[O], we have |q\u2217(D) \u2212\u03c6| \u22641/2000.\nProof. The case \u03c6 = 0 we have q\u2217(D) = 0. If \u03c6 = 1/500, then we have that Ei\u2208[p] mi = \u03c6 since\n|B| = \u03c6 \u00b7 p. Hence,\nq\u2217(D) = E\ni\u223cDq\u2217(i) = \u03c6 \u2212\nPr\ni\u2190R[p]\nh\ni \u2208T R \u2227mi = 1\ni\nwhere Pr\nh\ni \u2208T R \u2227mi = 1\ni\n\u2264Pr\nh\ni \u2208T Ri\n= |T R|/p = (n \u2212500)/p \u22641/2000.\nWe will now show that the oracle cannot guess the value of \u03c6 with su\ufb03ciently high proba-\nbility provided that the recovery phase succeeded.\nClaim 3.5.\nPr\nAttackn[O]\n\u0014\u0010\n|S \\ T R| \u2264500\n\u0011\n\u2227\n\f\f\fO(x,q\u2217) \u2212\u03c6\n\f\f\f \u2264\n1\n2000\n\u0015\n\u22641 \u2212\u2126(1)\nProof. Consider the case where \u03c6 = 1/500. We have\nPr\nh\n\u2200i \u2208S \\ T R, mi = 0\n\f\f\f|S \\ T R| \u2264500\ni\n\u2265\n499\nY\ni=0\n (1 \u2212\u03c6)p \u2212i\np \u2212i\n!\n\u2265\n (1 \u2212\u03c6)p \u2212499\np \u2212499\n!500\n=\n \n1 \u2212\u03c6\np\np \u2212499\n!500\n\u2265(1 \u22122\u03c6)500 =\n\u0012\n1 \u2212\n1\n250\n\u0013500\n\u22651\n4e2\nwhere we used that p \u22652000. On the other hand, when \u03c6 = 0, we have\nPr\nh\n\u2200i \u2208S \\ T R, mi = 0\n\f\f\f|S \\ T R| \u2264500\ni\n= 1.\nNote that because the oracle is natural it answer only depends on mi for i \u2208S \\ T R. When the\noracle sees only that mi = 0 for every i \u2208S \\T R, it cannot give an answer that is simultaneously\naccurate to within 1/2000 for both the case of \u03c6 = 0 and for the case of \u03c6 = 1/500. The event\nmi = 0 for every i \u2208S \\ T R occurs with at least probability 1/4e2 as shown above. Conditioned\non this event, both cases \u03c6 = 0 and \u03c6 = 1/500 have constant probability. Hence, the answer of\nthe oracle must be far from \u03c6 with constant probability. Formally,\nPr\nAttack\n\u0014\f\f\fO(x,q\u2217) \u2212\u03c6\n\f\f\f \u2264\n1\n2000\n\f\f\f\f\f |S \\ T R| \u2264500\n\u0015\n\u22641 \u2212\u2126(1).\nBy Lemma, this implies\nPr\nAttack\n\u0014\u0012\f\f\fO(x,q\u2217) \u2212\u03c6\n\f\f\f \u2264\n1\n2000\n\u0013\n\u2227(|S \\ T R| \u2264500)\n\u0015\n\u22641 \u2212\u2126(1)\n1 \u2212o(1) \u22641 \u2212\u2126(1).\nLemma 3.6. If O is natural, then\nPr\nAttackn,d[O]\n\u0014\n(|S \\ T R| \u2264500) \u2227|O(x,q\u2217) \u2212q\u2217(D)| \u2264\n1\n2000\n\u0015\n\u22641 \u2212\u2126(1)\nProof. By Claim 3.4, we have that |q\u2217(D) \u2212\u03c6| \u22641/2000. Claim 3.5 shows that\nPr\nAttack\n\u0014\n(|S \\ T R| \u2264500) \u2227\n\f\f\fO(x,q\u2217) \u2212\u03c6\n\f\f\f \u2264\n1\n2000\n\u0015\n\u22641 \u2212\u2126(1).\nThe statement of the lemma now follows from a triangle inequality.\n14\n3.3\nPutting it together\nTheorem 3.7. There is no natural oracle O that is (1/2000)-accurate for n3+o(1) adaptively chosen\nqueries given n samples.\nProof. The entire attack will consist of k = R \u00b7 \u2113FPC + 1 queries, where R = n \u2212500 and \u2113FPC =\n\u02dcO(p2) = \u02dcO(n2). Therefore the entire attack consists of k = n3+o(1) queries.\nTherefore, if O is natural, by Lemma 3.2,\nPr\nAttackn[O]\nh\n|S \\ T R| > 500\ni\n= on(1)\nBy Lemma 3.6,\nPr\nAttackn[O]\n\u0014\n(|S \\ T R| \u2264500) \u2227|O(x,q\u2217) \u2212q\u2217(D)| \u2264\n1\n2000\n\u0015\n\u22641 \u2212\u2126(1)\nCombining these two statements gives\nPr\nAttackn[O]\n\u0014\n|O(x,q\u2217) \u2212q\u2217(D)| \u2264\n1\n2000\n\u0015\n\u22641 \u2212\u2126(1)\nHowever, the de\ufb01nition of an accurate oracle asserts, in particular, that\nPr\nAttackn[O]\n\u0014\n|O(x,q\u2217) \u2212q\u2217(D)| \u2264\n1\n2000\n\u0015\n\u22651 \u2212o(1)\nand thereby we obtain a contradiction.\n4\nLower bound for all computationally bounded oracles\nIn this section we will show that there is no computationally e\ufb03cient oracle that is accurate\nfor a su\ufb03ciently large number of adaptively chosen queries, and thereby formally establish\nTheorem 1.1 in the introduction. To do so, we will construct an adversary that chooses a dis-\ntribution D, and then issues queries to the oracle such that no computationally e\ufb03cient oracle\ngiven samples from D can answer all the queries correctly.\n4.1\nEncryption schemes\nOur attack relies on the existence of a semantically secure private-key encryption scheme that\nwe brie\ufb02y recall here. An encryption scheme is a triple of e\ufb03cient algorithms (Gen,Enc,Dec)\nwith the following syntax:\n\u2022 Gen is a randomized algorithm that a security parameter \u03bb and outputs an \u2113Enc(\u03bb)-bit\nsecret key for some non-decreasing function \u2113Enc : N \u2192N. Formally, sk \u2190R Gen(1\u03bb).\n\u2022 Enc is a randomized algorithm that takes as input a secret key and a one-bit message\nm \u2208{0,1} and outputs a ciphertext c. Formally, c \u2190R Enc(sk,m).\n\u2022 Dec is a deterministic algorithm that takes as input a secret key and a ciphertext c and\noutputs a decryption m\u2032. If the ciphertext c was an encryption of m under the key sk, then\nm\u2032 = m. Formally, if c \u2190R Enc(sk,m), then Dec(sk,c) = m with probability 1.\n15\nRoughly, security of the encryption scheme asserts that no polynomial time adversary who\ndoes not know the secret key can distinguish encryptions of m = 0 from encryptions of m =\n1, even if the adversary has access to an oracle that returns the encryption of an arbitrary\nmessage under the unknown key. For convenience, we will require that this security property\nholds simultaneously for an arbitrary polynomial number of secret keys. The existence of\nan encryption scheme with this property follows immediately from the existence an ordinary\nsemantically secure encryption scheme. We start with the stronger de\ufb01nition only to simplify\nour proofs. A secure encryption scheme exists under the minimal cryptographic assumption\nthat one-way functions exist. The formal de\ufb01nition of security is not needed until Section A.\n4.2\nDescription of the attack\nThe adversary is speci\ufb01ed in Figure 4. The adversary works in three phases. In the \ufb01rst phase\nthe adversary chooses the distribution D randomly. Then the oracle is given samples from D\nand the adversary performs a recovery phase in order to identify (most of) the samples the\noracle received. Finally, the adversary uses knowledge of (most of) the samples to \ufb01nd a query\nthat the oracle cannot answer accurately. See Section 1.1 for more informal description of the\nadversary. In Figure 4, (Gen,Enc,Dec) is an encryption scheme with key length \u2113Enc(\u03bb) and\n(FPC.Gen,FPC.Trace) is a \ufb01ngerprinting code of length \u2113FPC(p). Observe that Attackn,d is only\nwell de\ufb01ned for pairs n,d \u2208N such that there exists \u03bb \u2208N for which \u2113Enc(1)+\u2308log(2000n)\u2309\u2264d.\nThrough this section we will assume that n = n(d) = poly(d) and that d is a su\ufb03ciently large\nconstant, which ensures that Attackn,d is well de\ufb01ned.\n4.3\nAnalysis of the recovery phase\nThe goal of the recovery phase of the algorithm is to identify most of the samples x1,...,xn that\nare held by the oracle. Once the attacker has this information, he can use it to \ufb01nd queries that\ndistinguish the oracle\u2019s keys from the population and force the oracle to be inaccurate.\nIn order to recover keys, the attacker will force the oracle to give answers that are consis-\ntent with the \ufb01ngerprinting codes F1,...,FR, which are then given to FPC.Trace to recover an\nelement of the sample. Our \ufb01rst claim establishes that an accurate oracle will indeed force the\noracle to give answers consistent with the \ufb01ngerprinting codes.\nClaim 4.1. If O is (1/12)-accurate for n \u00b7 \u2113FPC(2000n) + 1 adaptively chosen queries then for every\npolynomial n = n(d) and every su\ufb03ciently large d \u2208N,\nPr\nAttackn,d[O]\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u2200r \u2208[R], for .99\u2113FPC choices of j \u2208[\u2113FPC],\n\f\f\f\fO(x,qr\nj) \u2212Ei\u2208S\\T r\u22121 [Fr(i,j)]\n\f\f\f\f \u22641/3\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\u22651 \u2212o(1)\nProof. First we show that,\nPr\nAttack\n\"\n\u2200r \u2208[R],j \u2208[\u2113FPC]\n\f\f\f\f\f\fO(x,qr\nj) \u2212E\ni\u2208[p][Fr(i,j)]\n\f\f\f\f\f\f \u22641/6\n#\n\u22651 \u2212o(1)\n16\nThe distribution D:\nGiven parameters d,n, let p = 2000n, let R = n \u2212500\nLet \u03bb be the largest integer such that \u2113Enc(\u03bb) + \u2308logp\u2309\u2264d\nFor i \u2208[p], let ski \u2190R Gen(1\u03bb) and let yi = (i,ski)\nLet D be the uniform distribution over\nn\ny1,...,yp\no\n\u2286{0,1}d\nChoose samples x1,...,xn \u2190R D, let x = (x1,...,xn)\nLet S \u2286[p] be the set of unique indices i such that (i,ski) appears in x\nRecovery phase:\nSetup \ufb01ngerprinting codes and ciphertexts:\nLet F1,...,FR \u2190R FPC.Gen(1p), let \u2113FPC = \u2113FPC(p) be code length\nFor r = 1,...,R, i = 1,...,p, j = 1,...,\u2113FPC, let cr(i,j) = Enc(ski,Fr(i,j))\nLet T 0 = \u2205\nFor round r = 1,...,R:\nFor j = 1,...,\u2113FPC :\nDe\ufb01ne the query qr\nj(i\u2032,sk\u2032) to be Dec(sk\u2032,cr(i\u2032,j)) if i\u2032 < T r\u22121 and 0 otherwise\nLet ar\nj = O(x;qr\nj)\nLet ar = (ar\n1,...,ar\n\u2113FPC)\nLet ir = FPC.Trace(Fr,ar), and let T r = T r\u22121 \u222a{ir}\nAttack phase:\nLet \u03c6 = 0 with probability 1/2 and \u03c6 = 1/500 with probability 1/2\nSample a random subset B \u2286[p] of size \u03c6 \u00b7 p.\nLet mi = 1 for all i \u2208B and 0 for all i \u2208[p] \\ B\nLet c\u2217\ni = Enc(ski,mi) for all i \u2208[p]\nDe\ufb01ne the query q\u2217(i\u2032,sk\u2032) to be Dec(sk\u2032,c\u2217\ni\u2032) if i\u2032 < T R and 0 otherwise\nLet a\u2217= O(x,q\u2217)\nFigure 4: Attackn,d[O]\nObserve that by de\ufb01nition, for every r,j,\nE\n(i,ski)\u2190RD\nh\nqr\nj(i,ski)\ni\n= 1\np\nX\ni\u2208[p]\\T r\u22121\nDec(ski,cr(i,j)) + 1\np\nX\ni\u2208T r\u22121\n0\n= 1\np\nX\ni\u2208[p]\\T r\u22121\nFr(i,j)\nwhere the last equality is because cr(i,j) \u2190R Enc(ski,Fr(i,j)). Since |T r\u22121| \u2264n and Fr(i,j) \u2208{0,1},\n\u2200r,j\n\f\f\f\f\f\f\nE\n(i,ski)\u2190RD\nh\nqr\nj(i,ski)\ni\n\u2212E\ni\u2208[p][Fr(i,j)]\n\f\f\f\f\f\f \u2264n\np \u22641\n12\n(7)\n17\nIn Attack, the oracle\u2019s input x consists of n samples from D. Moreover, the total number of\nqueries issued to the oracle is at most k = n \u00b7 \u2113FPC(2000n) + 1. Since the oracle is assumed to be\n(1/12)-accurate for k queries given n samples in {0,1}d,\nPr\nAttack\n\"\n\u2200r,j\n\f\f\f\f\f\fO(x,qr\nj) \u2212\nE\n(i,ski)\u2190RD\nh\nqr\nj(i,ski)\ni\f\f\f\f\f\f \u22641\n12\n#\n\u22651 \u2212o(1)\n(8)\nApplying the triangle inequality to (7) and (8), this shows\nPr\nAttack\n\"\n\u2200r,j\n\f\f\f\f\f\fO(x,qr\nj) \u2212E\ni\u2208[p][Fr(i,j)]\n\f\f\f\f\f\f \u22641/6\n#\n\u22651 \u2212o(1).\n(9)\nBy Lemma 2.4, since |S \\ T r\u22121| \u2265500, for every r, if Fr \u2190R FPC.Gen(1p), then\nPr\n\"\nfor .99\u2113FPC choices of j,\n\f\f\f\f\f\f E\ni\u2208[p][Fr(i,j)] \u2212E\ni\u2208S\nh\nFr\nS(i,j)\ni\f\f\f\f\f\f \u22641/6\n#\n\u22651 \u2212negl(n)\nwhere the probability is taken over the choice of Fr \u2190R FPC.Gen. By a union bound over\nr = 1,...,R, where R = n \u2212500, if F1,...,FR \u2190R FPC.Gen, then\nPr\n\"\n\u2200r, for .99\u2113FPC choices of j,\n\f\f\f\f\f\f E\ni\u2208[p][Fr(i,j)] \u2212E\ni\u2208S\nh\nFr\nS(i,j)\ni\f\f\f\f\f\f \u22641/6\n#\n\u22651 \u2212negl(n)\n(10)\nThe claim now follows by combining (9) and (10).\nNow that we have established Claim 4.1, we know that in every round r, the oracle O hold-\ning x returns a set of answers that are consistent with the \ufb01ngerprinting code Fr\nS\\T r\u22121. However,\nthis fact alone is not enough to guarantee that FPC.Trace returns a user in S \\ T r\u22121, because the\nqueries to the oracle depend on rows of Fr for users outside of S \\ T r\u22121, whereas the security\nof the \ufb01ngerprinting code applies only to algorithms that only have access to the rows of Fr\nfor users in S \\ T r\u22121. To remedy this problem we rely on the fact that the rows of Fr outside of\nS \\T r\u22121 are encrypted under keys sk that are not known to the oracle. Thus, a computationally\ne\ufb03cient oracle \u201cdoes not know\u201d those rows. We can formalize this argument by comparing\nAttack to an IdealAttack where rows of Fr for users outside of S \\ T r\u22121 are replaced with zeros,\nand argue that the adversary cannot distinguish between these two attacks without breaking\nthe security of the encryption scheme.\nClaim 4.2. Let Z1 be the event\n\u2200r \u2208[R], for .99\u2113FPC choices of j \u2208[\u2113FPC],\n\f\f\f\f\fO(x,qr\nj) \u2212\nE\ni\u2208S\\T r\u22121 [Fr(i,j)]\n\f\f\f\f\f \u22641/3\nAssume (Gen,Enc,Dec) is a computationally secure encryption scheme with key length \u2113Enc(\u03bb) = \u03bb\nand let n = n(d) be any polynomial. Then if O is computationally e\ufb03cient, for every d \u2208N\n\f\f\f\f\f\f\nPr\nIdealAttackn,d[O][Z1] \u2212\nPr\nAttackn,d[O][Z1]\n\f\f\f\f\f\f \u2264negl(d)\nThe proof follows from the security of the encryption scheme. We defer the details to\nSection A.\n18\nThe distribution D:\nGiven parameters d,n, let p = 2000n, let R = n \u2212500\nLet \u03bb be the largest integer such that \u2113Enc(\u03bb) + \u2308logp\u2309\u2264d\nFor i \u2208[p], let ski \u2190R Gen(1\u03bb) and let yi = (i,ski)\nLet D be the uniform distribution over\nn\ny1,...,yp\no\n\u2286{0,1}d\nChoose samples x1,...,xn \u2190R D, let x = (x1,...,xn)\nLet S \u2286[p] be the set of unique indices i such that (i,ski) appears in x\nRecovery phase:\nSetup \ufb01ngerprinting codes and ciphertexts:\nLet F1,...,FR \u2190R FPC.Gen(1p), let \u2113FPC = \u2113FPC(p) be code length\nFor r = 1,...,R, i \u2208S, j = 1,...,\u2113FPC, let cr(i,j) = Enc(ski,Fr(i,j))\nFor r = 1,...,R, i \u2208[p] \\ S, j = 1,...,\u2113FPC, let cr(i,j) = Enc(ski,0)\nLet T 0 = \u2205\nFor round r = 1,...,R:\nFor j = 1,...,\u2113FPC :\nDe\ufb01ne the query qr\nj(i\u2032,sk\u2032) to be Dec(sk\u2032,cr(i\u2032,j)) if i\u2032 < T r\u22121 and 0 otherwise\nLet ar\nj = O(x;qr\nj)\nLet ar = (ar\n1,...,ar\n\u2113FPC)\nLet ir = FPC.Trace(Fr,ar), and let T r = T r\u22121 \u222a{ir}\nAttack phase:\nLet \u03c6 = 0 with probability 1/2 and \u03c6 = 1/500 with probability 1/2\nSample a random subset B \u2286[p] of size \u03c6 \u00b7 p.\nLet mi = 1 for all i \u2208B and 0 for all i \u2208[p] \\ B\nFor each i \u2208S, let c\u2217\ni = Enc(ski,mi), for each i \u2208[p] \\ S, let c\u2217\ni = Enc(ski,0)\nDe\ufb01ne the query q\u2217(i\u2032,sk\u2032) to be Dec(sk\u2032,c\u2217\ni\u2032) if i\u2032 < T R and 0 otherwise\nLet a\u2217= O(x,q\u2217)\nFigure 5: IdealAttackn,d[O]\nClaim 4.3. If O is computationally e\ufb03cient and (1/12)-accurate for n \u00b7 \u2113FPC(2000n) + 1 adaptively\nchosen queries, then for any polynomial n = n(d), and every su\ufb03ciently large d \u2208N,\nPr\nIdealAttackn,d[O]\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u2200r \u2208[R], for .99\u2113FPC choices of j \u2208[\u2113FPC],\n\f\f\f\fO(x,qr\nj) \u2212Ei\u2208S\\T r\u22121 [Fr(i,j)]\n\f\f\f\f \u22641/3\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\u22651 \u2212o(1)\nThe proof is immediate by combining Claim 4.1 and Claim 4.2.\nNext, we argue that in IdealAttack, with high probability FPC.Trace only outputs users\ncontained in the sample S.\nClaim 4.4. If O is computationally e\ufb03cient and (1/12)-accurate for n \u00b7 \u2113FPC(2000n) + 1 adaptively\nchosen queries, then for any polynomial n = n(d), and every su\ufb03ciently large d \u2208N,\nPr\nIdealAttackn,d[O]\nh\n|S \\ T R| > 500\ni\n\u2264o(1)\n19\nProof. Fix any round r \u2208{1,...,|S| \u2212500} and let U = S \\T r\u22121. By the security of the \ufb01ngerprint-\ning code, we have that for every algorithm A\nPr\nFr\u2190RFPC.Gen(1p)\nh\n(A(Fr\nU) \u2208Con(Fr\nU)) \u2227(FPC.Trace(Fr,A(Fr\nU)) < U)\ni\n\u2264negl(n)\nObserve that in IdealAttack, the oracle O is never given any input that depends on rows of\nFr that belong to users outside of U: The queries issued in rounds r\u2032 , r depend only on Fr\u2032,\nwhich is independent from Fr. And in round r the query only depends on ciphertexts cr(i,j)\nfor i < T r\u22121, which are all independent of Fr(i,j) whenever i < U. Therefore we have\nPr\nFr\u2190RFPC.Gen(1p)\nh\n(ar \u2208Con(Fr\nU)) \u2227(FPC.Trace(Fr,ar) < U)\ni\n\u2264negl(n)\n(11)\nBy a union bound over r = 1,...,|S| \u2212500, we also have\nPr\nF1,...,F|S|\u2212500\u2190RFPC.Gen(1p)\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u2203r\n\u0010\nar \u2208Con(Fr\nS\\T r\u22121)\n\u0011\n\u2227\n\u0010\nFPC.Trace(Fr,ar) < S \\ T r\u22121\u0011\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\u2264negl(n)\n(12)\nBy Claim 4.3, we have that with probability at least 1\u2212o(1), it holds that for all r \u2208{1,...,|S| \u2212500}\nand for .99\u2113FPC choices of j \u2208[\u2113FPC]\n\f\f\f\f\far\nj \u2212E\ni\u2208U [Fr(i,j)]\n\f\f\f\f\f \u22641/3\nNote that in order to apply Claim 4.3 we have used the fact that when r \u2208{1,...,|S| \u2212500},\n|S \\ T r\u22121| \u2265500. If this condition is satis\ufb01ed, then indeed ar \u2208Con(Fr\nU). Therefore, combining\nwith (12), we have\nPr\nF1,...,F|S|\u2212500\u2190RFPC.Gen(1p)\nh\n\u2203r,FPC.Trace(Fr,ar) < S \\ T r\u22121i\n\u2264o(1)\nNow the claim follows by observing that\nPr\nIdealAttackn,d[O]\nh\n|S \\ T R| > 500\ni\n\u2264\nPr\nIdealAttackn,d[O]\nh\n\u2203r \u2208{1,...,|S| \u2212500} FPC.Trace(Fr,ar) < S \\ T r\u22121i\n\u2264o(1)\nFinally, we show that if |S\\T R| \u2264500 with high probability in IdealAttack, then |S\\T R| \u2264500\nwith high probability in Attack. Again, we do so by arguing that Attack and IdealAttack are\ncomputationally indistinguishable.\nClaim 4.5. Let Z2 be the event\nn\n|S \\ T R| \u2264500\no\n. Assume (Gen,Enc,Dec) is a computationally secure\nencryption scheme with key length \u2113Enc(\u03bb) = \u03bb and let n = n(d) be any polynomial. Then if O is\ncomputationally e\ufb03cient, for every d \u2208N\n\f\f\f\f\f\f\nPr\nIdealAttackn,d[O][Z2] \u2212\nPr\nAttackn,d[O][Z2]\n\f\f\f\f\f\f \u2264negl(d).\n20\nThe proof follows from the security of the encryption scheme. We defer the details to\nSection A.\nLemma 4.6. If O is computationally e\ufb03cient and (1/12)-accurate for n \u00b7\u2113FPC(2000n)+1 adaptively\nchosen queries, then for any polynomial n = n(d), and every su\ufb03ciently large d \u2208N,\nPr\nAttackn,d[O]\nh\n|S \\ T R| > 500\ni\n= o(1)\nThe proof is immediate by combining Claim 4.4 and Claim 4.5.\n4.4\nAnalysis of the attack phase\nBy the arguments of Section 4.3, we know that if the oracle is computationally e\ufb03cient and\naccurately answers all the queries in the recovery phase, then with high probability |S \\ T R| \u2264\n500. In this section we will show that if these events indeed occur, then the probability that the\noracle answers q\u2217accurately in the attack phase is bounded away from 1 by a constant. Since\nan accurate oracle is required to answer each query accurately with probability at least 1\u2212o(1),\nwe will have obtained a contradiction.\nTo begin with we show that the population answer q\u2217(D) is close to the value \u03c6 in the real\nattack.\nClaim 4.7. For every polynomial n = n(d) and every su\ufb03ciently large d \u2208N, in Attackn,d[O], we\nhave |q\u2217(D) \u2212\u03c6| \u22641/2000.\nProof. The case \u03c6 = 0 we have q\u2217(D) = 0. If \u03c6 = 1/500, then we have that Ei\u2208[p] mi = \u03c6 since\n|B| = \u03c6 \u00b7 p. Hence,\nq\u2217(D) =\nE\n(i,sk)\u223cDq\u2217(i,sk) = \u03c6 \u2212\nPr\ni\u2190R[p]\nh\ni \u2208T R \u2227mi = 1\ni\nwhere Pr\nh\ni \u2208T R \u2227mi = 1\ni\n\u2264Pr\nh\ni \u2208T Ri\n= |T R|/p = (n \u2212500)/p \u22641/2000.\nWe will show that the oracle cannot guess the value of \u03c6 with su\ufb03ciently high probability\nin IdealAttack provided that the recovery phase succeeded.\nClaim 4.8. For every polynomial n = n(d) and every su\ufb03ciently large d \u2208N,\nPr\nIdealAttackn,d[O]\n\u0014\u0010\n|S \\ T R| \u2264500\n\u0011\n\u2227\n\f\f\fO(x,q\u2217) \u2212\u03c6\n\f\f\f \u2264\n1\n2000\n\u0015\n\u22641 \u2212\u2126(1)\nProof. Consider the case where \u03c6 = 1/500. We have\nPr\nh\n\u2200i \u2208S \\ T R, mi = 0\n\f\f\f|S \\ T R| \u2264500\ni\n=\n499\nY\ni=0\n (1 \u2212\u03c6)p \u2212i\np \u2212i\n!\n\u2264\n (1 \u2212\u03c6)p \u2212499\np \u2212499\n!500\n=\n \n1 \u2212\u03c6\np\np \u2212499\n!500\n\u2264(1 \u22122\u03c6)500\n(p \u22652000)\n=\n\u0012\n1 \u2212\n1\n250\n\u0013500\n\u22651\n4e2\n21\nOn the other hand, when \u03c6 = 0, we have\nPr\nh\n\u2200i \u2208S \\ T R, mi = 0\n\f\f\f|S \\ T R| \u2264500\ni\n= 1.\nNote that in IdealAttack the oracle only sees mi for i \u2208S \\ T R. When the oracle sees only that\nmi = 0 for every i \u2208S \\ T R, it cannot give an answer that is simultaneously accurate to within\n1/2000 for both the case of \u03c6 = 0 and for the case of \u03c6 = 1/500. The event mi = 0 for every\ni \u2208S \\T R occurs with at least probability 1/2e as shown above. Conditioned on this event, both\ncases \u03c6 = 0 and \u03c6 = 1/500 have constant probability. Hence, the answer of the oracle must be\nfar from \u03c6 with constant probability. Formally,\nPr\nIdealAttack\n\u0014\f\f\fO(x,q\u2217) \u2212\u03c6\n\f\f\f \u2264\n1\n2000\n\f\f\f\f\f |S \\ T R| \u2264500\n\u0015\n\u22641 \u2212\u2126(1).\nBy Claim 4.4, this implies\nPr\nIdealAttack\n\u0014\u0012\f\f\fO(x,q\u2217) \u2212\u03c6\n\f\f\f \u2264\n1\n2000\n\u0013\n\u2227(|S \\ T R| \u2264500)\n\u0015\n\u22641 \u2212\u2126(1)\n1 \u2212o(1) \u22641 \u2212\u2126(1).\nAs in the analysis of the recovery phase, we will \ufb01rst argue that the probability the oracle\nis accurate for q\u2217in Attack is nearly the same as it is in an IdealAttack where the query q\u2217has\nbeen modi\ufb01ed to contain no information about users outside of S.\nClaim 4.9. Let Z3 be the event\nn\n|S \\ T R| \u2264500 \u2227\n\f\f\fO(x,q\u2217) \u2212\u03c6\n\f\f\f \u2264\n1\n2000\no\n. Let (Gen,Enc,Dec) is a com-\nputationally secure encryption scheme with key length \u2113Enc(\u03bb) = \u03bb and n = n(d) be any polynomial.\nThen if O is computationally e\ufb03cient,\n\f\f\f\f\f\f\nPr\nIdealAttackn,d[O][Z3] \u2212\nPr\nAttackn,d[O][Z3]\n\f\f\f\f\f\f \u2264negl(d)\nThe proof will follow from the security of the encryption scheme. We defer the details to\nSection A.\nLemma 4.10. If O is computationally e\ufb03cient, then for any polynomial n = n(d), and every su\ufb03-\nciently large d \u2208N,\nPr\nAttackn,d[O]\n\u0014\n(|S \\ T R| \u2264500) \u2227|O(x,q\u2217) \u2212q\u2217(D)| \u2264\n1\n2000\n\u0015\n\u22641 \u2212\u2126(1)\nProof. By Claim 4.7, we have that |q\u2217(D) \u2212\u03c6| \u22641/2000. Combining Claim 4.8 with Claim 4.9,\nwe further have\nPr\nAttack\n\u0014\n(|S \\ T R| \u2264500) \u2227\n\f\f\fO(x,q\u2217) \u2212\u03c6\n\f\f\f \u2264\n1\n2000\n\u0015\n\u22641 \u2212\u2126(1).\nThe statement of the lemma now follows from a triangle inequality.\n22\n4.5\nPutting it together\nWe can now prove Theorem 1.1 from the introduction.\nTheorem 4.11. There is no computationally e\ufb03cient oracle O that is (1/2000)-accurate for n3+o(1)\nadaptively chosen queries given n samples.\nProof. The entire attack will consist of k = R \u00b7 \u2113FPC + 1 queries, where R = n \u2212500 and \u2113FPC =\n\u02dcO(p2) = \u02dcO(n2). Therefore the entire attack consists of k = n3+o(1) queries.\nTherefore, if O, by Lemma 4.6,\nPr\nAttackn,d[O]\nh\n|S \\ T R| > 500\ni\n= on(1)\nBy Lemma 4.10,\nPr\nAttackn,d[O]\n\u0014\n(|S \\ T R| \u2264500) \u2227|O(x,q\u2217) \u2212q\u2217(D)| \u2264\n1\n2000\n\u0015\n\u22641 \u2212\u2126(1)\nCombining these two statements gives\nPr\nAttackn,d[O]\n\u0014\n|O(x,q\u2217) \u2212q\u2217(D)| \u2264\n1\n2000\n\u0015\n\u22641 \u2212\u2126(1)\nHowever, the de\ufb01nition of an accurate oracle asserts, in particular, that\nPr\nAttackn,d[O]\n\u0014\n|O(x,q\u2217) \u2212q\u2217(D)| \u2264\n1\n2000\n\u0015\n\u22651 \u2212o(1)\nand thereby we obtain a contradiction.\n4.6\nAn information-theoretic lower bound\nIn this section we show how our argument can be extended to give an information-theoretic\nlower bound when the number of samples is much smaller than the dimensionality of the data\n(Theorem 1.2). Since the argument follows the outline of the computational hardness result\nquite closely, we only highlight the parts of the proof that need modi\ufb01cation. The assump-\ntion that the oracle is computationally e\ufb03cient was used only to establish that Attackn,d[O]\nand IdealAttackn,d[O] are indistinguishable (Claims 4.2, 4.5, and 4.9). The argument (proven\nin Section A) relies on two facts: 1) that no adversary who runs in time poly(\u03bb) can distin-\nguish between an oracle that returns encryptions of chosen messages m1,...,mk and an oracle\nthat returns encryptions of 0, and 2) there is a secure encryption scheme with keys of length\n\u2113Enc(\u03bb) = \u03bb, therefore if n(d) is polynomial, Attackn,d[O] will instantiate the encryption with\nsecurity parameter \u03bb = \u2126(d).\nIn order to prove an analogous information-theoretic statement, we \ufb01rst observe that the\nnumber of messages that will be encrypted during the execution of Attackn,d[O] is at most\nk = \u02dcO(n3), and the encryption scheme only needs to be secure for k single-bit messages. For any\nnumber of single-bit messages k, there exists an encryption scheme that is secure for k messages\nwith key length \u2113Enc(\u03bb,k) = k (namely, the classic \u201cone-time pad\u201d encryption scheme). There-\nfore, if we choose d \u2265k +\u2308logp\u2309= \u02dcO(n3), we can instantiate Attackn,d[O] using the information-\ntheoretically secure encryption scheme. This will su\ufb03ce to prove an information-theoretic\nanalogue of Claims 4.2, 4.5, and 4.9, which combined with the remaining arguments of Sec-\ntions 4.3 and 4.4, yields Theorem 1.2 in the introduction. Formally,\n23\nTheorem 4.12. There is no oracle O that for every n \u2208N is (1/2000,on(1))-accurate for n3+o(1)\nadaptively chosen queries given n samples in {0,1}d for d = d(n) = n3+o(1).\n5\nLower bounds for avoiding blatant non-privacy\nIn this section we show how our arguments also imply that computationally e\ufb03cient oracles\nthat guarantee accuracy for adaptively chosen statistical queries must be blatantly non-private,\nand thereby establish Theorem 1.3 in the introduction.\n5.1\nBlatant non-privacy\nBefore we can de\ufb01ne blatant non-privacy, we need to de\ufb01ne a notion of accuracy that is more\nappropriate for the application to privacy. In contrast to De\ufb01nition 2.1 where accuracy is de-\n\ufb01ned with respect to the distribution, here we de\ufb01ne accurate with respect to the sample itself.\nWith this change in mind, we model blatant non-privacy via the following game.\nApriv chooses a set y = {y1,...,y2n} \u2286{0,1}d\nSample a random subset x \u2286y of size n\nFor j = 1,...,k\nA(q1,a1,...,qj\u22121,aj\u22121) outputs a query qj\nO(x,qj) outputs aj\nApriv outputs a set x\u2032 \u2286y\nFigure 6: NonPrivacyn,d[O,Apriv]\nDe\ufb01nition 5.1. An oracle O is (\u03b1,\u03b2)-sample-accurate for k adaptively chosen queries given n sam-\nples in {0,1}d if for every adversary Apriv,\nPr\nNonPrivacyn,d,k[O,Apriv]\nh\n\u2200j \u2208[k]\n\f\f\fO(x,qj) \u2212qj(x)\n\f\f\f \u2264\u03b1\ni\n\u22651 \u2212\u03b2 .\nAs a shorthand, we will say that O is \u03b1-sample-accurate for k queries if for every n,d \u2208N, O is\n(\u03b1,on(1))-accurate for k queries given n samples in {0,1}d. Here, k may depend on n and d and\non(1) is a function of n that tends to 0.\nDe\ufb01nition 5.2. Giving \u03b1-accurate answers to k adaptively chosen queries is blatantly non-private\nfor e\ufb03cient oracles if there exists an adversary Apriv such that for every oracle O that is compu-\ntationally e\ufb03cient and \u03b1-sample-accurate for k adaptively chosen queries,\nPr\nNonPrivacyn,d,k[O,Apriv]\n\u0002|x\u25b3x\u2032| > n/100\u0003 \u2264on(1)\nIf the conclusion holds even for computationally ine\ufb03cient oracles then we replace \u201cfor\ne\ufb03cient oracles\u201d with \u201cfor unbounded oracles\u201d in the de\ufb01nition.\n24\n5.2\nLower bounds\nIn this section we show the following theorem\nTheorem 5.3. Giving accurate answers to n3+o(1) adaptively chosen queries is blatantly non-private\nfor computationally e\ufb03cient oracles.\nWe establish this theorem via an adversary that essentially performs only the reconstruction\nphase of Attack. The adversary is described in Figure 7. Observe that in Attack, we have\nalready established that there is an adversary that recovers a set T R such that |T R\u25b3x| \u2264500\nwhen x is drawn from a distribution D and O gives accurate answers for the distribution D.\nThe key di\ufb00erence between that guarantee and the one we must establish, is that here we want\nto establish blatant non-privacy when the oracle is accurate for the sample. However, this can\nbe addressed via a fairly simple modi\ufb01cation to the argument.\nThe set y:\nGiven parameters d,n, let R = .99n\nLet \u03bb be the largest integer such that \u2113Enc(\u03bb) + \u2308log2n\u2309\u2264d\nFor i \u2208[2n], let ski \u2190R Gen(1\u03bb) and let yi = (i,ski)\nChoose a subsample x \u2286y of size n\nRecovery phase:\nSetup \ufb01ngerprinting codes and ciphertexts:\nLet F1,...,FR \u2190R FPC.Gen(12n), let \u2113FPC = \u2113FPC(2n) be code length\nFor r = 1,...,R, i = 1,...,2n, j = 1,...,\u2113FPC, let cr(i,j) = Enc(ski,Fr(i,j))\nLet T 0 = \u2205\nFor round r = 1,...,R:\nFor j = 1,...,\u2113FPC :\nDe\ufb01ne the query qr\nj(i\u2032,sk\u2032) to be Dec(sk\u2032,cr(i\u2032,j)) if i\u2032 < T r\u22121 and 0 otherwise\nLet ar\nj = O(x;qr\nj)\nLet ar =\n\u0010 n\nn\u2212r\n\u0011\n(ar\n1,...,ar\n\u2113FPC)\nLet ir = FPC.Trace(Fr,ar), and let T r = T r\u22121 \u222a{ir}\nFigure 7: PrivacyAttackn,d[O]\nAs before, we introduce a related \u201cideal attack\u201d for which we can show recovery succeeds.\nClaim 5.4. For every oracle O, and every n,d \u2208N\nPr\nIdealPrivacyAttackn,d[O]\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u0012\n\u2200j \u2208[\u2113FPC],r \u2208[R]\n\f\f\f\far\nj \u2212qr\nj(x)\n\f\f\f\f \u22641/300\n\u0013\n\u2227(|x \\ T R| > .01n)\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\u2264negl(n)\nProof. Fix any round r = 1,...,R, let U = x \\ T r\u22121. We will show that\nPr\nFr\u2190RFPC.Gen(12n)\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u0012\n\u2200j \u2208[\u2113FPC]\n\f\f\f\far\nj \u2212qr\nj(x)\n\f\f\f\f \u22641/300\n\u0013\n\u2227(ir < U) \u2227(\u2200r\u2032 < r, ir\u2032 \u2208x \\ T r\u2032\u22121)\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\u2264negl(n)\n25\nThe set y:\nGiven parameters d,n, let R = .99n\nLet \u03bb be the largest integer such that \u2113Enc(\u03bb) + \u2308log2n\u2309\u2264d\nFor i \u2208[2n], let ski \u2190R Gen(1\u03bb) and let yi = (i,ski)\nChoose a subsample x \u2286y of size n\nRecovery phase:\nSetup \ufb01ngerprinting codes and ciphertexts:\nLet F1,...,FR \u2190R FPC.Gen(12n), let \u2113FPC = \u2113FPC(2n) be code length\nFor r = 1,...,R, i \u2208x, j = 1,...,\u2113FPC, let cr(i,j) = Enc(ski,Fr(i,j))\nFor r = 1,...,R, i < x, j = 1,...,\u2113FPC, let cr(i,j) = Enc(ski,0)\nLet T 0 = \u2205\nFor round r = 1,...,R:\nFor j = 1,...,\u2113FPC :\nDe\ufb01ne the query qr\nj(i\u2032,sk\u2032) to be Dec(sk\u2032,cr(i\u2032,j)) if i\u2032 < T r\u22121 and 0 otherwise\nLet ar\nj = O(x;qr\nj)\nLet ar =\n\u0010 n\nn\u2212r\n\u0011\n(ar\n1,...,ar\n\u2113FPC)\nLet ir = FPC.Trace(Fr,ar), and let T r = T r\u22121 \u222a{ir}\nFigure 8: IdealPrivacyAttackn,d[O]\nBy the security of the \ufb01ngerprinting code, we have that for every U \u2286[2n] and every algorithm\nA, if ar \u2190R A(FU), then\nPr\nFr\u2190RFPC.Gen(12n)\nh\n(ar \u2208Con(Fr\nU) \u2227(FPC.Trace(Fr,ar) < U)\ni\n\u2264negl(n)\nNow we need to show that\n\u0010\n\u2200r\u2032 < r, ir\u2032 \u2208x \\ T r\u2032\u22121\u0011\n\u2227(\u2200j \u2208[\u2113FPC]|ar\nj \u2212qr\nj(x)| \u22641/300) =\u21d2ar \u2208Con(Fr\nU)\n(13)\nObserve that, by construction\nqr\nj(x) = 1\nn\nX\ni\u2208x\nDec(ski,cr\nj)\n= 1\nn\nX\ni\u2208U\nDec(ski,Enc(ski,Fr(i,j))) + 1\nn\nX\ni<U\nDec(ski,Enc(ski,0))\n= 1\nn\nX\ni\u2208U\nFr(i,j)\n(14)\nObserve that if\n\f\f\f\far\nj \u2212qr\nj(x)\n\f\f\f\f \u22641/300 and for every r\u2032 < r, ir\u2032 \u2208x \\ T r\u2032\u22121, then |T r| = r and |U| =\n26\n|x \\ T r| = n \u2212r. In this case, we have\n\f\f\f\f\f\f\f\n\u0012\nn\nn \u2212r\n\u0013\nar\nj \u22121\n|U|\nX\ni\u2208U\nFr(i,j)\n\f\f\f\f\f\f\f\n\u2264\n\f\f\f\f\f\f\f\n\u0012 n\n|U|\n\u0013\nqr\nj \u22121\n|U|\nX\ni\u2208U\nFr(i,j)\n\f\f\f\f\f\f\f\n+\n\u0012\nn\nn \u2212r\n\u0013\u0012 1\n300\n\u0013\n=\n\u0012\nn\nn \u2212r\n\u0013\u0012 1\n300\n\u0013\n(14)\n\u22641\n3\n(r \u2264.99n)\nSo we conclude that if ar\n1,...,ar\n\u2113FPC are accurate to within 1/300, and for every r\u2032 < r, ir\u2032 \u2208x\\T r\u2032\u22121,\nthen ar =\n\u0010 n\nn\u2212r\n\u0011\n(ar\n1,...,ar\n\u2113FPC) is contained in Con(Fr\nU), which is precisely (13). Combining (13)\nwith the security of the \ufb01ngerprinting code, we have\nPr\nFr\u2190RFPC.Gen(12n)\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u0012\n\u2200j \u2208[\u2113FPC]\n\f\f\f\far\nj \u2212qr\nj(x)\n\f\f\f\f \u22641/300\n\u0013\n\u2227(ir < U) \u2227(\u2200r\u2032 < r, ir\u2032 \u2208x \\ T r\u2032\u22121)\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\u2264negl(n)\nas desired.\nTo conclude the proof, we observe that\nPr\nIdealPrivacyAttackn,d[O]\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u0012\n\u2200j \u2208[\u2113FPC],r \u2208[R]\n\f\f\f\far\nj \u2212qr\nj(x)\n\f\f\f\f \u22641/300\n\u0013\n\u2227(|x \\ T R| > .01n)\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\u2264negl(n)\n=\nPr\nIdealPrivacyAttackn,d[O]\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u0012\n\u2200j \u2208[\u2113FPC],r \u2208[R]\n\f\f\f\far\nj \u2212qr\nj(x)\n\f\f\f\f \u22641/300\n\u0013\n\u2227(\u2200r \u2208[R] ir \u2208x \\ T r\u22121)\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\u2264negl(n)\n\u2264\nPr\nFr\u2190RFPC.Gen(12n)\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u0012\n\u2200j \u2208[\u2113FPC]\n\f\f\f\far\nj \u2212qr\nj(x)\n\f\f\f\f \u22641/300\n\u0013\n\u2227(ir < U) \u2227(\u2200r\u2032 < r, ir\u2032 \u2208x \\ T r\u2032\u22121)\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n\u2264R \u00b7 negl(n) \u2264negl(n)\nAs we did in proving the lower bounds for answering adaptively chosen statistical queries,\nwe now claim that PrivacyAttack and IdealPrivacyAttack are computationally indistinguish-\nable\nClaim 5.5. Let Z be the event\n\u0012\n\u2200j \u2208[\u2113FPC],r \u2208[R]\n\f\f\f\far\nj \u2212qj(x)\n\f\f\f\f \u22641/300\n\u0013\n\u2227\n\u0010\n|x \\ T R| > .01n\n\u0011\nLet (Gen,Enc,Dec) is a computationally secure encryption scheme with key length \u2113Enc(\u03bb) = \u03bb and\nn = n(d) be any polynomial. Then if O is computationally e\ufb03cient,\n\f\f\f\f\f\f\nPr\nPrivacyAttackn,d[O][Z] \u2212\nPr\nIdealPrivacyAttackn,d[O][Z]\n\f\f\f\f\f\f = negl(d)\n27\nThe analysis is essentially identical to what was shown in the proof of the lower bounds for\nanswering adaptively chosen statistical queries, so we omit the proof.\nWe can now combine these two claims to prove Theorem 5.3\nProof of Theorem 5.3. By combining Claim 5.4 and 5.5, we have\nPr\nPrivacyAttackn,d[O]\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\u0012\n\u2200j \u2208[\u2113FPC],r \u2208[R]\n\f\f\f\far\nj \u2212qj(x)\n\f\f\f\f \u22641/300\n\u0013\n\u2227(|x \\ T R| > .01n)\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\u2264negl(n)\nIf O is \u03b1-accurate, then\nPr\nPrivacyAttackn,d[O]\n\u0014\n\u2200j \u2208[\u2113FPC],r \u2208[R]\n\f\f\f\far\nj \u2212qj(x)\n\f\f\f\f \u22641/300\n\u0015\n\u22651 \u2212on(1)\ntherefore\nPr\nPrivacyAttackn,d[O]\nh\n|x \\ T R| > .01n\ni\n\u22651 \u2212on(1)\nSince |x \\ T R| \u2264.01n, and |T R| \u2264.99n implies |T R\u25b3x| \u2264.01n, we have\nPr\nPrivacyAttackn,d[O]\nh\n|T R\u25b3x| > .01n\ni\n\u2264on(1)\nThis completes the proof.\nAs we did in Section 4.6, we can prove an information-theoretic analogue of our hardness\nresult for avoiding blatant non-privacy.\nTheorem 5.6. Giving accurate answers to n3+o(1) adaptively chosen queries on n samples of dimen-\nsion d = n3+o(1) is blatantly non-private for unbounded oracles.\nThe proof is essentially identical to what is sketched in Section 4.6.\nReferences\n[BE02]\nOlivier Bousquet and Andr\u00b4e Elissee\ufb00. Stability and generalization. Journal of Ma-\nchine Learning Research, 2:499\u2013526, 2002.\n[BH95]\nYoav Benjamini and Yosef Hochberg. Controlling the false discovery rate: a practi-\ncal and powerful approach to multiple testing. Journal of the Royal Statistical Society.\nSeries B (Methodological), 57(1):289\u2013300, 1995.\n[BS98]\nDan Boneh and James Shaw. Collusion-secure \ufb01ngerprinting for digital data. IEEE\nTransactions on Information Theory, 44(5):1897\u20131905, 1998.\n[BUV14]\nMark Bun, Jonathan Ullman, and Salil P. Vadhan. Fingerprinting codes and the\nprice of approximate di\ufb00erential privacy. In STOC, pages 1\u201310. ACM, May 31 \u2013\nJune 3 2014.\n[CFN94]\nBenny Chor, Amos Fiat, and Moni Naor. Tracing traitors. In Yvo Desmedt, editor,\nCRYPTO, volume 839 of Lecture Notes in Computer Science, pages 257\u2013270. Springer,\n1994.\n28\n[DFH+14] Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold,\nand Aaron Roth. Guilt-free data exploration (tentative title). Manuscript, 2014.\n[DMNS06] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.\nCalibrating\nnoise to sensitivity in private data analysis. In Shai Halevi and Tal Rabin, editors,\nTCC, volume 3876 of Lecture Notes in Computer Science, pages 265\u2013284. Springer,\n2006.\n[DNR+09] Cynthia Dwork, Moni Naor, Omer Reingold, Guy N. Rothblum, and Salil P. Vadhan.\nOn the complexity of di\ufb00erentially private data release: e\ufb03cient algorithms and\nhardness results. In Michael Mitzenmacher, editor, STOC, pages 381\u2013390. ACM,\n2009.\n[HR10]\nMoritz Hardt and Guy Rothblum. A multiplicative weights mechanism for privacy-\npreserving data analysis.\nIn Proc. 51st Foundations of Computer Science (FOCS),\npages 61\u201370. IEEE, 2010.\n[HW13]\nMoritz Hardt and David P. Woodru\ufb00. How robust are linear sketches to adaptive\ninputs?\nIn Dan Boneh, Tim Roughgarden, and Joan Feigenbaum, editors, STOC,\npages 121\u2013130. ACM, 2013.\n[Kea93]\nMichael J. Kearns. E\ufb03cient noise-tolerant learning from statistical queries. In S. Rao\nKosaraju, David S. Johnson, and Alok Aggarwal, editors, STOC, pages 392\u2013401.\nACM, 1993.\n[RR10]\nAaron Roth and Tim Roughgarden. Interactive privacy via the median mechanism.\nIn Proc. 42nd Symposium on Theory of Computing (STOC), pages 765\u2013774. ACM,\n2010.\n[Tar08]\nG\u00b4abor Tardos. Optimal probabilistic \ufb01ngerprint codes. J. ACM, 55(2), 2008.\n[Ull13]\nJonathan Ullman. Answering n2+o(1) counting queries with di\ufb00erential privacy is\nhard. In Dan Boneh, Tim Roughgarden, and Joan Feigenbaum, editors, STOC, pages\n361\u2013370. ACM, 2013.\nA\nSecurity reductions from Section 4\nIn Sections 4.3 and 4.4 we made several claims comparing the probability of events in Attack to\nthe probability of events in IdealAttack. Each of these claims follow from the assumed security\nof the encryption scheme. In this section we restate and prove these claims. Since the claims\nare all of a similar nature, the proof will be somewhat modular.\nBefore we begin recall the formal de\ufb01nition of security of an encryption scheme. Security\nis de\ufb01ned via a pair of oracles E0 and E1. E1(sk1,...,skp,\u00b7) takes as input the index of a key\ni \u2208[p] and a message m and returns Enc(ski,m), whereas E0(sk1,...,skp,\u00b7) takes the same input\nbut returns Enc(ski,0). The security of the encryption scheme asserts that for randomly chosen\nsecret keys, no computationally e\ufb03cient adversary can tell whether or not it is interacting with\nE0 or E1.\n29\nDe\ufb01nition A.1. An encryption scheme (Gen,Enc,Dec) is secure if for every polynomial p = p(\u03bb),\nand every poly(\u03bb)-time adversary B, if sk1,...,skp \u2190R Gen(1\u03bb)\n\f\f\f\fPr\nh\nBE0(sk1,...,skp,\u00b7) = 1\ni\n\u2212Pr\nh\nBE1(sk1,...,skp,\u00b7) = 1\ni\f\f\f\f = negl(\u03bb)\nClaim A.2 (Claim 4.2 Restated). Let Z1 be the event\n\u2200r \u2208[R], for .99\u2113FPC choices of j \u2208[\u2113FPC],\n\f\f\f\f\fO(x,qr\nj) \u2212\nE\ni\u2208S\\T r\u22121 [Fr(i,j)]\n\f\f\f\f\f \u22641/3\nLet (Gen,Enc,Dec) is a computationally secure encryption scheme with key length \u2113Enc(\u03bb) = \u03bb and\nn = n(d) be any polynomial. Then if O is computationally e\ufb03cient,\n\f\f\f\f\f\f\nPr\nIdealAttackn,d[O][Z1] \u2212\nPr\nAttackn,d[O][Z1]\n\f\f\f\f\f\f \u2264negl(d)\nClaim A.3 (Claim 4.5 Restated). Let Z2 be the event\nn\n|S \\ T R| \u2264500\no\nLet (Gen,Enc,Dec) is a com-\nputationally secure encryption scheme with key length \u2113Enc(\u03bb) = \u03bb and n = n(d) be any polynomial.\nThen if O is computationally e\ufb03cient,\n\f\f\f\f\f\f\nPr\nIdealAttackn,d[O][Z2] \u2212\nPr\nAttackn,d[O][Z2]\n\f\f\f\f\f\f \u2264negl(d)\nClaim A.4 (Claim 4.9 Restated). Let Z3 be the event\n(|S \\ T R| \u2264500) \u2227|O(x,q\u2217) \u2212q\u2217(D)| \u2264\n1\n2000\nLet (Gen,Enc,Dec) is a computationally secure encryption scheme with key length \u2113Enc(\u03bb) = \u03bb and\nn = n(d) be any polynomial. Then if O is computationally e\ufb03cient,\n\f\f\f\f\f\f\nPr\nIdealAttackn,d[O][Z3] \u2212\nPr\nAttackn,d[O][Z3]\n\f\f\f\f\f\f \u2264negl(d)\nTo prove each of these claims c \u2208{1,2,3}, we construct an adversary Bc that will attempt to\nuse O to break the security of the encryption. We construct Bc in such a way that its advan-\ntage in breaking the security of encryption is precisely the di\ufb00erence in the probability of the\nevent Zc between Attack and IdealAttack, which implies that the di\ufb00erence in probabilities is\nnegligible. The simulator is given in Figure 9\nProof of Claims A.2, A.3, A.4. First, observe that for c \u2208{1,2,3}, Bc is computationally e\ufb03cient\nas long as FPC.Gen,FPC.Trace, and O are all computationally e\ufb03cient. E\ufb03ciency of FPC.Gen\nand FPC.Trace will be satis\ufb01ed by the construction in Theorem 2.3 and e\ufb03ciency of O is by\nassumption of the claim. Also notice B can determine whether Zc has occurred e\ufb03ciently.\nNow we observe that when the oracle is E1 (the oracle that takes as input i and m and returns\nEnc(ski,m)), and sk1,...,skp are chosen randomly from Gen(1\u03bb), then the view of the oracle is\nidentical to Attackn,d[O]. Speci\ufb01cally, the oracle holds a random sample of pairs (i,ski) and\nis shown queries that are encryptions either under keys it knows or random unknown keys.\nMoreover, the messages being encrypted are chosen from the same distribution. On the other\n30\nSimulate constructing and sampling from D:\nGiven parameters d,n, let p = 2000n, let R = n \u2212500\nLet \u03bb be the largest integer such that \u2113Enc(\u03bb) + \u2308logp\u2309\u2264d\nSample users u1,...,un \u2190R [p], let S be the set of unique users in the sample\nChoose new keys ski \u2190R Gen(1\u03bb) for i \u2208S\nFor i \u2208n, let xi = (ui,skui), let x = (x1,...,xn)\nSimulate the recovery phase:\nSetup \ufb01ngerprinting codes and ciphertexts:\nLet F1,...,FR \u2190R FPC.Gen(1p), let \u2113FPC = \u2113FPC(p) be code length\nFor r = 1,...,R, i = 1,...,p, j = 1,...,\u2113FPC\nIf i \u2208S let cr(i,j) = Enc(ski,Fr(i,j)), otherwise ask E for an encryption\nof Fr(i,j) under key ski, that is cr(i,j) = Eb(sk1,...,skp,i,Fr(i,j))\nLet T 0 = \u2205. For round r = 1,...,R:\nFor j = 1,...,\u2113FPC :\nDe\ufb01ne the query qr\nj(i\u2032,sk\u2032) to be Dec(sk\u2032,cr(i\u2032,j)) if i\u2032 < T r\u22121 and 0 otherwise\nLet ar\nj = O(x;qr\nj)\nLet ar = (ar\n1,...,ar\n\u2113FPC), let ir = FPC.Trace(Fr,ar), and let T r = T r\u22121 \u222a{ir}\nAttack phase:\nLet \u03c6 = 0 with probability 1/2 and \u03c6 = 1/500 with probability 1/2\nSample a random subset B \u2286[p] of size \u03c6 \u00b7 p.\nLet mi = 1 for all i \u2208B and 0 for all i \u2208[p] \\ B\nFor each i \u2208S, let c\u2217\ni = Enc(ski,mi), for each i \u2208[p] \\ S, ask E for an encryption\nof mi under key ski, that is c\u2217\ni = Eb(sk1,...,skp,i,mi)\nDe\ufb01ne the query q\u2217(i\u2032,sk\u2032) to be Dec(sk\u2032,c\u2217\ni\u2032) if i\u2032 < T R and 0 otherwise\nLet a\u2217= O(x,q\u2217)\nOutput 1 if and only if the event Zc occurs\nFigure 9: B\nEb(sk1,...,skp,\u00b7)\nc,n,d\nhand, when the oracle is E0 (the oracle that takes as input i and c and returns Enc(ski,0)), then\nthe view of the oracle is identical to Attackn,d[O]. Thus we have that for c \u2208{1,2,3},\n\f\f\f\f\f\f\nPr\nIdealAttackn,d[O][Zc] \u2212\nPr\nAttackn,d[O][Zc]\n\f\f\f\f\f\f\n=\n\f\f\f\f\f\f\f\nPr\nsk1,...,skp\u2190RGen(1\u03bb)\n\"\nB\nE0(sk1,...,skp,\u00b7)\nc,n,d\n= 1\n#\n\u2212\nPr\nsk1,...,skp\u2190RGen(1\u03bb)\n\"\nB\nE1(sk1,...,skp,\u00b7)\nc,n,d\n= 1\n#\f\f\f\f\f\f\f\n= negl(\u03bb) = negl(d)\nThe last equality holds because we have chosen p = 2000n(d) = poly(d), and therefore we have\n\u03bb = d \u2212\u2308logp\u2309= d \u2212O(logd). This completes the proof of all three claims.\n31\n",
        "sentence": " Recent work on privacy-preserving machine learning has considered how datamining competitions such as Kaggle could potentially be \u201chacked\u201d, either intentionally or inadvertently, by using information from an oracle that reports a classifier\u2019s accuracy on the test set (Blum and Hardt, 2015; Hardt and Ullman, 2014; Zheng, 2015; Whitehill, 2016). Related work: Over the past few years there has been growing theoretical and practical interest in the statistical validity of scientific results that are obtained from adaptive data analyses, in which the results of one experiment inform the design of the next (Dwork et al., 2015; Hardt and Ullman, 2014).",
        "context": "ceeds even when the oracle is blatantly non-private. In the setting of false discovery, we de\ufb01ne\naccuracy with respect to the underlying distribution and show that achieving this notion of\naccuracy is hard for the oracle.\nOur work builds on a close connection to the problem of designing privacy-preserving oracles.\nHere, the goal is to provide answers to statistical queries in such a way that the analyst does\nsketches. However, their work also noted the connection between di\ufb00erential privacy and\nvalidly answering adaptively chosen queries. On the technical side, our iterative approach\nwas inspired by their results."
    },
    {
        "title": "An examination of data confidentiality and disclosure issues related to publication of empirical roc curves",
        "author": [
            "G.J. Matthews",
            "O. Harel"
        ],
        "venue": "Academic radiology 20(7):889\u2013896.",
        "citeRegEx": "Matthews and Harel,? 2013",
        "shortCiteRegEx": "Matthews and Harel",
        "year": 2013,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": "",
        "context": null
    },
    {
        "title": "Differentially private algorithms for empirical machine learning",
        "author": [
            "B. Stoddard",
            "Y. Chen",
            "A. Machanavajjhala"
        ],
        "venue": "CoRR abs/1411.5428.",
        "citeRegEx": "Stoddard et al\\.,? 2014",
        "shortCiteRegEx": "Stoddard et al\\.",
        "year": 2014,
        "abstract": "An important use of private data is to build machine learning classifiers.\nWhile there is a burgeoning literature on differentially private classification\nalgorithms, we find that they are not practical in real applications due to two\nreasons. First, existing differentially private classifiers provide poor\naccuracy on real world datasets. Second, there is no known differentially\nprivate algorithm for empirically evaluating the private classifier on a\nprivate test dataset.\n  In this paper, we develop differentially private algorithms that mirror real\nworld empirical machine learning workflows. We consider the private classifier\ntraining algorithm as a blackbox. We present private algorithms for selecting\nfeatures that are input to the classifier. Though adding a preprocessing step\ntakes away some of the privacy budget from the actual classification process\n(thus potentially making it noisier and less accurate), we show that our novel\npreprocessing techniques significantly increase classifier accuracy on three\nreal-world datasets. We also present the first private algorithms for\nempirically constructing receiver operating characteristic (ROC) curves on a\nprivate test set.",
        "full_text": "arXiv:1411.5428v2  [cs.LG]  21 Nov 2014\nDifferentially Private Algorithms for Empirical Machine\nLearning\nBen Stoddard\nDuke University\nstodds@cs.duke.edu\nYan Chen\nDuke University\nyanchen@cs.duke.edu\nAshwin Machanavajjhala\nDuke University\nashwin@cs.duke.edu\nABSTRACT\nAn important use of private data is to build machine learning classi-\n\ufb01ers. While there is a burgeoning literature on differentially private\nclassi\ufb01cation algorithms, we \ufb01nd that they are not practical in real\napplications due to two reasons. First, existing differentially private\nclassi\ufb01ers provide poor accuracy on real world datasets. Second,\nthere is no known differentially private algorithm for empirically\nevaluating the private classi\ufb01er on a private test dataset.\nIn this paper, we develop differentially private algorithms that\nmirror real world empirical machine learning work\ufb02ows. We con-\nsider the private classi\ufb01er training algorithm as a blackbox. We\npresent private algorithms for selecting features that are input to\nthe classi\ufb01er. Though adding a preprocessing step takes away some\nof the privacy budget from the actual classi\ufb01cation process (thus\npotentially making it noisier and less accurate), we show that our\nnovel preprocessing techniques sign\ufb01cantly increase classi\ufb01er ac-\ncuracy on three real-world datasets. We also present the \ufb01rst private\nalgorithms for empirically constructing receiver operating charac-\nteristic (ROC) curves on a private test set.\n1.\nINTRODUCTION\nOrganizations, like statistical agencies, hospitals and internet com-\npanies, collect ever increasing amounts of information from indi-\nviduals with the hope of gleaning valuable insights from this data.\nThe promise of effectively utilizing such \u2018big-data\u2019 has been real-\nized in part due to the success of off-the-shelf machine learning\nalgorithms, especially supervised classi\ufb01ers [3]. As the name sug-\ngests, a classi\ufb01er assigns to a new observation (e.g., an individual,\nan email, etc.) a class chosen from a set of two or more class la-\nbels (e.g., spam/ham, healthy/sick, etc.), based on training exam-\nples with known class membership. However, when classi\ufb01ers are\ntrained on datasets containing sensitive information, ensuring that\nthe training algorithm and the output classi\ufb01er does not leak sensi-\ntive information in the data is important. For instance, Fredrikson\net al [8] proposed a model inversion attack using which properties\n(genotype) of individuals in the training dataset can be learnt from\nlinear regression models built on private medical data.\nTo address this concern, recent work has focused on develop-\ning private classi\ufb01er training algorithms that ensure a strong notion\nof privacy called \u01eb-differential privacy [6] \u2013 the classi\ufb01er output\nby a differentially private training algorithm does not signi\ufb01cantly\nchange due to the insertion or deletion of any one training example.\nDifferentially private algorithms have been developed for training\nNaive Bayes classi\ufb01ers [25], logistic regression [2], support vector\nmachines [23] and decision trees [9]. All of these techniques work\nby infusing noise into the training process.\nDespite the burgeoning literature in differentially private classi\ufb01-\ncation, their adoption by practitioners in the industry or government\nagencies has been startlingly rare. We believe there are two impor-\ntant contributing factors. First, we observe that (see experiments\nin Section 5) an off-the-shelf private classi\ufb01er training algorithm,\nwhen running on real datasets, often results in classi\ufb01ers with mis-\nclassi\ufb01cation rates that are signi\ufb01cantly higher than that output by\na non-private training algorithm. In fact, Fredrikson et al [8] also\nshow that differentially private algorithms for the related problem\nof linear regression result in unacceptable error when applied to\nreal medical datasets.\nSecond, the state-of-the-art private classi\ufb01cation algorithms do\nnot support typical classi\ufb01cation work\ufb02ows. In particular, real datasets\nusually have many features that are of little to no predictive value,\nand feature selection techniques [5] are used to identify the predic-\ntive subset of features. To date there are no differentially private\nfeature selection techniques.\nMoreover, empirical machine learning work\ufb02ows perform model\ndiagnostics on a test set that is disjoint from the training set. These\ndiagnostics quantify trained classi\ufb01er\u2019s prediction accuracy on un-\nseen data. Since the unseen data must be drawn from the same\ndistribution as the training dataset, the classi\ufb01er is usually trained\non a part of the dataset, and tested on the rest of the dataset. Since\nwe assume the training dataset is private, the test dataset used for\nevaluating the classi\ufb01er\u2019s prediction accuracy is also private.\nA typical diagnostic for measuring the prediction accuracy of a\nbinary classi\ufb01er (i.e., two classes) is the receiver operating charac-\nteristic (ROC) curve. Recent work [19] has shown that releasing an\nROC curve computed on a private test set can leak sensitive infor-\nmation to an adversary with access to certain properties of the test\ndataset. Currently, there is no known method to privately evaluate\nthe prediction accuracy of a classi\ufb01er on a private test dataset.\nContributions: This paper addresses the aforementioned short-\ncomings of the current state-of-the-art in differentially private clas-\nsi\ufb01cation. We consider the differentially private classi\ufb01cation algo-\nrithms as a black box in order to ensure that (a) our algorithms are\nclassi\ufb01er agnostic, and (b) a privacy non-expert can use our algo-\nrithms without any knowledge of how a private classi\ufb01er works.\nFirst, we develop a suite of differentially private feature selection\n1\ntechniques based on (a) perturbing predictive scores of individual\nfeatures, (b) clustering features and (c) a novel method called pri-\nvate threshold testing (which may be of independent interest with\napplications to other problems). In non-private work\ufb02ows, training\na classi\ufb01er on a subset of predictive features helps reduce the vari-\nance in the data and thus results in more accurate classi\ufb01ers. With\nmulti-step differentially private work\ufb02ows, either each step of the\nwork\ufb02ow should work with a different subset of the data, or more\nnoise must be infused in each step of the work\ufb02ow. Thus it is not\nnecessarily obvious that a work\ufb02ow constituting private feature se-\nlection followed by private classi\ufb01cation should improve accuracy\nover a work\ufb02ow that executes a private classi\ufb01er on the original\ndata. Nevertheless, we show on real datasets and with two differ-\nentially private classi\ufb01ers (Naive Bayes [25] and logistic regression\n[2]) that private feature selection indeed leads to signi\ufb01cant im-\nprovement in the classi\ufb01ers prediction accuracy. In certain cases,\nour differentially private algorithms are able to achieve accuracies\nattained by non-private classi\ufb01ers.\nSecond, we develop novel algorithms for constructing the ROC\ncurve given a classi\ufb01er and a private test set. An ROC curve is con-\nstructed by computing the true and false positive rates on different\nsubsets of the data. In the non-private case, typically t subsets are\nchosen, where t is the size of the test dataset. The main issue is\nthat these subsets of the test dataset are overlapping and, hence, the\ntrue positive and false positive rates are correlated. Thus, a naive\nalgorithm that directly adds noise to the t sets of counts results in\nROC curves that are very different from the true ROC curve. We\nsolve the \ufb01rst challenge by (a) carefully choosing the subsets using\na differentially private recursive partitioning scheme, and (b) mod-\neling the computation of the correlated true and false positive rates\nas one of privately answering a workload of one sided range queries\n(a problem that is well studied in the literature). Thus we can utilize\nalgorithms from prior work ([27]) to accurately compute the statis-\ntics needed for the ROC curve. The utility of all our algorithms are\ncomprehensively evaluated on three high dimensional datasets.\nOrganization: Section 2 introduces the notation. Section 3 de-\nscribes our novel feature selection algorithms. We discuss private\nevaluation of classi\ufb01ers in Section 4. Experimental results on three\nreal world datasets are presented in Section 5. Finally, we discuss\nrelated work in Section 6 and conclude in Section 7.\n2.\nNOTATION\nLet D be a dataset having d attributes, and let D denote the set\nof all such datasets. One of the attributes is designated as the la-\nbel L. The remainder of the attributes are called features F. We\nassume that all the attributes are binary (though all of the results\nin the paper can be extended to non-binary features). For instance,\nin text classi\ufb01cation datasets (used in our experiments) binary fea-\ntures correspond to presence or absence of speci\ufb01c words from a\nprespeci\ufb01ed vocabulary.\nFor any tuple t in dataset D, let t[L] denote the value of the\nlabel of the tuple, and t[F] denote value of feature F for that tuple.\nWe assume that feature vectors are sparse; every tuple has at most\ns features with t[F] \u0338= 0. We denote by n the number of tuples\nin D, and by n\u03c8 the number of tuples in the dataset (D\u03c8) that\nsatisfy a boolean predicate \u03c8. For instance, nF =1\u2227L=1 denotes the\nnumber of tuples t that satisfy t[F] = 1 \u2227t[L] = 1. We de\ufb01ne by\nPD(\u03c8) = n\u03c8/n the empirical probability of \u03c8 in the dataset D.\n2.1\nDifferential Privacy\nAn algorithm satis\ufb01es differential privacy if its output on a dataset\ndoes not signi\ufb01cantly change due to the presence or absence of any\nsingle tuple in the dataset.\nDEFINITION 1\n(DIFFERENTIAL PRIVACY [6]). Two datasets\nare called neighbors, denoted by (D1, D2) \u2208N if either D1 =\nD2 \u222a{t} or D2 = D1 \u222a{t}. A randomized algorithm M satis\ufb01es\n\u01eb-differential privacy if \u2200s \u2208range(M) and \u2200(D1, D2) \u2208N,\nPr[M(D) = s] \u2264e\u01eb \u00b7 P[M(D\u2032) = s]\n(1)\nHere, \u01eb is the privacy parameter that controls how much an ad-\nversary can distinguish between neighboring datasets D1 and D2.\nLarger \u01eb corresponds to lesser privacy and permits algorithms that\nretain more information about the data (i.e., utility).\nA variant\nof the above de\ufb01nition where neighboring datasets have the same\nnumber of tuples, but differ in one of the tuples is called bounded\ndifferential privacy.\nAlgorithms that satisfy differential privacy work by infusing noise\nbased on a notion called sensitivity.\nDEFINITION 2\n(GLOBAL SENSITIVITY). The global sensitiv-\nity of a function f : D \u2192Rm, denoted by S(f) is de\ufb01ned as the\nlargest L1 difference ||f(D1)\u2212f(D2)||1, where D1, D2 are neigh-\nboring. More formally,\nS(f) =\nmax\n(D1,D2)\u2208N ||f(D1) \u2212f(D2)||1\n(2)\nA popular differentially private algorithm is the Laplace mecha-\nnism [7] de\ufb01ned as follows:\nDEFINITION 3. The Laplace mechanism, denoted by M Lap,\nprivately computes a function f : D \u2192Rm by computing f(D) +\n\u03b7. \u03b7 \u2208Rm is a vector of independent random variables, where\neach \u03b7i is drawn from the Laplace distribution with parameter\nS(f)/\u01eb. That is, P[\u03b7i = z] \u221de\u2212z\u00b7\u01eb/S(f).\nDifferentially private algorithms satisfy the following composi-\ntion properties that allow us to design complex work\ufb02ows by piec-\ning together differentially private algorithms.\nTHEOREM 1\n(COMPOSITION [20]). Let M1(\u00b7) and M2(\u00b7) be\n\u01eb1- and \u01eb2-differentially private algorithms. Then,\n\u2022 Sequential Compositon: Releasing the outputs of M1(D)\nand M2(D) satis\ufb01es \u01eb1 + \u01eb2-differential privacy.\n\u2022 Parallel Composition: Releasing M1(D1) and M2(D2), where\nD1 \u2229D2 = \u2205satis\ufb01es max(\u01eb1, \u01eb2)-differential privacy.\n\u2022 Postprocessing: Releasing M1(D) and M2(M1(D)) satis-\n\ufb01es \u01eb1-differential privacy. That is, postprocessing an output\nof a differentially private algorithm does not incur any addi-\ntional loss of privacy.\nHence, the privacy parameter \u01eb is also called the privacy budget,\nand the goal is to develop differentially private work\ufb02ows that max-\nimize utility given a \ufb01xed privacy budget.\n3.\nPRIVATE FEATURE SELECTION\nIn this section, we present differentially private techniques for\nfeature selection that improve the accuracy of differentially private\nclassi\ufb01ers. We consider the classifer as a blackbox.\nMore formally, a classi\ufb01er C takes as input a record of fea-\ntures and outputs a probability distribution over the set of labels.\nThroughout this paper we consider binary classi\ufb01ers; i.e., L =\n{0, 1}. Thus without loss of generality we can de\ufb01ne the classi-\n\ufb01er as outputting a real number p \u2208[0, 1] which corresponds to the\nprobability of L = 1. Two examples of such classi\ufb01ers include the\nNaive Bayes classi\ufb01er and logistic regression [3].\n2\nFeature selection is a dimensionality reduction technique that\ntypically precedes classi\ufb01cation, where only a subset of the fea-\ntures F\u2032 \u2282F in the dataset are retained based on some criterion of\nhow well F\u2032 predicts the label L [11]. The classi\ufb01er is then trained\non the dataset restricted to features in F\u2032. Since features are se-\nlected based on their properties in the data, the fact that a feature\nis selected can allow attackers to distinguish between neighboring\ndatasets. Thus, by sequential composition, one needs to spend a\npart of the total privacy budget \u01eb for feature selection (say \u01ebfs), and\nuse the remainder (\u01eb \u2212\u01ebfs) for training the blackbox classi\ufb01er.\nFeature selection methods can be categorized as \ufb01lter, wrapper\nand embedded methods [11]. Filter methods assign scores to fea-\ntures based on their correlation with the label, and are independent\nof the downstream classi\ufb01cation algorithm. Features with the best\nscores are retained. Wrappers are meta-algorithms that score sets\nof features using a statistical model. Embedded techniques include\nfeature selection in the classi\ufb01cation algorithm. In this paper, we\nfocus on \ufb01lter methods so that an analyst does not need to know\nthe internals of the private classi\ufb01er. Filters compute a ranking or a\nscore for features based on their correlation with their label. Filter\nmethods may rank/score individual features or sets of features. We\nfocus on methods that score individual features. Features can be\nselected by choosing the top-k or those above some threshold \u03c4.\nThus, the problem we consider can be stated as follows: Let D be\nthe set of all training datasets with binary features F and a binary\nlabel L. Let Q : F \u00d7 D \u2192R be a scoring function that quanti\ufb01es\nhow well F predicts L for a speci\ufb01c dataset. Let F\u03c4 denote the\nsubset of features such that \u2200F \u2208F\u03c4, Q(F, D) > \u03c4. Two subsets\nof features F1, F2 \u2282F, are similar if their symmetric difference\nis small. An example measure of similarity between F1 and F2 is\nthe Jaccard distance (de\ufb01ned as |F1 \u2229F2|/|F1 \u222aF2|).\nPROBLEM 1\n(SCOREBASEDFS). Given a dataset D \u2208D and\na threshold \u03c4, compute F\u2032 \u2282F while satisfying \u01eb-differential pri-\nvacy such that the similarity between F\u2032 and F\u03c4 is maximized.\nWe next describe a few example scoring methods, and present\ndifferentially private algorithms for the SCOREBASEDFS problem.\n3.1\nExample Scoring Functions\nTotal Count: The total count score for a feature F, denoted by\nT C(F, D), is nF =1 the number of tuples with t[F] = 1. Picking\nfeatures with a large total count eliminates features that rarely take\nthe value 1.\nDifference Count: The difference count score for a feature F, de-\nnoted by DC(F, D), is de\ufb01ned as:\nDC(F, D) = |nF =1\u2227L=1 \u2212nF =1\u2227L=0|\n(3)\nDC(F, D) is large whenever one label is more frequent than the\nother label for F = 1. The difference count is smallest when both\nlabels are equally likely for tuples with F = 1. The difference\ncount is the largest when L is either all 1s or all 0s when condi-\ntioned on F = 1.\nPurity Index [11]: The purity index for a feature F, denoted by\nPI(F, D), is de\ufb01ned as:\nPI(F, D) = max\n\u001a\n|nF =1\u2227L=1 \u2212nF =1\u2227L=0|,\n|nF =0\u2227L=1 \u2212nF =0\u2227L=0|\n\u001b\n(4)\nPI(F, D) is the same as DC(F, D), except that it also considers\nthe difference in counts when the feature takes the value 0.\nInformation Gain: Information gain is a popular measure of cor-\nrelation between two attributes and is de\ufb01ned as follows.\nAlgorithm 1 Cluster Selection (Q(\u00b7), \u01ebfs, rounds, centers, s, \u03c4)\npoints \u2190{counts needed for Q(F, D) | F \u2208F)}\nclusters \u2190pkmeans(points,rounds, centers, \u01ebfs, s)\naccepted \u2190{}\nfor cluster in clusters do\ncenter \u2190cluster.center()\nif score(center) \u2265\u03c4 then\naccepted.add(cluster.features())\nend if\nend for\nreturn accepted\nDEFINITION 4\n(INFORMATION GAIN). The information en-\ntropy H of a data set D is de\ufb01ned as:\nH(D) = \u2212\nX\n\u2113\u2208L\nPD(L = \u2113) ln PD(L = \u2113)\n(5)\nThe information gain for a speci\ufb01c feature F is de\ufb01ned as:\nIG(F, D) = H(D) \u2212\nX\nf\u2208F\nPD(F = f) \u00b7 H(DF =f)\n(6)\nInformation gain of a feature F is identical to the mutual informa-\ntion of F and L.\n3.2\nScore Perturbation\nA simple strategy for feature selection is: (a) perturb feature\nscores using the Laplace mechanism, and (b) pick the features whose\nnoisy score crosses the threshold \u03c4 (or pick the top-k features sorted\nby noisy scores). The scale of the Laplace noise required for pri-\nvacy is S(Q) \u00b7 \u2206(Q)/\u01ebfs, where (i) S(Q) is the global sensitivity\nof the scoring function on one feature, and (ii) \u2206(Q) is the number\nof feature scores that are affected by adding or removing one tuple.\nThe sensitivity of the total score T C, difference score DC, and\npurity index PI are all 1. The sensitivity of information gain func-\ntion has been shown to be O(log n) [9, 29], where n is (an upper\nbound on) the number of tuples in the dataset. Information gain\nis considered a better scoring function for feature selection in the\nnon-private case (than T C, DC or PI). However, due to its high\nsensitivity, feature selection based on noisy information gain results\nin lower accuracy, as poor features can get high noisy scores.\nRecall that s is the maximum number of non-zeros appearing in\nany tuple. Thus, \u2206(T C) and \u2206(DC) are both s \u2013 these scores only\nchange for features with a 1 in the tuple that is added or deleted. On\nthe other hand, IG(F, D) and PI(F, D) can change whether t[F]\nis 1 or 0 for the tuple that is added or deleted. Thus, \u2206(IG) and\n\u2206(PI) are equal to the total number of features |F| >> s. 1 High\nsensitivity due to a large s or a large \u2206(Q) can result in poor utility\n(poor features selected). Moreover, we observe (see Section 5.1)\nthat a large s also results in lower accuracy of private classi\ufb01cation.\nWe can circumvent this by sampling; from every tuple t choose at\nmost r features that have t[F] = 1. Sampling is able to force a\nbound on the number of 1s in any tuples, and thus limit the noise.\nHowever, this comes at the cost of throwing away valuable data.\n3.3\nCluster Selection\nThe shortcoming of score perturbation is that we are adding noise\nindividually to the scores of all the features. As the number of fea-\ntures increases, the probability that undesirable features get chosen\n1If we used bounded differential privacy where neighboring\ndatasets have the same number of tuples, we can show that \u2206(Q) \u2264\n2 \u00b7 s for any scoring function, since the neighboring datasets differ\nin values of at most 2 \u00b7 s attributes.\n3\nAlgorithm 2 Private Threshold Testing (D, Q, \u03c4)\n\u02dc\u03c4 \u2190\u03c4 + Lap(1/\u01eb)\nfor each query Qi \u2208Q do\nif Qi(D) \u2265\u02dc\u03c4 then\nv[i] \u21901\nelse\nv[i] \u21900\nend if\nend for\nreturn v\nincreases (due to high noisy scores), thus degrading the utility of\nthe selected features. One method to reduce the amount of noise\nadded is to privately cluster the features based on their scores, com-\npute a representative score for each private cluster, and then pick\nfeatures from high scoring clusters. This is akin to recent work on\ndata dependent mechanisms for releasing histograms and answer-\ning range queries that group categories with similar counts and re-\nlease a single noisy count for each group [16, 18, 28].\nWe represent each feature F as a vector of counts required to\ncompute the scoring function Q. For instance, for T C and DC\nscoring functions, F could be represented as a two dimensional\npoint using the counts nF =1\u2227L=0 and nF =1\u2227L=1. We use private\nk-means clustering [4] to cluster the points. k-means clustering ini-\ntializes the cluster centers (\u00b51, ..., \u00b5k) (e.g. randomly) and updates\nthem iteratively as follows: 1) assign each point to the nearest clus-\nter center, 2) recompute the center of each cluster, until reaching\nsome convergence criterion or a \ufb01xed number of iterations. This\nalgorithm can be made to satisfy differential privacy by privately\ncomputing in each iteration (a) the number of points in each new\ncluster, qa, and (b) the sum of the points in each cluster, qb. The\nglobal sensitivity of qa is 1, and the global sensitivity of qb is \u2206(Q)\n(or r if sampling is used). The number of iterations is \ufb01xed, and the\nprivacy budget is split evenly across all the iterations.\nOnce clusters have been privately assigned, the centers them-\nselves can be evaluated based on their coordinates. For instance,\nT C and DC can be computed using the sum and difference (resp.)\nof the two-dimensional cluster centers. Depending on the score of\nthe group all or none of the associated features will be accepted.\nThis score does not have to be perturbed as it is computed via the\ncenters that are the result of a private mechanism.\n3.4\nPrivate Threshold Testing\nIn this section we present a novel mechanism, called private\nthreshold testing (PTT), for the SCOREBASEDFS problem whose\nutility is independent of both s and the number of features |F|, and\ndoes not require sampling. Rather than perturbing the scores of\nall the functions, PTT perturbs a threshold \u03c4 and returns the set of\nfeatures with scores greater than the perturbed threshold. We be-\nlieve PTT has applications beyond feature selection and hence we\ndescribe it more generally.\nLet Q = {Q1, Q2, . . . , Qm} denote a set of real valued queries\nover a dataset D, all of which have the same sensitivity \u03c3. (In our\ncase, each Qi = Q(Fi, D), and m = |F|). PTT has as input\nthe set of queries Q and a real number \u03c4, and outputs a vector\nv \u2208{0, 1}m, where v[i] = 1 if and only if Qi(D) \u2265\u02dc\u03c4.\nThe private algorithm is outlined in Algorithm 2. PTT creates\na noisy threshold \u02dc\u03c4 by adding Laplace noise with scale \u03c3/\u01eb to \u03c4.\nThe output vector v is populated by comparing the unperturbed\nquery answer Q(D) to \u02dc\u03c4. We can show that despite answering\nm comparison queries (where m can be very large) each with a\nsensitivity of \u03c3, PTT ensures 2\u03c3\u01eb-differential privacy (rather than\nm\u03c3\u01eb-differential privacy that results from a simple application of\nsequential composition).\nTHEOREM 2. Private Threshold Testing is 2\u03c3\u01eb-differentially pri-\nvate for any set of queries Q all of which have a sensitivity \u03c3.\nPROOF. (sketch) Consider the set of queries for which PTT out-\nput 1 (call it Q1); i.e., for these queries, Q(D) > \u02dc\u03c4. Note that for\nany value of the noisy threshold, say \u02dc\u03c4 = z, if Q(D) \u2265z, then for\nany neighboring database Q(D\u2032) \u2265z \u2212\u03c3 (since \u03c3 is the sensitiv-\nity). However, since \u02dc\u03c4 is drawn from the Laplace distribution, we\nhave that\nP (\u02dc\u03c4=z)\nP (\u02dc\u03c4=z\u2212\u03c3) \u2264e\u03c3\u01eb. Therefore,\nP(Q(D) = 1, \u2200Q \u2208Q1) =\nZ\nz\nP(\u02dc\u03c4 = z)\nY\nQ\u2208Q1\nP(Q(D) > z)dz\n\u2264\ne\u03c3\u01eb\nZ\nz\nP(\u02dc\u03c4 = z \u2212\u03c3)\nY\nQ\u2208Q1\nP(Q(D\u2032) > z \u2212\u03c3)dz\n=\ne\u03c3\u01ebP(Q(D\u2032) = 1, \u2200Q \u2208Q1)\nAn analogous bound for Q0 yields the requires e2\u03c3\u01eb bound.\nWe can show that \u03c4 can be chosen based on the database D. In fact\nwe can show the following stronger result for count-based queries.\nCOROLLARY 1. Let Q be a set of queries with sensitivity \u03c3.\nLet \u03c4 be a function on D that computes the threshold, also having\nsensitivity \u03c3. If the values of Q and \u03c4 on D are non-decreasing (or\nnon-increasing) when a tuple is added (or deleted resp.) from D,\nthen PTT is \u03c3\u01eb-differentially private.\nPROOF. (sketch) Case (i) \u03c4 is a constant: When D = D\u2032 \u222a\n{t}, for all z, Qi(D) < z implies Qi(D\u2032) < z. Thus, r0 =\nP (Q(D)=0,\u2200Q\u2208Q0)\nP (Q(D\u2032)=0,\u2200Q\u2208Q0) is already bounded above by 1, while r1 =\nP (Q(D)=1,\u2200Q\u2208Q1)\nP (Q(D\u2032)=1,\u2200Q\u2208Q1) is bounded above by e\u03c3\u01eb from proof of Tho-\nerem 2. When D\u2032 = D \u222a{t}, we have r1 < 1 and r0 \u2264e\u03c3\u01eb.\nCase (ii) \u03c4 is a function of D: When D = D\u2032 \u222a{t}, it holds that\nP(\u02dc\u03c4(D) = z) \u2264e\u03c3\u01ebP(\u02dc\u03c4(D\u2032) = z \u2212\u03c3). This is because \u03c4(D\u2032)\nlies between [\u03c4(D) \u2212\u03c3, \u03c4(D)]. The rest of the proof remains.\nWhile Theorem 2 applies to all our scoring functions (T C, DC, PI\nand IG), the stronger result from Corollary 1 only applies to T C.\nAdvantages over prior work: First, PTT permits releasing whether\nor not a set of query answers are greater than a threshold \u03c4 even if\nthe sensitivity of releasing the answers of all the queries may be\nlarge. PTT only requires: (i) query answers to be real numbered\nand (ii) each query has a small sensitivity \u03c3. The privacy guarantee\nis independent of the number of queries.\nNext, PTT can output whether or not a potentially unbounded\nnumber of query answers cross a threshold. This is a signi\ufb01cant\nimprovement over the related sparse vector technique (SVT) \ufb01rst\ndescribed in Hardt [13], which allows releasing upto a constant c\nquery answers that are above a threshold \u03c4. SVT works as follows:\n(i) pick a noisy threshold \u02dc\u03c4 using \u01eb/2 privacy budget, (ii) perturb\nall the queries using Laplace noise using a budget of \u01eb/2c, and (iii)\nreleasing the \ufb01rst c query answers whose noisy answers are greater\nthan \u02dc\u03c4. Once c query answers are released the algorithm halts. PTT\nis able to give a positive or negative answer for all queries, since it\ndoes not release the actual query answers.\nFinally, PTT does not add noise to the query answers, but only\ncompares them to a noisy threshold. This means that the answer to\na query for which PTT output 1 is in fact greater than the answer\nto a query for which PTT output 0. This is unlike NOISYCUT, a\n4\ntechnique used in Lee et al [17]. Both PTT and NOISYCUT solve the\nsame problem of comparing a set of query answers to a threshold.\nWhile PTT only adds noise to the threshold, NOISYCUT adds noise\nto both the query answers and the threshold. We experimentally\nshow (in Section 5.1) that PTT has better utility than NOISYCUT.\nThat is, suppose Q1 is the set of queries whose true answers are >\n\u03c4, and QP\n1 and QN\n1 are the set of queries with a 1 output according\nto PTT and NOISYCUT, resp. We show that QP\n1 is almost always\nmore similar to Q1 than QN\n1 .\nWe quantify the utility of our feature selection algorithms by ex-\nperimentally showing their effect on differentially private classi-\n\ufb01ers in Section 5.\n4.\nPRIVATEEVALUATION OF CLASSIFIERS\nIn this section, we describe an algorithm to quantify the accuracy\nof any binary classi\ufb01er under differential privacy on a test dataset\ncontaining sensitive information.\n4.1\nROC curves\nReceiver operating characteristic (ROC) curves are typically used\nto quantify the accuracy of binary classifers. Let Dtest be a test\ndataset. For every tuple t \u2208Dtest, let t[L] \u2208{0, 1} denote the\ntrue label, and p(t) \u2208[0, 1] denote the prediction returned by some\nclassi\ufb01er (probability that t[L] = 1). Let n1 and n0 denote the\nnumber of tuples with true label 1 and 0 respectively.\nGiven a threshold \u03b8, we say that the predicted label p\u03b8(t) is 1 if\np(t) > \u03b8. Based on the true label as well as the predicted label (at\na given threshold \u03b8), we can quantify the accuracy of the classi\ufb01er\non the dataset as follows. True positives, T P(\u03b8), are the tuples in\nDtest whose true label and predicted label equals 1; i.e., t[L] =\n1 \u2227p(t) > \u03b8. True negatives, T N(\u03b8), denote the tuples whose\ntrue and predicted labels are 0. False positives, FP(\u03b8) are tuples\nwhose true label is 0 but the predicted label is 1. False negatives,\nFN(\u03b8) are tuples whose true label is 1 but the predicted label is 0.\nWe will use the notation T P(\u03b8), FP(\u03b8), etc. to both denote the set\nof tuples as well as the cardinality of these sets.\nThe true-positive rate T PR(\u03b8) is de\ufb01ned as the probability that a\ntuple in the test set having label 1 is correctly classi\ufb01ed to have label\n1. The false-positive rate FPR(\u03b8), is de\ufb01ned as the probability that\na data having label 0 is wrongly classi\ufb01ed to have label 1. Thus,\nT PR(\u03b8) = T P(\u03b8)\nn1\nand FPR(\u03b8) = FP(\u03b8)\nn0\n(7)\nThe Receiver operating characteristic (ROC) curve is de\ufb01ned by\nplotting pairs of FPR(\u03b8) versus T PR(\u03b8) over all possible thresh-\nolds \u03b8 \u2208\u0398. ROC curve starts at (0,0) and ends at (1,1). In order to\nevaluate the accuracy of a binary classi\ufb01er, we consider the area un-\nder the ROC curve (AUC). If the classi\ufb01er is good, the ROC curve\nwill be close to the left and upper boundary and AUC will be close\nto 1. On the other hand, if the classi\ufb01er is poor, the ROC curve will\nbe close to the 45\u25e6line from (0,0) to (1,1) with AUC around 0.5.\nRecent work [19] has shown that releasing the actual ROC curves\non a private test dataset can allow an attacker with prior knowl-\nedge to reconstruct the test dataset. An extreme yet illustrative\nexample is as follows: suppose an attacker knows the entire test\ndataset except one record. Given the real ROC curve, the attacker\ncan determine the unknown label by simply enumerating over all\nlabels (and checking which choice led to the given ROC curve).\nHence, directly releasing the real ROC curve may leak information\nof the data and we need a differentially private method for generat-\ning ROC curves to protect the private test dataset.\n4.2\nPrivate ROC curves\nAlgorithm 3 PriROC (T, P, \u01eb)\n1. Use \u01eb1 budget to choose the set of thresholds for computing\nT PRs and FPRs\n2. Use \u01eb2 = \u01eb\u2212\u01eb1 budget to compute the noisy T PRs and FPRs\nat all thresholds\n3. Postprocess the T PRs and FPRs sequences to maintain con-\nsistency.\nThere are three important challenges when generating differen-\ntially private ROC curves \u2013 (i) how to privately compute T PR and\nFPR values, (ii) how many and what thresholds to pick, and (iii)\nhow to ensure the monotonicity of the T PR and FPR values.\nOne can use the Laplace mechanism to compute T PR(\u03b8) and\nFPR(\u03b8). The global sensitivity of releasing n0 and n1 is 1. The\nglobal sensitivity of each of the T P(\u03b8) and FP(\u03b8) values equals 1.\nThus they can all released by adding Laplace noise with sensitivity\n2|\u0398| + 1, where |\u0398| is the number of thresholds. However, as we\nwill show later, the linear dependence of sensitivity on the number\nof thresholds can lead to signi\ufb01cant errors in the ROC curves and\nthe area under the curve.\nThis brings us to the next concern of the number of thresholds. In\nthe non-private case, one can pick all the prediction probabilities as-\nsociated with each tuple in the test dataset as a threshold. However,\nas |\u0398| increases, more counts need to be computed leading to more\nnoise. Moreover, the predictions themselves cannot be publicly re-\nleased, and hence the thresholds must be chosen in a private man-\nner. Finally, the true T PR and FPR values satisfy the following\nmonotonicity property: for all \u03b81 \u2264\u03b82, T PR(\u03b81) \u2264T PR(\u03b82)\nand FPR(\u03b81) \u2264FPR(\u03b82). The private T PR and FPR values\nmust also satisfy this property to get a valid ROC curve.\nOur algorithm for computing differentially private ROC curves,\ncalled PriROC (Algorithm 3), addresses all the aforementioned con-\ncerns. PriROC \ufb01rst privately chooses a set of thresholds (using pri-\nvacy parameter \u01eb1). By modeling T P and FP values as one-sided\nrange queries, PriROC can compute noisy T PRs and FPRs val-\nues (using the remaining privacy budget \u01eb2) with much lower error\nthan using the Laplace mechanism. Finally, a postprocessing step\nenforces the monotonicity of T PRs and FPRs. We next describe\nthese steps in detail.\n4.2.1\nComputing noisy TPRs & FPRs\nSuppose we are given a set of thresholds \u0398 = {\u03b81, . . . , \u03b8\u2113},\nwhere \u03b8i > \u03b8i+1 for all i. Assume that \u03b80 = 1 and \u03b8\u2113= 0. That\nis, for all records t \u2208Dtest, the prediction p(t) is greater than \u03b8\u2113,\nbut not greater than \u03b80. Since, T P(\u03b8) corresponds to the number\nof tuples t with t[L] = 1 \u2227p(t) \u2265\u03b8, T P(\u03b8\u2113) is the total number\nof tuples with t[L] = 1 (denoted by n1). Similarly, FP(\u03b8\u2113) is the\ntotal number of tuples with t[L] = 0 (denoted by n0). Thus:\nT PR(\u03b8i) = T P(\u03b8i)\nn1\n= T P(\u03b8i)\nT P(\u03b8\u2113) \u22001 \u2264i \u2264\u2113\nFPR(\u03b8i) = FP(\u03b8i)\nn0\n= FP(\u03b8i)\nFP(\u03b8\u2113) \u22001 \u2264i \u2264\u2113\nTherefore, an ROC curve can be constructed by just computing\nT P(\u03b8i) and FP(\u03b8i) for all \u03b8i \u2208\u0398.\nWe next observe that the true positive and false positive counts\neach correspond to a set of one-sided range queries.\nDEFINITION 5\n(ONE-SIDED RANGE QUERY).\nLet X = {x1, x2, . . . , xn} denotes a set of counts. A query qj is\ncalled a one sided range query, and qj(X) is the sum of the \ufb01rst\n5\nj elements in X. That is, qj(X)\n=\nPj\ni=1 xi. The set Cn =\n{q1, . . . , qn} denotes the workload of all one sided range queries.\nIn our context, let XT P\n\u0398\n= {xT P\n1\n, xT P\n2\n, . . . , xT P\n\u2113\n}, where xT P\ni\nis the number of tuples t \u2208Dtest with t[L] = 1 and \u03b8i\u22121 \u2265p(t) >\n\u03b8i. It is easy to check that T P(\u03b8i) is the sum of the \ufb01rst i counts in\nXT P\n\u0398 . We can similarly de\ufb01ne XF P\n\u0398 , and show that each FP(\u03b8i)\nis also the answer to a one-sided range query qi on XT P\n\u0398 .\nIt is well known that the Laplace mechanism is not optimal in\nterms of error for the workload of one-sided range queries Cn. Un-\nder Laplace mechanism, each query answer would have a mean\nsquare error of O(n2/\u01eb2). Instead, using strategies like the hierar-\nchical mechanism [14] or Privelet [27] allow answering each one-\nsided range query with no more than O(log3 n/\u01eb2) error. In our ex-\nperiments, we use the Privelet mechanism to compute the T P and\nFP counts with a privacy budget of \u01eb2/2 for each. The Privelet al-\ngorithm \ufb01rst computes the wavelet coef\ufb01cients of the counts in X,\nadds noise to the wavelet coef\ufb01cients and then reconstructs a new\n\u02c6\nX from the noisy wavelet coef\ufb01cients. One-sided range queries are\ncomputed on \u02c6\nXT P\n\u0398\nto get the T P counts and on \u02c6\nXF P\n\u0398\nto get the\nFP counts, which in turn are used to construct the noisy T PR(\u03b8)\nand FPR(\u03b8) values. Since all steps subsequent to Privelet do not\nuse the original data, the fact that releasing T PR(\u03b8) and FPR(\u03b8)\nsatis\ufb01es \u01eb2-differential privacy follows from the privacy of Privelet.\n4.2.2\nChoosing Thresholds\nThere are two important considerations when choosing the set of\nthresholds \u0398. The number of thresholds must not be very large,\nas the total error is directly related to |\u0398|. At the same time, the\nthresholds must be chosen carefully so that the ROC curve on those\nthresholds is a good approximation of the ROC curve drawn using\nall the predictions in the test data. We present two heuristics for\nchoosing \u0398 that take into account the above considerations.\nA simple data-independent strategy for picking the set of thresh-\nolds is to choose them uniformly from [0, 1]. More precisely, if\nn is the cardinality of Dtest, we choose the number of thresholds\nto be an \u03b1 \u2208[0, 1] fraction of n, and choose the set of thresholds\nto be \u0398 = {0,\n1\n\u230a\u03b1n\u230b,\n2\n\u230a\u03b1n\u230b, . . . , \u230a\u03b1n\u230b\u22121\n\u230a\u03b1n\u230b, 1}. We call this strategy\n\u03b1-FIXEDSPACE. This strategy works well when the predictions\nP = {p(t)|t \u2208Dtest} are uniformly spread out in [0, 1]. Since,\n\u03b1-FIXEDSPACE is data independent, \u01eb1 = 0, and all the privacy\nbudget can be used for computing the T PR and FPR values.\n\u03b1-FIXEDSPACE is not a good strategy in the general case. For in-\nstance, suppose a majority of the predictions are less than the small-\nest threshold \u03b81 =\n1\n\u230a\u03b1n\u230b. Then the ROC curve for all those points\nwill be approximated with a single point (T PR(\u03b81), FPR(\u03b81))\npossibly resulting in a signi\ufb01cant loss in accuracy in the AUC.\nHence, we present k-RECURSIVEMEDIANS, a data dependent\nstrategy that addresses skewed prediction distributions by recur-\nsively partitioning the data domain such that each partition has\nroughly the same number of tuples (Algorithm 4). The algorithm\ntakes as input \u01eb, the privacy budget for choosing thresholds, k, the\nnumber of recursive steps, and P = {p(t)|t \u2208Dtest}, the multiset\nof predictions. As the name suggests the algorithm has k recursive\nsteps, and each uses a privacy budget of \u01eb/k.\nThe algorithm recursively calls a subroutine FINDMEDIANS com-\nputing the noisy median of all predictions within the range (left, right).\nInitally, left = 0 and right = 1. Since median has a high global\nsensitivity (equal to right if all values are in the range (left, right)),\nwe use the smooth sensitivity framework [21] for computing the\nnoisy median. We refer the reader to the original paper for details\non computing the smooth sensitivity for median. We choose to\nAlgorithm 4 k-RECURSIVEMEDIANS\nfunction k-RECURSIVEMEDIANS(P,\u01eb, k)\n\u01eb\u2032 \u2190\u01eb\nk\nreturn FINDMEDIANS(P,\u01eb\u2032, k, 0, 1)\nend function\nfunction FINDMEDIANS(P,\u01eb\u2032, k, left, right)\nif k = 0 then return\nend if\nm \u2190median(P)\n\u02dcm \u2190m +\n8S\u2217\nfmed,\u01eb\u2032 (P )\n\u01eb1\n\u2217z, z is random noise \u221d\n1\n1+z2\nif \u02dcm \u2264left or \u02dcm \u2265right then\n\u02dcm = (left + right)/2\nend if\nP1 \u2190{P[i] | P[i]< \u02dcm}\nP2 \u2190{P[i] | P[i]> \u02dcm}\nreturn\nFINDMEDIANS(P1, \u01eb\u2032, k \u22121, left, \u02dcm) \u222a\n\u02dcm \u222a\nFINDMEDIANS(P2, \u01eb\u2032, k \u22121, \u02dcm, right)\nend function\nsample noise from distribution K/(1+|z|2) (where K is a normal-\nization constant). We can generate samples from the distribution by\npicking U uniformly from (0, 1) and computing tan(\u03c0(U \u22120.5))\n(since the CDF of the distribution is \u221darctan(z)).\nThe resulting noisy median \u02dcm could fall out of the range (left, right).\nThis could either happen due to random chance, or more likely be-\ncause the smooth sensitivity of the points within the range is high.\nA high smooth sensitivity occurs either due to a small number of\ndata points, or when about half the data points are very close to\nleft, and the rest of the points are very close to right. Then a point\nin the middle of the range (e.g., (left + right)/2) is a good par-\ntition point, and is used instead of \u02dcm. The algorithm proceeds to\nrecursively \ufb01nd the medians of points in (left, \u02dcm) and ( \u02dcm, right).\nThe algorithm returns after it completes k levels of recursion. The\nnumber of thresholds output by k\u2212RecursiveMedians is 2k.\nTHEOREM 3. Algorithm 4 (k-RECURSIVEMEDIANS) satis\ufb01es\n\u01eb-differential privacy.\nPROOF. (sketch) The proof follows from the following state-\nments: Computing the median of a set of points in each invocation\nof FINDMEDIANS satis\ufb01es \u01eb/k-differential privacy. This is true as\nlong as noise is drawn from the distribution \u221d1/(1 + |z|\u03b3), scaled\nappropriately by the smooth sensitivity and \u03b3 \u22651. In each recur-\nsive step, computing the medians in disjoint partitions of the data\nsatis\ufb01es \u01eb/k-differential privacy by parallel composition. Since the\nnumber of recursions is bounded by k, k-RECURSIVEMEDIANS\nsatis\ufb01es \u01eb-differential privacy by serial composition.\n4.2.3\nEnsuring monotonicity\nT PR(\u03b8) and FPR(\u03b8) values in the original ROC curve are\nmonotonic. That is, the true positive rates satisfy the following\nconstraint: 0 \u2264T PR(\u03b81) \u2264. . . \u2264T PR(\u03b8\u2113) = 1. However,\nthis may not be true of the noisy T PR and FPR values (gener-\nated using the strategy from the previous section). We leverage the\nordering constraint between the T PR and FPR values to boost\nthe accuracy by using the constrained inference method proposed\nby Hay et al [14]. Since this is a postprocessing step, there is no\nimpact on privacy.\nThe error introduced by our algorithms for generating ROC curves\nvaries with different datasets. Therefore, we empirically evaluate\nthe utility of our algorithms on real data in the next section.\n6\n5.\nEXPERIMENTS\nIn this section we experimentally evaluate our differentially pri-\nvate algorithms for feature selection (Section 5.1)) and generating\nROC curves (Section 5.2). The main takeaways from the exper-\nimental evaluation on differentially private feature selection are:\n\u2022 Spending a part of the privacy budget for private feature selec-\ntion can signi\ufb01cantly improve the misclassi\ufb01cation rate (10%\n- 15%) of a differentially private classi\ufb01er. This is despite a\nnoisier classi\ufb01er due to the smaller privacy budget.\n\u2022 Feature selection using private threshold testing consistently re-\nsults in classi\ufb01ers with higher accuracy than feature selection\nusing score perturbation and cluster selection PTT also signif-\nicantly outperforms a related technique NOISYCUT in solving\nthe SCOREBASEDFS problem.\n\u2022 In the differential privacy regime, simple scoring techniques\n(like total count T C) perform as well or even better than mea-\nsures like information gain IG that are considered best in the\nnon-private regime.\nThe main takeaways from the experimental evaluation on differen-\ntially private ROC curves are:\n\u2022 The area under the curve (AUC) measure for the differentially\nprivate ROC curves are close to the AUC measures for the true\nROC curves. Therefore, with high probability differentially pri-\nvate ROC curves can be used to distinguish between classi\ufb01ers\nthat are signi\ufb01cantly different.\n\u2022 The AUC error for ROC curves generated by PriROC is signif-\nicantly smaller than AUC error for ROC curves based on true\nand false positive rates computed using the Laplace mechanism.\n\u2022 The k-RECURSIVEMEDIANS method to pick thresholds results\nin better ROC curves than using \u03b1-FIXEDSPACE.\n\u2022 The number of thresholds chosen to generate the differentially\nprivate ROC curve does not signi\ufb01cantly affect the AUC error.\n5.1\nFeature Selection\n5.1.1\nSetup\nWe use three text classi\ufb01cation datasets - TWITTER, SMS and\nREUTERS. The TWITTER dataset [10] was collected for the task\nof sentiment classi\ufb01cation.\nEach tweet is associated with a bi-\nnary sentiment label \u2013 positive or negative. The datast contains 1.6\nmillion tweets from which we randomly sampled 7304 tweets for\nour experiments. We constructed binary features for every word\n(excluding stop words) resulting a total of 32935 features. Since\neach tweet contained at most 20 non-stop words, we set s = 20.\nThe SMS dataset [1] contains 5574 SMS messages associated with\nspam/ham label. The dataset has a total of 8021 features. Since\nSMS messages are short, we again set s = 20. The REUTERS\ndataset consists of 21578 news articles tagged with topics. To get a\ntraining dataset with a binary class label, we chose a corpus of 6906\narticles labeled as earnings-related or not (based on the \u201dearn\u201d topic\nkeyword). Since an article does not have a word limit, we do not\nhave a small bound on s like in TWITTER or SMS. The total num-\nber of features is 33389.\nWe choose to evaluate our feature selection algorithm on two\nstate of the art differentially private classi\ufb01ers \u2013 Naive Bayes [25],\nand the differentially private ERM implementation of logistic re-\ngression [2]. The Naive Bayes (NB) classi\ufb01er assumes that the\nfeatures are conditionally independent given the label L. Given a\nfeature vector x \u2208{0, 1}|F|, the predicting label given by\nargmax\u2113\u2208{0,1}Pr[L = \u2113] \u00b7\nY\nF \u2208F\nPr[F = x[F]|L = \u2113]\nThus, the Naive Bayes classi\ufb01er can be made private by releasing\ndifferentially private counts of n, nL=\u2113, and nF =i\u2227L=\u2113from the\ntraining data set, for i, \u2113\u2208{0, 1}.\nLogistic regression models the log odds of the prediction as lin-\near function of the features. Empirical risk minimization is used\nto \ufb01t the linear model given a dataset. For non-private logistic re-\ngression, we have used the prepackaged Scikit-learn logistic regres-\nsion classi\ufb01er [22]. We use an implementation of Chaudhuri et al\u2019s\n[2] differentially private empirical risk minimization (henceforth\ncalled ERM) for logistic regression.\nThe accuracy of a classi\ufb01er is measured using the fraction of\npredictions that match the true label on a held out test set. The\nresults are average over 10 runs (using 10-fold cross validation) to\naccount for the noise introduced due to differential privacy.\n5.1.2\nFeature Selection Results\nFigure 1 presents a comparison of all the discussed feature selec-\ntion methods across all three data sets using a non-private and a pri-\nvate naive bayes classi\ufb01er. In the non-private case (Figures 1(a),1(c),\nand 1(e)), we see a small improvement in the accuracy using all\nthree scoring techniques T C, DC and IG. PI resulted in a simi-\nlar accuracy as DC and is not shown. IG has the highest accuracy\nfor all the datasets.\nIn the private case (Figures 1(b),1(d), and 1(f)), \u2018All\u2019 corresponds\nto no feature selection, and \u2018All-sampling\u2019 correponds to using all\nthe features but with sampling (to reduce the sensitivity) with r =\n10. For the private graphs, the total \u01eb-budget is 1.0. We see that\neven though sampling throws away valuable data, we already see\nan increase in the accuracy. This is because sampling also helps\nreduce the sensitivity of the classi\ufb01er training algorithm. Note that\nwe do not report the \u2018All\u2019 bar for REUTERS\u2013 since we can\u2019t bound\nthe lenght of an article, the suf\ufb01cient statistics for the naive bayes\nclassi\ufb01er have a very high sensitivity. We also show the accuracy\nof the majority classi\ufb01er, which always predicts the majority class.\nNext we add feature selection. Both score perturbation and clus-\ntering are used in conjunction with sampling (to reduce sensitivity).\nPrivate threshold testing (PTT) does not use sampling. For score\nperturbation the budget split is .5 for selection and .5 for classi\ufb01ca-\ntion (budget split is discussed in Section 5.1.4). For clustering and\nPTT the budget split is .2 for selection and .8 for classi\ufb01cation.\nWe see that most of the feature selection techniques (and scor-\ning functions) result in a higher accuracy than \u2018All-sampling\u2019. One\nexception is IG due to its high sensitivity. Additionally as noted\nin section 3.2, experiments with score perturbation of Information\nGain were run under bounded differential privacy (since the sensi-\ntivity of IG is higher under unbounded differential privacy). We\nsee poor accuracy with IG and score perturbation despite this. We\ndo not report IG under clustering and PI under score perturbation\nand clustering due to their high sensitivity. We are surprised to see\nthat T C is as good as or better than \u201cbest\u201d non-private scoring tech-\nniques across all three datasets and all differentially private feature\nselection techniques. This is due to its low sensitivity. We also note\na trend that PTT with T C is more accurate than clustering with T C\nwhich is in turn more accurate than score perturbation with T C.\nFigure 2 contains the same tests, but with the ERM classi\ufb01er.\nWe only show results on the SMS dataset due to space constraints.\nWe found that the private ERM code does not scale well to large\nnumber of features. For that reason we \ufb01rst selected the top 5000\nfeatures according to T C scoring function and used that in place\n7\n0.45\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nAccuracy\nMajority Classifier\nAll\nTotal: 500\nDifference: 500\nInformation Gain: 500\n(a) Twitter Non-private\n0.45\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nAccuracy\nMajority Classifier\nAll\nAll - Sampling\nTotal: 500\nDifference: 500\nInformation Gain: 500\nClustering - Total\nClustering - Difference\nThreshold - Total\nThreshold - Difference\nThreshold - Purity Index\nThreshold - IG\n(b) Twitter Private\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nAccuracy\nMajority Classifier\nAll\nTotal: 500\nDifference: 500\nInformation Gain: 500\n(c) SMS Non-private\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nAccuracy\nMajority Classifier\nAll\nAll - Sampling\nTotal: 500\nDifference: 500\nInformation Gain: 500\nClustering - Total\nClustering - Difference\nThreshold - Total\nThreshold - Difference\nThreshold - Purity Index\nThreshold - IG\n(d) SMS Private\n0.45\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nAccuracy\nMajority Classifier\nAll\nTotal: 500\nDifference: 500\nInformation Gain: 500\n(e) Reuters Non-private\n0.45\n0.50\n0.55\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nAccuracy\nMajority Classifier\nAll - Sampling\nTotal: 500\nDifference: 500\nInformation Gain: 500\nClustering - Total\nClustering - Difference\nThreshold - Total\nThreshold - Difference\nThreshold - Purity Index\nThreshold - IG\n(f) Reuters Private\nFigure 1: Naive Bayes classi\ufb01cation with the TWITTER, SMS and REUTERS datasets.\nof the \u2018All\u2019 features. Feature selection was then performed on this\nrestricted dataset. We see the same trends as in the case of the Naive\nBayes classi\ufb01er. The results are comparable to those run on the\nprivate Naive Bayes classi\ufb01er, but with a lower accuracy overall.\nThis lower accuracy could be because Naive Bayes is known to\noutperform other methods for the text classi\ufb01cation task.\n5.1.3\nSCOREBASEDFS Comparison\nWe also evaluate the quality of the just the feature selection algo-\nrithms (without considering a classi\ufb01er). The accuracy of a feature\nselection technique is quanti\ufb01ed as follows. Let F\u03c4 be the true set\nof features whose scores are greater than the threshold (under some\n\ufb01xed scoring function), and let F\u2032 be the set of features returned by\na differentially private algorithm for SCOREBASEDFS. We de\ufb01ne\nprecision (pre), recall (rec) and F1-score (F1) as follows:\npre = |F\u03c4 \u2229F\u2032|\n|F\u2032|\n, rec = |F\u03c4 \u2229F\u2032|\n|F\u03c4|\n, F1 = 2 \u00b7 pre \u00b7 rec\npre + rec\nFigure 3 shows the F1 scores for 4 private feature selection meth-\nods using T C \u2013 score perturbation, clustering, PTT and NOISYCUT\n[17]. The x-axis corresponds to different thresholds \u03c4. The x-axis\nvalues on the top represent |F\u03c4|.\nThere are two notable features of these plots. First, PTT does the\nbest of all selection methods at all thresholds. This is due to the fact\nthat only the threshold is perturbed. Since the ordering of feature\nscores is maintained, F\u2032 is a superset of F\u03c4 (with rec = 1) or is a\nsubset of F\u03c4 (with pre = 1). In particular it signi\ufb01cantly outper-\nforms NOISYCUT under small thresholds (or when many features\nmust be chosen). Second, we are able to see what settings would\ncause the other methods to struggle. Both score perturbation and\nNOISYCUT have poorer accuracy as \u03c4 decreases (or number of fea-\ntures increases). This is because feature score are perturbed, and as\nwe increase the number of features to be selected there is a larger\nchance that good features are eliminated and poorer features are re-\nturned just by random chance. Clustering shows the reverse trend.\nThis is because low scoring features tend to cluster together result-\ning in large clusters (resulting in low sensitivity). The same is not\ntrue for high scoring features.\n5.1.4\nParameter Tuning\nIn this section we present empirical justi\ufb01cation for some of our\n8\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nAccuracy\nMajority Classifier\nAll\nTotal: 500\nDifference: 500\nInformation Gain: 500\n(a) SMS Non-private\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nAccuracy\nMajority Classifier\nAll (5000)\nAll - Sampling\nTotal: 500\nDifference: 500\nClustering - Total\nClustering - Difference\nThreshold - Total\nThreshold - Difference\nThreshold - Purity Index\nThreshold - IG\n(b) SMS Private\nFigure 2: Logisitic regression with the SMS dataset. ERM used for private regression.\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n605\n302\n194\n139\n104\n83\n66\n51\n41\n33\nF1 value\nThresholds:Scores\nTrue number of features\n(a) PTT\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n605\n302\n194\n139\n104\n83\n66\n51\n41\n33\nF1 value\nThresholds:Scores\nTrue number of features\n(b) NOISYCUT\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n605\n302\n194\n139\n104\n83\n66\n51\n41\n33\nF1 value\nThresholds:Scores\nTrue number of features\n(c) Score Perturbation\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n605\n302\n194\n139\n104\n83\n66\n51\n41\n33\nF1 value\nThresholds:Scores\nTrue number of features\n(d) Cluster\nFigure 3: F1 Score Comparison among 4 Private Feature Selection Algorithms on SMS data\ndesign choices \u2013 budget split, and sample rate selection. We defer\nthe problem of classi\ufb01er agnostic automatic parameter tuning to\nfuture work.\nPrivacy Budget Split: We empirically tested the accuracy of the\nclassi\ufb01er with feature selection under different budget splits. Fig-\nures 5(a) and 5(b) show (on the TWITTER and SMS datasets, resp.)\none example of Naive Bayes classi\ufb01cation with score perturbation\nusing the T C score function.\nWe see that the best accuracy is\nachieved when feature selection and classi\ufb01cation equally split the\nbudget. Since clustering and PTT have much lower sensitivities we\n\ufb01nd than a much smaller part of the budget (0.2) is required for\nthese techniques to get the best accuracy (graphs not shown).\nSplitting data vs Privacy Budget: Rather than splitting the pri-\nvacy budget, one could execute feature selection and classi\ufb01cation\non disjoint subsets of the data. By parallel composition, one can use\nall the privacy budget for both tasks. However, experiments on the\nNaive Byes classi\ufb01er with PTT showed splitting the data resulted in\nclassi\ufb01ers whose average accuracy was very close to that of the ma-\njority classi\ufb01er. Since feature selection is run on a slightly different\ndataset, wrong features are being chosen for classi\ufb01er training.\nSampling Rate Selection: Figures 5(c) and 5(d) show the change\nin system accuracy as the sampling rate r is changed for the SMS\nand TWITTER data sets. We see that selecting alow sampling rate is\ndetrimental since too much information is lost. Alternatively select-\ning a sampling rate that is too high loses accuracy from increasing\nthe sensitivity used when drawing noise for privacy. A moderate\nrate of sampling that preserves enough information while reducing\nthe required global sensitivity for privacy will do best.\nTotal Budget Selection Figure 4 shows the accuracy of the private\nclassi\ufb01er with the best private score perturbation, clustering and\nPTT feature selection algorithm under different settings of the total\nprivacy budget (\u01eb = 1, 0.5, 0.25 and 0.1). The same settings for\nbudget split and sampling are held throughout. For the TWITTER\nand REUTERS datasets (which are harder to predict) we see the ac-\n\u01eb\nAUC Error\nLaplace\n\u03b1-FIXEDSPACE\nk-RECURSIVEMEDIANS\nSMS\nTWI\nSMS\nTWI\nSMS\nTWI\n1\n0.218\n0.073\n0.034\n0.065\n0.023\n0.055\n0.5\n0.343\n0.108\n0.042\n0.094\n0.029\n0.063\n0.25\n0.372\n0.211\n0.079\n0.151\n0.054\n0.102\n0.1\n0.442\n0.340\n0.146\n0.229\n0.092\n0.203\nTable 1:\nROC area L1 error (median) for both SMS and\nTWITTER datasets based on all possible thresholds\ncuracy begin to approach the majority classi\ufb01er as the total budget\nis reduced to 0.1.\n5.2\nPrivate Evaluation\nWe use the held out test sets of the SMS and TWITTER datasets\nwhich come from the previous section. SMS test set contains 558\ndata, and each tuple t has a true label t[L] \u2208{0, 1} as well as a\nprediction p(t) \u2208[0, 1] for the label 1. In SMS, 481 out of 558\ndata have true label equals 1. The TWITTER test dataset contains\n684 different tuples, 385 of which have label equal to 1.\nFigure 6 shows the real ROC curves as well as the differentially\nprivate ROC curves for both SMS and TWITTER datasets under 4\ndifferent privacy budgets by using k-RECURSIVEMEDIANS. Re-\ncall that, in k-RECURSIVEMEDIANS, \u01eb1 privacy budget is used for\nselecting a set of thresholds, and \u01eb2 = \u01eb \u2212\u01eb1 is used for generating\nthe ROC curve. We set \u01eb1 = 0.2\u01eb.\nThe solid line refers to the real ROC curve, while the dashed line\nrepresents the differentially private ROC curve. When the privacy\nbudget is not small (\u01eb = 1), the private ROC curve is very close\nto the real ROC curve, which means our private ROC curve is a\ngood replacement of the real ROC curve, correctly re\ufb02ecting the\nperformance of the input classi\ufb01er.\n9\n1.0\n0.5\n0.25\n0.1\nTotal Budget\n0.45\n0.50\n0.55\n0.60\n0.60\nAccuracy\nMajority Classifier\nAll - Sample\nTotal: 500\nCluster\nThreshold\n(a) Twitter Budget\n1.0\n0.5\n0.25\n0.1\nTotal Budget\n0.65\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nAccuracy\nMajority Classifier\nAll - Sample\nTotal: 500\nCluster\nThreshold\n(b) SMS Budget\n1.0\n0.5\n0.25\n0.1\nTotal Budget\n0.45\n0.50\n0.55\n0.60\n0.60\nAccuracy\nMajority Classifier\nAll - Sample\nTotal: 500\nCluster\nThreshold\n(c) Reuters Budget\nFigure 4: Accuracy of the system versus total budget selection.\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nPortion of budget for selection\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\nAccuracy\n(a) Twitter Budget\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nPortion of budget for selection\n0.80\n0.82\n0.84\n0.86\n0.88\n0.90\n0.92\n0.94\nAccuracy\n(b) SMS Budget\n0\n5\n10\n15\n20\nSampling Rate\n0.60\n0.65\n0.70\n0.75\n0.80\n0.85\nAccuracy\n(c) Twitter Sampling Rate\n0\n5\n10\n15\n20\nSampling Rate\n0.80\n0.82\n0.84\n0.86\n0.88\n0.90\n0.92\n0.94\nAccuracy\n(d) SMS Sampling Rate\nFigure 5: Tuning the budget split (without sampling) and sampling rate (with a 50% budget split).\nFigure 7 reports the comparison of the errors among three differ-\nent algorithms. The Laplace line refers to the error by directly using\nLaplace Mechanism using t thresholds (that can be chosen based on\nthe data). The FixedSpace line shows the error of \u03b1-FIXEDSPACE,\nwith \u03b1 \u00b7 n thresholds chosen uniformly in [0, 1].\nAnd the line\nRecursiveMedians presents the error of k-RECURSIVEMEDIANS,\nwith 2k thresholds. The x-axis corresponds to \u01eb and the y-axis cor-\nresponds to the L1 error of the area between the real ROC curve\nand the private ROC curve under certain privacy budget. The error\nshows the median value after running our algorithm 10 times. The\nreason why we pick the median error instead of the average value\nis to counter the effect of outliers.\nTo understand the effect of choosing differing numbers of thresh-\nolds, we choose \u03b1 = 1, 0.5, 0.25 and 0.125. The ensure that the\nnoise introduced is roughly the same in all algorithms, we vary t\nand k as 10, 9, 8 and 7. For instance, for \u03b1 = 1 and t, k = 10, we\nhave O(n) thresholds for \u03b1-FIXEDSPACE and k-RECURSIVEMEDIANS\n(29 \u2264n \u2264210 for the SMS and TWITTER datasets), and O(log n)\nthresholds for Laplace.\nIn \ufb01gure 7, we can see that k-RECURSIVEMEDIANS and \u03b1-\nFIXEDSPACE can largely improve the accuracy of the output com-\npared with directly using Laplace Mechanism under all \u01eb and \u03b1 set-\ntings. The difference in error is largest for small epsilon. Although\nthe noise scale is the same for the three methods in each experi-\nment, since the number of thresholds is very small the LaplaceROC\ncurve can\u2019t hope to approximate the true ROC curve well enough.\nFurthermore, for both datasets, the k-RECURSIVEMEDIANSmethod\nperforms better than \u03b1-FIXEDSPACE method under nearly all pa-\nrameter settings, which means computing noisy quantiles help choose\nthe right set of thresholds.\nTable 1 represents the graphs in Figure 7 for t, k = 10 and \u03b1 = 1\nin tabular form. It is interesting to note that k-RECURSIVEMEDIANS\n 0\n 0.05\n 0.1\n 0.15\n 0.2\n 0.25\n 0.3\n 0.35\n 0.4\n10\n9\n8\n7\nError\nk\nepsilon = 1\nepsilon = 0.5\nepsilon = 0.25\nepsilon = 0.1\n 0\n 0.05\n 0.1\n 0.15\n 0.2\n 0.25\n 0.3\n 0.35\n 0.4\n10\n9\n8\n7\nError\nk\nepsilon = 1\nepsilon = 0.5\nepsilon = 0.25\nepsilon = 0.1\nFigure 8: Number of thresholds: SMS (left) and TWITTER\n(right) datasets, based on all \u01eb\nhas 10 times lower error than Laplace for \u01eb = 1 on SMS.\n5.2.1\nChoosing the number of thresholds\nThe value of \u03b1 in \u03b1-FIXEDSPACE and k in k-RECURSIVEMEDIANS\ndetermines the number of thresholds we will use to compute ROC\ncurve. It will affect three different aspects. First, the bigger size\nof thresholds, the better we ca hope to approximate the true ROC\ncurve. Second, larger threshold sets result in larger noise being\nused to perturb T PRs and FPRs. Third, the last step of our al-\ngorithm is to do postprocessings in order to maintain consistency\nand its relationship to \u03b1, k is not very clear. Our goal is to pick the\nvalue of \u03b1, k which lead to the best trade off.\nFigure 8 presents the comparions of the errors for k-RECURSIVEMEDIANS\namong different choies for k under all \u01eb values. The x-axis show\n4 different settings for k. We can see that for both datasets, there\nis no speci\ufb01c setting of k that leads to the best performance of k-\nRECURSIVEMEDIANS for all \u01eb settings. The graph looks similar\nfor \u03b1-FIXEDSPACE (not shown).\n10\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\nTrue Positive Rate\nFalse Positive Rate\nTrue\nDP:epsilon = 1\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\nTrue Positive Rate\nFalse Positive Rate\nTrue\nDP:epsilon = 0.5\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\nTrue Positive Rate\nFalse Positive Rate\nTrue\nDP:epsilon = 0.25\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\nTrue Positive Rate\nFalse Positive Rate\nTrue\nDP:epsilon = 0.1\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\nTrue Positive Rate\nFalse Positive Rate\nTrue\nDP:epsilon = 1\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\nTrue Positive Rate\nFalse Positive Rate\nTrue\nDP:epsilon = 0.5\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\nTrue Positive Rate\nFalse Positive Rate\nTrue\nDP:epsilon = 0.25\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\n 0\n 0.2\n 0.4\n 0.6\n 0.8\n 1\nTrue Positive Rate\nFalse Positive Rate\nTrue\nDP:epsilon = 0.1\nFigure 6: True & Private ROC curves, SMS (above) and TWITTER (below) datasets, \u01eb = 1, 0.5, 0.25 and 0.1 (left to right)\n 0\n 0.1\n 0.2\n 0.3\n 0.4\n 0.5\n 0.6\n 0.7\n1.0\n0.5\n0.25\n0.1\nError\nEpsilon\nLaplace(t=10)\nFixedSpace(alpha = 1)\nRecursiveMedians(k=10)\n 0\n 0.1\n 0.2\n 0.3\n 0.4\n 0.5\n 0.6\n 0.7\n1.0\n0.5\n0.25\n0.1\nError\nEpsilon\nLaplace(t=9)\nFixedSpace(alpha = 1/2)\nRecursiveMedians(k=9)\n 0\n 0.1\n 0.2\n 0.3\n 0.4\n 0.5\n 0.6\n 0.7\n1.0\n0.5\n0.25\n0.1\nError\nEpsilon\nLaplace(t=8)\nFixedSpace(alpha = 1/4)\nRecursiveMedians(k=8)\n 0\n 0.1\n 0.2\n 0.3\n 0.4\n 0.5\n 0.6\n 0.7\n1.0\n0.5\n0.25\n0.1\nError\nEpsilon\nLaplace(t=7)\nFixedSpace(alpha = 1/8)\nRecursiveMedians(k=7)\n 0\n 0.1\n 0.2\n 0.3\n 0.4\n 0.5\n 0.6\n 0.7\n1.0\n0.5\n0.25\n0.1\nError\nEpsilon\nLaplace(t=10)\nFixedSpace(alpha = 1)\nRecursiveMedians(k=10)\n 0\n 0.1\n 0.2\n 0.3\n 0.4\n 0.5\n 0.6\n 0.7\n1.0\n0.5\n0.25\n0.1\nError\nEpsilon\nLaplace(t=9)\nFixedSpace(alpha = 1/2)\nRecursiveMedians(k=9)\n 0\n 0.1\n 0.2\n 0.3\n 0.4\n 0.5\n 0.6\n 0.7\n1.0\n0.5\n0.25\n0.1\nError\nEpsilon\nLaplace(t=8)\nFixedSpace(alpha = 1/4)\nRecursiveMedians(k=8)\n 0\n 0.1\n 0.2\n 0.3\n 0.4\n 0.5\n 0.6\n 0.7\n1.0\n0.5\n0.25\n0.1\nError\nEpsilon\nLaplace(t=7)\nFixedSpace(alpha = 1/8)\nRecursiveMedians(k=7)\nFigure 7: Error Comparison, SMS (above) and TWITTER (below) datasets\nThus, it seems best to set k = \u2308log n\u2309. The following is one pos-\nsible reason for the AUC error not depending on k: One may pick\na small number of thresholds to reduce the noise if the true ROC\ncurve can be accurately described using a small number of points.\nBut in this case, the postprocessing step that enforces monotonicity\nresults in error that has a strong dependence on the number of dis-\ntinct T PR and FPR values, and not the total number of thresholds\n(see Theorem 2 [14]).\n6.\nRELATED WORK\nDifferentially Private Classi\ufb01ers: Private models for classi\ufb01ca-\ntion has been a popular area of exploration for privacy research.\nPrevious work has produced differentially private training algo-\nrithms for Naive Bayes classi\ufb01cation [25], decision trees [9, 15],\nlogistic regression [2, 30] and support vector machines [2] amongst\nothers. Apart from classi\ufb01er training, Chaudhuri el al. [26] present\na generic algorithm for differentially private parameter tuning and\nmodel selection. However, this work does not assume a blackbox\nclassi\ufb01er, and makes strong stability assumptions about the training\nalgorithm. In contrast, our algorithms are classi\ufb01er agnostic. Addi-\ntionally Thakurtha et al. [24] present an algorithm for model selec-\ntion again assuming strong stability assumptions about the model\ntraining algorithm. We would like to note that the work in these pa-\nper is in some sense orthogonal to the feature selection algorithms\nwe present, and can be used in conjunction with the results in the\npaper (for instance, to choose the right threshold \u03c4 or the right num-\nber of features to select).\nPrivate Threshold Testing: As mentioned before, private thresh-\nold testing (PTT) is inspired by the sparse vector technique (SVT)\n[13] which was \ufb01rst used in the context of the multiplicative weights\nmechanism [12]. While PTT aims to only release whether or not\na query answer is greater than a threshold, SVT releases the actual\nanswers that are above the threshold and thus can only release a\nconstant number of answers. Lee et al [17] solve the same problem\nas PTT in the context of frequent itemset mining. The propose an\n11\nalgorithm NOISYCUT which we show is inferior to PTT. While the\ntechniques for proving the privacy of all these techniques are simi-\nlar, our proof for PTT is the tightest thus allowing us only add noise\nto the threshold and get the best utility (amongst competitors) for\nanswering comparison queries.\nPrivate Evaluation: Receiver operating characteristic (ROC) curves\nare used quantifying the prediction accuracy of binary classi\ufb01ers.\nHowever, directly releasing the ROC curve may reveal the sensi-\ntive information of the input dataset [19]. In this paper, we propose\nthe \ufb01rst differentially private algorithm for generating private ROC\ncurves under differential privacy. Chaudhuri et al [26] proposes a\ngeneric technique for evaluating a classi\ufb01er on a private test set.\nHowever, they assume that the global sensitivity of the evaluation\nalgorithm is low. Hence, their work will not apply to generating\nROC curves, since the suf\ufb01cient statistics for generating the ROC\ncurve (the set of true and false positive counts) have a high global\nsensitivity. Despite this high sensitivity, we present strategies that\ncan privately compute ROC curves with very low noise by model-\ning the suf\ufb01cient statistics as one-sided range queries.\n7.\nCONCLUSIONS\nIn this paper, we presented algorithms that can aid the adoption\nof differentially private methods for classi\ufb01er training on private\ndata. We present novel algorithms for private feature selection and\nexperimentally show using three real high dimensional datasets that\nspending a part of the privacy budget for feature selection can im-\nprove the prediction accuracy of the classi\ufb01er trained on the se-\nlected features. Moreover, we also solve the problem of privately\ngenerating ROC curves. This allows a user to quantify the predic-\ntion accuracy of a binary classi\ufb01er on a private test dataset. In con-\njunction, these algorithms can now allow a data analyst to mimic\ntypical \u2018big-data\u2019 work\ufb02ows that (a) preprocess the data (i.e., select\nfeatures), (b) build a model (i.e., train a classi\ufb01er), and (c) evaluate\nthe model on a held out test set (i.e., generate an ROC curve) on\nprivate data while ensuring differential privacy without sacri\ufb01cing\ntoo much accuracy.\n8.\nREFERENCES\n[1] T. A. Almeida, J. M. G. Hidalgo, and T. P. Silva. Towards sms spam\n\ufb01ltering: Results under a new dataset. International Journal of\nInformation Security Science, pages 1\u201318, 2012.\n[2] A. and Sarwate and K. Chaudhuri. Differentially Private Empirical\nRisk Minimization. CoRR, abs/0912.0, 2009.\n[3] C. M. Bishop. Pattern Recognition and Machine Learning\n(Information Science and Statistics). Springer-Verlag New York, Inc.,\nSecaucus, NJ, USA, 2006.\n[4] A. Blum, C. Dwork, F. McSherry, and K. Nissim. Practical privacy:\nThe sulq framework. PODS \u201905, pages 128\u2013138, New York, NY,\nUSA, 2005. ACM.\n[5] M. Dash and H. Liu. Feature selection for classi\ufb01cation. Intelligent\nData Analysis, 1:131\u2013156, 1997.\n[6] C. Dwork. Differential privacy. In in ICALP, pages 1\u201312. Springer,\n2006.\n[7] C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise\nto sensitivity in private data analysis. TCC\u201906, pages 265\u2013284,\nBerlin, Heidelberg, 2006. Springer-Verlag.\n[8] M. Fredrikson, E. Lantz, S. Jha, S. Lin, D. Page, and T. Ristenpart.\nPrivacy in pharmacogenetics: An end-to-end case study of\npersonalized warfarin dosing. SEC\u201914, pages 17\u201332, Berkeley, CA,\nUSA, 2014. USENIX Association.\n[9] A. Friedman and A. Schuster. Data mining with differential privacy.\nKDD \u201910, pages 493\u2013502, New York, NY, USA, 2010. ACM.\n[10] A. Go, R. Bhayani, and L. Huang. Twitter sentiment classi\ufb01cation\nusing distant supervision. CS224N Project Report, Stanford, pages\n1\u201312, 2009.\n[11] I. Guyon, S. Gunn, M. Nikravesh, and L. A. Zadeh. Feature\nExtraction: Foundations and Applications (Studies in Fuzziness and\nSoft Computing). Springer-Verlag New York, Inc., 2006.\n[12] M. Hardt and G. N. Rothblum. A multiplicative weights mechanism\nfor privacy-preserving data analysis. In In FOCS, pages 61\u201370, 2010.\n[13] M. A. W. Hardt. A Study of Privacy and Fairness in Sensitive Data\nAnalysis. PhD thesis, MIT, 2011.\n[14] M. Hay, V. Rastogi, G. Miklau, and D. Suciu. Boosting the accuracy\nof differentially private histograms through consistency. Proc. VLDB\nEndow., 3(1-2):1021\u20131032, Sept. 2010.\n[15] G. Jagannathan. A Practical Differentially Private Random Decision\nTree Classi\ufb01er. Trans. Data Privacy, 5(1):273\u2013295, 2012.\n[16] G. Kellaris and S. Papadopoulos. Practical differential privacy via\ngrouping and smoothing. Proc. VLDB Endow., 6(5):301\u2013312, Mar.\n2013.\n[17] J. Lee and C. W. Clifton. Top-k frequent itemsets via differentially\nprivate fp-trees. KDD \u201914, pages 931\u2013940, New York, NY, USA,\n2014. ACM.\n[18] C. Li, M. Hay, G. Miklau, and Y. Wang. A data- and workload-aware\nalgorithm for range queries under differential privacy.\n[19] G. J. Matthews and O. Harel. An examination of data con\ufb01dentiality\nand disclosure issues related to publication of empirical roc curves.\nvolume 20, pages 889\u2013896. Elsevier, 2013.\n[20] F. McSherry and K. Talwar. Mechanism design via differential\nprivacy. FOCS \u201907, pages 94\u2013103, Washington, DC, USA, 2007.\nIEEE Computer Society.\n[21] K. Nissim, S. Raskhodnikova, and A. Smith. Smooth sensitivity and\nsampling in private data analysis. STOC \u201907, pages 75\u201384, New\nYork, NY, USA, 2007. ACM.\n[22] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion,\nO. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg,\nJ. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and\nE. Duchesnay. Scikit-learn: Machine learning in Python. Journal of\nMachine Learning Research, 12:2825\u20132830, 2011.\n[23] A. D. Sarwate, K. Chaudhuri, and C. Monteleoni. Differentially\nprivate support vector machines. CoRR, abs/0912.0071, 2009.\n[24] A. G. Thakurta and A. Smith. Differentially private feature selection\nvia stability arguments, and the robustness of the lasso. In\nConference on Learning Theory, pages 819\u2013850, 2013.\n[25] J. Vaidya, B. Sha\ufb01q, A. Basu, and Y. Hong. Differentially private\nnaive bayes classi\ufb01cation. WI-IAT \u201913, pages 571\u2013576, Washington,\nDC, USA, 2013. IEEE Computer Society.\n[26] Q. Xiao, R. Chen, and K.-L. Tan. Differentially private network data\nrelease via structural inference. KDD \u201914, pages 911\u2013920, New York,\nNY, USA, 2014. ACM.\n[27] X. Xiao, G. Wang, and J. Gehrke. Differential privacy via wavelet\ntransforms. volume 23, pages 1200\u20131214, Piscataway, NJ, USA,\nAug. 2011. IEEE Educational Activities Department.\n[28] J. Xu, Z. Zhang, X. Xiao, Y. Yang, and G. Yu. Differentially private\nhistogram publication. ICDE \u201912, pages 32\u201343, Washington, DC,\nUSA, 2012. IEEE Computer Society.\n[29] J. Zhang, G. Cormode, C. M. Procopiuc, D. Srivastava, and X. Xiao.\nPrivbayes: Private data release via bayesian networks. SIGMOD \u201914,\npages 1423\u20131434, New York, NY, USA, 2014. ACM.\n[30] J. Zhang, X. Xiao, Y. Yang, Z. Zhang, and M. Winslett. Privgene:\nDifferentially private model \ufb01tting using genetic algorithms. In\nSIGMOD, pages 665\u2013676, 2013.\n12\nAPPENDIX\nA.\nPROOF OF THEOREM 2\nPROOF. For any two neighboring datasets D and D\u2032, we would\nlike to show:\nP(vD \u2192\u02c6v)\nP(vD\u2032 \u2192\u02c6v)\n\u2264\ne2\u03c3\u01eb\nwhere vD and vD\u2032 denote the outputs of the non private threshold\ntest on D and D\u2032 resp., and \u02c6v is the output of PTT. Let N 1 = {i \u2208\n[m] |\u02c6v[i] = 1} and N 0 = {i \u2208[m] |\u02c6v[i] = 0} denote the set of 1\nand 0 answers resp. of PTT. Let \u02c6v[< i] denote the answers returned\nby PTT for queries 1 through i \u22121. Then\nP(vD \u2192\u02c6v)\nP(vD\u2032 \u2192\u02c6v) =\nY\ni\u2208[m]\nP(Qi(D) = \u02c6v[i] | \u02c6v[< i])\nP(Qi(D\u2032) = \u02c6v[i] | \u02c6v[< i])\n=\nY\ni\u2208N1\nP(Qi(D) = 1 | \u02c6v[< i])\nP(Qi(D\u2032) = 1 | \u02c6v[< i]) \u00d7\nY\ni\u2208N0\nP(Qi(D) = 0 | \u02c6v[< i])\nP(Qi(D\u2032) = 0 | \u02c6v[< i])\nY\ni\u2208N1\nP(Qi(D) = 1 | \u02c6v[< i])\n=\nZ\nz\nP(\u02dc\u03c4 = z)\nY\ni\u2208N1\nP(Qi(D) = 1 | \u02dc\u03c4 = z)dz\n=\nZ\nz\nP(\u02dc\u03c4 = z)\nY\ni\u2208N1\nP(Qi(D) > z)dz\nThe following two facts complete the proof. First, for any z,\nP(\u02dc\u03c4 = z) \u2264e\u03c3\u01ebP(\u02dc\u03c4 = z \u2212\u03c3)\n(8)\nSecond, for neighboring databases D and D\u2032,\nQi(D) \u2265z\n\u21d2\nQi(D\u2032) \u2265z \u2212\u03c3\nP(Qi(D) \u2265z)\n\u2264\nP(Qi(D\u2032) \u2265z \u2212\u03c3)\n(9)\nTherefore, we get:\nY\ni\u2208N1\nP(Qi(D) = 1 | \u02c6v[< i])\n=\nZ\nz\nP(\u02dc\u03c4 = z)\nY\ni\u2208N1\nP(Qi(D) > z)dz\n\u2264\ne\u03c3\u01eb\nZ\nz\nP(\u02dc\u03c4 = z \u2212\u03c3)\nY\ni\u2208N1\nP(Qi(D\u2032) > z \u2212\u03c3)dz\n=\ne\u03c3\u01eb Y\ni\u2208N1\nP(Qi(D\u2032) = 1 | \u02c6v[< i])\nAn analogous proof for N 0 gives the required bound of e2\u03c3\u01eb.\n13\n",
        "sentence": "",
        "context": "1\u201312, 2009.\n[11] I. Guyon, S. Gunn, M. Nikravesh, and L. A. Zadeh. Feature\nExtraction: Foundations and Applications (Studies in Fuzziness and\nSoft Computing). Springer-Verlag New York, Inc., 2006.\n(Information Science and Statistics). Springer-Verlag New York, Inc.,\nSecaucus, NJ, USA, 2006.\n[4] A. Blum, C. Dwork, F. McSherry, and K. Nissim. Practical privacy:\nThe sulq framework. PODS \u201905, pages 128\u2013138, New York, NY,\nUSA, 2005. ACM.\nInformation Security Science, pages 1\u201318, 2012.\n[2] A. and Sarwate and K. Chaudhuri. Differentially Private Empirical\nRisk Minimization. CoRR, abs/0912.0, 2009.\n[3] C. M. Bishop. Pattern Recognition and Machine Learning"
    },
    {
        "title": "Signal detection theory in the 2AFC paradigm: attention, channel uncertainty and probability summation",
        "author": [
            "C. Tyler",
            "Chen",
            "C.-C."
        ],
        "venue": "Vision Research 40(22):3121\u20133144.",
        "citeRegEx": "Tyler et al\\.,? 2000",
        "shortCiteRegEx": "Tyler et al\\.",
        "year": 2000,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": "",
        "context": null
    },
    {
        "title": "Exploiting an oracle that reports AUC scores in machine learning contests",
        "author": [
            "J. Whitehill"
        ],
        "venue": "AAAI, 1345\u20131351.",
        "citeRegEx": "Whitehill,? 2016",
        "shortCiteRegEx": "Whitehill",
        "year": 2016,
        "abstract": "In machine learning contests such as the ImageNet Large Scale Visual\nRecognition Challenge and the KDD Cup, contestants can submit candidate\nsolutions and receive from an oracle (typically the organizers of the\ncompetition) the accuracy of their guesses compared to the ground-truth labels.\nOne of the most commonly used accuracy metrics for binary classification tasks\nis the Area Under the Receiver Operating Characteristics Curve (AUC). In this\npaper we provide proofs-of-concept of how knowledge of the AUC of a set of\nguesses can be used, in two different kinds of attacks, to improve the accuracy\nof those guesses. On the other hand, we also demonstrate the intractability of\none kind of AUC exploit by proving that the number of possible binary labelings\nof $n$ examples for which a candidate solution obtains a AUC score of $c$ grows\nexponentially in $n$, for every $c\\in (0,1)$.",
        "full_text": "Exploiting an Oracle that Reports AUC Scores\nin Machine Learning Contests\nJacob Whitehill\nOf\ufb01ce of the Vice Provost for Advances in Learning\nHarvard University\njacob whitehill@harvard.edu\nMarch 22, 2015\nAbstract\nIn machine learning contests such as the ImageNet Large Scale Visual Recognition Challenge [RDS+15]\nand the KDD Cup, contestants can submit candidate solutions and receive from an oracle (typically the\norganizers of the competition) the accuracy of their guesses compared to the ground-truth labels. One of\nthe most commonly used accuracy metrics for binary classi\ufb01cation tasks is the Area Under the Receiver\nOperating Characteristics Curve (AUC). In this paper we provide proofs-of-concept of how knowledge\nof the AUC of a set of guesses can be used, in two different kinds of attacks, to improve the accuracy\nof those guesses. On the other hand, we also demonstrate the intractability of one kind of AUC exploit\nby proving that the number of possible binary labelings of n examples for which a candidate solution\nobtains a AUC score of c grows exponentially in n, for every c \u2208(0, 1).\nIntroduction\nMachine learning and data-mining competitions such as the ImageNet Large Scale Visual Recognition Challenge\n[RDS+15], KDD Cup [KDD15], and Facial Expression Recognition and Analysis (FERA) Challenge [VGA+15] have\nhelped to advance the state-of-the-art of machine learning, deep learning, and computer vision research. By establish-\ning common benchmarks and setting a clearer boundary between training and testing datasets \u2013 participants typically\nnever gain access to the testing labels directly \u2013 these competitions help researchers to estimate the performance of\ntheir classi\ufb01ers more reliably. However, the bene\ufb01t of such contests depends on the integrity of the competition and the\ngeneralizability of performance to real-world contexts. If contestants could somehow \u201chack\u201d the competition to learn\nillegitimately the labels of the test set and increase their scores, then the value of the contest would diminish greatly.\nOne potential window that data-mining contestants could exploit is the accuracy \u201coracle\u201d set up by the competition\norganizers to give contestants a running estimate of their classi\ufb01er\u2019s performance: In many data-mining contests (e.g.,\nthose organized by Kaggle), contestants may submit, up to a \ufb01xed maximum number of times per day, a set of guesses\nfor the labels in the testing set. The oracle will then reply with the accuracy of the contestant\u2019s guesses on a (possibly\nrandomized) subset of the test data. There are several ways in which these oracle answers can be exploited, including:\n(1) If some contestants were able to circumvent the daily maximum number of accuracy queries they can submit to the\noracle (e.g., by illegally registering multiple accounts on the competition\u2019s website), then they could use those extra\noracle responses to perform additional parameter or hyperparameter optimization over the test set and potentially gain\na competitive edge. (2) The accuracy reported by the oracle, even though it is an aggregate performance metric over\nthe entire test set (or a large subset), could convey information about the labels of individual examples in the test set.\nContestants could use this information to re\ufb01ne their guesses about the test labels. Given that the difference in accuracy\nbetween contestants is often tiny \u2013 in KDD Cup 2015, for example, the #1 and #2 contestants\u2019 accuracies differed by\n0.0003 AUC [KDD15] \u2013 even a small edge achieved by exploiting the AUC oracle can be perceived as worthwhile.\nTo date, attacks of type (1) have already been implemented and documented [Sim15]. However, to the best of\nour knowledge, attacks of type (2) have not previously been investigated. In this paper, we consider how an attacker\n1\narXiv:1506.01339v2  [cs.LG]  13 Nov 2015\ncould orchestrate attacks of type (2) on an oracle that reports the Area Under the Receiver Operating Characteristics\nCurve (AUC), which is one of the most common performance metrics for binary classi\ufb01ers. Speci\ufb01cally, we make the\nfollowing contributions:\n(a) We describe an attack whereby an attacker whose classi\ufb01er already achieves high AUC and who knows the\nprevalence of each class can use the oracle to infer the labels of a few test examples with complete certainty.\n(b) We provide a proof-of-concept of how the AUC score c of a set of guesses constrains the set of possible labelings\nof the entire test set, and how this information can be harnessed, using standard Bayesian inference, to improve\nthe accuracy of those guesses.\n(c) We show that a brute-force attack of type (b) above is computationally tractable only for very small datasets.\nSpeci\ufb01cally, we prove that the number of possible binary labelings of n examples for which a candidate solution\nobtains a AUC score of c grows exponentially in n, for every c \u2208(0, 1).\nAs the importance and prominence of data-mining competitions continue to increase, attackers will \ufb01nd more and\nmore ingenious methods of hacking them. The greater goal of this paper is to raise awareness of this potential danger.\nRelated Work\nOur work is related to the problem of data leakage, which is the inadvertent introduction of information about test\ndata into the training dataset of data-mining competitions. Leakage has been named one of the most important data-\nmining mistakes [MNEI09] and can be surprisingly insidious and dif\ufb01cult to identify and prevent [KBF+00, KRPS12].\nLeakage has traditionally been de\ufb01ned in a \u201cstatic\u201d sense, e.g., an artifact of the data preparation process that causes\ncertain features to reveal the target label with complete certainty. The exploitation of an AUC oracle can be seen as\na form of \u201cdynamic\u201d leakage: the oracle\u2019s AUC response during the competition to a set of guesses submitted by a\ncontestant can divulge the identity of particular test labels or at least constrain the set of possible labelings.\nOur research also relates to privacy-preserving machine learning and differential privacy (e.g., [Dwo11, CM09,\nBLR13]), which are concerned with how to provide useful aggregate statistics about a dataset \u2013 e.g., the mean value of\na particular attribute, or even a hyperplane to be used for classifying the data \u2013 without disclosing private information\nabout particular examples within the dataset. [SCM14], for example, proposed an algorithm for computing \u201cprivate\nROC\u201d curves and associated AUC statistics. The prior work most similar to ours is by [MH13], who show how an\nattacker who already knows most of the test labels can estimate the remaining labels if he/she gains access to an\nempirical ROC curve, i.e., a set of classi\ufb01er thresholds and corresponding true positive and false positive rates. In a\nsimulation on 100 samples, they show how a simple Markov-chain Monte Carlo algorithm can recover the remaining\n10% of missing test labels, with high accuracy, if 90% of the test labels are already known.\nROC, AUC, and 2AFC\nOne of the most common ways to quantify the performance of a binary classi\ufb01er is the Receiver Operating Charac-\nteristics (ROC) curve. Suppose a particular test set has ground-truth labels y1, . . . , yn \u2208{0, 1} and the classi\ufb01er\u2019s\nguesses for these labels are \u02c6y1, . . . , \u02c6yn \u2208R. For any \ufb01xed threshold \u03b8 \u2208R, the false positive rate of these guesses is\nFP(\u03b8) .=\n1\nn0\nP\ni\u2208Y\u2212I[\u02c6yi \u2265\u03b8] and the true positive rate is TP(\u03b8) .=\n1\nn1\nP\ni\u2208Y+ I[\u02c6yi \u2265\u03b8], where I[\u00b7] \u2208{0, 1} is an in-\ndicator function, Y\u2212= {i : yi = 0} and Y+ = {i : yi = 1} are the index sets of the negatively and positively labeled\nexamples, and n0 = |Y\u2212|, n1 = |Y+|. The ROC curve is constructed by plotting (FP(\u03b8), TP(\u03b8)) for all possible \u03b8.\nThe Area Under the ROC Curve (AUC) is then the integral of the ROC curve over the interval [0, 1].\nAn alternative but equivalent interpretation of the AUC [TC00, AGH+05], which we use in this paper, is that it\nis equal to the probability of correct response in a 2-Alternative Forced-Choice (2AFC) task, whereby the classi\ufb01er\u2019s\nreal-valued outputs are used to discriminate between one positively labeled and one negatively labeled example drawn\nfrom the set of all such pairs in the test set. If the AUC is 1, then the classi\ufb01er can discriminate between a positive\nand a negative example perfectly (i.e., with probability 1). A classi\ufb01er that guesses randomly has AUC of 0.5. Using\n2\nthis probabilistic de\ufb01nition, given the ground-truth labels y1:n .= y1, . . . , yn and the classi\ufb01er\u2019s real-valued guesses\n\u02c6y1:n .= \u02c6y1, . . . , \u02c6yn, we can de\ufb01ne the function f to compute the AUC of the guesses as:\nf(y1:n, \u02c6y1:n)\n.=\n1\nn0n1\nX\ni\u2208Y\u2212\nX\nj\u2208Y+\nI[\u02c6yi < \u02c6yj] + 1\n2I[\u02c6yi = \u02c6yj]\nIn this paper, we will assume that the classi\ufb01er\u2019s guesses \u02c6y1, . . . , \u02c6yn are all distinct (i.e., \u02c6yi = \u02c6yj \u21d0\u21d2i = j), which\nin many classi\ufb01cation problems is common. In this case, the formula above simpli\ufb01es to:\nf(y1:n, \u02c6y1:n)\n.=\n1\nn0n1\nX\ni\u2208Y\u2212\nX\nj\u2208Y+\nI[\u02c6yi < \u02c6yj]\n(1)\nAs is evident in Eq. 1, all that matters to the AUC is the relative ordering of the \u02c6yi, not their exact values. Also, if all\nexamples belong to the same class and either n1 = 0 or n0 = 0, then the AUC is unde\ufb01ned. Finally, the AUC is a\nrational number because it can be written as the fraction of two integers p and q. We use these facts later in the paper.\nExploiting the AUC Score: A Simple Example\nAs a \ufb01rst example of how knowing the AUC of a set of guesses can reveal the ground-truth test labels, consider a\nhypothetical tiny test set of just 4 examples such that yi \u2208{0, 1} is the ground-truth label for example i \u2208{1, 2, 3, 4}.\nSuppose a contestant estimates, through some machine learning process, that the probabilities that these examples\nbelong to the positive class are \u02c6y1 = 0.5, \u02c6y2 = 0.6, \u02c6y3 = 0.9, and \u02c6y4 = 0.4, and that the contestant submits these\nguesses to the oracle. If the oracle replies that these guesses have an AUC of 0.75, then the contestant can conclude\nwith complete certainty that the true solution is y1 = 1, y2 = 0, y3 = 1, and y4 = 0 because this is the only ground-\ntruth labeling satisfying Eq. 1 (see Table 1). The contestant can then revise his/her guesses based on the information\nreturned by the oracle and receive a perfect score. Interestingly, in this example, the fact that the AUC is 0.75 is\neven more informative than if the AUC of the initial guesses were 1, because the latter is satis\ufb01ed by three different\nground-truth labelings.\nThis simple example raises the question of whether knowledge of the AUC could be exploited in more general\ncases. In the next sections we explore two possible attacks that a contestant might wage.\nAttack 1: Deducing Highest/Lowest-Ranked Labels with Certainty\nIn this section we describe how a contestant, whose guesses are already very accurate (AUC close to 1), can orchestrate\nan attack to infer a few of the test set labels with complete certainty. This could be useful for several reasons: (1) Even\nthough the attacker\u2019s AUC is close to 1, he/she may not know the actual test set labels \u2013 see Table 1 for an example. If\nthe same test examples were ever re-used in a subsequent competition, then knowing their labels could be helpful. (2)\nOnce the attacker knows some of the test labels with certainty, he/she can now use these examples for training. This\ncan be especially bene\ufb01cial when the test set is drawn from a different population than the training set (e.g., different\nset of human subjects\u2019 face images [VJM+11]). (3) If multiple attackers all score a high AUC but have very different\nsets of guesses, then they could potentially collude to infer the labels of a large number of test examples.\nThe attack requires rather strong prior knowledge of the exact number of positive and negative examples in the test\nset (n1 and n0, respectively).\nProposition 1. Let D be a dataset with labels y1, . . . , yn, of which n0 are negative and n1 are positive. Let \u02c6y1, . . . , \u02c6yn\nbe a contestant\u2019s real-valued guesses for the labels of D such that \u02c6yi = \u02c6yj \u21d0\u21d2i = j. Let c = f(y1:n, \u02c6y1:n) denote\nthe AUC achieved by the real-valued guesses with respect to the ground-truth labels. For any positive integer k \u2264n0,\nif c > 1 \u2212\n1\nn1 +\nk\nn0n1 , then the \ufb01rst k examples according to the rank order of \u02c6y1, . . . , \u02c6yn must be negatively labeled.\nSimilarly, for any positive integer k \u2264n1, if c > 1 \u2212\n1\nn0 +\nk\nn0n1 , then the last k examples according to the rank order\nof \u02c6y1, . . . , \u02c6yn must be positively labeled.\n3\nAUC for different labelings\ny1\ny2\ny3\ny4\nAUC\n0\n0\n0\n0\n\u2013\n0\n0\n0\n1\n0.00\n0\n0\n1\n0\n1.00\n0\n0\n1\n1\n0.50\n0\n1\n0\n0\n\u22480.67\n0\n1\n0\n1\n0.25\n0\n1\n1\n0\n1.00\n0\n1\n1\n1\n\u22480.67\n1\n0\n0\n0\n\u22480.33\n1\n0\n0\n1\n0.00\n1\n0\n1\n0\n0.75\n1\n0\n1\n1\n\u22480.33\n1\n1\n0\n0\n0.50\n1\n1\n0\n1\n0.00\n1\n1\n1\n0\n1.00\n1\n1\n1\n1\n\u2013\nTable 1: Accuracy (AUC) achieved when a contestant\u2019s real-valued guesses of the test labels are \u02c6y1 = 0.5, \u02c6y2 =\n0.6, \u02c6y3 = 0.9, \u02c6y4 = 0.4, shown for each possible ground-truth labeling. Only for one possible labeling (highlighted)\ndo the contestant\u2019s guesses achieve AUC of exactly 0.75.\nProof. Without loss of generality, suppose that the indices are arranged such that the \u02c6yi are sorted, i.e., \u02c6y1 < . . . < \u02c6yn.\nSuppose, by way of contradiction, that m of the \ufb01rst k examples were positively labeled, where 1 \u2264m \u2264k. For each\nsuch possible m, we can \ufb01nd at least m(n0 \u2212k) pairs that are misclassi\ufb01ed according to the real-valued guesses by\npairing each of the m positively labeled examples within the index range {i : 1 \u2264i \u2264k} with each of (n0 \u2212k)\nnegatively labeled examples within the index range {j : k + 1 \u2264j \u2264n}. In each such pair (i, j), yi = 1 and yj = 0,\nand yet \u02c6yi < \u02c6yj, and thus the pair is misclassi\ufb01ed. The minimum number of misclassi\ufb01ed pairs, over all m in the\nrange {1, . . . , k}, is clearly n0 \u2212k (for m = 1). Since there are n0n1 total pairs in D consisting of one positive and\none negative example, and since the AUC is maximized when the number of misclassi\ufb01ed pairs is minimized, then the\nmaximum AUC that could be achieved when m \u22651 of the \ufb01rst k examples are positively labeled is\n1 \u2212n0 \u2212k\nn0n1\n= 1 \u22121\nn1\n+\nk\nn0n1\nBut this is less than c. We must therefore conclude that m = 0, i.e., all of the \ufb01rst k examples are negatively labeled.\nThe proof is exactly analogous for the case when c > 1 \u2212\n1\nn0 +\nk\nn0n1 .\nExample\nSuppose that a contestant\u2019s real-valued guesses \u02c6y1, . . . , \u02c6yn achieve an AUC of c = 0.985 on a dataset containing\nn0 = 45 negative and n1 = 55 positive examples, and that n0 and n1 are known to him/her. Then the contestant can\nconclude that the labels of the \ufb01rst (according to the rank order of \u02c6y1, . . . , \u02c6yn) 7 examples must be negative and the\nlabels of the last 17 examples must be positive.\nAttack 2: Integration over Satisfying Solutions\nThe second attack that we describe treats the AUC reported by the oracle as an observed random variable in a standard\nsupervised learning framework. In contrast to Attack 1, no prior knowledge of n0 or n1 is required. Note that the\n4\n\u1d9a\nX1\nXn\n\u01761\n\u0176n\n...\n...\nC\nY1\nYn\n...\nFeatures\nGuesses\nTrue labels\nAccuracy (AUC), \nreported by oracle\nClassifier \nparameter, learnt \non training data\nFigure 1: Without node C, this graphical model shows a standard supervised learning problem: after estimating \u03b8\n(on training data, not shown), the test labels Y1, . . . , Yn can be estimated from feature vectors X1, . . . , Xn, and then\nsubmitted to the organizers of the competition. Node C represents the contestant\u2019s accuracy (AUC), which is often\nprovided by an oracle and can be leveraged to improve the guesses for the test set labels. Only the shaded variables\nare observed.\nattack we describe uses only a single oracle query to improve an existing set of real-valued guesses. More sophisticated\nattacks might conceivably re\ufb01ne the contestant\u2019s guesses in an iterative fashion using multiple queries. Notation: In\nthis section only, capital letters denote random variables and lower-case letters represent instantiated values.\nConsider the graphical model of Fig. 1, which depicts a test set containing n examples where each example i is\ndescribed by a vector Xi \u2208Rm of m features (e.g., image pixels). Under the model, each label Yi \u2208{0, 1} is generated\naccording to P(Yi = 1 | xi, \u03b8) = g(xi, \u03b8), where g : Rm \u00d7 Rm \u2192[0, 1] could be, for example, the sigmoid function\nof logistic regression and \u03b8 \u2208Rm is the classi\ufb01er parameter. Note that this is a standard probabilistic discriminative\nmodel \u2013 the only difference is that we have created an intermediate variable \u02c6Yi \u2208[0, 1] to represent g(xi, \u03b8) explicitly\nfor each i. Speci\ufb01cally, we de\ufb01ne:\nP(\u02c6yi | xi, \u03b8)\n=\n\u03b4(\u02c6yi \u2212g(xi, \u03b8))\nP(Yi = 1 | \u02c6yi)\n=\n\u02c6yi\nwhere \u03b4 is the Dirac delta function.\nThe classi\ufb01cation parameter \u03b8 can be estimated from training data (not shown), and thus we consider it to be\nobserved. Using X1:n and an estimate for \u03b8, the contestant can then compute \u02c6Y1:n and submit these as his/her guesses\nto the competition organizers. The question is: if the competition allows access to an oracle that reports C (i.e., variable\nC is observed), how can this additional information be used? Since the AUC C is a deterministic function (Eq. 1) of\ny1:n and \u02c6y1:n, we have:\nP(c | y1:n, \u02c6y1:n) = \u03b4(f(y1:n, \u02c6y1:n) \u2212c)\nThen, according to standard Bayesian inference, the contestant can use C to update his/her posterior estimate of each\n5\nlabel Yi as follows:\nP(yi | \u02c6y1:n, c)\n=\nX\ny\u00aci\nP(y1:n | \u02c6y1:n, c)\nwhere y\u00aci refers to y1, . . . , yi\u22121, yi+1, . . . , yn.\n=\nX\ny\u00aci\nP(c | y1:n, \u02c6y1:n)P(y1:n | \u02c6y1:n)\nP(c | \u02c6y1:n)\n\u221d\nX\ny\u00aci\n\uf8ee\n\uf8f0P(c | y1:n, \u02c6y1:n)\nY\nj\nP(yj | \u02c6yj)\n\uf8f9\n\uf8fb\n=\nX\ny\u00aci\n\u03b4(f(y1:n, \u02c6y1:n) \u2212c)\nY\nj\nP(yj | \u02c6yj)\n=\nX\ny\u00aci :\nf(y1:n, \u02c6y1:n) = c\nY\nj\nP(yj | \u02c6yj)\n(2)\nIn other words, to compute the (unnormalized) posterior probability that Yi = yi given C = c, simply \ufb01nd all label\nassignments to the other variables Y1, . . . , Yi\u22121, Yi+1, . . . , Yn such that the AUC is c, and then compute the sum of\nthe likelihoods Q\nj P(yj | \u02c6yj) over all such assignments.\nSimulation\nAs a proof-of-concept of the algorithm described above, we conducted a simulation on a tiny dataset of n = 16\nexamples. In particular, we let g(x, \u03b8) = (1 + exp(\u2212\u03b8\u22a4x))\u22121 (sigmoid function for logistic regression), and we\nsampled \u03b8 and X1, . . . , Xn from an m-dimensional Normal distribution with zero mean and diagonal unit covariance.\nIn our simulations, the contestant does not know the value of \u03b8 but can estimate it from a training dataset containing\nk examples (with L2 regularization of 1). In each simulation, the contestant computes \u02c6Y1:n from its estimate of \u03b8 and\nthe feature vectors X1:n. The contestant then submits \u02c6Y1:n as guesses to the oracle, receives the AUC score C, and\nthen computes P(Y1 = 1 | \u02c6y1:n, c), . . . , P(Yn = 1 | \u02c6y1:n, c). The contestant then submits these posterior probabilities\nas its second set of guesses and receives an updated AUC score C\u2032. After each simulation run, we record the accuracy\ngain C\u2032 \u2212C. By varying k \u2208{1, . . . , 20}, m \u2208{4, 5, . . . , 16}, and averaging over 50 simulation runs per (m, k)\ncombination, we can then compute the expected accuracy gain \u2206AUC (i.e., C\u2032 \u2212C) as a function of the initial AUC\n(C).\nResults: The graph in Fig. 2 indicates that, for a wide range of starting AUC values C, a small but worthwhile\naverage increase in accuracy can be achieved, particularly when C is closer to 0.5.\nTractability\nIn the simulation above, we used a brute-force approach when solving Eq. 2: we created a list of all 2n possible binary\ntuples (y1, . . . , yn) and then simply selected those tuples that satis\ufb01ed f(y1:n, \u02c6y1:n) = c. However, if the number of\nsuch tuples were small, and if one could ef\ufb01ciently enumerate over them, then the attack would become much more\npractical. This raises an important question: for a dataset of size n and a \ufb01xed set of real-valued guesses \u02c6y1, . . . , \u02c6yn, are\nthere certain AUC values for which the number of possible binary labelings is sub-exponential in n? We investigate\nthis question in the next section.\n6\nFigure 2: Tiny simulation of how exploiting knowledge of the AUC of a set of guesses can improve accuracy, as a\nfunction of existing accuracy.\n1\n2\n...\n4q\n0\n...\n0\n1\n...\n1\n0\n...\n0\n0\n...\n0\n1\n...\n1\n2(2p-q)\nq\nq\n2(q-p)\n2(q-p)\nGuess \u0177\nLabel y\nRight band\nLeft band\nFigure 3: Construction of a binary labeling for which the AUC is c, for any c = p\nq such that 0.5 \u2264c < 1.\n7\nThe Number of Satisfying Solutions Grows Exponentially in n for Every AUC\nc \u2208(0, 1)\nIn this section we prove that the number of tuples (y1, . . . , yn) for which a contestant\u2019s guesses achieve a \ufb01xed AUC\nc grows exponentially in n, for every c \u2208(0, 1). (Note that this is different from proving that, for a dataset of some\n\ufb01xed size n, the number of tuples (y1, . . . , yn) for which a contestant\u2019s guesses achieve some AUC c is exponential in\nn.) Our proof is by construction: for any AUC c = p\nq , p, q \u2208Z+, p < q, we show how to construct a dataset of size\nn = 4q such that the number of satisfying binary labelings is at least (2 \u22122 |c \u22120.5|)n/4. Intuitively, this lower-bound\ngrows more quickly for AUC values close to 0.5 than for AUC values close to 0 or 1.\nFirst, we prove a simple lemma:\nLemma 1. Let a, b, c \u2208Z such that a > b > 0 and c \u22650. Then a+c\nb+c \u2264a\nb .\nProof. By way of contradiction, suppose a+c\nb+c > a\nb . Then\n(a + c)b\n>\na(b + c)\nab + bc\n>\nab + ac\nbc\n>\nac\nwhich implies b > a.\nProposition 2. Let D be a dataset consisting of n = 4q examples for some q \u2208Z+, and let \u02c6y1, . . . , \u02c6yn be a contestant\u2019s\nreal-valued guesses for the binary labels of D such that \u02c6yi = \u02c6yj\n\u21d0\u21d2\ni = j. Then for any AUC c such that\nc = p\nq , p, q \u2208Z+ and p < q, the number of distinct binary labelings y1, . . . , yn for which f(y1:n, \u02c6y1:n) = c is at least\n(2 \u22122 |c \u22120.5|)n/4.\nProof. Without loss of generality, suppose that the indices are arranged such that the \u02c6yi are sorted, i.e., \u02c6y1 < . . . < \u02c6yn.\nSince the AUC is invariant under monotonic transformations of the real-valued guesses, we can represent each \u02c6yi\nsimply by its index i. Since c is a fraction of pairs that are correctly classi\ufb01ed, we can write it as p/q for positive\nintegers p, q. We will handle the cases c \u22650.5 and c < 0.5 separately.\nCase 1 (0.5 \u2264c < 1): Construct a dataset of size n = 4q as shown in Fig. 3: the \ufb01rst 2(2p \u2212q) entries\nare negative examples, and of the remaining 2(3q \u22122p) entries (which we call the \u201cright band\u201d), 2q are positive\nand 4(q \u2212p) are negative. Moreover, the right band is arranged symmetrically in the following sense: for each i \u2208\n{2(2p \u2212q) + 1, . . . , 4q}, yi = 1 \u21d0\u21d2yj = 1 where j = 2(2p \u2212q) + (4q \u2212i + 1).\nGiven this construction, we must calculate how many pairs containing one positive and one negative example are\ncorrectly and incorrectly classi\ufb01ed. Note that each of the \ufb01rst 2(2p \u2212q) negative examples in the left band can be\npaired with each of the 2q positive examples in the right band, and that each of these positive examples has a higher\n\u02c6y value than the negative examples; hence, each of these 2q(2)(2p \u2212q) = 8pq \u22124q2 pairs is classi\ufb01ed correctly.\nThe only remaining pairs of examples occur within the right band. To calculate the number of correctly/incorrectly\nclassi\ufb01ed pairs in the right band, we exploit the fact that it is symmetric: For any index pair (i, j) where i, j \u2208\n{2(2p \u2212q) + 1, . . . , 4q}, where yi = 0 and yj = 1, and where i < j (and hence \u02c6yi < \u02c6yj), we can \ufb01nd exactly one\nother pair (i\u2032, j\u2032) for which yi\u2032 = 0 and yj\u2032 = 1 and for which i\u2032 > j\u2032. Hence, within the right band, the numbers of\ncorrectly and incorrectly classi\ufb01ed pairs are equal. Since there are 2q(4)(q \u2212p) = 8q2 \u22128pq pairs within this band\ntotal, then 4q2 \u22124pq are classi\ufb01ed correctly and 4q2 \u22124pq are classi\ufb01ed incorrectly.\nSumming the pairs of examples within the right band and the pairs between the left and right bands, we have\n8pq \u22124q2 + 8q2 \u22128pq = 4q2 pairs total. The number of correctly classi\ufb01ed pairs is 4q2 \u22124pq + 8pq \u22124q2 = 4pq,\nand thus the AUC is 4pq/(4q2) = p/q = c, as desired.\nNow that we have constructed a single labeling of size n = 4q for which the AUC is c, we can construct many\nmore simply by varying the positions of the 2q positive entries within the right band of 2(3q \u22122p) entries. To preserve\n8\nsymmetry, we can vary the positions of half of the positive examples within half of the right band and then simply\n\u201cre\ufb02ect\u201d the positions onto the other half. In total, the number of choices is:\n\u00123q \u22122p\nq\n\u0013\n=\n(3q \u22122p)!\nq!(3q \u22122p \u2212q)!\n=\n(3q \u22122p)!\nq!(2q \u22122p)!\n=\n(3q \u22122p)(3q \u22122p \u22121) \u00b7 \u00b7 \u00b7 (2q \u22122p + 2)(2q \u22122p + 1)\nq(q \u22121) \u00b7 \u00b7 \u00b7 (2)(1)\nWe now apply Lemma 1 and the fact that the numerator and denominator both contain q terms:\n\u00123q \u22122p\nq\n\u0013\n\u2265\n\u00123q \u22122p\nq\n\u0013q\n=\n\u00123q \u22122p\nq\n\u0013n/4\n=\n(3 \u22122c)n/4\nCase 2 (0 < c < 0.5): The proof is analogous except that we \u201c\ufb02ip\u201d the AUC around 0.5 and correspondingly \u201c\ufb02ip\u201d\nthe labels left-to-right. Let r = q \u2212p (so that r/q = 1 \u2212p/q). Then, we form a similar construction as above, except\nthat the left sequence of all negative examples is moved to the right. Speci\ufb01cally, we create a symmetric sequence of\nlength 2(3q \u22122r) such that 2q examples are positive and 4(q \u2212r) are negative. We then append 2(2r \u2212q) entries to\nthe right that are all negative. This results in\n1\n2 (2q \u00d7 4(q \u2212r)) = 4q2 \u22124qr\npairs that are classi\ufb01ed correctly and\n2(2r \u2212q) \u00d7 2q + 1\n2 (2q \u00d7 4(q \u2212r))\n=\n8qr \u22124q2 + 4q2 \u22124qr\n=\n4qr\npairs that are classi\ufb01ed incorrectly. In total, there are 4qr+4q2\u22124qr = 4q2 pairs, so that the AUC is (4q2\u22124qr)/4q2 =\n1 \u2212r/q = p/q, as desired.\n9\nAnalogously to above, we can form\n\u00123q \u22122r\nq\n\u0013\n=\n(3q \u22122r)!\nq!(2q \u22122r)!\n\u2265\n\u00123q \u22122r\nq\n\u0013n/4\n=\n\u00123q \u22122(q \u2212p)\nq\n\u0013n/4\n=\n\u0012q + 2p\nq\n\u0013n/4\n=\n(1 + 2c)n/4\nsymmetric constructions of the left band.\nCombining Case 1 and Case 2, we \ufb01nd that the number of binary labelings for which the AUC is c is at least\n(2 \u22122 |c \u22120.5|)n/4\nfor all 0 < c < 1.\nConclusion\nIn this paper we have examined properties of the Area Under the ROC Curve (AUC) that can enable a contestant of\na data-mining contest to exploit an oracle that reports AUC scores to illegitimately attain higher performance. We\npresented two simple attacks: one whereby a contestant whose guesses already achieve high accuracy can infer, with\ncomplete certainty, the values of a few of the test set labels; and another whereby a contestant can harness the oracle\u2019s\nAUC information to improve his/her guesses using standard Bayesian inference. To our knowledge, our paper is the\n\ufb01rst to formally investigate these kinds of attacks.\nThe practical implications of our work are mixed: On the one hand, we have provided proofs-of-concept that\nsystematic exploitation of AUC oracles is possible, which underlines the importance of taking simple safeguards such\nas (a) adding noise to the output of the oracle, (b) limiting the number of times that a contestant may query the oracle,\nand (c) not re-using test examples across competitions. On the other hand, we also provided evidence \u2013 in the form of\na proof that the number of binary labelings for which a set of guesses attains an AUC of c grows exponentially in the\ntest set size n \u2013 that brute-force probabilistic inference to improve one\u2019s guesses is intractable except for tiny datasets.\nIt is conceivable that some approximate inference algorithms might overcome this obstacle.\nAs data-mining contests continue to grow in number and importance, it is likely that more creative exploitation \u2013\ne.g., attacks that harness multiple oracle queries instead of just single queries \u2013 will be attempted. It is even possible\nthat the focus of effort in such contests might shift from developing effective machine learning classi\ufb01ers to querying\nthe oracle strategically, without training a useful classi\ufb01er at all. With our paper we hope to highlight an important\npotential problem in the machine learning community.\nReferences\n[AGH+05] Shivani Agarwal, Thore Graepel, Ralf Herbrich, Sariel Har-Peled, and Dan Roth. Generalization bounds\nfor the area under the ROC curve. In Journal of Machine Learning Research, pages 393\u2013425, 2005.\n[BLR13] Avrim Blum, Katrina Ligett, and Aaron Roth. A learning theory approach to noninteractive database pri-\nvacy. Journal of the ACM (JACM), 60(2):12, 2013.\n10\n[CM09]\nKamalika Chaudhuri and Claire Monteleoni. Privacy-preserving logistic regression. In Advances in Neural\nInformation Processing Systems, pages 289\u2013296, 2009.\n[Dwo11] Cynthia Dwork. Differential privacy. In HenkC.A. van Tilborg and Sushil Jajodia, editors, Encyclopedia of\nCryptography and Security, pages 338\u2013340. Springer US, 2011.\n[KBF+00] Ron Kohavi, Carla E Brodley, Brian Frasca, Llew Mason, and Zijian Zheng. Kdd-cup 2000 organizers\u2019\nreport: Peeling the onion. ACM SIGKDD Explorations Newsletter, 2(2):86\u201393, 2000.\n[KDD15] KDD Cup Organizers. https://www.kddcup2015.com/submission-rank.html, 2015.\n[KRPS12] Shachar Kaufman, Saharon Rosset, Claudia Perlich, and Ori Stitelman. Leakage in data mining: Formu-\nlation, detection, and avoidance. ACM Transactions on Knowledge Discovery from Data (TKDD), 6(4):15,\n2012.\n[MH13]\nGregory J Matthews and Ofer Harel. An examination of data con\ufb01dentiality and disclosure issues related\nto publication of empirical roc curves. Academic radiology, 20(7):889\u2013896, 2013.\n[MNEI09] Gary Miner, Robert Nisbet, and John Elder IV. Handbook of statistical analysis and data mining applica-\ntions. Academic Press, 2009.\n[RDS+15] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang,\nAndrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. ImageNet Large\nScale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), pages 1\u201342, April\n2015.\n[SCM14] Ben Stoddard, Yan Chen, and Ashwin Machanavajjhala. Differentially private algorithms for empirical\nmachine learning. CoRR, abs/1411.5428, 2014.\n[Sim15]\nTom Simonite. Why and how Baidu cheated an arti\ufb01cial intelligence test. MIT Technology Review, 6 2015.\n[TC00]\nC. Tyler and C.-C. Chen. Signal detection theory in the 2AFC paradigm: attention, channel uncertainty and\nprobability summation. Vision Research, 40(22):3121\u20133144, 2000.\n[VGA+15] M Valstar, J Girard, T Almaev, Gary McKeown, Marc Mehu, Lijun Yin, Maja Pantic, and J Cohn. Fera\n2015-second facial expression recognition and analysis challenge. Proc. IEEE ICFG, 2015.\n[VJM+11] Michel F. Valstar, Bihan Jiang, Marc M\u00b4ehu, Maja Pantic, and Klaus Scherer. The \ufb01rst facial expression\nrecognition and analysis challenge. In Proceedings of the IEEE International Conference on Automatic\nFace and Gesture Recognition, 2011.\n11\n",
        "sentence": " Recent work on privacy-preserving machine learning has considered how datamining competitions such as Kaggle could potentially be \u201chacked\u201d, either intentionally or inadvertently, by using information from an oracle that reports a classifier\u2019s accuracy on the test set (Blum and Hardt, 2015; Hardt and Ullman, 2014; Zheng, 2015; Whitehill, 2016). Recent research on privacy-preserving machine learning (Whitehill, 2016; Blum and Hardt, 2015; Zheng, 2015) has shown how information on the accuracy of a contestant\u2019s guesses, returned to the contestant by an oracle, can divulge information about the test data\u2019s true labels. Moreover, the recursive algorithm above can also be used constructively (though with large space costs) to compute the set of all binary vectors y of length n, of which n1 are 1, such that h(y, \u0177) = d for any d; conceivably, this could be useful for performing some kind of attack that uses the set of all compatible binary ground-truth vectors to improve the contestant\u2019s accuracy (Whitehill, 2016). , as part of some algorithmic attack to maximize performance within a datamining competition (Whitehill, 2016).",
        "context": "for the labels in the testing set. The oracle will then reply with the accuracy of the contestant\u2019s guesses on a (possibly\nrandomized) subset of the test data. There are several ways in which these oracle answers can be exploited, including:\nillegitimately the labels of the test set and increase their scores, then the value of the contest would diminish greatly.\nOne potential window that data-mining contestants could exploit is the accuracy \u201coracle\u201d set up by the competition\ncontestant can divulge the identity of particular test labels or at least constrain the set of possible labelings.\nOur research also relates to privacy-preserving machine learning and differential privacy (e.g., [Dwo11, CM09,"
    },
    {
        "title": "Toward a better understanding of leaderboard",
        "author": [
            "W. Zheng"
        ],
        "venue": "arXiv preprint arXiv:1510.03349.",
        "citeRegEx": "Zheng,? 2015",
        "shortCiteRegEx": "Zheng",
        "year": 2015,
        "abstract": "The leaderboard in machine learning competitions is a tool to show the\nperformance of various participants and to compare them. However, the\nleaderboard quickly becomes no longer accurate, due to hack or overfitting.\nThis article gives two pieces of advice to prevent easy hack or overfitting. By\nfollowing these advice, we reach the conclusion that something like the Ladder\nleaderboard introduced in [blum2015ladder] is inevitable. With this\nunderstanding, we naturally simplify Ladder by eliminating its redundant\ncomputation and explain how to choose the parameter and interpret it. We also\nprove that the sample complexity is cubic to the desired precision of the\nleaderboard.",
        "full_text": "Toward a Better Understanding of Leaderboard\nZHENG Wenjie\nAbstract\nThe leaderboard in machine learning competitions is a tool to show the performance of various\nparticipants and to compare them. However, the leaderboard quickly becomes no longer accu-\nrate, due to hack or over\ufb01tting. This article gives two pieces of advice to prevent easy hack or\nover\ufb01tting. By following these advice, we reach the conclusion that something like the Ladder\nleaderboard introduced in [1] is inevitable. With this understanding, we naturally simplify Ladder\nby eliminating its redundant computation and explain how to choose the parameter and interpret\nit. We also prove that the sample complexity is cubic to the desired precision of the leaderboard.\n1\nIntroduction\nMachine learning competitions have been a popular platform for young students to practice their\nknowledge, for scientists to apply their expertise, and for industries to solve their data mining problems.\nFor instance, the Internet streaming media company Net\ufb02ix held the Net\ufb02ix Prize competition in\n2006, to \ufb01nd a better program to predict user preferences. Kaggle, an online platform, hosts regularly\ncompetitions since 2010.\nThese competitions are usually prediction problems. The participant is given the independent variable\nX, and then he is required to predict the dependent variable Y . Usually, the host divides his data into\nthree data sets: training, validation and test. The training dataset is fully available: every participant\n(having a competition account) can download it and observe its Y as well as its X. This allows them\nto build their models. The validation data set is partially available to participants: they can only\nobserve its X. This dataset is used to construct the so-called leaderboard. The participants submit\ntheir prediction of Y to the host, and the host calculates their scores and ranks, and show them on the\nleaderboard, so that every participant could know his chance to win the competition. The test dataset\nis private. They are only used once at the \ufb01nal day to determine who is the \ufb01nal winner. Usually, the\nwinner gets a reward.\nThe reason that the \ufb01nal result is determined by the reserved test set instead of the validation set is\nbecause the validation set could be hacked. Since the participant could submit his prediction over and\nover during the life of the competition, he has much chance to improve his model\u2019s performance on\nthe validation set, either by over\ufb01tting or hacking. In consequence, by the \ufb01nal day, the score he gets\non the validation set may have been much higher than his model deserves. This is why it is frequently\nobserved that the \ufb01nal winner of the competition is not the \u201cwinner\u201d on the leaderboard.\nAlthough the leaderboard has no e\ufb00ect on the decision of the \ufb01nal winner, it could be quite annoying\nif it cannot truly re\ufb02ect the performance of each participant.\nFirstly, such a leaderboard allures\ninexperienced participants to over\ufb01t the validation set. Secondly, it encourages certain participants to\nhack the validation set in order to get a fake temporary honor or to disturb the order of the competition.\nThirdly, it is not a good experience to see one\u2019s non-over\ufb01tting model rank below someone hacking the\nvalidation set. It could be said that during the whole life of the competition, the participants compete\naround the leaderboard.\nIn view of this, some researchers tried to build an accurate leaderboard by preserving the accuracy of\nthe estimator of the loss function. This could be hard since the participant can modify their model\n1\narXiv:1510.03349v2  [stat.ML]  7 Jun 2017\nadaptively according to the feedback they get from the leaderboard. [2, 3] suggest that maintain-\ning accurate estimates on a sequence of many adaptively chosen classi\ufb01ers may be computationally\nintractable. In light of this, [1] proposes the Ladder mechanism to restrain the feedback that the\nparticipant could get from the leaderboard. The idea is that the participant gets a score if and only\nif this score is higher than the best among the past by some margin. By restraining the feedback, the\nparticipants have less information to adapt their models, and thus less chance to hack the leaderboard\nby over\ufb01tting the validation set.\nHowever, [1] fails to point out whether this kind of mechanism is necessary: does there exist any other\nmechanism that achieves the same or better e\ufb00ect? If we have to use Ladder, what is its strength and\nshortcoming? How well can we hack the leaderboard? Is is true that the \ufb01rst leader is better than the\nsecond? If so, then by how much? There are two parameters in Ladder: margin \u03b7 and precision \u03b7;\nwhat is their relationship? Does the heuristic way to choose \u03b7 provided in the paper have any theoretic\nguarantee? If the participant holds many accounts, is Ladder still e\ufb00ective?\nIn our paper, we answer these questions. A better understanding of the leaderboard will be achieved\nduring the reading of this article. First, we show that traditional leaderboard is easy to hack. In\nconsequence, something like Ladder mechanism is necessary. Then, we perform another hack to show\nthat a leaderboard cannot be arbitrarily accurate (Section 2). Afterwards, we recognize the essence\ninside the Ladder mechanism and thus simplify it (Section 3). Finally, we generalize the Theorem 3.1\nin [1] to take into consideration of the fact that each participant may be allowed to possess multiple\naccounts. And we slightly improve the upper bound as well (by eliminating the dependence on n in\nthe logarithmic factor). Our result shows that, while using Ladder mechanism, the leaderboard needs\n\u02dcO(M\u03f5\u22123) samples to control the error within \u03f5, where M is the number of accounts.1 This result\nsuggests that Ladder is relatively robust to number of submissions, but may still be vulnerable to\nnumber of accounts (Section 4). In this article, we study the binary classi\ufb01cation competition, but our\nresult can be straightforwardly generalized to other kinds of competitions.\nThe highlight of this article is that we are not advertising any \u201cmagic\u201d algorithm; we are just pursuing\na better understanding of the leaderboard. We depart from some basic property (robust against hacks\nand over\ufb01ttings) that a leaderboard should satisfy in order to protect its accuracy and fairness. We\nreach the conclusion that something like Ladder is inevitable. This understanding further allows us\nto eliminate the redundant computation in the origin Ladder, and to only retain its essence. We also\ngive an upper bound. But we do not stop there. We interpret this upper bound and use it as a tool\nto understand the advantages as well as limitation of Ladder when used in practice.\n2\nLeaderboard failure\nIn this sections, we show some examples where the leaderboard is hackable if it releases certain infor-\nmation. With these examples, we know at least what to avoid when building a leaderboard.\n2.1\nFull-information leaderboard is hackable\nIn this subsection, we show that if a leaderboard shows the score of each submission, this leaderboard\nis easy to hack.\nSupposing that the validation set contains n di\ufb00erent data points S = {(x1, y1), (x2, y2), . . . , (xn, yn)},\nwhere yi \u2208{0, 1} for each i.\nThe participant is expected to build a function f = f(x), so that\nf(x) is a good estimator of y. Let the score be the accuracy of this estimator, which is de\ufb01ned as\nscore(f) = 1\nn\nPn\ni=1 1{yi=f(xi)} on the validation set. Every time the participant submits his \u02c6yi = f(xi)\nto the host, the host shows the score of f to the participant via the leaderboard. We show that this\nkind of leaderboard is easy to hack.\n1 \u02dcO() stands for omitting the logarithm term.\n2\nFigure 1: Attack on various leaderboard (sample size: 1000). Blue: boosting attack on traditional\nleaderboard. Green: boosting attack on Ladder. Red: brute-force enumeration attack on parameter-\nfree Ladder. Blue curve can also be seen as if a hacker uses boosting with 1000 accounts to hack\nLadder leaderboard.\nTo hack this leaderboard, we perform a boosting attack.2 The idea is that if we have many independent\nsubmissions, whose accuracy are only a little higher than 0.5, then we can combine them via majority\nvote policy to construct a submission whose accuracy is much higher than 0.5.\nIn detail, we randomly pick a vector u \u2208{0, 1}n. If its accuracy is higher than 0.5, then we keep v = u,\nand otherwise v = 1n \u2212u. Having got m such vectors v1, v2, . . . , vm, we construct the submission\n\u02c6ym = (\u02c6ym\n1 , \u02c6ym\n2 , . . . , \u02c6ym\nn )T , where \u02c6ym\ni\nequals to 1, if\n1\nm\nPm\nj=1 vj\ni > 0.5, and equals to 0 otherwise.\nFigure 1 shows the result of this attack on a leaderboard of 1000 samples. We see that within 103\nsubmissions, the hacker\u2019s score climbs from 0.5 to 0.8 on the leaderboard.\nTherefore, in order to\nprotect the leaderboard from the boosting attack, we cannot release information each time there is\na submission. In consequence, we adopt the idea that the leaderboard gives the participant feedback\nonly when his score is higher than the highest in the past.\n2.2\nHigh-precision leaderboard is hackable\nNormally, a leaderboard shows two things \u2013 score and rank. In this subsection, we show that if a\nleaderboard precisely re\ufb02ects the ranks, then this leaderboard is easy to hack.\nFor this, we consider a minimal leaderboard, which shows nothing other than the ranks. In other\nwords, the participants are not able to observe the scores. Furthermore, inheriting the argument from\nthe previous subsection, the leaderboard uses the highest score that a participant has ever achieved to\ncompute the rank. In other words, a participant knows nothing even if he beats his old scores unless\nhis new score is higher enough to beat another participant, whose rank was higher than his.\nThis leaderboard displays really little information. However, even with so little information displayed,\nit is still hackable. For this, we perform a brute-force enumeration attack. Precisely, the hacker signs\nup two accounts A and B. At \ufb01rst, he uses A to submit a random guess u1, and he gets a rank a1 for\nA. Then, he \ufb02ips one component in this submission (say, u1\n1 from 0 to 1, or from 1 to 0), and uses B\nto submit it as u2. He will get a rank b1 for B, which is di\ufb00erent than a1. Let us assume that b1 is\nhigher than a1(otherwise, we just switch the name of account A and B). Then, he \ufb02ips an unchanged\n2Actually this is not really a boosting technique, but we use the same terminology as in [1] here.\n3\ncomponent (say u2\n2) and switches to A to submit it as u3. The score u3 yields is either higher or lower\nthan u2. If it is lower than u2 (must be equal to u1 in this case), then he sees no change on A\u2019s rank.\nIn this case, he repeats this step by \ufb02ipping another component (say u2\n3) until it is higher than u2 or\nall components have been \ufb02ipped once. If it is higher than u2, since the leaderboard precisely re\ufb02ects\nthe rank, it must move A\u2019s rank from a1to a2, which is higher than b1. Once again, the hacker switches\nto the account B and repeats the process . . . He gets a1 \u227ab1 \u227aa2 \u227ab2 \u227aa3 \u227a\u00b7 \u00b7 \u00b7. Since the score\nis bounded by 1, and each score increment is constant, the hacker \ufb01nally gets the score 1, which also\nmeans getting all answers right and ranking the highest on the leaderboard.\nWith this simple attack, we show that as long as the leaderboard precisely re\ufb02ects the rank, a hacker\nequipped with two accounts can achieve arbitrarily high score. Therefore, a leaderboard should never\nreveal precise ranks. In other words, there are cases where two participants with di\ufb00erent scores (this\ndi\ufb00erence will not be observable) see them ranked together on the leaderboard.\n3\nSimpli\ufb01ed Ladder leaderboard\nIn the previous section, we learned that a leaderboard should avoid some pitfalls. In this section, we\nshow that the Ladder leaderboard [1] successfully avoids them. We \ufb01rst introduce Ladder and simplify\nit, and then demonstrate its robustness against boosting and enumeration attacks. Throughout this\npaper, we use the following notation.\nNotation.\n[x]\u03b7 denotes the number x rounded to the nearest integer multiple of \u03b7; \u230ax\u230b\u03b7 to the nearest\nnot higher than x; \u2308x\u2309\u03b7 to the nearest not lower than x. \u03b7 is a number in (0, 1], and is usually among\nthe values 0.1, 0.01, etc.. When \u03b7 is missing, it is consider to be 1 in convention. log x denotes the\nbinary logarithm.\nThe idea of Ladder is simple.\nThe leaderboard only shows the best score that a participant has\never achieved, and updates it only when a record-breaking score is higher than it by some margin \u03b7\n(Algorithm 1). Notice that there is a parameter \u03b7 in this algorithm. To overcome this inconvenience,\n[1] also suggests a parameter-free Ladder leaderboard. However, this parameter-free version is hackable\n(Figure 1). The method is to make a \ufb01rst submission containing half 1 and half 0. Then switch the\nplace of a 1 and a 0 in each submission.\nIn this paper, we give a simpli\ufb01ed Ladder version (Algorithm 2) as well as a way to choose the optimal\nvalue of \u03b7. Comparing these two algorithms, the only tiny di\ufb00erence is the condition in Step 3 \u2013 we\ndrop the margin \u03b7. This raises naturally the question whether this modi\ufb01cation breaks the algorithm?\nNo. In fact, the margin \u03b7 is already captured in the assignment Rt \u2190[ht]\u03b7 by he precision \u03b7. Since\nRt\u22121 is always an integer multiple of \u03b7, Rt can be greater than Rt\u22121 if and only if ht is higher than\nRt\u22121 by a margin of\n\u03b7\n2.\nThe simpli\ufb01cation does not stop here.\nIndeed, Step 3 can be rephrased\nas Rt = max\n\u0010\nRt\u22121, [ht]\u03b7\n\u0011\n. So the idea of the simpli\ufb01ed Ladder leaderboard is just to authentically\ndisplay the best score achieved by each participant so far, but with a certain level of precision \u03b7.\nAlgorithm 1 Original Ladder [1]\nAssign initial score R0 \u2190\u2212\u221e.\nfor round t = 1, 2, . . . do\n1. Receive submission ut\n2. ht \u2190score of ut\n3. If ht > Rt\u22121 + \u03b7 then Rt \u2190[ht]\u03b7 else Rt \u2190Rt\u22121\n4. Show Rt on the leaderboard\nend for\nNote: [x]\u03b7 denotes the number x rounded to the nearest integer multiple of \u03b7.\n4\nAlgorithm 2 Simpli\ufb01ed Ladder\nAssign initial score R0 \u2190\u2212\u221e.\nfor round t = 1, 2, . . . do\n1. Receive submission ut\n2. ht \u2190score of ut\n3. If ht > Rt\u22121 then Rt \u2190[ht]\u03b7 else Rt \u2190Rt\u22121\n4. Show Rt on the leaderboard\nend for\nNote: [x]\u03b7 denotes the number x rounded to the nearest integer multiple of \u03b7.\nThis understanding is very helpful. On the one hand, it simpli\ufb01es the implementation of the Ladder\nleaderboard. The practitioners have less chance to make an error (e.g., by accidentally dropping the\nprecision \u03b7 or con\ufb01gure a smaller one). On the other hand, it greatly simpli\ufb01es the analysis. \u03b7 here is\nno longer an algorithmic parameter. It is instead the precision which the leaderboard o\ufb00ers.\nAfter the presentation of Ladder algorithm, now let us try to answer this question: does Ladder avoid\nthe pitfalls mentioned above? Yes. On the one hand, it only reveals the highest score so far. On\nthe other hand, it does not give arbitrarily precise information \u2013 a participant yielding 0.644 is not\ndistinguishable from another participant yielding 0.636 when \u03b7 = 0.01.\nBut there still remain questions that whether Ladder is hackable.\nIs it robust against all attacks\nbesides the above mentioned ones? The answer is yes, provided that the attacker does not possess\nmany accounts. And the robustness is proportional to the cubic root of the size of the validation set.\nIf we want the precision \u03b7 to be 0.1, we should have 103 samples; if \u03b7 = 0.01, we will need 106 samples.\nThis will be proved in the next section.\nHere again our understanding of Ladder contributes. If \u03b7 is too large, which means that the precision\nis low, the participants will not be distinguishable \u2013 they are clustered on the leaderboard. Such a\nleaderboard is not informative. If \u03b7 is too small, which means the precision is too high and the leader-\nboard reveals too much information, there will not be enough samples to maintain the authenticity of\nthe leaderboard \u2013 the leaderboard is easy to hack or over\ufb01t. Such a leaderboard is false. This trade-o\ufb00\nis the central topic of the next section.\nIn the rest of this section, we present some results about some attacks on Ladder. Figure 1 shows that\nLadder is robust against the boosting attack. Figure 2 shows some brute-force enumeration attacks\non Ladder. In these examples, to defend against the attacks, Ladder uses less samples than necessary,\nfor the brute-force is not very e\ufb03cient, since it does not make use of all information available on the\nleaderboard.\nFigure 2: Attack on Ladder. Each trajectory is correspondent to an attack. Left: n=1000, \u03b7=0.01.\nRight: n=20000, \u03b7=0.001.\n5\n4\nSample complexity\nIn this section, we present the sample complexity of the Ladder leaderboard. We show that \u03b7 is not\nonly the display precision of the leaderboard, but also the optimal value of \u03b7 is the lowest leaderboard\nerror possible. This optimal value is \u03b7\u2217= \u02dcO\n\u0010\n3q\nM\nn\n\u0011\n, where M is the number of accounts and n is the\nnumber of samples in the validation set.\nSuppose that our data (X, Y ) lie in some space \u2126\u00d7 {0, 1}. They follow a distribution D on this space.\nValidation set S = {(x1, y1), . . . , (xn, yn)} are samples drawn i.i.d. from this distribution. A classi\ufb01er\nof this problem is represented by the function f : \u2126\u2192{0, 1}. The accuracy of this classi\ufb01er is de\ufb01ned\nas\nRD(f) := Pr(f(X) = Y ).\nIts accuracy on the validation set is de\ufb01ned as\nRS(f) := 1\nn\nn\nX\ni=1\nI(f(xi) = yi),\nwhere I(\u00b7) is the indicator function.\nRS(f) can be seen as an estimator of RD(f), whose error could be measured by the quantity |RS(f) \u2212\nRD(f)|. Normally, this error should be small [4, 5, 6, 7]. However, due to the over\ufb01tting or hack by\nrepeated and adaptive submissions, this error could grow larger and larger. As this error grows, the\nleaderboard is no longer a quali\ufb01ed index of the performance of participants. The scores it displays\nno longer re\ufb02ect the true accuracy of the models, and the ranks it shows do not truly imply that one\nparticipant\u2019s model is better than another\u2019s. This is why the traditional leaderboard fails.\nSince RS(f) is no longer a good estimator of RD(f), one may ask whether there exist other estimators.\n[2, 3] show that no computationally e\ufb03cient estimator can achieve error o(1) on more than n2+o(1)\nadaptively chosen functions in a traditional leaderboard. Therefore, [1] as well as this article tries\nanother approach: the Ladder leaderboard.\nIn Ladder, the leaderboard only displays the best ever score that an account has achieved Rt :=\nmax1\u2264i\u2264t RS(fi), where fi is the function which characterizes the i-th submission associated with a\ngiven account. Thus, at the moment t, the error of the score displayed on the leaderboard could be\nmeasured by the quantity |Rt\u2212max1\u2264i\u2264t RD(fi)|. Across the time, the leaderboard error of R1, . . . , Rk\nof a single account is measured with\nlberr(R1, . . . , Rk) := max\n1\u2264t\u2264k\n\f\f\f\fRt \u2212max\n1\u2264i\u2264t RD(fi)\n\f\f\f\f .\nA small leaderboard error means that the score displayed on the leaderboard is close to the best score\nthe account in question gets on the underlying true distribution.\n[1] gives an upper bound to the leaderboard error. However, it does not take into consideration the\nfact that a participant may possess multiple accounts, in which case their reasoning breaks. In this\npaper, we take that into consideration and our upper bound is slightly tighter than theirs (logarithmic\nfactor) when degenerated to one-person-one-account case.\nIf a participant has multiple accounts, he can then switch among di\ufb00erent accounts to submit successive\nsubmissions. His submission thus does not depend only on the history of the current account, but also\non the histories of other accounts. Denote\nFt =\n(\nf m\ni\n: 1 \u2264i \u2264km, 1 \u2264m \u2264M,\nM\nX\nm=1\nkm = t\n)\n6\nas the submission history right after the moment t, where f m\ni\nsigni\ufb01es using account m to submit\naccount m\u2019s i-th submission, and km is the subtotal submissions associated with account m. Denote\nRt =\n(\nRm\ni : 1 \u2264i \u2264km, 1 \u2264m \u2264M,\nM\nX\nm=1\nkm = t\n)\nas the feedback (score) history associated with Ft.\nTheorem. Given a competition with a validation set of n samples, where the Ladder leaderboard\nemploys a display precision of \u03b7 , and each participant can possess at most M accounts. For any\nset of k (adaptively chosen) classi\ufb01ers Fk submitted by a participant, his scores Rk displayed on the\nleaderboard satisfy\nPr\n\u001a\nmax\n1\u2264t\u2264km,1\u2264m\u2264M\n\f\f\f\fRm\nt \u2212max\n1\u2264i\u2264t RD(f m\ni )\n\f\f\f\f > \u03b7\n\u001b\n\u2264exp\n\u0012\n\u2212\u03b72n\n2\n+\n\u0012M\n\u03b7 + 1\n\u0013\nlog 2k + 1\n\u0013\n.\n(1)\nIn particular, for some \u03b7 = O\n\u0012\n3q\nM log k\nn\n\u0013\n, Ladder achieves with high probability: for any m =\n1, . . . , M,\nlberr(Rm\n1 , . . . , Rm\nkm) \u2264O\n \n3\nr\nM log k\nn\n!\n.\nHere, we successfully thrust the number of submissions k into the logarithmic factor.\nThus, the\nleaderboard error is no longer sensitive to the number of submissions. A participant can submit as\nmany times as he wishes (if he is able of course). However, we notice that the number of accounts\nM is still outside of the logarithmic factor, which means that the leaderboard error grows quickly\nwhen M grows. Although it is only an upper bound, which is less persuasive than a lower bound,\nwe can provide a counter example to illustrate the e\ufb00ect of multi-account. Consider the extreme case\nwhere the participant submits each submission with a brand new account every time (i.e., M = k),\nthe leaderboard error grows quickly with the submissions. Indeed, Ladder shows no di\ufb00erence from\nthe traditional leaderboard in this case.\nThe theorem\u2019s aim is to prove a small leaderboard error.\nBut why does it matter?\nWhat is the\nrelation to the robustness of a leaderboard? The consequence of a small leaderboard error means that\na participant\u2019s score sticks to his score on the ground truth. It is not likely that he could climb up on\nthe leaderboard either by over\ufb01tting or by hack. If he marks a leap on the leaderboard, chances are\nthat he really improved his prediction model.\nTherefore, the theorem can be interpreted as: when the display precision of ladder is set to the optimal\nvalue \u03b7\u2217= O\n\u0012\n3q\nM log k\nn\n\u0013\n, a participant who gets a score s (an integer multiple of \u03b7\u2217) has large chance\nthat his true score on the ground truth is within [s \u2212\u03b7\u2217, s + \u03b7\u2217]. If two participants A and B get\nthe score sA and sB respectively, where sA \u2212sB > 2\u03b7\u2217, chances are that A really outperforms B.\nParticularly, a hacker has little chance to get a score higher than 1\n2 + \u03b7\u2217, since he learns nothing and\nhis true score should be the same as the random guess.\nNaturally, we would like \u03b7\u2217small. This depends on n. We see that to achieve a small \u03b7\u2217= \u03f5, we will\nneed O\n\u0010\nM log k\n\u03f53\n\u0011\nsamples.\n5\nProof of Theorem\nFrom the state-of-art literature [4, 5, 6, 7], we already have\nPr\n\u001a\nmax\n1\u2264t\u2264k |RS(ht) \u2212RD(ht)| > \u03b5\n\u001b\n\u22642k exp(\u22122\u03b52n),\n(2)\n7\nfor a series of functions h1, . . . , hk which are independent of the validation set S. This inequality is\nquite close to our destination. However, because of the sequential and adaptive nature of our problem,\nht+1 is a function of RS(h1), . . . , RS(ht), which means that it is not independent of S. Thus, we\ncannot apply the above inequality directly. The technique employed in this proof is to eliminate the\ndependence by enumerating all possible realizations.\nProof. Suppose that the participant has an algorithm A to decide the next function which characterizes\nthe next submission, and which account to submit with, in using the past history: ht+1 = A(Rt), where\nht+1 will become one member of the f m\ni\nin Ft+1. A can be either deterministic or random provided\nthat it does not depend on S.\nht+1 is dependent on S, however,\ng := A\n(\nrm\ni : 1 \u2264i \u2264km, 1 \u2264m \u2264M,\nM\nX\nm=1\nkm = t\n)\nis not, where rm\ni\nis one realization of Rm\ni . In consequence, we can apply (2) to g. The remaining issue\nis to count how many di\ufb00erent g\u2019s we could have within k submissions.\nTo this end, we use a compression algorithm to encode every possible g. First of all, to specify at which\nsubmission this g is submitted, we need \u2308log k\u2309bits. Then, each g can have history coming from M\ndi\ufb00erent accounts. For each single account, we calculate the bits needed. Since the history within an\naccount is a monotone increasing series, which should be multiples of 1/\u03b7 and be in interval [0, 1], it\ncan only take value in \u23081/\u03b7\u2309numbers and jump at most \u230a1/\u03b7\u230bsteps. Now we calculate the number of\nbits required to encode each jump. Here, we use a trick, which allows us to get rid of the n inside the\nlogarithm in [1] \u2013 we only code the place where there is a jump regardless of jumping height. If the\njump height is 1/\u03b7, then we code this place once. If the jump height is s/\u03b7, then we code it s times.\nTo code this place once, we need at most \u2308log k\u2309bits. Thus, the total bits demanded is\n\u2308log k\u2309+ M \u00d7\n\u00161\n\u03b7\n\u0017\n\u00d7 \u2308log k\u2309\u2264(M\n\u03b7 + 1) log 2k.\nThen, we can apply (2) to the g\u2019s in setting \u03f5 = \u03b7/2:\nPr\n\u001a\nmax\ng\n|RS(g) \u2212RD(g)| > \u03b7\n2\n\u001b\n\u22642 \u00d7 2( M\n\u03b7 +1) log 2k exp\n\u0012\n\u2212\u03b72n\n2\n\u0013\n.\nThe left side equals exactly\nPr\n\u001a\nmax\nh\u2208Fk |RS(h) \u2212RD(h)| > \u03b7\n2\n\u001b\n,\nwhile the right side is bounded by\nexp\n\u0012\n\u2212\u03b72n\n2\n+\n\u0012M\n\u03b7 + 1\n\u0013\nlog 2k + 1\n\u0013\n,\nwhich is exactly the right side of (1).\nConditioned on the event\n\b\nmaxh\u2208Fk |RS(h) \u2212RD(h)| \u2264\u03b7\n2\n\t\n, we have\nmax\n1\u2264t\u2264km,1\u2264m\u2264M\n\f\f\f\f max\n1\u2264i\u2264t RS(f m\ni ) \u2212max\n1\u2264i\u2264t RD(f m\ni )\n\f\f\f\f \u2264\u03b7\n2.\nAnd since we have\n\f\f\f\fRm\nt \u2212max\n1\u2264i\u2264t RS(f m\ni )\n\f\f\f\f \u2264\u03b7\n2\n8\nbecause of the rounding error, by the triangular inequality, we get\nmax\n1\u2264t\u2264km,1\u2264m\u2264M\n\f\f\f\fRm\nt \u2212max\n1\u2264i\u2264t RD(f m\ni )\n\f\f\f\f \u2264\u03b7,\nwhich is exactly what we want on the left side of (1).\n6\nDiscussion\nLadder is vulnerable if the number of accounts each participant can hold is unlimited. It is possible\nto launch a boosting attack on Ladder leaderboard by using a brand-new account for each submission\n(Figure (1)). Given limited number of accounts (e.g. one account for each participant), Ladder is\nrobust against the number of submissions. However, compared with the quadratic sample complexity\nof general statistical / machine learning tasks, the cubic sample complexity of the Ladder leaderboard\nmay still remain a bit too expensive. For a mere 0.01 leaderboard error, the validation set has to have\n106 samples. This is not possible in most competitions. Even if it is, we may still have questions such\nas why not put these samples into the training dataset so as to enable the participants to use more\ncomplex models. This makes the loss of Ladder more than its gain. On the other hand, we do not\nknow whether this cubic root upper bound is tight. We have yet found an e\ufb03cient attack algorithm\nthat could achieve this upper bound, nor have we discovered a tight lower bound. That is to say,\nLadder may actually work better than we expected here. In practice, the competition hosts employ\nas well other measures, such as limiting the number of submissions per day, disqualifying participants\nsecretly signing up other accounts etc., to strengthen the accuracy of the leaderboard. These measures\ncould be combined with Ladder so as to provide a more accurate leaderboard than the traditional one.\nReferences\n[1] Avrim Blum and Moritz Hardt. The ladder: A reliable leaderboard for machine learning competi-\ntions. In Proceedings of The 32nd International Conference on Machine Learning, pages 1006\u20131014,\n2015.\n[2] Marcus Hardt and Jonathan Ullman. Preventing false discovery in interactive data analysis is\nhard. In Foundations of Computer Science (FOCS), 2014 IEEE 55th Annual Symposium on, pages\n454\u2013463. IEEE, 2014.\n[3] Thomas Steinke and Jonathan Ullman. Interactive \ufb01ngerprinting codes and the hardness of pre-\nventing false discovery. arXiv preprint arXiv:1410.1228, 2014.\n[4] Olivier Bousquet and Andr\u00e9 Elissee\ufb00. Stability and generalization. The Journal of Machine Learn-\ning Research, 2:499\u2013526, 2002.\n[5] Olivier Bousquet, St\u00e9phane Boucheron, and G\u00e1bor Lugosi.\nIntroduction to statistical learning\ntheory. In Advanced lectures on machine learning, pages 169\u2013207. Springer, 2004.\n[6] Luc Devroye, L\u00e1szl\u00f3 Gy\u00f6r\ufb01, and G\u00e1bor Lugosi. A probabilistic theory of pattern recognition, vol-\nume 31. Springer Science & Business Media, 2013.\n[7] Vladimir Vapnik. The nature of statistical learning theory. Springer Science & Business Media,\n2013.\n9\n",
        "sentence": " Recent work on privacy-preserving machine learning has considered how datamining competitions such as Kaggle could potentially be \u201chacked\u201d, either intentionally or inadvertently, by using information from an oracle that reports a classifier\u2019s accuracy on the test set (Blum and Hardt, 2015; Hardt and Ullman, 2014; Zheng, 2015; Whitehill, 2016). Recent research on privacy-preserving machine learning (Whitehill, 2016; Blum and Hardt, 2015; Zheng, 2015) has shown how information on the accuracy of a contestant\u2019s guesses, returned to the contestant by an oracle, can divulge information about the test data\u2019s true labels. Therefore, the design of algorithms to generate contest leaderboards that are robust to \u201chacking\u201d, whether intentional as part of an attack or inadvertently due to adaptive overfitting, has begun to generate significant research interest (Blum and Hardt, 2015; Zheng, 2015).",
        "context": "board reveals too much information, there will not be enough samples to maintain the authenticity of\nthe leaderboard \u2013 the leaderboard is easy to hack or over\ufb01t. Such a leaderboard is false. This trade-o\ufb00\nis the central topic of the next section.\nmation. With these examples, we know at least what to avoid when building a leaderboard.\n2.1\nFull-information leaderboard is hackable\nIn this subsection, we show that if a leaderboard shows the score of each submission, this leaderboard\nis easy to hack.\naround the leaderboard.\nIn view of this, some researchers tried to build an accurate leaderboard by preserving the accuracy of\nthe estimator of the loss function. This could be hard since the participant can modify their model\n1"
    }
]