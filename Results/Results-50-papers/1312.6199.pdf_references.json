[
    {
        "title": "How to explain individual classification decisions",
        "author": [
            "David Baehrens",
            "Timon Schroeter",
            "Stefan Harmeling",
            "Motoaki Kawanabe",
            "Katja Hansen",
            "Klaus- Robert M\u00fcller"
        ],
        "venue": "The Journal of Machine Learning Research,",
        "citeRegEx": "1",
        "shortCiteRegEx": "1",
        "year": 2010,
        "abstract": "After building a classifier with modern tools of machine learning we\ntypically have a black box at hand that is able to predict well for unseen\ndata. Thus, we get an answer to the question what is the most likely label of a\ngiven unseen data point. However, most methods will provide no answer why the\nmodel predicted the particular label for a single instance and what features\nwere most influential for that particular instance. The only method that is\ncurrently able to provide such explanations are decision trees. This paper\nproposes a procedure which (based on a set of assumptions) allows to explain\nthe decisions of any classification method.",
        "full_text": "arXiv:0912.1128v1  [stat.ML]  6 Dec 2009\nHow to Explain Individual Classification Decisions\nHow to Explain Individual Classi\ufb01cation Decisions\nDavid Baehrens\u2217\nbaehrens@cs.tu-berlin.de\nTimon Schroeter\u2217\ntimon@cs.tu-berlin.de\nTechnische Universit\u00a8at Berlin\nFranklinstr. 28/29, FR 6-9\n10587 Berlin, Germany\nStefan Harmeling\u2217\nstefan.harmeling@tuebingen.mpg.de\nMPI for Biological Cybernetics\nSpemannstr. 38\n72076 T\u00a8ubingen, Germany\nMotoaki Kawanabe\nmotoaki.kawanabe@first.fraunhofer.de\nFraunhofer Institute FIRST.IDA\nKekulestr.7\n12489 Berlin, Germany\nand\nTechnische Universit\u00a8at Berlin\nFranklinstr. 28/29, FR 6-9\n10587 Berlin, Germany\nKatja Hansen\nkhansen@cs.tu-berlin.de\nKlaus-Robert M\u00a8uller\nklaus-robert.mueller@tu-berlin.de\nTechnische Universit\u00a8at Berlin\nFranklinstr. 28/29, FR 6-9\n10587 Berlin, Germany\nEditor: Carl Edward Rasmussen\nAbstract\nAfter building a classi\ufb01er with modern tools of machine learning we typically have a black\nbox at hand that is able to predict well for unseen data. Thus, we get an answer to the\nquestion what is the most likely label of a given unseen data point. However, most methods\nwill provide no answer why the model predicted the particular label for a single instance\nand what features were most in\ufb02uential for that particular instance. The only method\nthat is currently able to provide such explanations are decision trees. This paper proposes\na procedure which (based on a set of assumptions) allows to explain the decisions of any\nclassi\ufb01cation method.\nKeywords:\nexplaining, nonlinear, black box model, kernel methods, Ames mutagenicity\n\u2217. The \ufb01rst three authors contributed equally.\n1\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\n1. Introduction\nAutomatic nonlinear classi\ufb01cation is a common and powerful tool in data analysis. Machine\nlearning research has created methods that are practically useful and that can classify unseen\ndata after being trained on a limited training set of labeled examples.\nNevertheless, most of the algorithms do not explain their decision. However in practical\ndata analysis it is essential to obtain an instance based explanation, i.e. we would like to\ngain an understanding what input features made the nonlinear machine give its answer for\neach individual data point.\nTypically, explanations are provided jointly for all instances of the training set, for ex-\nample feature selection methods (including Automatic Relevance Determination) \ufb01nd out\nwhich inputs are salient for a good generalization (see for a review Guyon and Elissee\ufb00,\n2003).\nWhile this can give a coarse impression about the global usefulness of each in-\nput dimension, it is still an ensemble view and does not provide an answer on an in-\nstance basis.1 In the neural network literature also solely an ensemble view was taken in\nalgorithms like input pruning (e.g. Bishop, 1995; LeCun, Bottou, Orr, and M\u00a8uller, 1998).\nThe only classi\ufb01cation which does provide individual explanations are decision trees (e.g.\nHastie, Tibshirani, and Friedman, 2001).\nThis paper proposes a simple framework that provides local explanation vectors applica-\nble to any classi\ufb01cation method in order to help understanding prediction results for single\ndata instances. The local explanation yields the features being relevant for the prediction\nat the very points of interest in the data space and is able to spot local peculiarities which\nare neglected in the global view e.g. due to cancellation e\ufb00ects.\nThe paper is organized as follows: We de\ufb01ne local explanation vectors as class probability\ngradients in Section 2 and give an illustration for Gaussian Process Classi\ufb01cation (GPC).\nSome methods output a prediction without a direct probability interpretation. For these\nwe propose in Section 3 a way to estimate local explanations. In Section 4 we will apply\nour methodology to learn distinguishing properties of Iris \ufb02owers by estimating explanation\nvectors for a k-NN classi\ufb01er applied to the classic Iris data set. Section 5 will discuss how our\napproach applied to a SVM classi\ufb01er allows us to explain how digits \u201dtwo\u201d are distinguished\nfrom digit \u201d8\u201d in the USPS data set. In Section 6 we discuss a more real-world application\nscenario where the proposed explanation capabilities prove useful in drug discovery: Human\nexperts regularly decide how to modify existing lead compounds in order to obtain new\ncompounds with improved properties. Models capable of explaining predictions can help in\nthe process of choosing promising modi\ufb01cations. Our automatically generated explanations\nmatch with chemical domain knowledge about toxifying functional groups of the compounds\nin question. Section 7 contrasts our approach with related work and Section 8 discusses\ncharacteristic properties and limitations of our approach, before we conclude the paper in\nSection 9.\n1. This point is illustrated in Figure 1 (Section 2). Applying feature selection methods to the training\nset (a) will lead to the (correct) conclusion that both dimensions are equally important for accurate\nclassi\ufb01cation. As an alternative to this ensemble view, one may ask: Which features (or combinations\nthereof) are most in\ufb02uential in the vicinity of each particular instance. As can be seen in Figure 1 (c),\nthe answer depends on where the respective instance is located. On the hypotenuse and at the corners\nof the triangle, both features contribute jointly, whereas along each of the remaining two edges the\nclassi\ufb01cation depends almost completely on just one of the features.\n2\nHow to Explain Individual Classification Decisions\n2. De\ufb01nitions of Explanation Vectors\nIn this Section we will give de\ufb01nitions for our approach of local explanation vectors in the\nclassi\ufb01cation setting. We start with a theoretical de\ufb01nition for multi-class Bayes classi\ufb01ca-\ntion and then give a specialized de\ufb01nition being more practical for the binary case.\nFor the multi-class case, suppose we are given data points x1, . . . , xn \u2208\u211cd with labels\ny1, . . . , yn \u2208{1, . . . , C} and we intend to learn a function that predicts the labels of unlabeled\ndata points. Assuming that the data could be modeled as being IID-sampled from some\nunknown joint distribution P(X, Y ), in theory, we can de\ufb01ne the Bayes classi\ufb01er,\ng\u2217(x) = arg\nmin\nc\u2208{1,...,C} P(Y \u0338=c | X =x)\nwhich is optimal for the 0-1 loss function (see Devroye, Gy\u00a8or\ufb01, and Lugosi, 1996).\nFor the Bayes classi\ufb01er we de\ufb01ne the explanation vector of a data point x0 to be the\nderivative with respect to x at x = x0 of the conditional probability of Y \u0338= g\u2217(x0) given\nX = x, or formally,\nDe\ufb01nition 1\n\u03b6(x0) := \u2202\n\u2202x P(Y \u0338=g\u2217(x0) | X =x)\n\f\f\f\f\nx=x0\nNote that \u03b6(x0) is a d-dimensional vector just like x0 is. The classi\ufb01er g\u2217partitions the\ndata space \u211cd into up to C parts on which g\u2217is constant. We assume that the conditional\ndistribution P(Y = c | X = x) is \ufb01rst-order di\ufb00erentiable w.r.t. x for all classes c and over\nthe entire input space. For instance, the assumption holds, if P(X = x | Y = c) is for all\nc \ufb01rst-order di\ufb00erentiable in x and the supports of the class densities overlap around the\nboarder for all the neighboring pairs in the partition by the Bayes classi\ufb01er. The vector\n\u03b6(x0) de\ufb01nes on each of those parts a vector \ufb01eld that characterizes the \ufb02ow away from the\ncorresponding class. Thus entries in \u03b6(x0) with large absolute values highlight features that\nwill in\ufb02uence the class label decision of x0. A positive sign of such an entry implies that\nincreasing that feature would lower the probability that x0 is assigned to g\u2217(x0). Ignoring the\norientations of the explanation vectors, \u03b6 forms a continuously changing (orientation-less)\nvector \ufb01eld along which the class labels change. This vector \ufb01eld lets us locally understand\nthe Bayes classi\ufb01er.\nWe remark that \u03b6(x0) becomes a zero vector, e.g. when P(Y \u0338= g\u2217(x0) | X = x)|x=x0 is\nequal to one in some neighborhood of x0. Our explanation vector \ufb01ts well to probabilistic\nclassi\ufb01ers such as Gaussian Process Classi\ufb01cation (GPC), where the conditional distribution\nP(Y = c | X = x) is usually not completely \ufb02at in some regions. In the case of deterministic\nclassi\ufb01ers, despite of this issue, Parzen window estimators with appropriate widths (Section\n3) can provide meaningful explanation vectors for many samples in practice (see also Section\n8).\nFor the case of binary classi\ufb01cation we directly de\ufb01ne local explanation vectors as local\ngradients of the probability function p(x) = P(Y = 1 | X = x) of the learned model for the\npositive class.\nSo for a probability function p\n:\n\u211cd \u2192[0, 1] of a classi\ufb01cation model learned from\nexamples {(x1, y1), . . . , (xn, yn)} \u2208\u211cd \u00d7{\u22121, +1} the explanation vector for a classi\ufb01ed test\npoint x0 is the local gradient of p at x0:\n3\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\nDe\ufb01nition 2\n\u03b7p(x0) := \u2207p(x)|x=x0\nBy this de\ufb01nition the explanation \u03b7 is again a d-dimensional vector just like the test\npoint x0 is. The sign of each of its individual entries indicates whether the prediction would\nincrease or decrease when the corresponding feature of x0 is increased locally and each\nentry\u2019s absolute value give the amount of in\ufb02uence in the change in prediction. As a vector\n\u03b7 gives the direction of the steepest ascent from the test point to higher probabilities for the\npositive class. For binary classi\ufb01cation the negative version \u2212\u03b7p(x0) indicates the changes\nin features needed to increase the probability for the negative class which may be especially\nuseful for x0 predicted in the positive class.\nFor an example we apply De\ufb01nition 2 to model predictions learned by Gaussian Process\nClassi\ufb01cation (GPC), see Rasmussen and Williams (2006). GPC is used here for three rea-\nsons:\n(i) In our real-world application we are interested in classifying data from drug discovery,\nwhich is an area where Gaussian processes have proven to show state-of-the-art performance,\nsee e.g. Obrezanova, Cs\u00b4anyi, Gola, and Segall (2007); Schroeter, Schwaighofer, Mika, ter Laak, S\u00a8ulzle, Ganzer,\n(2007c); Schroeter, Schwaighofer, Mika, Laak, Suelzle, Ganzer, Heinrich, and M\u00a8uller (2007a,b);\nSchwaighofer, Schroeter, Mika, Laub, ter Laak, S\u00a8ulzle, Ganzer, Heinrich, and M\u00a8uller (2007);\nSchwaighofer, Schroeter, Mika, Hansen, ter Laak, Lienau, Reichel, Heinrich, and M\u00a8uller (2008);\nObrezanova, Gola, Champness, and Segall (2008). It is natural to expect a model with high\nprediction accuracy on a complex problem to capture relevant structure of the data which is\nworth explaining and may give domain speci\ufb01c insights in addition to the values predicted.\nFor an evaluation of the explaining capabilities of our approach on a complex problem from\nchemoinformatics see Section 6.\n(ii) GPC does model the class probability function used in De\ufb01nition 2 directly. For other\nclassi\ufb01cation methods such as Support Vector Machines which do not provide a probability\nfunction as its output in Section 3 we give an example for an estimation method starting\nfrom De\ufb01nition 1.\n(iii) The local gradients of the probability function can be calculated analytically for di\ufb00er-\nentiable kernel as we discuss next.\nLet f(x) = Pn\ni=1 \u03b1ik(x, xi) be a GP model trained on sample points x1, . . . , xn \u2208\u211cd\nwhere k is a kernel function and \u03b1i are the learned weights of each sample point. For a test\npoint x0 \u2208\u211cd let varf(x0) be the variance of f(x0) under the GP posterior for f. Because\nthe posterior cannot be calculated analytically for GP classi\ufb01cation models, we used an\napproximation by expectation propagation (EP) (Kuss and Ramussen, 2005). In the case\nof the probit likelihood term de\ufb01ned by the error function, the probability for being of the\npositive class p(x0) can be computed easily from this approximated posterior as\np(x0) = 1\n2erfc\n \n\u2212f(x0)\n\u221a\n2 \u2217\np\n1 + varf(x0)\n!\n,\nwhere erfc denotes the complementary error function (see Equation 6 in Schwaighofer, Schroeter, Mika, Hansen,\n2008).\nThen the local gradient of p(x0) is given by\n4\nHow to Explain Individual Classification Decisions\n\u2207p(x)|x=x0\n=\u22071\n2erfc\n \n\u2212f(x)\n\u221a\n2 \u2217\np\n1 + varf(x)\n!\f\f\f\f\f\nx=x0\n=\u22071\n2\n \n1 \u2212erf\n \n\u2212f(x)\n\u221a\n2 \u2217\np\n1 + varf(x)\n!!\f\f\f\f\f\nx=x0\n= \u22121\n2\u2207erf\n \n\u2212f(x)\n\u221a\n2 \u2217\np\n1 + varf(x)\n!\f\f\f\f\f\nx=x0\n= \u2212\nexp\n\u0010\n\u2212f(x0)2\n2(1+varf (x0))\n\u0011\n\u221a\u03c0\n\u2207\n \n\u2212f(x)\n\u221a\n2 \u2217\np\n1 + varf(x)\n!\f\f\f\f\f\nx=x0\n= \u2212\nexp\n\u0010\n\u2212f(x0)2\n2(1+varf (x0))\n\u0011\n\u221a\u03c0\n \n\u22121\n\u221a\n2\u2207\n \nf(x)\np\n1 + varf(x)\n!\f\f\f\f\f\nx=x0\n!\n=\nexp\n\u0010\n\u2212f(x0)2\n2(1+varf (x0))\n\u0011\n\u221a\n2\u03c0\n \n\u2207f(x)|x=x0\np\n1 + varf(x0) + f(x0)\n\u0012\n\u2207varf(x)|x=x0 \u2217\u22121\n2 (1 + varf(x0))\u22123\n2\n\u0013\u0013\n=\nexp\n\u0010\n\u2212f(x0)2\n2(1+varf (x0))\n\u0011\n\u221a\n2\u03c0\n \n\u2207f(x)|x=x0\np\n1 + varf(x0) \u22121\n2\nf(x0)\n(1 + varf(x0))\n3\n2\n\u2207varf(x)|x=x0\n!\n.\nAs a kernel function choose e.g. the RBF-kernel k(x0, x1) = exp(\u2212w(x0 \u2212x1)2), which has\nthe derivative (\u2202/\u2202x0,j)k(x0, x1) = \u22122w exp(\u2212w(x0 \u2212x1)2)(x0,j \u2212x1,j) for j \u2208{1, . . . , d}.\nThen the elements of the local gradient \u2207f(x)|x=x0 are\n\u2202f\n\u2202x0,j\n= \u22122w\nn\nX\ni=1\n\u03b1i exp(\u2212w(x0 \u2212xi)2)(x0,j \u2212xi,j)\nfor j \u2208{1, . . . , d}.\nFor varf(x0) = k(x0, x0) \u2212kT\n\u2217(K + \u03a3)\u22121k\u2217the derivative is given by2\n\u2207varf(x)|x=x0 = \u2202varf\n\u2202x0,j\n=\n\u0012\n\u2202\n\u2202x0,j\nk(x0, x0)\n\u0013\n\u22122 \u2217kT\n\u2217(K + \u03a3)\u22121\n\u2202\n\u2202x0,j\nk\u2217\nfor j \u2208{1, . . . , d}.\nPanel (a) of Figure 1 shows the training data of a simple object classi\ufb01cation task\nand panel (b) shows the model learned using GPC3. The data is labeled \u22121 for the blue\npoints and +1 for the red points. As illustrated in panel (b) the model is a probability\nfunction for the positive class which gives every data point a probability of being in this\n2. Here k\u2217= (k(x0, x1), . . . , k(x0, xn))T is the evaluation of the kernel function between the test point\nx0 and every training point. \u03a3 is the diagonal matrix of the variance site parameter. For details see\nRasmussen and Williams (2006, Chapter 3)\n3. Hyperparameters were tuned by a gradient ascend on the evidence.\n5\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\n0\n0.2\n0.4\n0.6\n0.8\n1\n0\n0.2\n0.4\n0.6\n0.8\n1\n\u22121\n\u22120.5\n0\n0.5\n1\n(a) Object\n(b) Model\n0\n0.2\n0.4\n0.6\n0.8\n1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n(c) Local explanation vectors\n0\n0.2\n0.4\n0.6\n0.8\n1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n(d) Direction of explanation vectors\nFigure 1: Explaining simple object classi\ufb01cation with Gaussian Processes\nclass. Panel (c) shows the probability gradient of the model together with the local gradient\nexplanation vectors. On the hypotenuse and at the corners of the triangle explanations from\nboth features interact towards the triangle class while along the edges the importance of\none of the two feature dimensions singles out. At the transition from the negative to the\npositive class the length of the local gradient vectors represents the increased importance\nof the relevant features. In panel (d) we see that explanations close to the edges of the\nplot (especially in the right hand side corner) point away from the positive class. However,\npanel (c) shows that their magnitude is very small. For discussion of this issue, see Section\n8.\n3. Estimating Explanation Vectors\nSeveral classi\ufb01er methods estimate directly the decision rule, which often has no interpre-\ntation as a probability function which is used in our De\ufb01nition 2 in Section 2. For example\n6\nHow to Explain Individual Classification Decisions\nSupport Vector Machines estimate a decision function of the form\nf(x) =\nn\nX\ni=1\n\u03b1ik(xi, x) + b,\n\u03b1i, b \u2208\u211c.\nSuppose we have two classes (each with one cluster) in one dimension (see\nFigure 2) and train a SVM with RBF kernel. For points outside the data clusters f(x)\ntends to zero. Thus, the derivative of f(x) (shown as arrows above the curves) for points\non the very left or on the very right side of the axis will point to the wrong side. In the\n0\nx\np(       |   )\ny=1  x\n1\n0.5\n0\nx\nclassifier output\nFigure 2: Classi\ufb01er output of an SVM (top) compared to p(y=1|x) (bottom).\nfollowing, we will explain how explanations can be obtained for such classi\ufb01ers.\nIn practice we do not have access to the true underlying distribution P(X, Y ). Con-\nsequently, we have no access to the Bayes classi\ufb01er as de\ufb01ned in Section 2. Instead we\ncan apply sophisticated learning machinery like Support Vector Machines (Vapnik, 1995;\nSch\u00a8olkopf and Smola, 2002; M\u00a8uller, Mika, R\u00a8atsch, Tsuda, and Sch\u00a8olkopf, 2001) that esti-\nmates some classi\ufb01er g that tries to mimic g\u2217. For test data points z1, . . . , zm \u2208\u211cd which\nare assumed to be sampled from the same unknown distribution as the training data, g\nestimates labels g(z1), . . . , g(zm). Now, instead of trying to explain g\u2217to which we have\nno access, we will de\ufb01ne explanation vectors that help us understand the classi\ufb01er g on the\ntest data points.\nSince we do not assume that we have access to some intermediate real-valued classi\ufb01er\noutput here (of which g might be a thresholded version and which further might not be\nan estimate of P(Y = c | X = x)), we suggest to approximate g by another classi\ufb01er \u02c6g the\nactual form of which resembles the Bayes classi\ufb01er. There are several choices for \u02c6g, e.g.\n7\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\nGPC, logistic regression and Parzen windows.4 In this paper we apply Parzen windows to\nthe training points to estimate the weighted class densities P(Y =c) \u00b7 P(X | Y =c),\n\u02c6p\u03c3(x, y=c) = 1\nn\nX\ni\u2208Ic\nk\u03c3(x \u2212xi)\n(1)\nfor the index set Ic = {i | g(xi) = c} and with k\u03c3(z) being a Gaussian kernel k\u03c3(z) =\nexp(\u22120.5 z\u22a4z/\u03c32)/\n\u221a\n2\u03c0\u03c32 (as always other kernels are also possible). This estimates P(Y =\nc | X =x) for all c,\n\u02c6p\u03c3(y=c|x) =\n\u02c6p\u03c3(x, y=c)\n\u02c6p\u03c3(x, y=c) + \u02c6p\u03c3(x, y\u0338=c) \u2248\nP\ni\u2208Ic k\u03c3(x \u2212xi).\nP\ni k\u03c3(x \u2212xi),\n(2)\nand thus an estimate of the Bayes classi\ufb01er (that mimics g),\n\u02c6g\u03c3(x) = arg\nmin\nc\u2208{1,...,C} \u02c6p\u03c3(y\u0338=c | x).\nThis approach has the advantage, that we can use our estimated classi\ufb01er g to generate\nany amount of labeled data for for constructing \u02c6g. The single hyper-parameter \u03c3 is chosen,\nsuch that \u02c6g approximates g (which we want to explain), i.e.\n\u02c6\u03c3 := arg min\n\u03c3\nm\nX\nj=1\nI {g(zj)\u0338=\u02c6g\u03c3(zj)} ,\nwhere I{\u00b7 \u00b7 \u00b7 } is the indicator function. \u03c3 is assigned the constant value \u02c6\u03c3 from here on and\nomitted as a subscript. For \u02c6g it is straightforward to de\ufb01ne explanation vectors:\nDe\ufb01nition 3\n\u02c6\u03b6(z) := \u2202\n\u2202x \u02c6p(y\u0338=g(z) | x)\n\f\f\f\f\nx=z\n=\n\u0010 P\ni/\u2208Ig(z) k(z \u2212xi)\n\u0011\u0010 P\ni\u2208Ig(z) k(z \u2212xi)(z \u2212xi)\n\u0011\n\u03c32 \u0000 Pn\ni=1 k(z \u2212xi)\n\u00012\n\u2212\n\u0010 P\ni/\u2208Ig(z) k(z \u2212xi)(z \u2212xi)\n\u0011\u0010 P\ni\u2208Ig(z) k(z \u2212xi)\n\u0011\n\u03c32 \u0000 Pn\ni=1 k(z \u2212xi)\n\u00012\nwhich is easily derived using Eq. (2) and the derivative of Eq. (1), see Appendix A.2.1. Note\nthat we use g instead of \u02c6g. This choice ensures that the orientation of \u02c6\u03b6(z) \ufb01ts to the labels\nassigned by g, which allows better interpretations.\nIn summary, we imitate the classi\ufb01er g which we would like to explain locally, by a Parzen\nwindow classi\ufb01er \u02c6g that has the same form as the Bayes estimator and for which we can\nthus easily estimate the explanation vectors using De\ufb01nition 3. Practically there are some\ncaveats: the mimicking classi\ufb01er \u02c6g has to be estimated from g even in high dimensions; this\nneeds to be done with care. However, in principle we have an arbitrary amount of training\ndata available for constructing \u02c6g since we may use our estimated classi\ufb01er g to generate\nlabeled data.\n4. For Support Vector Machines Platt (1999) \ufb01ts a sigmoid function to map the outputs to probabilities.\nIn the following, we will present a more general method for estimating explanation vectors.\n8\nHow to Explain Individual Classification Decisions\n4. Explaining Iris Flower Classi\ufb01cation by k-Nearest Neighbors\nThe Iris \ufb02ower data set (introduced in Fisher, 1936) describes 150 \ufb02owers from the genus\nIris by 4 features: sepal length, sepal width, petal length, and petal width, which are easily\nmeasured properties of certain leaves of the corolla of the \ufb02ower. There are three clusters\nin that data which correspond to three di\ufb00erent species: Iris setosa, Iris virginica, and Iris\nversicolor.\nLet us consider the problem of classifying the data points of Iris versicolor (class 0)\nagainst the other two species (class 1). We applied some standard classi\ufb01cation machinery\nto this problem as detailed in the following:\n\u2022 Class 0 consists of all examples of Iris versicolor.\n\u2022 Class 1 consists of all examples of Iris setosa and Iris virginica.\n\u2022 Randomly split 150 data points into 100 training and 50 test examples.\n\u2022 Normalize training and test set using the mean and variance of the training set.\n\u2022 Apply k-nearest neighbor classi\ufb01cation with k = 4 (chosen by leave-one-out cross\nvalidation on the training data).\n\u2022 Training error is 3% (i.e. 3 mistakes in 100).\n\u2022 Test error is 8% (i.e. 4 mistakes in 50).\nIn order to estimate explanation vectors we mimic the classi\ufb01cation results with a Parzen\nwindow classi\ufb01er.\nThe best \ufb01t (3% error) is obtained with a kernel width of \u03c3 = 0.26\n(chosen by leave-one-out cross validation on the training data).\nSince the explanation vectors live in the input space we can visualize them with scatter\nplots of the initially measured features. The resulting explanations (i.e. vectors) for the test\nset are shown in Figure 3. The blue dots correspond to explanation vectors for Iris setosa\nand the red dots for Iris virginica (both class 1). Both groups of dots point to the green\ndots of Iris versicolor. The most important feature is the combination of petal length and\npetal width (see the corresponding panel), the product of which corresponds roughly to the\narea of the petals. However, the resulting explanations for the two species in class 1 are\ndi\ufb00erent:\n\u2022 Iris setosa (class 1) is di\ufb00erent from Iris versicolor (class 0) because its petal area is\nsmaller.\n\u2022 Iris virginica (class 1) is di\ufb00erent from Iris versicolor (class 0) because its petal area\nis larger.\nAlso the dimensions of the sepal (another part of the blossom) is relevant, but not as\ndistinguishing.\n9\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\nFigure 3: Scatter plots of the explanation vectors for the test data. Shown are all explana-\ntion vectors for both classes: class 1 containing Iris setosa (shown in blue) and Iris\nvirginica (shown in red) versus class 0 containing only one species Iris versicolor\n(shown in green). Note that the explanations why an Iris \ufb02ower is not an Iris\nversicolor is di\ufb00erent for Iris setosa and Iris virginica.\n10\nHow to Explain Individual Classification Decisions\nFigure 4: USPS digits (training set): \u2019twos\u2019 (left) and \u2019eights\u2019 (right) with correct classi\ufb01-\ncation. For each digit from left to right: (i) explanation vector (with black being\nnegative, white being positive), (ii) the original digit, (iii-end) arti\ufb01cial digits\nalong the explanation vector towards the other class.\nFigure 5: USPS digits (test set bottom part): \u2019twos\u2019 (left) and \u2019eights\u2019 (right) with correct\nclassi\ufb01cation. For each digit from left to right: (i) explanation vector (with black\nbeing negative, white being positive), (ii) the original digit, (iii-end) arti\ufb01cial\ndigits along the explanation vector towards the other class.\n11\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\n5. Explaining USPS Digit Classi\ufb01cation by Support Vector Machine\nWe now apply the framework of estimating explanation vectors to a high dimensional data\nset, the USPS digits. The classi\ufb01cation problem that we designed for illustration purposes\nis detailed in the following list:\n\u2022 all digits are 16\u00d716 images which are reshaped to 256\u00d71 dimensional column vectors\n\u2022 classi\ufb01er: SVM from Schwaighofer (2002) with RBF-kernel-width \u03c3 = 1 and regu-\nlarization constant C = 10 (chosen by grid search in cross validation on the training\ndata).\n\u2022 training set: 47 \u2019twos\u2019, 53 \u2019eights\u2019; training error 0.00\n\u2022 test set: 48 \u2019twos\u2019, 52 \u2019eights\u2019; test error 0.05\nWe approximated the estimated class labels obtained by the SVM with the Parzen window\nclassi\ufb01er (Parzen window size \u03c3 = 10.2505, chosen by grid search in cross validation on the\ntraining data). The SVM and the Parzen window classi\ufb01er only disagreed on 2% of the test\nexamples, so a good \ufb01t was achieved. Figures 4 and 5 show our results. All parts show three\nexamples per row. For each example we display from left to right: (i) the explanation vector,\n(ii) the original digit, (iii-end) arti\ufb01cial digits along the explanation vector towards the other\nclass.5 These arti\ufb01cial digits should help to understand and interpret the explanation vector.\nLet us \ufb01rst have a look at the results on the training set:\nFigure 4 (left panel): Let us focus on the top example framed in red. The line that forms\nthe \u2019two\u2019 is part of some \u2019eight\u2019 from the data set. Thus the parts of the lines that\nare missing show up in the explanation vector: if the dark parts (which correspond to\nthe missing lines) are added to the \u2019two\u2019 digit then it will be classi\ufb01ed as an \u2019eight\u2019.\nOr in other words, because of the lack of those parts the digit was classi\ufb01ed as a \u2019two\u2019\nand not as an \u2019eight\u2019. A similar explanation holds for the middle example framed in\nred of the same Figure. Not all examples transform easily to \u2019eights\u2019: besides adding\nparts of black lines, some existing black spots (that the digit has to be a \u2019two\u2019) must\nbe removed. This is re\ufb02ected in the explanation vector by white spots/lines. Curious\nis the bottom \u2019two\u2019 framed in red, which is actually a dash and is in the data set by\nmistake. However, its explanation vector shows nicely which parts have to be added\nand which have to be removed.\nFigure 4 (right panel): we see similar results for the \u2019eights\u2019 class.\nThe explanation\nvectors again tell us how the \u2019eights\u2019 must change to become classi\ufb01ed as \u2019twos\u2019.\nHowever, sometimes the transformation does not reach the \u2019twos\u2019. This is probably\ndue to the fact that some of the \u2019eights\u2019 are inside the cloud of \u2019eights\u2019.\nOn the test set the explanation vectors are not as pronounced as on the training set.\nHowever, they show similar tendencies:\n5. For the sake of simplicity, no intermediate updates were performed, i.e. arti\ufb01cial digits were generated\nby taking equal sized steps in the direction given by the original explanation vector calculated fot the\noriginal digit.\n12\nHow to Explain Individual Classification Decisions\nFigure 5 (left panel): we see the correctly classi\ufb01ed \u2019twos\u2019. Let\u2019s focus on the example\nframed in red. Again the explanation vector shows us how to edit the image of the\n\u2019two\u2019 to make it some of the \u2019eights\u2019, i.e. exactly what parts of the digit have been\nimportant for the classi\ufb01cation result. For several other \u2019twos\u2019 the explanation vectors\ndo not directly lead to the \u2019eights\u2019 but weight the di\ufb00erent parts of the digits which\nhave been relevant for the classi\ufb01cation.\nFigure 5 (right panel): similarly to the training data, we see that also these explanation\nvectors are not bringing all \u2019eights\u2019 to \u2019two\u2019. Their explanation vectors mainly suggest\nto remove most of the eights (the dark parts) and add some in the lower part (the\nlight parts, which look like a white shadow).\nOverall, our \ufb01ndings can be summarized, that the explanation vectors tell us how to edit\nour example digits to change the assigned class label. Hereby, we get a better understanding\nof the reasons why the chosen classi\ufb01er classi\ufb01ed the way it did.\n6. Explaining Mutagenicity Classi\ufb01cation by Gaussian Processes\nIn the following Section we describe an application of our local gradient explanation method-\nology to a complex real world data set. Our aim is to \ufb01nd structure speci\ufb01c to the problem\ndomain that has not been fed into training explicitly but is captured implicitly by the\nGPC model in the high-dimensional feature space used to determine its prediction. We\ninvestigate the task of predicting Ames mutagenic activity of chemical compounds. Not\nbeing mutagenic (i.e. not able to cause mutations in the DNA) is an important require-\nment for compounds under investigation in drug discovery and design.\nThe Ames test\n(Ames, Gurney, Miller, and Bartsch, 1972) is a standard experimental setup for measuring\nmutagenicity. The following experiments are based on a set of Ames test results for 6512\nchemical compounds that we published previously.6\nGPC was applied as detailed in the following:\n\u2022 Class 0 consists of non-mutagenic compounds\n\u2022 Class 1 consists of mutagenic compounds\n\u2022 Randomly split 6512 data points into 2000 training and 4512 test examples such that:\n\u2013 The training set consists of equally many class 0 and class 1 examples.\n\u2013 For the steroid compound class the balance in the train and test set is enforced.\n\u2022 10 additional random splits were investigated individually. This con\ufb01rmed the results\npresented below.\n\u2022 Each example (chemical compound) is represented by a vector of counts of 142 molecu-\nlar substructures calculated using the Dragon software (Todeschini, Consonni, Mauri, and Pavan,\n2006).\n6. See Hansen, Mika, Schroeter, Sutter, Laak, Steger-Hartmann, Heinrich, and M\u00a8uller (2009) for results of\nmodeling this set using di\ufb00erent machine learning methods.\nThe data itself is available online at\nhttp://ml.cs.tu-berlin.de/toxbenchmark\n13\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\n0\n0.2\n0.4\n0.6\n0.8\n1\n0\n0.2\n0.4\n0.6\n0.8\n1\nfalse positive rate\ntrue positive rate\n \n \nAUC = 0.84\nFigure 6: Receiver operating curve of GPC model for mutagenicity prediction\n\u2022 Normalize training and test set using the mean and variance of the training set.\n\u2022 Apply GPC model with RBF kernel\n\u2022 Performance (84 % area under curve) con\ufb01rms our previous results (Hansen, Mika, Schroeter, Sutter, Laak\n2009). Error rates can be obtained from Figure 6.\nTogether with the prediction we calculated the explanation vector (as introduced in Section\n2 with De\ufb01nition 2) for each test point. The remainder of this Section is an evaluation of\nthese local explanations.\nIn Figures 7 and 8 we show the distribution of the local importance of selected fea-\ntures across the test set: For each input feature we generate a histogram of local impor-\ntance values, as indicated by its corresponding entry in the explanation vector of each of\nthe 4512 test compounds. The features examined in Figure 7 are counts of substructures\nknown to cause mutagenicity.\nWe show all approved \u201cspeci\ufb01c toxicophores\u201d introduced\nby Kazius, McGuire, and Bursi (2005) that are also represented in the Dragon set of fea-\ntures. The features shown in Figure 8 are known to detoxify certain toxicophores (again\nsee Kazius, McGuire, and Bursi, 2005). With the exception of 7(e) the toxicophores also\nhave a toxifying in\ufb02uence according to our GPC prediction model. Feature 7(e) seems to\nbe mostly irrelevant for the prediction of the GPC model on the test points. In contrast\nthe detoxicophores show overall negative in\ufb02uence on the prediction outcome of the GPC\nmodel. Modifying the test compounds by adding toxicophores will increase the probabil-\nity of being mutagenic as predicted by the GPC model while adding detoxicophores will\ndecrease this predicted probability.\nSo we have seen that the conclusions drawn from our explanation vectors agree with\nestablished knowledge about toxicophores and detoxicophores.\nWhile this is reassuring,\nsuch a sanity check required existing knowledge about which compounds are toxicophores\nand detoxicophores and which are not. Thus it is interesting to ask, whether we also could\nhave discovered that knowledge from the explanation vectors.\nTo answer this question\n14\nHow to Explain Individual Classification Decisions\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\n0.14\nlocal gradient DR17:nArNO2\nrelative frequency\n(a) aromatic nitro\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.02\n0.04\n0.06\n0.08\n0.1\nlocal gradient DR17:nArNH2\nrelative frequency\n(b) aromatic amine\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.01\n0.02\n0.03\n0.04\n0.05\nlocal gradient DR17:nArNO\nrelative frequency\n(c) aromatic nitroso\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.02\n0.04\n0.06\n0.08\nlocal gradient DR17:nRNNOx\nrelative frequency\n(d) aliphatic nitrosamine\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nlocal gradient DR17:nArNNOx\nrelative frequency\n(e) aromatic nitrosamine\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.01\n0.02\n0.03\n0.04\n0.05\nlocal gradient DR17:nOxiranes\nrelative frequency\n(f) epoxide\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nlocal gradient DR17:nAziridines\nrelative frequency\n(g) aziridine\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.02\n0.04\n0.06\n0.08\n0.1\n0.12\nlocal gradient DR17:nN=N\nrelative frequency\n(h) azide\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.02\n0.04\n0.06\n0.08\n0.1\nlocal gradient DR17:nArNHO\nrelative frequency\n(i) aromatic hydroxylamine\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.01\n0.02\n0.03\n0.04\n0.05\n0.06\n0.07\nlocal gradient X:AliphaticHalide\nrelative frequency\n(j) aliphatic halide\nFigure 7: Distribution of local importance of selected features across the test set of 4512\ncompounds. Nine out of ten known toxicophores (Kazius, McGuire, and Bursi,\n2005) indeed exhibit positive local gradients.\n15\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.02\n0.04\n0.06\n0.08\n0.1\nlocal gradient DR17:nSO2N\nrelative frequency\n(a) sulfonamide\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.005\n0.01\n0.015\n0.02\n0.025\n0.03\n0.035\nlocal gradient DR17:nSO2OH\nrelative frequency\n(b) sulfonic acid\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.01\n0.02\n0.03\n0.04\n0.05\nlocal gradient DR17:nS(=O)2\nrelative frequency\n(c) arylsulfonyl\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.01\n0.02\n0.03\n0.04\n0.05\nlocal gradient DR17:nRCOOH\nrelative frequency\n(d) aliphatic carboxylic acid\n\u22121\n\u22120.5\n0\n0.5\n1\n0\n0.02\n0.04\n0.06\n0.08\n0.1\nlocal gradient DR17:nArCOOH\nrelative frequency\n(e) aromatic carboxylic acid\nFigure 8: Distribution of local importance of selected features across the test set of 4512\ncompounds. All \ufb01ve known detoxicophores exhibit negative local gradients\nwe ranked all 142 features by the means of their local gradients7. Clear trends result: 9\nout of 10 known toxicophores can be found close the top of the list (mean rank of 19).\nThe only exception (rank 81) is the aromatic nitrosamine feature.8\nThis trend is even\nstronger for the detoxicophores: The mean rank of these \ufb01ve features is 138 (out of 142), i.e.\nthey consistently exhibit the largest negative local gradients. Consequently, the established\nknowledge about toxicophores and detoxicophores could indeed have been discovered using\nour methodology.\nIn the following paragraph we will discuss steroids9 as an example of an important\ncompound class for which the meaning of features di\ufb00ers from this global trend, so that\nlocal explanation vectors are needed to correctly identify relevant features.\nFigure 9 displays the di\ufb00erence in relevance of epoxide (a) and aliphatic nitrosamine (c)\nsubstructures for the predicted mutagenicity of steroids and non-steroid compounds. For\n7. Tables resulting from this ranking are made available as a supplement to this paper and can be down-\nloaded from the journals website.\n8. This \ufb01nding agrees with the result obtained by visually inspecting Figure 7(e). We found that only very\nfew compounds with this feature are present in the data set. Consequently, detection of this feature is\nonly possible if enough of these few compounds are included in the training data. This was not the case\nin the random split used to produce the results presented above.\n9. Steroids are natural products and occur in humans, animals and plants. They have a characteristic\nbackbone containing four fused carbon-rings.\nMany hormones important to the development of the\nhuman body are steroids, including androgens, estrogens, progestagens, cholesterol and natural anabolics.\nThese have been used as starting points for the development of many di\ufb00erent drugs, including the most\nreliable contraceptives currently on the market.\n16\nHow to Explain Individual Classification Decisions\n\u22120.5\n0\n0.5\n1\n0\n0.05\n0.1\n0.15\n0.2\nKS p\u2212value = 0.00\nsymm. KLD = 23.14\nlocal gradient DR17:nOxiranes\nrelative frequency\n \n \nsteroid\nnon\u2212steroid\n(a) epoxide feature: steroid vs. non-steroid\n\u22120.5\n0\n0.5\n1\n0\n0.02\n0.04\n0.06\n0.08\nKS p\u2212value = 0.12\nsymm. KLD = 11.08\nlocal gradient DR17:nOxiranes\nrelative frequency\n \n \nrandom\nothers\n(b) epoxide feature: random compounds vs. the rest\n\u22120.2\n0\n0.2\n0.4\n0.6\n0\n0.05\n0.1\n0.15\n0.2\n0.25\nKS p\u2212value = 0.00\nsymm. KLD = 12.51\nlocal gradient DR17:nRNNOx\nrelative frequency\n \n \nsteroid\nnon\u2212steroid\n(c) aliphatic nitrosamine feature: steroid vs.\nnon-\nsteroid\n\u22120.2\n0\n0.2\n0.4\n0.6\n0\n0.02\n0.04\n0.06\n0.08\n0.1\nKS p\u2212value = 0.16\nsymm. KLD = 5.07\nlocal gradient DR17:nRNNOx\nrelative frequency\n \n \nrandom\nothers\n(d) aliphatic nitrosamine feature:\nrandom com-\npounds vs. the rest\nFigure 9: The local distribution of feature importance to steroids and random non-steroid\ncompounds signi\ufb01cantly di\ufb00ers for two known toxicophores. The small local gra-\ndients found for the steroids (shown in blue) indicate that the presence of each\ntoxicophore is irrelevant to the molecules toxicity.\nFor non-steroids (shown in\nred) the known toxicophores indeed exhibit positive local gradients.\n17\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\ncomparison we also show the distributions for compounds chosen at random from the test\nset (b,d). Each sub\ufb01gure contains two measures of (dis-)similarity for each pair of distribu-\ntions. The p-value of the Kolmogorov-Smirno\ufb00test (KS) gives the probability of error when\nrejecting the hypothesis that both relative frequencies are drawn from the same underlying\ndistribution. The symmetrized Kullback-Leibler divergence (KLD) gives a metric of the dis-\ntance between the two distributions.10 While containing epoxides generally tends to make\nmolecules mutagenic (see discussion above), we do not observe this e\ufb00ect for steroids: In\nFigure 9(a), almost all epoxide containing non-steroids exhibit positive gradients, thereby\nfollowing the global distribution of epoxide containing compounds as shown in Figure 7(f).\nIn contrast, almost all epoxide containing steroids exhibit gradients just below zero. \u201cIm-\nmunity\u201d of steroids to the epoxide toxicophore is an established fact and has \ufb01rst been\ndiscussed by Glatt, Jung, and Oesch (1983). This peculiarity in chemical space is clearly\nexhibited by the local explanation given by our approach. For aliphatic nitrosamine, the\nsituation in the GPC model is less clear but still the toxifying in\ufb02uence seems to be less in\nsteroids than in many other compounds. To our knowledge, this phenomenon has not yet\nbeen discussed in the pharmaceutical literature.\nIn conclusion, we can learn from the explanation vectors that:\n\u2022 toxicophores tend to make compounds mutagenic (class 1)\n\u2022 detoxicophores tend to make compounds non-mutagenic (class 0)\n\u2022 steroids are immune to the presence of some toxicophores (epoxide, possibly also\naliphatic nitrosamine)\n7. Related Work\nAssigning potentially di\ufb00erent explanations to individual data points distinguishes our ap-\nproach from conventional feature extraction methods that extract global features that are\nrelevant for all data points, i.e. those features that allow to achieve a small overall prediction\nerror. Our notion of explanation is not related to the prediction error, but only to the label\nprovided by the prediction algorithm. Even though the error is large, our framework is able\nto answer the question why the algorithm has decided on a data point the way it did.\nThe explanation vector proposed here is similar in spirit to sensitivity analysis which is\ncommon to various areas of information science. A classical example is the outlier sensitivity\nin statistics (Hampel, Ronchetti, Rousseeuw, and Stahel, 1986). In this case, the e\ufb00ects of\nremoving single data points on estimated parameters are evaluated by an in\ufb02uence function.\nIf the in\ufb02uence for a data point is signi\ufb01cantly large, it is detected as an outlier and should be\nremoved for the following analysis. In regression problems, leverage analysis is a procedure\nalong similar lines. It detects leverage points which have potential to give large impact\non the estimate of the regression function. In contrast to the in\ufb02uential points (outliers),\nremoving a leverage sample may not actually change the regressor, if its response is very\nclose to the predicted value. E.g. for linear regression the samples whose inputs are far from\n10. Symmetry is achieved by averaging the two Kullback-Leibler divergences:\nKL(P 1,P 2)+KL(P 2,P 1)\n2\n, cf.\nJohnson and Sinanovic (2000). To prevent zero-values in the histograms which would lead to in\ufb01nite KL\ndistances, an \u03b5 > 0 has been added to each bin count.\n18\nHow to Explain Individual Classification Decisions\nthe mean are the leverage points. Our framework of explanation vectors considers a di\ufb00erent\nview. It describes the in\ufb02uence of moving single data points locally and it thus answers the\nquestion which directions are locally most in\ufb02uential to the prediction. The explanation\nvectors are used for extracting sensitive features which are relevant to the prediction results,\nrather than detecting/eliminating the in\ufb02uential samples.\nIn recent decades, explanation of results by expert systems have been an important\ntopic in the AI community. Especially, for those based on Bayesian belief networks, such\nexplanation is crucial in practical use. In this context sensitivity analysis has also been\nused as a guiding principle (Horvitz, Breese, and Henrion, 1988). There the in\ufb02uence is\nevaluated by removing a set of variables (features) from evidences and the explanation is\nconstructed from those variables which a\ufb00ect inference (relevant variables). For example,\nSuermondt (1992) measures the cost of omitting a single feature Ei by the cross-entropy\nH\u2212(Ei) = H(p(D|E); P(D|E\\Ei) ) =\nN\nX\nj=1\nP(dj|E) log\nP(dj|E)\np(dj|E\\Ei),\nwhere E denotes evidences and D = (d1, . . . , dN)T is the target variable. The cost of a\nsubset F \u2282E can be de\ufb01ned similarly. This line of research is more connected to our work,\nbecause explanation can depend on the assigned values of the evidences E, and is thus local.\nSimilarly Robnik-\u02c7Sikonja and Kononenko (2008) and \u02c7Strumbelj and Kononenko (2008)\ntry to explain the decision of trained kNN-, SVM- and ANN-models for individual instances\nby measuring the di\ufb00erence in their prediction with sets of features omitted. The cost of\nomitting features is evaluated as the information di\ufb00erence, the log-odds ratio or the dif-\nference of probabilities between the model with knowledge about all features and with\nomissions respectively. To know what the prediction would be without the knowledge of\na certain feature the model is retrained for every choice of features whose in\ufb02uence is to\nbe explained. To save the time of combinatorial training Robnik-\u02c7Sikonja and Kononenko\n(2008) propose to use neutral values which have to be estimated by a known prior distri-\nbution of all possible parameter values. As a theoretical framework for considering feature\ninteractions, \u02c7Strumbelj and Kononenko (2008) propose to calculate the di\ufb00erences between\nmodel predictions for every choice of feature subset.\nFor multi-layer perceptrons F\u00b4eraud and Cl\u00b4erot (2002) measure the importance of indi-\nvidual input variables on clusters of test points. Therefore the change in the model output\nis evaluated for the change of a single input variable in a chosen interval while all other\ninput variables are \ufb01xed. Lemaire and Feraud (2007) use a similar approach on an instance\nby instance basis. By considering each input variable in turn there is no way to measure\ninput feature interactions on the model output (see LeCun, Bottou, Orr, and M\u00a8uller, 1998).\nThe principal di\ufb00erences between our approach and these frameworks are: (i) We con-\nsider continuous features and no structure among them is required, while some other frame-\nworks start from binary features and may require discretization steps with the need to\nestimate parameters for it. (ii) We allow changes in any direction, i.e. any weighted com-\nbination of variables, while other approaches only consider one feature at a time or the\nomission of a set of variables.\n19\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\np(       |   )\ny=1  x\nx1\nx1\nx2\n0.5\nFigure 10: \u03b6(x) is the zero vector in the middle of the cluster in the middle.\n8. Discussion\nBy now we have shown that our methods for calculating / estimating explanation vectors\nare useful in a variety of situations. In the following we discuss their limitations.\nWhat can we do, if the derivative is zero?\nThis situation is depicted in Figure 10. In\nthe lower panel we see a two-dimensional data set consisting of three clusters. The middle\ncluster has a di\ufb00erent class than the clusters on the left and on the right. Relevant for\nthe classi\ufb01cation is only the horizontal coordinate (i.e. x1). The upper panel shows the\nprojected data and a representative slice of \u03b6(x). However, the explanation \u03b6(x) for the\ncenter point of the middle cluster is the zero vector, because at that point p(Y =1|X =x) is\nmaximal. What can we do in such situations? Actually, the (normalized) explanation vector\nis derived from the following optimization problem for \ufb01nding the locally most in\ufb02uential\ndirection: argmax\u2225\u03b5\u2225=1 {p(Y \u0338=g\u2217(x0)|X = x0 + \u03b5) \u2212p(Y \u0338=g\u2217(x0)|X = x0)}.\nIn case that\nthe \ufb01rst derivative of the above criterion is zero, its Taylor expansion starts from the second\norder term, which is a quadratic form in its Hessian matrix. In the example data set with\nthree clusters, the explanation vector is constant along the second dimension. The most\ninteresting direction is given by the eigenvector corresponding to the largest eigenvalue of\nthe Hessian. This direction will be in our example along the \ufb01rst dimension. Thus, we can\nlearn from the Hessian that the \ufb01rst coordinate is relevant for the classi\ufb01cation, but we do\nnot obtain an orientation for it. Instead it means that both directions (left and right) will\nin\ufb02uence the classi\ufb01cation. However, if the conditional distribution P(Y = 1 | X = x) is \ufb02at\nin some regions, no meaningful explanation can be obtained by the gradient-based approach\nwith the remedy mentioned above. Practically, by using Parzen window estimators with\nlarger widths, the explanation vector can capture coarse structures of the classi\ufb01er at the\npoints which are not so far from the boarders. In A.2.2 we give an illustration of this point.\nIn the future, we would like to work on global approaches, e.g. based on distances to the\nboarders, or extensions of the approach by Robnik-\u02c7Sikonja and Kononenko (2008). Since\n20\nHow to Explain Individual Classification Decisions\nthese procedures are expected to be computationally demanding, our proposal is useful in\npractice, in particular for probabilistic classi\ufb01ers.\nDoes our framework generate di\ufb00erent explanations for di\ufb00erent prediction\nmodels?\nWhen using the local gradient of the model prediction directly as in De\ufb01ni-\ntion 2 and Section 6, the explanation follows the given model precisely by de\ufb01nition. For\nthe estimation framework this depends on whether the di\ufb00erent classi\ufb01ers classify the data\ndi\ufb00erently. In that case the explanation vectors will be di\ufb00erent, which makes sense, since\nthey should explain the classi\ufb01er at hand, even if its estimated labels were not all correct.\nOn the other hand, if the di\ufb00erent classi\ufb01ers agree on all labels, the explanation will be\nexactly equal.\nWhich implicit limitations do analytical gradients inherit from Gaussian Process\nmodels?\nA particular phenomenon can be observed at the boundaries of the training data:\nFar from the training data, Gaussian Process Classi\ufb01cation models predict a probability of\n0.5 for the positive class. When querying the model in an area of the feature space where\npredictions are negative, and one approaches the boundaries of the space populated with\ntraining data, explanation vectors will point away from any training data and therefore\nalso away from areas of positive prediction. This behavior can be observed in Figure 1(d),\nwhere unit length vectors indicate the direction of explanation vectors. In the right hand\nside corner, arrows point away from the triangle.\nHowever, we can see that the length\nof these vectors is so small, that they are not even visible in Figure 1(c). Consequently,\nthis property of GPC models does not pose a restriction for identifying the locally most\nin\ufb02uential features by investigating the features with the highest absolute values in the\nrespective partial derivatives, as shown in Section 6.\nStationarity of the data.\nSince explanation vectors are de\ufb01ned as local gradients of the\nmodel prediction (see De\ufb01nition 2), no assumption on the data is made: The local gradients\nfollow the predictive model in any case. If, however, the model to be explained assumes\nstationarity of the data, the explanation vectors will inherit this limitation and re\ufb02ect any\nshortcomings of the model (e.g. when the model is applied to non-stationary data). Our\nmethod for estimating explanation vectors, on the other hand, assumes stationarity of the\ndata.\nWhen modeling data that is in fact non-stationary, appropriate measures to deal with\nsuch data sets should be taken.\nOne option is to separate the feature space into sta-\ntionary and non-stationary parts using Stationary Subspace Analysis as introduced by\nvon B\u00a8unau, Meinecke, Kir\u00b4aly, and M\u00a8uller (2009). For further approaches to data set shift\nsee Sugiyama, Nakajima, Kashima, von Buenau, and Kawanabe (2007b), Sugiyama, Krauledat, and M\u00a8uller\n(2007a) and the book by Quionero-Candela, Sugiyama, Schwaighofer, and Lawrence (2009).\n9. Conclusion\nThis paper proposes a method that sheds light into the black boxes of nonlinear classi\ufb01ers.\nIn other words, we introduce a method that can explain the local decisions taken by arbitrary\n(possibly) nonlinear classi\ufb01cation algorithms. In a nutshell, the estimated explanations are\nlocal gradients that characterize how a data point has to be moved to change its predicted\n21\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\nlabel.\nFor models where such gradient information cannot be calculated explicitly, we\nemploy a probabilistic approximate mimic of the learning machine to be explained.\nTo validate our methodology we show how it can be used to draw new conclusions on\nhow the various Iris \ufb02owers in Fisher\u2019s famous data set are di\ufb00erent from each other and\nhow to identify the features with which certain types of digits 2 and 8 in the USPS data set\ncan be distinguished. Furthermore, we applied our method to a challenging drug discovery\nproblem. The results on that data fully agree with existing domain knowledge, which was\nnot available to our method. Even local peculiarities in chemical space (the extraordinary\nbehavior of steroids) was discovered using the local explanations given by our approach.\nFuture directions are two-fold: First we believe that our method will \ufb01nd its way into the\ntool boxes of practitioners who not only want to automatically classify their data but who\nalso would like to understand the learned classi\ufb01er. Thus using our explanation framework\nin computation biology (see Sonnenburg, Zien, Philips, and R\u00a8atsch, 2008) and in decision\nmaking experiments in psychophysics (e.g. Kienzle, Franz, Sch\u00a8olkopf, and Wichmann, 2009)\nseems most promising. The second direction is to generalize our approach to other prediction\nproblems such as regression.\nAcknowledgments\nThis work was supported in part by the FP7-ICT Programme of the European Community,\nunder the PASCAL2 Network of Excellence, ICT-216886 and by DFG Grant MU 987/4-1.\nWe would like to thank Andreas Sutter, Antonius Ter Laak, Thomas Steger-Hartmann and\nNikolaus Heinrich for publishing the Ames mutagenicity data set (Hansen, Mika, Schroeter, Sutter, Laak, Stege\n2009).\nA. Appendix\nA.1 Illustration of direct local gradients\nIn the following we give some illustrative examples of our method to explain models using\nlocal gradients.\nSince the explanation is derived directly from the respective model, it\nis interesting to investigate its acuteness depending on di\ufb00erent model parameters and in\ninstructive scenarios. We examine the e\ufb00ects that local gradients exhibit when choosing\ndi\ufb00erent kernel functions, when introducing outliers, and when the classes are not linearly\nseparable locally.\nA.1.1 Choice of kernel function\nFigure 11 shows the e\ufb00ect of di\ufb00erent kernel functions on the triangle toy data from Figure\n1 in Section 2. The following observations can be made:\n\u2022 In any case note that the local gradients explain the model, which in turn may or may\nnot capture the true situation.\n\u2022 In Sub\ufb01gure 11(a) the linear kernel leads to a model which fails to capture the non-\nlinear class separation. This model misspeci\ufb01cation is re\ufb02ected by the explanations\ngiven for this model in Sub\ufb01gure 11(b).\n22\nHow to Explain Individual Classification Decisions\n(a) linear model\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n(b) linear explanation\n(c) rational quadratic model\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n(d) rational quadratic explanation\nFigure 11: The e\ufb00ect of di\ufb00erent kernel functions to the local gradient explanations\n\u2022 The rational quadratic kernel is able to more accurately model the non-linear sep-\naration.\nIn Sub\ufb01gure 11(c) a non-optimal degree parameter has been chosen for\nillustrative purposes. For other parameter values the rational quadratic kernel leads\nto similar results as the RBF kernel function used in Figure 1.\n\u2022 The explanations in Sub\ufb01gure 11(d) obtained for this model show local perturbations\nat the small \u201cbumps\u201d of the model but the trends towards the positive class are still\nclear.\nAs previously observed in Figure 1, the explanations make clear that both\nfeatures interact at the corners and on the hypotenuse of the triangle class.\nA.1.2 Outliers\nIn Figure 12 the e\ufb00ects of two outliers in the classi\ufb01cation data to GPC with RBF kernel are\nshown. Once more, note that the local gradients explain the model, which in turn may or\n23\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\n0\n0.2\n0.4\n0.6\n0.8\n1\n0\n0.2\n0.4\n0.6\n0.8\n1\n\u22121\n\u22120.5\n0\n0.5\n1\n(a) outliers in classes\n(b) outliers in model\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n(c) outlier explanation\nFigure 12: The e\ufb00ect of outliers to the local gradient explanations\nmay not capture the true situation. The size of the region a\ufb00ected by the outliers depends\non the kernel width parameter. We consider the following items:\n\u2022 Local gradients are in the same way sensitive to outliers as the model which they try\nto explain. Here a single outlier deforms the model and with it the explanation which\nmay be extracted from it.\n\u2022 Being derivatives the sensitivity of local gradients to a nearby outlier is increased over\nthe sensitivity of the model prediction itself.\n\u2022 Thus the local gradient of a point near an outlier may not re\ufb02ect a true explanation\nof the features important in reality. Nevertheless it is the model here which is wrong\naround an outlier in the \ufb01rst place.\n\u2022 The histograms in the Figures 7, 8, and 9 in Section 6 show the trends of the respective\nfeatures in the distribution of all test points and are thus not a\ufb00ected by single outliers.\n24\nHow to Explain Individual Classification Decisions\nTo compensate for the e\ufb00ect of outliers to the local gradients of points in the a\ufb00ected\nregion we propose to use a sliding window method to smooth the gradients around each\npoint of interest. Thus for each point use the mean of all local gradients in the hypercube\ncentered at this point and of appropriate size. This way the disrupting e\ufb00ect of an outlier\nis averaged out for an appropriately chosen window size.\nA.1.3 Local non-linearity\n0\n0.2\n0.4\n0.6\n0.8\n1\n0\n0.2\n0.4\n0.6\n0.8\n1\n\u22121\n\u22120.5\n0\n0.5\n1\n(a) locally non-linear object\n(b) locally non-linear model\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n(c) locally non-linear explanation\nFigure 13: The e\ufb00ect of local non-linearity to the local gradient explanations\nThe e\ufb00ect of locally non-linear class boundaries in the data is shown in Figure 13 again\nfor GPC with an RBF kernel. The following points can be observed:\n\u2022 All the non-linear class boundaries are accurately followed by the local gradients\n\u2022 The circle shaped region of negative examples surrounded by positive ones shows the\nfull range of feature interactions towards the positive class\n25\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\n\u2022 On the ridge of single positive instances the model introduces small valleys which are\nre\ufb02ected by the local gradients\nA.2 Estimating by Parzen window\nFinally we elaborate on some details of our estimation approach of local gradients by Parzen\nwindow approximation. First we give the derivation to obtain the explanation vector and\nsecond we examine how the explanation varies with the goodness of \ufb01t of the Parzen window\nmethod.\nA.2.1 Derivation of explanation vectors\nThese are more details on the derivation of Eq. (3). We use the index set Ic = {i | g(xi) = c}:\n\u2202\n\u2202xk\u03c3(x) = \u2212x\n\u03c32 k\u03c3(x)\n\u2202\n\u2202x \u02c6p\u03c3(x, y\u0338=c) = 1\nn\nX\ni/\u2208Ic\nk\u03c3(x \u2212xi)\u2212(x \u2212xi)\n\u03c32\n\u2202\n\u2202x \u02c6p\u03c3(y\u0338=c|x)\n=\n\u0010 P\ni/\u2208Ic k(x \u2212xi)\n\u0011\u0010 Pn\ni=1 k(x \u2212xi)(x \u2212xi)\n\u0011\n\u03c32 \u0000 Pn\ni=1 k(z \u2212xi)\n\u00012\n\u2212\n\u0010 P\ni/\u2208Ic k(x \u2212xi)(x \u2212xi)\n\u0011\u0010 Pn\ni=1 k(x \u2212xi)\n\u0011\n\u03c32 \u0000 Pn\ni=1 k(z \u2212xi)\n\u00012\n=\n\u0010 P\ni/\u2208Ic k(x \u2212xi)\n\u0011\u0010 P\ni\u2208Ic k(x \u2212xi)(x \u2212xi)\n\u0011\n\u03c32 \u0000 Pn\ni=1 k(z \u2212xi)\n\u00012\n\u2212\n\u0010 P\ni/\u2208Ic k(x \u2212xi)(x \u2212xi)\n\u0011\u0010 P\ni\u2208Ic k(x \u2212xi)\n\u0011\n\u03c32 \u0000 Pn\ni=1 k(z \u2212xi)\n\u00012\nand thus for the index set Ig(z) = {i | g(xi) = g(z)}\n\u02c6\u03b6(z) = \u2202\n\u2202x \u02c6p(y\u0338=g(z) | x)\n\f\f\f\f\nx=z\n=\n\u0010 P\ni/\u2208Ig(z) k(z \u2212xi)\n\u0011\u0010 P\ni\u2208Ig(z) k(z \u2212xi)(z \u2212xi)\n\u0011\n\u03c32 \u0000 Pn\ni=1 k(z \u2212xi)\n\u00012\n\u2212\n\u0010 P\ni/\u2208Ig(z) k(z \u2212xi)(z \u2212xi)\n\u0011\u0010 P\ni\u2208Ig(z) k(z \u2212xi)\n\u0011\n\u03c32 \u0000 Pn\ni=1 k(z \u2212xi)\n\u00012\n26\nHow to Explain Individual Classification Decisions\nA.2.2 Goodness of fit by Parzen window\nIn our estimation framework the quality of the local gradients depends on the approximation\nof the classi\ufb01er we want to explain by Parzen windows for which we can calculate the\nexplanation vectors as given by De\ufb01nition 3.\n(a) SVM model\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n(b) estimated explanation with \u03c3 = 0.00069\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n(c) estimated explanation with \u03c3 = 0.1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n(d) estimated explanation with \u03c3 = 1.0\nFigure 14: Good \ufb01t of Parzen window approximation a\ufb00ects the quality of the estimated\nexplanation vectors\nFigure 14(a) shows an SVM model trained on the classi\ufb01cation data from Figure 13(a).\nThe local gradients estimated for this model by di\ufb00erent Parzen window approximations\nare depicted in Sub\ufb01gures 14(b), 14(c), and 14(d). We observe the following points:\n\u2022 The SVM model was trained with C = 10 and using an RBF kernel of width \u03c3 = 0.01\n\u2022 In Sub\ufb01gure 14(b) a small window width has been chosen by minimizing the mean\nabsolute error over the validation set of labels predicted by the SVM classi\ufb01er. Thus we\n27\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\nobtain explaining local gradients on the class boundaries but zero vectors in the inner\nclass regions. While this resembles the piecewise \ufb02at SVM model most accurately it\nmay be more useful practically to choose a larger width to obtain non-zero gradients\npointing to the borders in this regions as well. For a more detailed discussion of zero\ngradients see Section 8.\n\u2022 A larger width practically useful in this example is shown in Sub\ufb01gure 14(c). Here\nthe local gradients in the inner class regions point to the other class as well.\n\u2022 For a too large window width in Sub\ufb01gure 14(d) the approximation fails to obtain\nlocal gradients which closely follow the model. Here only two directions are left and\nthe gradients for the blue class on the left and on the bottom point in the wrong\ndirection.\nReferences\nBruce\nN.\nAmes,\nE.\nG.\nGurney,\nJames\nA.\nMiller,\nand\nH.\nBartsch.\nCarcino-\ngens as Frameshift Mutagens:\nMetabolites and Derivatives of 2-Acetylamino\ufb02uorene\nand Other Aromatic Amine Carcinogens.\nProceedings of the National Academy\nof\nSciences\nof\nthe\nUnited\nStates\nof\nAmerica,\n69(11):3128\u20133132,\n1972.\nURL\nhttp://www.pnas.org/content/69/11/3128.abstract.\nC.M. Bishop. Neural Networks for Pattern Recognition. Oxford University Press, 1995.\nL. Devroye, L. Gy\u00a8or\ufb01, and G. Lugosi. A Probabilistic Theory of Pattern Recognition. Num-\nber 31 in Applications of Mathematics. Springer, New York, 1996.\nR.A. Fisher. The Use of Multiple Measurements in Taxonomic Problems. Annals of Eu-\ngenics, 7:179\u2013188, 1936.\nRaphael\nF\u00b4eraud\nand\nFabrice\nCl\u00b4erot.\nA\nmethodology\nto\nexplain\nneu-\nral\nnetwork\nclassi\ufb01cation.\nNeural\nNetworks,\n15(2):237\n\u2013\n246,\n2002.\nISSN\n0893-6080.\ndoi:\nDOI:10.1016/S0893-6080(01)00127-7.\nURL\nhttp://www.sciencedirect.com/science/article/B6T08-4441WFN-5/2/d097075076605aa08026f96410\nHansruedi Glatt, Reinhard Jung, and Franz Oesch.\nBacterial mutagenicity inves-\ntigation of epoxides:\ndrugs,\ndrug metabolites,\nsteroids and pesticides.\nMuta-\ntion Research/Fundamental and Molecular Mechanisms of Mutagenesis, 111(2):99\u2013\n118,\n1983.\nISSN 0027-5107.\ndoi:\nDOI:10.1016/0027-5107(83)90056-8.\nURL\nhttp://dx.doi.org/10.1016/0027-5107(83)90056-8.\nIsabelle Guyon and Andr\u00b4e Elissee\ufb00. An introduction to variable and feature selection. The\nJournal of Machine Learning Research, 3:1157\u20131182, 2003.\nF. R. Hampel, E. M. Ronchetti, P. J. Rousseeuw, and W. A. Stahel. Robust Statistics: The\nApproach Based on In\ufb02uence Functions. Wiley, New York, 1986.\nKatja Hansen, Sebastian Mika, Timon Schroeter, Andreas Sutter, Antonius Ter Laak,\nThomas Steger-Hartmann, Nikolaus Heinrich, and Klaus-Robert M\u00a8uller. A benchmark\n28\nHow to Explain Individual Classification Decisions\ndata set for in silico prediction of ames mutagenicity. Journal of Chemical Information\nand Modelling, 49(9):2077\u20132081, 2009. URL http://dx.doi.org/10.1021/ci900161g.\nTrevor Hastie, Robert Tibshirani, and Jerome Friedman. The Elements of Statistical Learn-\ning. Springer, 2001.\nE. J. Horvitz, J. S. Breese, and M. Henrion. Decision theory in expert systems and arti\ufb01cial\ninterigence.\nJournal of Approximation Reasoning, 2:247\u2013302, 1988.\nSpecial Issue on\nUncertainty in Arti\ufb01cial Intelligence.\nDon H. Johnson and Sinan Sinanovic. Symmetrizing the Kullback-Leibler distance. Tech-\nnical report, IEEE Transactions on Information Theory, 2000.\nJeroen Kazius, Ross McGuire, and Roberta Bursi. Derivation and validation of toxicophores\nfor mutagenicity prediction. J. Med. Chem., 48:312\u2013320, 2005.\nW. Kienzle, M. O. Franz, B. Sch\u00a8olkopf, and F. A. Wichmann. Center-surround patterns\nemerge as optimal predictors for human saccade targets. Journal of Vision, 9(5):1\u201315,\n2009.\nM. Kuss and C. E. Ramussen. Assesing approximate inference for bianry gaussian process\nclassi\ufb01cation. Journal of Machine Learning Research, 6:1679\u20131704, 2005.\nY. LeCun, L. Bottou, G.B. Orr, and K.-R. M\u00a8uller. E\ufb03cient backprop. In G.B. Orr and\nK.-R. M\u00a8uller, editors, Neural Networks: Tricks of the trade, pages 9\u201353. Springer, 1998.\nVincent Lemaire and Rapha\u00a8el Feraud. Une m\u00b4ethode d\u2019interpr\u00b4etation de scores. In Monique\nNoirhomme-Fraiture and Gilles Venturini, editors, EGC, volume RNTI-E-9 of Revue des\nNouvelles Technologies de l\u2019Information, pages 191\u2013192. C\u00b4epadu`es-\u00b4Editions, 2007. ISBN\n978-2-85428-763-9.\nK.R. M\u00a8uller, S. Mika, G. R\u00a8atsch, K. Tsuda, and B. Sch\u00a8olkopf. An introduction to kernel-\nbased learning algorithms. Neural Networks, IEEE Transactions on, 12(2):181\u2013201, 2001.\nOlga Obrezanova, G\u00b4abor Cs\u00b4anyi, Joelle M.R. Gola, and Matthew D. Segall.\nGaussian\nprocesses: A method for automatic QSAR modelling of adme properties. J. Chem. Inf.\nModel., 47(5):1847\u20131857, 2007. URL http://dx.doi.org/10.1021/ci7000633.\nOlga Obrezanova, Joelle M. R. Gola, Edmund J. Champness, and Matthew D. Segall.\nAutomatic QSAR modeling of adme properties:\nblood-brain barrier penetration\nand aqueous solubility.\nJ. Comput.-Aided Mol. Des.,\n22:431\u2013440,\n2008.\nURL\nhttp://dx.doi.org/10.1007/s10822-008-9193-8.\nJohn C. Platt. Probabilistic outputs for support vector machines and comparisons to reg-\nularized likelihood methods. In Advances in Large Margin Classi\ufb01ers, pages 61\u201374. MIT\nPress, 1999.\nJoaquin Quionero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D. Lawrence.\nDataset Shift in Machine Learning.\nThe MIT Press, 2009.\nISBN 0262170051,\n9780262170055.\n29\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\nC. E. Rasmussen and C. K. I. Williams. Gaussian Processes for Machine Learning. Springer,\n2006.\nMarko Robnik-\u02c7Sikonja and Igor Kononenko. Explaining classi\ufb01cations for individual in-\nstances. IEEE TKDE, 20(5):589\u2013600, 2008.\nB. Sch\u00a8olkopf and A. Smola. Learning with Kernels. MIT, 2002.\nTimon Schroeter, Anton Schwaighofer, Sebastian Mika, Antonius Ter Laak, Detlev Suel-\nzle, Ursula Ganzer, Nikolaus Heinrich, and Klaus-Robert M\u00a8uller.\nEstimating the do-\nmain of applicability for machine learning QSAR models:\nA study on aqueous sol-\nubility of drug discovery molecules.\nJournal of Computer Aided Molecular Design\n- special issue on \u201dADME and Physical Properties\u201d, 21(9):485\u2013498, 2007a.\nURL\nhttp://dx.doi.org/10.1007/s10822-007-9125-z.\nTimon Schroeter, Anton Schwaighofer, Sebastian Mika, Antonius Ter Laak, Detlev Suelzle,\nUrsula Ganzer, Nikolaus Heinrich, and Klaus-Robert M\u00a8uller. Machine learning models\nfor lipophilicity and their domain of applicability. Mol. Pharm., 4(4):524\u2013538, 2007b.\nURL http://dx.doi.org/10.1021/mp0700413.\nTimon Schroeter, Anton Schwaighofer, Sebastian Mika, Antonius ter Laak, Detlev S\u00a8ulzle,\nUrsula Ganzer, Nikolaus Heinrich, and Klaus-Robert M\u00a8uller. Predicting lipophilicity of\ndrug discovery molecules using gaussian process models. ChemMedChem, 2(9):1265\u20131267,\n2007c. URL http://dx.doi.org/10.1002/cmdc.200700041.\nA.\nSchwaighofer.\nSVM\nToolbox\nfor\nMatlab,\nJan\n2002.\nURL\nhttp://ida.first.fraunhofer.de/~anton/software.html.\nAnton Schwaighofer, Timon Schroeter, Sebastian Mika, Julian Laub, Antonius ter Laak,\nDetlev S\u00a8ulzle, Ursula Ganzer, Nikolaus Heinrich, and Klaus-Robert M\u00a8uller.\nAccu-\nrate solubility prediction with error bars for electrolytes:\nA machine learning ap-\nproach.\nJournal of Chemical Information and Modelling, 47(2):407\u2013424, 2007.\nURL\nhttp://dx.doi.org/10.1021/ci600205g.\nAnton Schwaighofer, Timon Schroeter, Sebastian Mika, Katja Hansen, Antonius ter Laak,\nPhilip Lienau, Andreas Reichel, Nikolaus Heinrich, and Klaus-Robert M\u00a8uller. A proba-\nbilistic approach to classifying metabolic stability. Journal of Chemical Information and\nModelling, 48(4):785\u2013796, 2008. URL http://dx.doi.org/10.1021/ci700142c.\nS\u00a8oren Sonnenburg, Alexander Zien, Petra Philips, and Gunnar R\u00a8atsch. POIMs: positional\noligomer importance matrices \u2014 understanding support vector machine based signal\ndetectors. Bioinformatics, 2008. (received the Best Student Paper Award at ISMB\u00b408).\nH. Suermondt.\nExplanation in Bayesian Belief Networks.\nPhD thesis, Department of\nComputer Science and Medicine, Stanford University, Stanford, CA, 1992.\nMasashi Sugiyama, Matthias Krauledat, and Klaus-Robert M\u00a8uller. Covariate shift adapta-\ntion by importance weighted cross validation. Journal of Machine Learning Research, 8:\n985\u20131005, May 2007a.\n30\nHow to Explain Individual Classification Decisions\nMasashi Sugiyama, Shinichi Nakajima, Hisashi Kashima, Paul von Buenau, and Motoaki\nKawanabe.\nDirect importance estimation with model selection and its application to\ncovariate shift adaptation. In Advances in Neural Information Processing Systems 20.\nMIT Press, 2007b.\nR. Todeschini, V. Consonni, A. Mauri, and M. Pavan. Dragon for windows and linux 2006.\nhttp://www.talete.mi.it/help/dragon_help/ (accessed 27 March 2009), 2006.\nV. Vapnik. The Nature of Statistical Learning Theory. Springer, 1995.\nPaul von B\u00a8unau,\nFrank C Meinecke,\nFranz J Kir\u00b4aly,\nand Klaus-Robert M\u00a8uller.\nFinding stationary\nsubspaces in multivariate\ntime series.\nPhysical review let-\nters,\n103(21):214101,\n2009.\ndoi:\n10.1103/PhysRevLett.103.214101.\nURL\nhttp://link.aps.org/abstract/PRL/v103/e214101.\nErik \u02c7Strumbelj and Igor Kononenko. Towards a model independent method for explaining\nclassi\ufb01cation for individual instances. In I.-Y. Song, J. Eder, and T.M. Nguyen, editors,\nData Warehousing and Knowledge Discovery, volume 5182 of Lecture Notes in Computer\nScience, pages 273\u2013282. Springer, 2008.\n31\n",
        "sentence": " decisions made by a model [1] and can be used to, for instance, identify the parts of the input which led to a correct classification of a given visual input instance (in other words, one can use a trained model for weakly-supervised localization). x+ r \u2208 [0, 1] \u2022 Minimize c|r|+ lossf (x+ r, l) subject to x+ r \u2208 [0, 1] The pixel intensities are scaled to be in the range [0, 1].",
        "context": ":\n\u211cd \u2192[0, 1] of a classi\ufb01cation model learned from\nexamples {(x1, y1), . . . , (xn, yn)} \u2208\u211cd \u00d7{\u22121, +1} the explanation vector for a classi\ufb01ed test\npoint x0 is the local gradient of p at x0:\n3\n0.4\n0.6\n0.8\n1\n\u22121\n\u22120.5\n0\n0.5\n1\n(a) locally non-linear object\n(b) locally non-linear model\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\n0.8\n0.9\n1\n(c) locally non-linear explanation\nlocal gradients that characterize how a data point has to be moved to change its predicted\n21\nD. Baehrens, T. Schroeter, S. Harmeling, M. Kawanabe, K. Hansen, K.-R. M\u00a8uller\nlabel."
    },
    {
        "title": "Learning deep architectures for ai",
        "author": [
            "Yoshua Bengio"
        ],
        "venue": "Foundations and trends\u00ae in Machine Learning,",
        "citeRegEx": "2",
        "shortCiteRegEx": "2",
        "year": 2009,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " It has been argued [2] that the deep stack of non-linear layers in between the input and the output unit of a neural network are a way for the model to encode a non-local generalization prior over the input space.",
        "context": null
    },
    {
        "title": "Imagenet: A large-scale hierarchical image database",
        "author": [
            "Jia Deng",
            "Wei Dong",
            "Richard Socher",
            "Li-Jia Li",
            "Kai Li",
            "Li Fei-Fei"
        ],
        "venue": "In Computer Vision and Pattern Recognition,",
        "citeRegEx": "3",
        "shortCiteRegEx": "3",
        "year": 2009,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " \u2022 The ImageNet dataset [3].",
        "context": null
    },
    {
        "title": "Visualizing higher-layer features of a deep network",
        "author": [
            "Dumitru Erhan",
            "Yoshua Bengio",
            "Aaron Courville",
            "Pascal Vincent"
        ],
        "venue": "Technical Report 1341,",
        "citeRegEx": "4",
        "shortCiteRegEx": "4",
        "year": 2009,
        "abstract": "",
        "full_text": "",
        "sentence": " They look for input images which maximize the activation value of this single feature [6, 13, 7, 4]. So far, unit-level inspection methods had relatively little utility beyond confirming certain intuitions regarding the complexity of the representations learned by a deep neural network [6, 13, 7, 4].",
        "context": null
    },
    {
        "title": "A discriminatively trained, multiscale, deformable part model",
        "author": [
            "Pedro Felzenszwalb",
            "David McAllester",
            "Deva Ramanan"
        ],
        "venue": "In Computer Vision and Pattern Recognition,",
        "citeRegEx": "5",
        "shortCiteRegEx": "5",
        "year": 2008,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " [5].",
        "context": null
    },
    {
        "title": "Rich feature hierarchies for accurate object detection and semantic segmentation",
        "author": [
            "Ross Girshick",
            "Jeff Donahue",
            "Trevor Darrell",
            "Jitendra Malik"
        ],
        "venue": "arXiv preprint arXiv:1311.2524,",
        "citeRegEx": "6",
        "shortCiteRegEx": "6",
        "year": 2013,
        "abstract": "Object detection performance, as measured on the canonical PASCAL VOC\ndataset, has plateaued in the last few years. The best-performing methods are\ncomplex ensemble systems that typically combine multiple low-level image\nfeatures with high-level context. In this paper, we propose a simple and\nscalable detection algorithm that improves mean average precision (mAP) by more\nthan 30% relative to the previous best result on VOC 2012---achieving a mAP of\n53.3%. Our approach combines two key insights: (1) one can apply high-capacity\nconvolutional neural networks (CNNs) to bottom-up region proposals in order to\nlocalize and segment objects and (2) when labeled training data is scarce,\nsupervised pre-training for an auxiliary task, followed by domain-specific\nfine-tuning, yields a significant performance boost. Since we combine region\nproposals with CNNs, we call our method R-CNN: Regions with CNN features. We\nalso compare R-CNN to OverFeat, a recently proposed sliding-window detector\nbased on a similar CNN architecture. We find that R-CNN outperforms OverFeat by\na large margin on the 200-class ILSVRC2013 detection dataset. Source code for\nthe complete system is available at http://www.cs.berkeley.edu/~rbg/rcnn.",
        "full_text": "Rich feature hierarchies for accurate object detection and semantic segmentation\nTech report (v5)\nRoss Girshick Jeff Donahue Trevor Darrell Jitendra Malik\nUC Berkeley\n{rbg,jdonahue,trevor,malik}@eecs.berkeley.edu\nAbstract\nObject detection performance, as measured on the\ncanonical PASCAL VOC dataset, has plateaued in the last\nfew years. The best-performing methods are complex en-\nsemble systems that typically combine multiple low-level\nimage features with high-level context. In this paper, we\npropose a simple and scalable detection algorithm that im-\nproves mean average precision (mAP) by more than 30%\nrelative to the previous best result on VOC 2012\u2014achieving\na mAP of 53.3%. Our approach combines two key insights:\n(1) one can apply high-capacity convolutional neural net-\nworks (CNNs) to bottom-up region proposals in order to\nlocalize and segment objects and (2) when labeled training\ndata is scarce, supervised pre-training for an auxiliary task,\nfollowed by domain-speci\ufb01c \ufb01ne-tuning, yields a signi\ufb01cant\nperformance boost.\nSince we combine region proposals\nwith CNNs, we call our method R-CNN: Regions with CNN\nfeatures. We also compare R-CNN to OverFeat, a recently\nproposed sliding-window detector based on a similar CNN\narchitecture. We \ufb01nd that R-CNN outperforms OverFeat\nby a large margin on the 200-class ILSVRC2013 detection\ndataset. Source code for the complete system is available at\nhttp://www.cs.berkeley.edu/\u02dcrbg/rcnn.\n1. Introduction\nFeatures matter. The last decade of progress on various\nvisual recognition tasks has been based considerably on the\nuse of SIFT [29] and HOG [7]. But if we look at perfor-\nmance on the canonical visual recognition task, PASCAL\nVOC object detection [15], it is generally acknowledged\nthat progress has been slow during 2010-2012, with small\ngains obtained by building ensemble systems and employ-\ning minor variants of successful methods.\nSIFT and HOG are blockwise orientation histograms,\na representation we could associate roughly with complex\ncells in V1, the \ufb01rst cortical area in the primate visual path-\nway.\nBut we also know that recognition occurs several\nstages downstream, which suggests that there might be hier-\n1. Input \nimage\n2. Extract region \nproposals (~2k)\n3. Compute \nCNN features\naeroplane? no.\n...\nperson? yes.\ntvmonitor? no.\n4. Classify \nregions\nwarped region\n...\nCNN\nR-CNN: Regions with CNN features\nFigure 1: Object detection system overview. Our system (1)\ntakes an input image, (2) extracts around 2000 bottom-up region\nproposals, (3) computes features for each proposal using a large\nconvolutional neural network (CNN), and then (4) classi\ufb01es each\nregion using class-speci\ufb01c linear SVMs. R-CNN achieves a mean\naverage precision (mAP) of 53.7% on PASCAL VOC 2010. For\ncomparison, [39] reports 35.1% mAP using the same region pro-\nposals, but with a spatial pyramid and bag-of-visual-words ap-\nproach. The popular deformable part models perform at 33.4%.\nOn the 200-class ILSVRC2013 detection dataset, R-CNN\u2019s\nmAP is 31.4%, a large improvement over OverFeat [34], which\nhad the previous best result at 24.3%.\narchical, multi-stage processes for computing features that\nare even more informative for visual recognition.\nFukushima\u2019s\n\u201cneocognitron\u201d\n[19],\na\nbiologically-\ninspired hierarchical and shift-invariant model for pattern\nrecognition, was an early attempt at just such a process.\nThe neocognitron, however, lacked a supervised training\nalgorithm. Building on Rumelhart et al. [33], LeCun et\nal. [26] showed that stochastic gradient descent via back-\npropagation was effective for training convolutional neural\nnetworks (CNNs), a class of models that extend the neocog-\nnitron.\nCNNs saw heavy use in the 1990s (e.g., [27]), but then\nfell out of fashion with the rise of support vector machines.\nIn 2012, Krizhevsky et al. [25] rekindled interest in CNNs\nby showing substantially higher image classi\ufb01cation accu-\nracy on the ImageNet Large Scale Visual Recognition Chal-\nlenge (ILSVRC) [9, 10]. Their success resulted from train-\ning a large CNN on 1.2 million labeled images, together\nwith a few twists on LeCun\u2019s CNN (e.g., max(x, 0) rectify-\ning non-linearities and \u201cdropout\u201d regularization).\nThe signi\ufb01cance of the ImageNet result was vigorously\n1\narXiv:1311.2524v5  [cs.CV]  22 Oct 2014\ndebated during the ILSVRC 2012 workshop. The central\nissue can be distilled to the following: To what extent do\nthe CNN classi\ufb01cation results on ImageNet generalize to\nobject detection results on the PASCAL VOC Challenge?\nWe answer this question by bridging the gap between\nimage classi\ufb01cation and object detection. This paper is the\n\ufb01rst to show that a CNN can lead to dramatically higher ob-\nject detection performance on PASCAL VOC as compared\nto systems based on simpler HOG-like features. To achieve\nthis result, we focused on two problems: localizing objects\nwith a deep network and training a high-capacity model\nwith only a small quantity of annotated detection data.\nUnlike image classi\ufb01cation, detection requires localiz-\ning (likely many) objects within an image. One approach\nframes localization as a regression problem. However, work\nfrom Szegedy et al. [38], concurrent with our own, indi-\ncates that this strategy may not fare well in practice (they\nreport a mAP of 30.5% on VOC 2007 compared to the\n58.5% achieved by our method). An alternative is to build a\nsliding-window detector. CNNs have been used in this way\nfor at least two decades, typically on constrained object cat-\negories, such as faces [32, 40] and pedestrians [35]. In order\nto maintain high spatial resolution, these CNNs typically\nonly have two convolutional and pooling layers. We also\nconsidered adopting a sliding-window approach. However,\nunits high up in our network, which has \ufb01ve convolutional\nlayers, have very large receptive \ufb01elds (195 \u00d7 195 pixels)\nand strides (32\u00d732 pixels) in the input image, which makes\nprecise localization within the sliding-window paradigm an\nopen technical challenge.\nInstead, we solve the CNN localization problem by oper-\nating within the \u201crecognition using regions\u201d paradigm [21],\nwhich has been successful for both object detection [39] and\nsemantic segmentation [5]. At test time, our method gener-\nates around 2000 category-independent region proposals for\nthe input image, extracts a \ufb01xed-length feature vector from\neach proposal using a CNN, and then classi\ufb01es each region\nwith category-speci\ufb01c linear SVMs. We use a simple tech-\nnique (af\ufb01ne image warping) to compute a \ufb01xed-size CNN\ninput from each region proposal, regardless of the region\u2019s\nshape. Figure 1 presents an overview of our method and\nhighlights some of our results. Since our system combines\nregion proposals with CNNs, we dub the method R-CNN:\nRegions with CNN features.\nIn this updated version of this paper, we provide a head-\nto-head comparison of R-CNN and the recently proposed\nOverFeat [34] detection system by running R-CNN on the\n200-class ILSVRC2013 detection dataset. OverFeat uses a\nsliding-window CNN for detection and until now was the\nbest performing method on ILSVRC2013 detection. We\nshow that R-CNN signi\ufb01cantly outperforms OverFeat, with\na mAP of 31.4% versus 24.3%.\nA second challenge faced in detection is that labeled data\nis scarce and the amount currently available is insuf\ufb01cient\nfor training a large CNN. The conventional solution to this\nproblem is to use unsupervised pre-training, followed by su-\npervised \ufb01ne-tuning (e.g., [35]). The second principle con-\ntribution of this paper is to show that supervised pre-training\non a large auxiliary dataset (ILSVRC), followed by domain-\nspeci\ufb01c \ufb01ne-tuning on a small dataset (PASCAL), is an\neffective paradigm for learning high-capacity CNNs when\ndata is scarce. In our experiments, \ufb01ne-tuning for detection\nimproves mAP performance by 8 percentage points. After\n\ufb01ne-tuning, our system achieves a mAP of 54% on VOC\n2010 compared to 33% for the highly-tuned, HOG-based\ndeformable part model (DPM) [17, 20]. We also point read-\ners to contemporaneous work by Donahue et al. [12], who\nshow that Krizhevsky\u2019s CNN can be used (without \ufb01ne-\ntuning) as a blackbox feature extractor, yielding excellent\nperformance on several recognition tasks including scene\nclassi\ufb01cation, \ufb01ne-grained sub-categorization, and domain\nadaptation.\nOur system is also quite ef\ufb01cient. The only class-speci\ufb01c\ncomputations are a reasonably small matrix-vector product\nand greedy non-maximum suppression. This computational\nproperty follows from features that are shared across all cat-\negories and that are also two orders of magnitude lower-\ndimensional than previously used region features (cf. [39]).\nUnderstanding the failure modes of our approach is also\ncritical for improving it, and so we report results from the\ndetection analysis tool of Hoiem et al. [23]. As an im-\nmediate consequence of this analysis, we demonstrate that\na simple bounding-box regression method signi\ufb01cantly re-\nduces mislocalizations, which are the dominant error mode.\nBefore developing technical details, we note that because\nR-CNN operates on regions it is natural to extend it to the\ntask of semantic segmentation. With minor modi\ufb01cations,\nwe also achieve competitive results on the PASCAL VOC\nsegmentation task, with an average segmentation accuracy\nof 47.9% on the VOC 2011 test set.\n2. Object detection with R-CNN\nOur object detection system consists of three modules.\nThe \ufb01rst generates category-independent region proposals.\nThese proposals de\ufb01ne the set of candidate detections avail-\nable to our detector. The second module is a large convo-\nlutional neural network that extracts a \ufb01xed-length feature\nvector from each region. The third module is a set of class-\nspeci\ufb01c linear SVMs. In this section, we present our design\ndecisions for each module, describe their test-time usage,\ndetail how their parameters are learned, and show detection\nresults on PASCAL VOC 2010-12 and on ILSVRC2013.\n2.1. Module design\nRegion proposals. A variety of recent papers offer meth-\nods for generating category-independent region proposals.\n2\naeroplane\nbicycle\nbird\ncar\nFigure 2: Warped training samples from VOC 2007 train.\nExamples include: objectness [1], selective search [39],\ncategory-independent object proposals [14], constrained\nparametric min-cuts (CPMC) [5], multi-scale combinatorial\ngrouping [3], and Cires\u00b8an et al. [6], who detect mitotic cells\nby applying a CNN to regularly-spaced square crops, which\nare a special case of region proposals. While R-CNN is ag-\nnostic to the particular region proposal method, we use se-\nlective search to enable a controlled comparison with prior\ndetection work (e.g., [39, 41]).\nFeature extraction. We extract a 4096-dimensional fea-\nture vector from each region proposal using the Caffe [24]\nimplementation of the CNN described by Krizhevsky et\nal. [25]. Features are computed by forward propagating\na mean-subtracted 227 \u00d7 227 RGB image through \ufb01ve con-\nvolutional layers and two fully connected layers. We refer\nreaders to [24, 25] for more network architecture details.\nIn order to compute features for a region proposal, we\nmust \ufb01rst convert the image data in that region into a form\nthat is compatible with the CNN (its architecture requires\ninputs of a \ufb01xed 227 \u00d7 227 pixel size). Of the many possi-\nble transformations of our arbitrary-shaped regions, we opt\nfor the simplest. Regardless of the size or aspect ratio of the\ncandidate region, we warp all pixels in a tight bounding box\naround it to the required size. Prior to warping, we dilate the\ntight bounding box so that at the warped size there are ex-\nactly p pixels of warped image context around the original\nbox (we use p = 16). Figure 2 shows a random sampling\nof warped training regions. Alternatives to warping are dis-\ncussed in Appendix A.\n2.2. Test-time detection\nAt test time, we run selective search on the test image\nto extract around 2000 region proposals (we use selective\nsearch\u2019s \u201cfast mode\u201d in all experiments). We warp each\nproposal and forward propagate it through the CNN in or-\nder to compute features. Then, for each class, we score\neach extracted feature vector using the SVM trained for that\nclass. Given all scored regions in an image, we apply a\ngreedy non-maximum suppression (for each class indepen-\ndently) that rejects a region if it has an intersection-over-\nunion (IoU) overlap with a higher scoring selected region\nlarger than a learned threshold.\nRun-time analysis. Two properties make detection ef\ufb01-\ncient. First, all CNN parameters are shared across all cate-\ngories. Second, the feature vectors computed by the CNN\nare low-dimensional when compared to other common ap-\nproaches, such as spatial pyramids with bag-of-visual-word\nencodings. The features used in the UVA detection system\n[39], for example, are two orders of magnitude larger than\nours (360k vs. 4k-dimensional).\nThe result of such sharing is that the time spent com-\nputing region proposals and features (13s/image on a GPU\nor 53s/image on a CPU) is amortized over all classes. The\nonly class-speci\ufb01c computations are dot products between\nfeatures and SVM weights and non-maximum suppression.\nIn practice, all dot products for an image are batched into\na single matrix-matrix product. The feature matrix is typi-\ncally 2000\u00d74096 and the SVM weight matrix is 4096\u00d7N,\nwhere N is the number of classes.\nThis analysis shows that R-CNN can scale to thousands\nof object classes without resorting to approximate tech-\nniques, such as hashing. Even if there were 100k classes,\nthe resulting matrix multiplication takes only 10 seconds on\na modern multi-core CPU. This ef\ufb01ciency is not merely the\nresult of using region proposals and shared features. The\nUVA system, due to its high-dimensional features, would\nbe two orders of magnitude slower while requiring 134GB\nof memory just to store 100k linear predictors, compared to\njust 1.5GB for our lower-dimensional features.\nIt is also interesting to contrast R-CNN with the recent\nwork from Dean et al. on scalable detection using DPMs\nand hashing [8]. They report a mAP of around 16% on VOC\n2007 at a run-time of 5 minutes per image when introducing\n10k distractor classes. With our approach, 10k detectors can\nrun in about a minute on a CPU, and because no approxi-\nmations are made mAP would remain at 59% (Section 3.2).\n2.3. Training\nSupervised pre-training. We discriminatively pre-trained\nthe CNN on a large auxiliary dataset (ILSVRC2012 clas-\nsi\ufb01cation) using image-level annotations only (bounding-\nbox labels are not available for this data).\nPre-training\nwas performed using the open source Caffe CNN library\n[24]. In brief, our CNN nearly matches the performance\nof Krizhevsky et al. [25], obtaining a top-1 error rate 2.2\npercentage points higher on the ILSVRC2012 classi\ufb01cation\nvalidation set. This discrepancy is due to simpli\ufb01cations in\nthe training process.\nDomain-speci\ufb01c \ufb01ne-tuning. To adapt our CNN to the\nnew task (detection) and the new domain (warped proposal\nwindows), we continue stochastic gradient descent (SGD)\ntraining of the CNN parameters using only warped region\nproposals.\nAside from replacing the CNN\u2019s ImageNet-\nspeci\ufb01c 1000-way classi\ufb01cation layer with a randomly ini-\ntialized (N + 1)-way classi\ufb01cation layer (where N is the\nnumber of object classes, plus 1 for background), the CNN\narchitecture is unchanged.\nFor VOC, N = 20 and for\nILSVRC2013, N = 200. We treat all region proposals with\n3\n\u22650.5 IoU overlap with a ground-truth box as positives for\nthat box\u2019s class and the rest as negatives. We start SGD at\na learning rate of 0.001 (1/10th of the initial pre-training\nrate), which allows \ufb01ne-tuning to make progress while not\nclobbering the initialization. In each SGD iteration, we uni-\nformly sample 32 positive windows (over all classes) and\n96 background windows to construct a mini-batch of size\n128. We bias the sampling towards positive windows be-\ncause they are extremely rare compared to background.\nObject category classi\ufb01ers. Consider training a binary\nclassi\ufb01er to detect cars.\nIt\u2019s clear that an image region\ntightly enclosing a car should be a positive example. Simi-\nlarly, it\u2019s clear that a background region, which has nothing\nto do with cars, should be a negative example. Less clear\nis how to label a region that partially overlaps a car. We re-\nsolve this issue with an IoU overlap threshold, below which\nregions are de\ufb01ned as negatives. The overlap threshold, 0.3,\nwas selected by a grid search over {0, 0.1, . . . , 0.5} on a\nvalidation set. We found that selecting this threshold care-\nfully is important. Setting it to 0.5, as in [39], decreased\nmAP by 5 points. Similarly, setting it to 0 decreased mAP\nby 4 points. Positive examples are de\ufb01ned simply to be the\nground-truth bounding boxes for each class.\nOnce features are extracted and training labels are ap-\nplied, we optimize one linear SVM per class. Since the\ntraining data is too large to \ufb01t in memory, we adopt the\nstandard hard negative mining method [17, 37]. Hard neg-\native mining converges quickly and in practice mAP stops\nincreasing after only a single pass over all images.\nIn Appendix B we discuss why the positive and negative\nexamples are de\ufb01ned differently in \ufb01ne-tuning versus SVM\ntraining. We also discuss the trade-offs involved in training\ndetection SVMs rather than simply using the outputs from\nthe \ufb01nal softmax layer of the \ufb01ne-tuned CNN.\n2.4. Results on PASCAL VOC 2010-12\nFollowing the PASCAL VOC best practices [15], we\nvalidated all design decisions and hyperparameters on the\nVOC 2007 dataset (Section 3.2). For \ufb01nal results on the\nVOC 2010-12 datasets, we \ufb01ne-tuned the CNN on VOC\n2012 train and optimized our detection SVMs on VOC 2012\ntrainval. We submitted test results to the evaluation server\nonly once for each of the two major algorithm variants (with\nand without bounding-box regression).\nTable 1 shows complete results on VOC 2010. We com-\npare our method against four strong baselines, including\nSegDPM [18], which combines DPM detectors with the\noutput of a semantic segmentation system [4] and uses ad-\nditional inter-detector context and image-classi\ufb01er rescor-\ning. The most germane comparison is to the UVA system\nfrom Uijlings et al. [39], since our systems use the same re-\ngion proposal algorithm. To classify regions, their method\nbuilds a four-level spatial pyramid and populates it with\ndensely sampled SIFT, Extended OpponentSIFT, and RGB-\nSIFT descriptors, each vector quantized with 4000-word\ncodebooks. Classi\ufb01cation is performed with a histogram\nintersection kernel SVM. Compared to their multi-feature,\nnon-linear kernel SVM approach, we achieve a large im-\nprovement in mAP, from 35.1% to 53.7% mAP, while also\nbeing much faster (Section 2.2). Our method achieves sim-\nilar performance (53.3% mAP) on VOC 2011/12 test.\n2.5. Results on ILSVRC2013 detection\nWe ran R-CNN on the 200-class ILSVRC2013 detection\ndataset using the same system hyperparameters that we used\nfor PASCAL VOC. We followed the same protocol of sub-\nmitting test results to the ILSVRC2013 evaluation server\nonly twice, once with and once without bounding-box re-\ngression.\nFigure 3 compares R-CNN to the entries in the ILSVRC\n2013 competition and to the post-competition OverFeat re-\nsult [34]. R-CNN achieves a mAP of 31.4%, which is sig-\nni\ufb01cantly ahead of the second-best result of 24.3% from\nOverFeat.\nTo give a sense of the AP distribution over\nclasses, box plots are also presented and a table of per-\nclass APs follows at the end of the paper in Table 8. Most\nof the competing submissions (OverFeat, NEC-MU, UvA-\nEuvision, Toronto A, and UIUC-IFP) used convolutional\nneural networks, indicating that there is signi\ufb01cant nuance\nin how CNNs can be applied to object detection, leading to\ngreatly varying outcomes.\nIn Section 4, we give an overview of the ILSVRC2013\ndetection dataset and provide details about choices that we\nmade when running R-CNN on it.\n3. Visualization, ablation, and modes of error\n3.1. Visualizing learned features\nFirst-layer \ufb01lters can be visualized directly and are easy\nto understand [25]. They capture oriented edges and oppo-\nnent colors. Understanding the subsequent layers is more\nchallenging. Zeiler and Fergus present a visually attrac-\ntive deconvolutional approach in [42]. We propose a simple\n(and complementary) non-parametric method that directly\nshows what the network learned.\nThe idea is to single out a particular unit (feature) in the\nnetwork and use it as if it were an object detector in its own\nright. That is, we compute the unit\u2019s activations on a large\nset of held-out region proposals (about 10 million), sort the\nproposals from highest to lowest activation, perform non-\nmaximum suppression, and then display the top-scoring re-\ngions. Our method lets the selected unit \u201cspeak for itself\u201d\nby showing exactly which inputs it \ufb01res on. We avoid aver-\naging in order to see different visual modes and gain insight\ninto the invariances computed by the unit.\n4\nVOC 2010 test aero bike bird boat bottle\nbus\ncar\ncat\nchair cow table\ndog\nhorse mbike person plant sheep sofa train\ntv\nmAP\nDPM v5 [20]\u2020\n49.2 53.8 13.1 15.3\n35.5\n53.4 49.7 27.0\n17.2\n28.8 14.7 17.8\n46.4\n51.2\n47.7\n10.8\n34.2\n20.7 43.8 38.3\n33.4\nUVA [39]\n56.2 42.4 15.3 12.6\n21.8\n49.3 36.8 46.1\n12.9\n32.1 30.0 36.5\n43.5\n52.9\n32.9\n15.3\n41.1\n31.8 47.0 44.8\n35.1\nRegionlets [41] 65.0 48.9 25.9 24.6\n24.5\n56.1 54.5 51.2\n17.0\n28.9 30.2 35.8\n40.2\n55.7\n43.5\n14.3\n43.9\n32.6 54.0 45.9\n39.7\nSegDPM [18]\u2020\n61.4 53.4 25.6 25.2\n35.5\n51.7 50.6 50.8\n19.3\n33.8 26.8 40.4\n48.3\n54.4\n47.1\n14.8\n38.7\n35.0 52.8 43.1\n40.4\nR-CNN\n67.1 64.1 46.7 32.0\n30.5\n56.4 57.2 65.9\n27.0\n47.3 40.9 66.6\n57.8\n65.9\n53.6\n26.7\n56.5\n38.1 52.8 50.2\n50.2\nR-CNN BB\n71.8 65.8 53.0 36.8\n35.9\n59.7 60.0 69.9\n27.9\n50.6 41.4 70.0\n62.0\n69.0\n58.1\n29.5\n59.4\n39.3 61.2 52.4\n53.7\nTable 1: Detection average precision (%) on VOC 2010 test. R-CNN is most directly comparable to UVA and Regionlets since all\nmethods use selective search region proposals. Bounding-box regression (BB) is described in Section C. At publication time, SegDPM\nwas the top-performer on the PASCAL VOC leaderboard. \u2020DPM and SegDPM use context rescoring not used by the other methods.\n0\n20\n40\n60\n80\n100\nUIUC\u2212IFP \nDelta \nGPU_UCLA \nSYSU_Vision \nToronto A \n*OverFeat (1) \n*NEC\u2212MU \nUvA\u2212Euvision \n*OverFeat (2) \n*R\u2212CNN BB \nmean average precision (mAP) in %\nILSVRC2013 detection test set mAP\n \n \n1.0%\n6.1%\n9.8%\n10.5%\n11.5%\n19.4%\n20.9%\n22.6%\n24.3%\n31.4%\ncompetition result\npost competition result\n0\n10\n20\n30\n40\n50\n60\n70\n80\n90\n100\n*R\u2212CNN BB\nUvA\u2212Euvision\n*NEC\u2212MU\n*OverFeat (1)\nToronto A\nSYSU_Vision\nGPU_UCLA\nDelta\nUIUC\u2212IFP\naverage precision (AP) in %\nILSVRC2013 detection test set class AP box plots\nFigure 3: (Left) Mean average precision on the ILSVRC2013 detection test set. Methods preceeded by * use outside training data\n(images and labels from the ILSVRC classi\ufb01cation dataset in all cases). (Right) Box plots for the 200 average precision values per\nmethod. A box plot for the post-competition OverFeat result is not shown because per-class APs are not yet available (per-class APs for\nR-CNN are in Table 8 and also included in the tech report source uploaded to arXiv.org; see R-CNN-ILSVRC2013-APs.txt). The red\nline marks the median AP, the box bottom and top are the 25th and 75th percentiles. The whiskers extend to the min and max AP of each\nmethod. Each AP is plotted as a green dot over the whiskers (best viewed digitally with zoom).\n1.0\n1.0\n0.9\n0.9\n0.9\n0.9\n0.9\n0.9\n0.9\n0.9\n0.9\n0.9\n0.9\n0.9\n0.9\n0.9\n1.0\n0.9\n0.9\n0.8\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.6\n0.6\n1.0\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.6\n0.6\n1.0\n0.9\n0.8\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n1.0\n1.0\n0.9\n0.9\n0.9\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n1.0\n0.9\n0.8\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\nFigure 4: Top regions for six pool5 units. Receptive \ufb01elds and activation values are drawn in white. Some units are aligned to concepts,\nsuch as people (row 1) or text (4). Other units capture texture and material properties, such as dot arrays (2) and specular re\ufb02ections (6).\n5\nVOC 2007 test\naero bike bird boat bottle\nbus\ncar\ncat\nchair cow table\ndog\nhorse mbike person plant sheep sofa train\ntv\nmAP\nR-CNN pool5\n51.8 60.2 36.4 27.8\n23.2\n52.8 60.6 49.2\n18.3\n47.8 44.3 40.8\n56.6\n58.7\n42.4\n23.4\n46.1\n36.7 51.3 55.7\n44.2\nR-CNN fc6\n59.3 61.8 43.1 34.0\n25.1\n53.1 60.6 52.8\n21.7\n47.8 42.7 47.8\n52.5\n58.5\n44.6\n25.6\n48.3\n34.0 53.1 58.0\n46.2\nR-CNN fc7\n57.6 57.9 38.5 31.8\n23.7\n51.2 58.9 51.4\n20.0\n50.5 40.9 46.0\n51.6\n55.9\n43.3\n23.3\n48.1\n35.3 51.0 57.4\n44.7\nR-CNN FT pool5\n58.2 63.3 37.9 27.6\n26.1\n54.1 66.9 51.4\n26.7\n55.5 43.4 43.1\n57.7\n59.0\n45.8\n28.1\n50.8\n40.6 53.1 56.4\n47.3\nR-CNN FT fc6\n63.5 66.0 47.9 37.7\n29.9\n62.5 70.2 60.2\n32.0\n57.9 47.0 53.5\n60.1\n64.2\n52.2\n31.3\n55.0\n50.0 57.7 63.0\n53.1\nR-CNN FT fc7\n64.2 69.7 50.0 41.9\n32.0\n62.6 71.0 60.7\n32.7\n58.5 46.5 56.1\n60.6\n66.8\n54.2\n31.5\n52.8\n48.9 57.9 64.7\n54.2\nR-CNN FT fc7 BB 68.1 72.8 56.8 43.0\n36.8\n66.3 74.2 67.6\n34.4\n63.5 54.5 61.2\n69.1\n68.6\n58.7\n33.4\n62.9\n51.1 62.5 64.8\n58.5\nDPM v5 [20]\n33.2 60.3 10.2 16.1\n27.3\n54.3 58.2 23.0\n20.0\n24.1 26.7 12.7\n58.1\n48.2\n43.2\n12.0\n21.1\n36.1 46.0 43.5\n33.7\nDPM ST [28]\n23.8 58.2 10.5\n8.5\n27.1\n50.4 52.0\n7.3\n19.2\n22.8 18.1\n8.0\n55.9\n44.8\n32.4\n13.3\n15.9\n22.8 46.2 44.9\n29.1\nDPM HSC [31]\n32.2 58.3 11.5 16.3\n30.6\n49.9 54.8 23.5\n21.5\n27.7 34.0 13.7\n58.1\n51.6\n39.9\n12.4\n23.5\n34.4 47.4 45.2\n34.3\nTable 2: Detection average precision (%) on VOC 2007 test. Rows 1-3 show R-CNN performance without \ufb01ne-tuning. Rows 4-6 show\nresults for the CNN pre-trained on ILSVRC 2012 and then \ufb01ne-tuned (FT) on VOC 2007 trainval. Row 7 includes a simple bounding-box\nregression (BB) stage that reduces localization errors (Section C). Rows 8-10 present DPM methods as a strong baseline. The \ufb01rst uses\nonly HOG, while the next two use different feature learning approaches to augment or replace HOG.\nVOC 2007 test\naero bike bird boat bottle\nbus\ncar\ncat\nchair cow table\ndog\nhorse mbike person plant sheep sofa train\ntv\nmAP\nR-CNN T-Net\n64.2 69.7 50.0 41.9\n32.0\n62.6 71.0 60.7\n32.7\n58.5 46.5 56.1\n60.6\n66.8\n54.2\n31.5\n52.8\n48.9 57.9 64.7\n54.2\nR-CNN T-Net BB\n68.1 72.8 56.8 43.0\n36.8\n66.3 74.2 67.6\n34.4\n63.5 54.5 61.2\n69.1\n68.6\n58.7\n33.4\n62.9\n51.1 62.5 64.8\n58.5\nR-CNN O-Net\n71.6 73.5 58.1 42.2\n39.4\n70.7 76.0 74.5\n38.7\n71.0 56.9 74.5\n67.9\n69.6\n59.3\n35.7\n62.1\n64.0 66.5 71.2\n62.2\nR-CNN O-Net BB 73.4 77.0 63.4 45.4\n44.6\n75.1 78.1 79.8\n40.5\n73.7 62.2 79.4\n78.1\n73.1\n64.2\n35.6\n66.8\n67.2 70.4 71.1\n66.0\nTable 3: Detection average precision (%) on VOC 2007 test for two different CNN architectures. The \ufb01rst two rows are results from\nTable 2 using Krizhevsky et al.\u2019s architecture (T-Net). Rows three and four use the recently proposed 16-layer architecture from Simonyan\nand Zisserman (O-Net) [43].\nWe visualize units from layer pool5, which is the max-\npooled output of the network\u2019s \ufb01fth and \ufb01nal convolutional\nlayer.\nThe pool5 feature map is 6 \u00d7 6 \u00d7 256 = 9216-\ndimensional. Ignoring boundary effects, each pool5 unit has\na receptive \ufb01eld of 195\u00d7195 pixels in the original 227\u00d7227\npixel input. A central pool5 unit has a nearly global view,\nwhile one near the edge has a smaller, clipped support.\nEach row in Figure 4 displays the top 16 activations for\na pool5 unit from a CNN that we \ufb01ne-tuned on VOC 2007\ntrainval. Six of the 256 functionally unique units are visu-\nalized (Appendix D includes more). These units were se-\nlected to show a representative sample of what the network\nlearns. In the second row, we see a unit that \ufb01res on dog\nfaces and dot arrays. The unit corresponding to the third row\nis a red blob detector. There are also detectors for human\nfaces and more abstract patterns such as text and triangular\nstructures with windows. The network appears to learn a\nrepresentation that combines a small number of class-tuned\nfeatures together with a distributed representation of shape,\ntexture, color, and material properties. The subsequent fully\nconnected layer fc6 has the ability to model a large set of\ncompositions of these rich features.\n3.2. Ablation studies\nPerformance layer-by-layer, without \ufb01ne-tuning. To un-\nderstand which layers are critical for detection performance,\nwe analyzed results on the VOC 2007 dataset for each of the\nCNN\u2019s last three layers. Layer pool5 was brie\ufb02y described\nin Section 3.1. The \ufb01nal two layers are summarized below.\nLayer fc6 is fully connected to pool5. To compute fea-\ntures, it multiplies a 4096\u00d79216 weight matrix by the pool5\nfeature map (reshaped as a 9216-dimensional vector) and\nthen adds a vector of biases. This intermediate vector is\ncomponent-wise half-wave recti\ufb01ed (x \u2190max(0, x)).\nLayer fc7 is the \ufb01nal layer of the network. It is imple-\nmented by multiplying the features computed by fc6 by a\n4096 \u00d7 4096 weight matrix, and similarly adding a vector\nof biases and applying half-wave recti\ufb01cation.\nWe start by looking at results from the CNN without\n\ufb01ne-tuning on PASCAL, i.e.\nall CNN parameters were\npre-trained on ILSVRC 2012 only. Analyzing performance\nlayer-by-layer (Table 2 rows 1-3) reveals that features from\nfc7 generalize worse than features from fc6. This means\nthat 29%, or about 16.8 million, of the CNN\u2019s parameters\ncan be removed without degrading mAP. More surprising is\nthat removing both fc7 and fc6 produces quite good results\neven though pool5 features are computed using only 6% of\nthe CNN\u2019s parameters. Much of the CNN\u2019s representational\npower comes from its convolutional layers, rather than from\nthe much larger densely connected layers. This \ufb01nding sug-\ngests potential utility in computing a dense feature map, in\nthe sense of HOG, of an arbitrary-sized image by using only\nthe convolutional layers of the CNN. This representation\nwould enable experimentation with sliding-window detec-\ntors, including DPM, on top of pool5 features.\nPerformance layer-by-layer, with \ufb01ne-tuning. We now\nlook at results from our CNN after having \ufb01ne-tuned its pa-\n6\nrameters on VOC 2007 trainval. The improvement is strik-\ning (Table 2 rows 4-6): \ufb01ne-tuning increases mAP by 8.0\npercentage points to 54.2%. The boost from \ufb01ne-tuning is\nmuch larger for fc6 and fc7 than for pool5, which suggests\nthat the pool5 features learned from ImageNet are general\nand that most of the improvement is gained from learning\ndomain-speci\ufb01c non-linear classi\ufb01ers on top of them.\nComparison to recent feature learning methods. Rela-\ntively few feature learning methods have been tried on PAS-\nCAL VOC detection. We look at two recent approaches that\nbuild on deformable part models. For reference, we also in-\nclude results for the standard HOG-based DPM [20].\nThe \ufb01rst DPM feature learning method, DPM ST [28],\naugments HOG features with histograms of \u201csketch token\u201d\nprobabilities. Intuitively, a sketch token is a tight distri-\nbution of contours passing through the center of an image\npatch. Sketch token probabilities are computed at each pixel\nby a random forest that was trained to classify 35\u00d735 pixel\npatches into one of 150 sketch tokens or background.\nThe second method, DPM HSC [31], replaces HOG with\nhistograms of sparse codes (HSC). To compute an HSC,\nsparse code activations are solved for at each pixel using\na learned dictionary of 100 7 \u00d7 7 pixel (grayscale) atoms.\nThe resulting activations are recti\ufb01ed in three ways (full and\nboth half-waves), spatially pooled, unit \u21132 normalized, and\nthen power transformed (x \u2190sign(x)|x|\u03b1).\nAll R-CNN variants strongly outperform the three DPM\nbaselines (Table 2 rows 8-10), including the two that use\nfeature learning. Compared to the latest version of DPM,\nwhich uses only HOG features, our mAP is more than 20\npercentage points higher: 54.2% vs. 33.7%\u2014a 61% rela-\ntive improvement. The combination of HOG and sketch to-\nkens yields 2.5 mAP points over HOG alone, while HSC\nimproves over HOG by 4 mAP points (when compared\ninternally to their private DPM baselines\u2014both use non-\npublic implementations of DPM that underperform the open\nsource version [20]).\nThese methods achieve mAPs of\n29.1% and 34.3%, respectively.\n3.3. Network architectures\nMost results in this paper use the network architecture\nfrom Krizhevsky et al. [25]. However, we have found that\nthe choice of architecture has a large effect on R-CNN de-\ntection performance. In Table 3 we show results on VOC\n2007 test using the 16-layer deep network recently proposed\nby Simonyan and Zisserman [43]. This network was one of\nthe top performers in the recent ILSVRC 2014 classi\ufb01ca-\ntion challenge. The network has a homogeneous structure\nconsisting of 13 layers of 3 \u00d7 3 convolution kernels, with\n\ufb01ve max pooling layers interspersed, and topped with three\nfully-connected layers. We refer to this network as \u201cO-Net\u201d\nfor OxfordNet and the baseline as \u201cT-Net\u201d for TorontoNet.\nTo use O-Net in R-CNN, we downloaded the pub-\nlicly\navailable\npre-trained\nnetwork\nweights\nfor\nthe\nVGG ILSVRC 16 layers model from the Caffe Model\nZoo.1 We then \ufb01ne-tuned the network using the same pro-\ntocol as we used for T-Net. The only difference was to use\nsmaller minibatches (24 examples) as required in order to\n\ufb01t within GPU memory. The results in Table 3 show that R-\nCNN with O-Net substantially outperforms R-CNN with T-\nNet, increasing mAP from 58.5% to 66.0%. However there\nis a considerable drawback in terms of compute time, with\nthe forward pass of O-Net taking roughly 7 times longer\nthan T-Net.\n3.4. Detection error analysis\nWe applied the excellent detection analysis tool from\nHoiem et al.\n[23] in order to reveal our method\u2019s error\nmodes, understand how \ufb01ne-tuning changes them, and to\nsee how our error types compare with DPM. A full sum-\nmary of the analysis tool is beyond the scope of this pa-\nper and we encourage readers to consult [23] to understand\nsome \ufb01ner details (such as \u201cnormalized AP\u201d). Since the\nanalysis is best absorbed in the context of the associated\nplots, we present the discussion within the captions of Fig-\nure 5 and Figure 6.\n3.5. Bounding-box regression\nBased on the error analysis, we implemented a sim-\nple method to reduce localization errors. Inspired by the\nbounding-box regression employed in DPM [17], we train a\nlinear regression model to predict a new detection window\ngiven the pool5 features for a selective search region pro-\nposal. Full details are given in Appendix C. Results in Ta-\nble 1, Table 2, and Figure 5 show that this simple approach\n\ufb01xes a large number of mislocalized detections, boosting\nmAP by 3 to 4 points.\n3.6. Qualitative results\nQualitative detection results on ILSVRC2013 are pre-\nsented in Figure 8 and Figure 9 at the end of the paper. Each\nimage was sampled randomly from the val2 set and all de-\ntections from all detectors with a precision greater than 0.5\nare shown. Note that these are not curated and give a re-\nalistic impression of the detectors in action. More qualita-\ntive results are presented in Figure 10 and Figure 11, but\nthese have been curated. We selected each image because it\ncontained interesting, surprising, or amusing results. Here,\nalso, all detections at precision greater than 0.5 are shown.\n4. The ILSVRC2013 detection dataset\nIn Section 2 we presented results on the ILSVRC2013\ndetection dataset. This dataset is less homogeneous than\n1https://github.com/BVLC/caffe/wiki/Model-Zoo\n7\nocc\ntrn\nsize\nasp\nview part\n0\n0.2\n0.4\n0.6\n0.8\n0.212\n0.612\n0.420\n0.557\n0.201\n0.720\n0.344\n0.606\n0.351\n0.677\n0.244\n0.609\n0.516\nnormalized AP\nR\u2212CNN fc6: sensitivity and impact\nocc\ntrn\nsize\nasp\nview part\n0\n0.2\n0.4\n0.6\n0.8\n0.179\n0.701\n0.498\n0.634\n0.335\n0.766\n0.442\n0.672\n0.429\n0.723\n0.325\n0.685\n0.593\nnormalized AP\nR\u2212CNN FT fc7: sensitivity and impact\nocc\ntrn\nsize\nasp\nview part\n0\n0.2\n0.4\n0.6\n0.8\n0.211\n0.731\n0.542\n0.676\n0.385\n0.786\n0.484\n0.709\n0.453\n0.779\n0.368\n0.720\n0.633\nnormalized AP\nR\u2212CNN FT fc7 BB: sensitivity and impact\nocc\ntrn\nsize\nasp\nview part\n0\n0.2\n0.4\n0.6\n0.8\n0.132\n0.339\n0.216\n0.347\n0.056\n0.487\n0.126\n0.453\n0.137\n0.391\n0.094\n0.388\n0.297\nnormalized AP\nDPM voc\u2212release5: sensitivity and impact\nFigure 6: Sensitivity to object characteristics. Each plot shows the mean (over classes) normalized AP (see [23]) for the highest and\nlowest performing subsets within six different object characteristics (occlusion, truncation, bounding-box area, aspect ratio, viewpoint, part\nvisibility). We show plots for our method (R-CNN) with and without \ufb01ne-tuning (FT) and bounding-box regression (BB) as well as for\nDPM voc-release5. Overall, \ufb01ne-tuning does not reduce sensitivity (the difference between max and min), but does substantially improve\nboth the highest and lowest performing subsets for nearly all characteristics. This indicates that \ufb01ne-tuning does more than simply improve\nthe lowest performing subsets for aspect ratio and bounding-box area, as one might conjecture based on how we warp network inputs.\nInstead, \ufb01ne-tuning improves robustness for all characteristics including occlusion, truncation, viewpoint, and part visibility.\ntotal false positives\npercentage of each type\nR\u2212CNN fc6: animals\n \n \n25\n100\n400\n1600 6400\n0\n20\n40\n60\n80\n100\nLoc\nSim\nOth\nBG\ntotal false positives\npercentage of each type\nR\u2212CNN FT fc7: animals\n \n \n25\n100\n400\n1600 6400\n0\n20\n40\n60\n80\n100\nLoc\nSim\nOth\nBG\ntotal false positives\npercentage of each type\nR\u2212CNN FT fc7 BB: animals\n \n \n25\n100\n400\n1600 6400\n0\n20\n40\n60\n80\n100\nLoc\nSim\nOth\nBG\ntotal false positives\npercentage of each type\nR\u2212CNN fc6: furniture\n \n \n25\n100\n400\n1600 6400\n0\n20\n40\n60\n80\n100\nLoc\nSim\nOth\nBG\ntotal false positives\npercentage of each type\nR\u2212CNN FT fc7: furniture\n \n \n25\n100\n400\n1600 6400\n0\n20\n40\n60\n80\n100\nLoc\nSim\nOth\nBG\ntotal false positives\npercentage of each type\nR\u2212CNN FT fc7 BB: furniture\n \n \n25\n100\n400\n1600 6400\n0\n20\n40\n60\n80\n100\nLoc\nSim\nOth\nBG\nFigure 5: Distribution of top-ranked false positive (FP) types.\nEach plot shows the evolving distribution of FP types as more FPs\nare considered in order of decreasing score. Each FP is catego-\nrized into 1 of 4 types: Loc\u2014poor localization (a detection with\nan IoU overlap with the correct class between 0.1 and 0.5, or a du-\nplicate); Sim\u2014confusion with a similar category; Oth\u2014confusion\nwith a dissimilar object category; BG\u2014a FP that \ufb01red on back-\nground. Compared with DPM (see [23]), signi\ufb01cantly more of\nour errors result from poor localization, rather than confusion with\nbackground or other object classes, indicating that the CNN fea-\ntures are much more discriminative than HOG. Loose localiza-\ntion likely results from our use of bottom-up region proposals and\nthe positional invariance learned from pre-training the CNN for\nwhole-image classi\ufb01cation. Column three shows how our simple\nbounding-box regression method \ufb01xes many localization errors.\nPASCAL VOC, requiring choices about how to use it. Since\nthese decisions are non-trivial, we cover them in this sec-\ntion.\n4.1. Dataset overview\nThe ILSVRC2013 detection dataset is split into three\nsets: train (395,918), val (20,121), and test (40,152), where\nthe number of images in each set is in parentheses. The\nval and test splits are drawn from the same image distribu-\ntion. These images are scene-like and similar in complexity\n(number of objects, amount of clutter, pose variability, etc.)\nto PASCAL VOC images. The val and test splits are exhaus-\ntively annotated, meaning that in each image all instances\nfrom all 200 classes are labeled with bounding boxes. The\ntrain set, in contrast, is drawn from the ILSVRC2013 clas-\nsi\ufb01cation image distribution. These images have more vari-\nable complexity with a skew towards images of a single cen-\ntered object. Unlike val and test, the train images (due to\ntheir large number) are not exhaustively annotated. In any\ngiven train image, instances from the 200 classes may or\nmay not be labeled. In addition to these image sets, each\nclass has an extra set of negative images. Negative images\nare manually checked to validate that they do not contain\nany instances of their associated class. The negative im-\nage sets were not used in this work. More information on\nhow ILSVRC was collected and annotated can be found in\n[11, 36].\nThe nature of these splits presents a number of choices\nfor training R-CNN. The train images cannot be used for\nhard negative mining, because annotations are not exhaus-\ntive. Where should negative examples come from? Also,\nthe train images have different statistics than val and test.\nShould the train images be used at all, and if so, to what\nextent? While we have not thoroughly evaluated a large\nnumber of choices, we present what seemed like the most\nobvious path based on previous experience.\nOur general strategy is to rely heavily on the val set and\nuse some of the train images as an auxiliary source of pos-\nitive examples.\nTo use val for both training and valida-\ntion, we split it into roughly equally sized \u201cval1\u201d and \u201cval2\u201d\nsets. Since some classes have very few examples in val (the\nsmallest has only 31 and half have fewer than 110), it is\nimportant to produce an approximately class-balanced par-\ntition. To do this, a large number of candidate splits were\ngenerated and the one with the smallest maximum relative\n8\nclass imbalance was selected.2\nEach candidate split was\ngenerated by clustering val images using their class counts\nas features, followed by a randomized local search that may\nimprove the split balance. The particular split used here has\na maximum relative imbalance of about 11% and a median\nrelative imbalance of 4%. The val1/val2 split and code used\nto produce them will be publicly available to allow other re-\nsearchers to compare their methods on the val splits used in\nthis report.\n4.2. Region proposals\nWe followed the same region proposal approach that was\nused for detection on PASCAL. Selective search [39] was\nrun in \u201cfast mode\u201d on each image in val1, val2, and test (but\nnot on images in train). One minor modi\ufb01cation was re-\nquired to deal with the fact that selective search is not scale\ninvariant and so the number of regions produced depends\non the image resolution. ILSVRC image sizes range from\nvery small to a few that are several mega-pixels, and so we\nresized each image to a \ufb01xed width (500 pixels) before run-\nning selective search. On val, selective search resulted in an\naverage of 2403 region proposals per image with a 91.6%\nrecall of all ground-truth bounding boxes (at 0.5 IoU thresh-\nold). This recall is notably lower than in PASCAL, where\nit is approximately 98%, indicating signi\ufb01cant room for im-\nprovement in the region proposal stage.\n4.3. Training data\nFor training data, we formed a set of images and boxes\nthat includes all selective search and ground-truth boxes\nfrom val1 together with up to N ground-truth boxes per\nclass from train (if a class has fewer than N ground-truth\nboxes in train, then we take all of them). We\u2019ll call this\ndataset of images and boxes val1+trainN. In an ablation\nstudy, we show mAP on val2 for N \u2208{0, 500, 1000} (Sec-\ntion 4.5).\nTraining data is required for three procedures in R-CNN:\n(1) CNN \ufb01ne-tuning, (2) detector SVM training, and (3)\nbounding-box regressor training. CNN \ufb01ne-tuning was run\nfor 50k SGD iteration on val1+trainN using the exact same\nsettings as were used for PASCAL. Fine-tuning on a sin-\ngle NVIDIA Tesla K20 took 13 hours using Caffe.\nFor\nSVM training, all ground-truth boxes from val1+trainN\nwere used as positive examples for their respective classes.\nHard negative mining was performed on a randomly se-\nlected subset of 5000 images from val1. An initial experi-\nment indicated that mining negatives from all of val1, versus\na 5000 image subset (roughly half of it), resulted in only a\n0.5 percentage point drop in mAP, while cutting SVM train-\ning time in half. No negative examples were taken from\n2Relative imbalance is measured as |a \u2212b|/(a + b) where a and b are\nclass counts in each half of the split.\ntrain because the annotations are not exhaustive. The ex-\ntra sets of veri\ufb01ed negative images were not used.\nThe\nbounding-box regressors were trained on val1.\n4.4. Validation and evaluation\nBefore submitting results to the evaluation server, we\nvalidated data usage choices and the effect of \ufb01ne-tuning\nand bounding-box regression on the val2 set using the train-\ning data described above. All system hyperparameters (e.g.,\nSVM C hyperparameters, padding used in region warp-\ning, NMS thresholds, bounding-box regression hyperpa-\nrameters) were \ufb01xed at the same values used for PAS-\nCAL. Undoubtedly some of these hyperparameter choices\nare slightly suboptimal for ILSVRC, however the goal of\nthis work was to produce a preliminary R-CNN result on\nILSVRC without extensive dataset tuning. After selecting\nthe best choices on val2, we submitted exactly two result\n\ufb01les to the ILSVRC2013 evaluation server. The \ufb01rst sub-\nmission was without bounding-box regression and the sec-\nond submission was with bounding-box regression.\nFor\nthese submissions, we expanded the SVM and bounding-\nbox regressor training sets to use val+train1k and val, re-\nspectively.\nWe used the CNN that was \ufb01ne-tuned on\nval1+train1k to avoid re-running \ufb01ne-tuning and feature\ncomputation.\n4.5. Ablation study\nTable 4 shows an ablation study of the effects of differ-\nent amounts of training data, \ufb01ne-tuning, and bounding-\nbox regression. A \ufb01rst observation is that mAP on val2\nmatches mAP on test very closely.\nThis gives us con\ufb01-\ndence that mAP on val2 is a good indicator of test set per-\nformance. The \ufb01rst result, 20.9%, is what R-CNN achieves\nusing a CNN pre-trained on the ILSVRC2012 classi\ufb01ca-\ntion dataset (no \ufb01ne-tuning) and given access to the small\namount of training data in val1 (recall that half of the classes\nin val1 have between 15 and 55 examples).\nExpanding\nthe training set to val1+trainN improves performance to\n24.1%, with essentially no difference between N = 500\nand N = 1000. Fine-tuning the CNN using examples from\njust val1 gives a modest improvement to 26.5%, however\nthere is likely signi\ufb01cant over\ufb01tting due to the small number\nof positive training examples. Expanding the \ufb01ne-tuning\nset to val1+train1k, which adds up to 1000 positive exam-\nples per class from the train set, helps signi\ufb01cantly, boosting\nmAP to 29.7%. Bounding-box regression improves results\nto 31.0%, which is a smaller relative gain that what was ob-\nserved in PASCAL.\n4.6. Relationship to OverFeat\nThere is an interesting relationship between R-CNN and\nOverFeat: OverFeat can be seen (roughly) as a special case\nof R-CNN. If one were to replace selective search region\n9\ntest set\nval2\nval2\nval2\nval2\nval2\nval2\ntest\ntest\nSVM training set\nval1 val1+train.5k val1+train1k val1+train1k val1+train1k val1+train1k\nval+train1k\nval+train1k\nCNN \ufb01ne-tuning set\nn/a\nn/a\nn/a\nval1\nval1+train1k val1+train1k val1+train1k val1+train1k\nbbox reg set\nn/a\nn/a\nn/a\nn/a\nn/a\nval1\nn/a\nval\nCNN feature layer\nfc6\nfc6\nfc6\nfc7\nfc7\nfc7\nfc7\nfc7\nmAP\n20.9\n24.1\n24.1\n26.5\n29.7\n31.0\n30.2\n31.4\nmedian AP\n17.7\n21.0\n21.4\n24.8\n29.2\n29.6\n29.0\n30.3\nTable 4: ILSVRC2013 ablation study of data usage choices, \ufb01ne-tuning, and bounding-box regression.\nproposals with a multi-scale pyramid of regular square re-\ngions and change the per-class bounding-box regressors to\na single bounding-box regressor, then the systems would\nbe very similar (modulo some potentially signi\ufb01cant differ-\nences in how they are trained: CNN detection \ufb01ne-tuning,\nusing SVMs, etc.). It is worth noting that OverFeat has\na signi\ufb01cant speed advantage over R-CNN: it is about 9x\nfaster, based on a \ufb01gure of 2 seconds per image quoted from\n[34]. This speed comes from the fact that OverFeat\u2019s slid-\ning windows (i.e., region proposals) are not warped at the\nimage level and therefore computation can be easily shared\nbetween overlapping windows. Sharing is implemented by\nrunning the entire network in a convolutional fashion over\narbitrary-sized inputs. Speeding up R-CNN should be pos-\nsible in a variety of ways and remains as future work.\n5. Semantic segmentation\nRegion classi\ufb01cation is a standard technique for seman-\ntic segmentation, allowing us to easily apply R-CNN to the\nPASCAL VOC segmentation challenge. To facilitate a di-\nrect comparison with the current leading semantic segmen-\ntation system (called O2P for \u201csecond-order pooling\u201d) [4],\nwe work within their open source framework. O2P uses\nCPMC to generate 150 region proposals per image and then\npredicts the quality of each region, for each class, using\nsupport vector regression (SVR). The high performance of\ntheir approach is due to the quality of the CPMC regions\nand the powerful second-order pooling of multiple feature\ntypes (enriched variants of SIFT and LBP). We also note\nthat Farabet et al. [16] recently demonstrated good results\non several dense scene labeling datasets (not including PAS-\nCAL) using a CNN as a multi-scale per-pixel classi\ufb01er.\nWe follow [2, 4] and extend the PASCAL segmentation\ntraining set to include the extra annotations made available\nby Hariharan et al. [22]. Design decisions and hyperparam-\neters were cross-validated on the VOC 2011 validation set.\nFinal test results were evaluated only once.\nCNN features for segmentation. We evaluate three strate-\ngies for computing features on CPMC regions, all of which\nbegin by warping the rectangular window around the re-\ngion to 227 \u00d7 227. The \ufb01rst strategy (full) ignores the re-\ngion\u2019s shape and computes CNN features directly on the\nwarped window, exactly as we did for detection. However,\nthese features ignore the non-rectangular shape of the re-\ngion. Two regions might have very similar bounding boxes\nwhile having very little overlap. Therefore, the second strat-\negy (fg) computes CNN features only on a region\u2019s fore-\nground mask. We replace the background with the mean\ninput so that background regions are zero after mean sub-\ntraction. The third strategy (full+fg) simply concatenates\nthe full and fg features; our experiments validate their com-\nplementarity.\nfull R-CNN\nfg R-CNN\nfull+fg R-CNN\nO2P [4]\nfc6\nfc7\nfc6\nfc7\nfc6\nfc7\n46.4\n43.0\n42.5\n43.7\n42.1\n47.9\n45.8\nTable 5: Segmentation mean accuracy (%) on VOC 2011 vali-\ndation. Column 1 presents O2P; 2-7 use our CNN pre-trained on\nILSVRC 2012.\nResults on VOC 2011. Table 5 shows a summary of our\nresults on the VOC 2011 validation set compared with O2P.\n(See Appendix E for complete per-category results.) Within\neach feature computation strategy, layer fc6 always outper-\nforms fc7 and the following discussion refers to the fc6 fea-\ntures. The fg strategy slightly outperforms full, indicating\nthat the masked region shape provides a stronger signal,\nmatching our intuition. However, full+fg achieves an aver-\nage accuracy of 47.9%, our best result by a margin of 4.2%\n(also modestly outperforming O2P), indicating that the con-\ntext provided by the full features is highly informative even\ngiven the fg features. Notably, training the 20 SVRs on our\nfull+fg features takes an hour on a single core, compared to\n10+ hours for training on O2P features.\nIn Table 6 we present results on the VOC 2011 test\nset, comparing our best-performing method, fc6 (full+fg),\nagainst two strong baselines. Our method achieves the high-\nest segmentation accuracy for 11 out of 21 categories, and\nthe highest overall segmentation accuracy of 47.9%, aver-\naged across categories (but likely ties with the O2P result\nunder any reasonable margin of error). Still better perfor-\nmance could likely be achieved by \ufb01ne-tuning.\n10\nVOC 2011 test\nbg\naero bike bird boat bottle\nbus\ncar\ncat\nchair cow table\ndog\nhorse mbike person plant sheep sofa train\ntv\nmean\nR&P [2]\n83.4 46.8 18.9 36.6 31.2\n42.7\n57.3 47.4 44.1\n8.1\n39.4 36.1 36.3\n49.5\n48.3\n50.7\n26.3\n47.2\n22.1 42.0 43.2\n40.8\nO2P [4]\n85.4 69.7 22.3 45.2 44.4\n46.9\n66.7 57.8 56.2\n13.5\n46.1 32.3 41.2\n59.1\n55.3\n51.0\n36.2\n50.4\n27.8 46.9 44.6\n47.6\nours (full+fg R-CNN fc6) 84.2 66.9 23.7 58.3 37.4\n55.4\n73.3 58.7 56.5\n9.7\n45.5 29.5 49.3\n40.1\n57.8\n53.9\n33.8\n60.7\n22.7 47.1 41.3\n47.9\nTable 6: Segmentation accuracy (%) on VOC 2011 test. We compare against two strong baselines: the \u201cRegions and Parts\u201d (R&P)\nmethod of [2] and the second-order pooling (O2P) method of [4]. Without any \ufb01ne-tuning, our CNN achieves top segmentation perfor-\nmance, outperforming R&P and roughly matching O2P.\n6. Conclusion\nIn recent years, object detection performance had stag-\nnated.\nThe best performing systems were complex en-\nsembles combining multiple low-level image features with\nhigh-level context from object detectors and scene classi-\n\ufb01ers. This paper presents a simple and scalable object de-\ntection algorithm that gives a 30% relative improvement\nover the best previous results on PASCAL VOC 2012.\nWe achieved this performance through two insights. The\n\ufb01rst is to apply high-capacity convolutional neural net-\nworks to bottom-up region proposals in order to localize\nand segment objects. The second is a paradigm for train-\ning large CNNs when labeled training data is scarce. We\nshow that it is highly effective to pre-train the network\u2014\nwith supervision\u2014for a auxiliary task with abundant data\n(image classi\ufb01cation) and then to \ufb01ne-tune the network for\nthe target task where data is scarce (detection). We conjec-\nture that the \u201csupervised pre-training/domain-speci\ufb01c \ufb01ne-\ntuning\u201d paradigm will be highly effective for a variety of\ndata-scarce vision problems.\nWe conclude by noting that it is signi\ufb01cant that we\nachieved these results by using a combination of classi-\ncal tools from computer vision and deep learning (bottom-\nup region proposals and convolutional neural networks).\nRather than opposing lines of scienti\ufb01c inquiry, the two are\nnatural and inevitable partners.\nAcknowledgments. This research was supported in part\nby DARPA Mind\u2019s Eye and MSEE programs, by NSF\nawards\nIIS-0905647,\nIIS-1134072,\nand\nIIS-1212798,\nMURI N000014-10-1-0933, and by support from Toyota.\nThe GPUs used in this research were generously donated\nby the NVIDIA Corporation.\nAppendix\nA. Object proposal transformations\nThe convolutional neural network used in this work re-\nquires a \ufb01xed-size input of 227 \u00d7 227 pixels. For detec-\ntion, we consider object proposals that are arbitrary image\nrectangles. We evaluated two approaches for transforming\nobject proposals into valid CNN inputs.\nThe \ufb01rst method (\u201ctightest square with context\u201d) en-\ncloses each object proposal inside the tightest square and\n(A)\n(B)\n(C)\n(D)\n(A)\n(B)\n(C)\n(D)\nFigure 7: Different object proposal transformations. (A) the\noriginal object proposal at its actual scale relative to the trans-\nformed CNN inputs; (B) tightest square with context; (C) tight-\nest square without context; (D) warp. Within each column and\nexample proposal, the top row corresponds to p = 0 pixels of con-\ntext padding while the bottom row has p = 16 pixels of context\npadding.\nthen scales (isotropically) the image contained in that\nsquare to the CNN input size. Figure 7 column (B) shows\nthis transformation.\nA variant on this method (\u201ctightest\nsquare without context\u201d) excludes the image content that\nsurrounds the original object proposal. Figure 7 column\n(C) shows this transformation. The second method (\u201cwarp\u201d)\nanisotropically scales each object proposal to the CNN in-\nput size. Figure 7 column (D) shows the warp transforma-\ntion.\nFor each of these transformations, we also consider in-\ncluding additional image context around the original object\nproposal. The amount of context padding (p) is de\ufb01ned as a\nborder size around the original object proposal in the trans-\nformed input coordinate frame. Figure 7 shows p = 0 pix-\nels in the top row of each example and p = 16 pixels in\nthe bottom row. In all methods, if the source rectangle ex-\ntends beyond the image, the missing data is replaced with\nthe image mean (which is then subtracted before inputing\nthe image into the CNN). A pilot set of experiments showed\nthat warping with context padding (p = 16 pixels) outper-\nformed the alternatives by a large margin (3-5 mAP points).\nObviously more alternatives are possible, including using\nreplication instead of mean padding. Exhaustive evaluation\nof these alternatives is left as future work.\n11\nB. Positive vs. negative examples and softmax\nTwo design choices warrant further discussion. The \ufb01rst\nis: Why are positive and negative examples de\ufb01ned differ-\nently for \ufb01ne-tuning the CNN versus training the object de-\ntection SVMs? To review the de\ufb01nitions brie\ufb02y, for \ufb01ne-\ntuning we map each object proposal to the ground-truth in-\nstance with which it has maximum IoU overlap (if any) and\nlabel it as a positive for the matched ground-truth class if the\nIoU is at least 0.5. All other proposals are labeled \u201cback-\nground\u201d (i.e., negative examples for all classes). For train-\ning SVMs, in contrast, we take only the ground-truth boxes\nas positive examples for their respective classes and label\nproposals with less than 0.3 IoU overlap with all instances\nof a class as a negative for that class. Proposals that fall\ninto the grey zone (more than 0.3 IoU overlap, but are not\nground truth) are ignored.\nHistorically speaking, we arrived at these de\ufb01nitions be-\ncause we started by training SVMs on features computed\nby the ImageNet pre-trained CNN, and so \ufb01ne-tuning was\nnot a consideration at that point in time. In that setup, we\nfound that our particular label de\ufb01nition for training SVMs\nwas optimal within the set of options we evaluated (which\nincluded the setting we now use for \ufb01ne-tuning). When we\nstarted using \ufb01ne-tuning, we initially used the same positive\nand negative example de\ufb01nition as we were using for SVM\ntraining. However, we found that results were much worse\nthan those obtained using our current de\ufb01nition of positives\nand negatives.\nOur hypothesis is that this difference in how positives\nand negatives are de\ufb01ned is not fundamentally important\nand arises from the fact that \ufb01ne-tuning data is limited.\nOur current scheme introduces many \u201cjittered\u201d examples\n(those proposals with overlap between 0.5 and 1, but not\nground truth), which expands the number of positive exam-\nples by approximately 30x. We conjecture that this large\nset is needed when \ufb01ne-tuning the entire network to avoid\nover\ufb01tting. However, we also note that using these jittered\nexamples is likely suboptimal because the network is not\nbeing \ufb01ne-tuned for precise localization.\nThis leads to the second issue: Why, after \ufb01ne-tuning,\ntrain SVMs at all? It would be cleaner to simply apply the\nlast layer of the \ufb01ne-tuned network, which is a 21-way soft-\nmax regression classi\ufb01er, as the object detector. We tried\nthis and found that performance on VOC 2007 dropped\nfrom 54.2% to 50.9% mAP. This performance drop likely\narises from a combination of several factors including that\nthe de\ufb01nition of positive examples used in \ufb01ne-tuning does\nnot emphasize precise localization and the softmax classi-\n\ufb01er was trained on randomly sampled negative examples\nrather than on the subset of \u201chard negatives\u201d used for SVM\ntraining.\nThis result shows that it\u2019s possible to obtain close to\nthe same level of performance without training SVMs af-\nter \ufb01ne-tuning. We conjecture that with some additional\ntweaks to \ufb01ne-tuning the remaining performance gap may\nbe closed. If true, this would simplify and speed up R-CNN\ntraining with no loss in detection performance.\nC. Bounding-box regression\nWe use a simple bounding-box regression stage to im-\nprove localization performance. After scoring each selec-\ntive search proposal with a class-speci\ufb01c detection SVM,\nwe predict a new bounding box for the detection using a\nclass-speci\ufb01c bounding-box regressor.\nThis is similar in\nspirit to the bounding-box regression used in deformable\npart models [17]. The primary difference between the two\napproaches is that here we regress from features computed\nby the CNN, rather than from geometric features computed\non the inferred DPM part locations.\nThe input to our training algorithm is a set of N train-\ning pairs {(P i, Gi)}i=1,...,N, where P i = (P i\nx, P i\ny, P i\nw, P i\nh)\nspeci\ufb01es the pixel coordinates of the center of proposal P i\u2019s\nbounding box together with P i\u2019s width and height in pixels.\nHence forth, we drop the superscript i unless it is needed.\nEach ground-truth bounding box G is speci\ufb01ed in the same\nway: G = (Gx, Gy, Gw, Gh). Our goal is to learn a trans-\nformation that maps a proposed box P to a ground-truth box\nG.\nWe parameterize the transformation in terms of four\nfunctions dx(P), dy(P), dw(P), and dh(P).\nThe \ufb01rst\ntwo specify a scale-invariant translation of the center of\nP\u2019s bounding box, while the second two specify log-space\ntranslations of the width and height of P\u2019s bounding box.\nAfter learning these functions, we can transform an input\nproposal P into a predicted ground-truth box \u02c6G by apply-\ning the transformation\n\u02c6Gx = Pwdx(P) + Px\n(1)\n\u02c6Gy = Phdy(P) + Py\n(2)\n\u02c6Gw = Pw exp(dw(P))\n(3)\n\u02c6Gh = Ph exp(dh(P)).\n(4)\nEach function d\u22c6(P) (where \u22c6is one of x, y, h, w) is\nmodeled as a linear function of the pool5 features of pro-\nposal P, denoted by \u03c65(P). (The dependence of \u03c65(P)\non the image data is implicitly assumed.) Thus we have\nd\u22c6(P) = wT\n\u22c6\u03c65(P), where w\u22c6is a vector of learnable\nmodel parameters. We learn w\u22c6by optimizing the regu-\nlarized least squares objective (ridge regression):\nw\u22c6= argmin\n\u02c6w\u22c6\nN\nX\ni\n(ti\n\u22c6\u2212\u02c6wT\n\u22c6\u03c65(P i))2 + \u03bb \u2225\u02c6w\u22c6\u22252 .\n(5)\n12\nThe regression targets t\u22c6for the training pair (P, G) are de-\n\ufb01ned as\ntx = (Gx \u2212Px)/Pw\n(6)\nty = (Gy \u2212Py)/Ph\n(7)\ntw = log(Gw/Pw)\n(8)\nth = log(Gh/Ph).\n(9)\nAs a standard regularized least squares problem, this can be\nsolved ef\ufb01ciently in closed form.\nWe\nfound\ntwo\nsubtle\nissues\nwhile\nimplementing\nbounding-box regression.\nThe \ufb01rst is that regularization\nis important: we set \u03bb = 1000 based on a validation set.\nThe second issue is that care must be taken when selecting\nwhich training pairs (P, G) to use. Intuitively, if P is far\nfrom all ground-truth boxes, then the task of transforming\nP to a ground-truth box G does not make sense. Using ex-\namples like P would lead to a hopeless learning problem.\nTherefore, we only learn from a proposal P if it is nearby\nat least one ground-truth box. We implement \u201cnearness\u201d by\nassigning P to the ground-truth box G with which it has\nmaximum IoU overlap (in case it overlaps more than one) if\nand only if the overlap is greater than a threshold (which we\nset to 0.6 using a validation set). All unassigned proposals\nare discarded. We do this once for each object class in order\nto learn a set of class-speci\ufb01c bounding-box regressors.\nAt test time, we score each proposal and predict its new\ndetection window only once. In principle, we could iterate\nthis procedure (i.e., re-score the newly predicted bounding\nbox, and then predict a new bounding box from it, and so\non). However, we found that iterating does not improve\nresults.\nD. Additional feature visualizations\nFigure 12 shows additional visualizations for 20 pool5\nunits. For each unit, we show the 24 region proposals that\nmaximally activate that unit out of the full set of approxi-\nmately 10 million regions in all of VOC 2007 test.\nWe label each unit by its (y, x, channel) position in the\n6 \u00d7 6 \u00d7 256 dimensional pool5 feature map. Within each\nchannel, the CNN computes exactly the same function of\nthe input region, with the (y, x) position changing only the\nreceptive \ufb01eld.\nE. Per-category segmentation results\nIn Table 7 we show the per-category segmentation ac-\ncuracy on VOC 2011 val for each of our six segmentation\nmethods in addition to the O2P method [4]. These results\nshow which methods are strongest across each of the 20\nPASCAL classes, plus the background class.\nF. Analysis of cross-dataset redundancy\nOne concern when training on an auxiliary dataset is that\nthere might be redundancy between it and the test set. Even\nthough the tasks of object detection and whole-image clas-\nsi\ufb01cation are substantially different, making such cross-set\nredundancy much less worrisome, we still conducted a thor-\nough investigation that quanti\ufb01es the extent to which PAS-\nCAL test images are contained within the ILSVRC 2012\ntraining and validation sets. Our \ufb01ndings may be useful to\nresearchers who are interested in using ILSVRC 2012 as\ntraining data for the PASCAL image classi\ufb01cation task.\nWe performed two checks for duplicate (and near-\nduplicate) images. The \ufb01rst test is based on exact matches\nof \ufb02ickr image IDs, which are included in the VOC 2007\ntest annotations (these IDs are intentionally kept secret for\nsubsequent PASCAL test sets). All PASCAL images, and\nabout half of ILSVRC, were collected from \ufb02ickr.com. This\ncheck turned up 31 matches out of 4952 (0.63%).\nThe second check uses GIST [30] descriptor matching,\nwhich was shown in [13] to have excellent performance at\nnear-duplicate image detection in large (> 1 million) image\ncollections. Following [13], we computed GIST descrip-\ntors on warped 32 \u00d7 32 pixel versions of all ILSVRC 2012\ntrainval and PASCAL 2007 test images.\nEuclidean distance nearest-neighbor matching of GIST\ndescriptors revealed 38 near-duplicate images (including all\n31 found by \ufb02ickr ID matching). The matches tend to vary\nslightly in JPEG compression level and resolution, and to a\nlesser extent cropping. These \ufb01ndings show that the overlap\nis small, less than 1%. For VOC 2012, because \ufb02ickr IDs\nare not available, we used the GIST matching method only.\nBased on GIST matches, 1.5% of VOC 2012 test images\nare in ILSVRC 2012 trainval. The slightly higher rate for\nVOC 2012 is likely due to the fact that the two datasets\nwere collected closer together in time than VOC 2007 and\nILSVRC 2012 were.\nG. Document changelog\nThis document tracks the progress of R-CNN. To help\nreaders understand how it has changed over time, here\u2019s a\nbrief changelog describing the revisions.\nv1 Initial version.\nv2 CVPR 2014 camera-ready revision. Includes substan-\ntial improvements in detection performance brought about\nby (1) starting \ufb01ne-tuning from a higher learning rate (0.001\ninstead of 0.0001), (2) using context padding when prepar-\ning CNN inputs, and (3) bounding-box regression to \ufb01x lo-\ncalization errors.\nv3 Results on the ILSVRC2013 detection dataset and com-\nparison with OverFeat were integrated into several sections\n(primarily Section 2 and Section 4).\n13\nVOC 2011 val\nbg\naero bike bird boat bottle\nbus\ncar\ncat\nchair cow table\ndog\nhorse mbike person plant sheep sofa train\ntv\nmean\nO2P [4]\n84.0 69.0 21.7 47.7 42.2\n42.4\n64.7 65.8 57.4\n12.9\n37.4 20.5 43.7\n35.7\n52.7\n51.0\n35.8\n51.0\n28.4 59.8 49.7\n46.4\nfull R-CNN fc6\n81.3 56.2 23.9 42.9 40.7\n38.8\n59.2 56.5 53.2\n11.4\n34.6 16.7 48.1\n37.0\n51.4\n46.0\n31.5\n44.0\n24.3 53.7 51.1\n43.0\nfull R-CNN fc7\n81.0 52.8 25.1 43.8 40.5\n42.7\n55.4 57.7 51.3\n8.7\n32.5 11.5 48.1\n37.0\n50.5\n46.4\n30.2\n42.1\n21.2 57.7 56.0\n42.5\nfg R-CNN fc6\n81.4 54.1 21.1 40.6 38.7\n53.6\n59.9 57.2 52.5\n9.1\n36.5 23.6 46.4\n38.1\n53.2\n51.3\n32.2\n38.7\n29.0 53.0 47.5\n43.7\nfg R-CNN fc7\n80.9 50.1 20.0 40.2 34.1\n40.9\n59.7 59.8 52.7\n7.3\n32.1 14.3 48.8\n42.9\n54.0\n48.6\n28.9\n42.6\n24.9 52.2 48.8\n42.1\nfull+fg R-CNN fc6 83.1 60.4 23.2 48.4 47.3\n52.6\n61.6 60.6 59.1\n10.8\n45.8 20.9 57.7\n43.3\n57.4\n52.9\n34.7\n48.7\n28.1 60.0 48.6\n47.9\nfull+fg R-CNN fc7 82.3 56.7 20.6 49.9 44.2\n43.6\n59.3 61.3 57.8\n7.7\n38.4 15.1 53.4\n43.7\n50.8\n52.0\n34.1\n47.8\n24.7 60.1 55.2\n45.7\nTable 7: Per-category segmentation accuracy (%) on the VOC 2011 validation set.\nv4 The softmax vs. SVM results in Appendix B contained\nan error, which has been \ufb01xed. We thank Sergio Guadar-\nrama for helping to identify this issue.\nv5 Added results using the new 16-layer network architec-\nture from Simonyan and Zisserman [43] to Section 3.3 and\nTable 3.\nReferences\n[1] B. Alexe, T. Deselaers, and V. Ferrari. Measuring the object-\nness of image windows. TPAMI, 2012. 2\n[2] P. Arbel\u00b4aez, B. Hariharan, C. Gu, S. Gupta, L. Bourdev, and\nJ. Malik. Semantic segmentation using regions and parts. In\nCVPR, 2012. 10, 11\n[3] P. Arbel\u00b4aez, J. Pont-Tuset, J. Barron, F. Marques, and J. Ma-\nlik. Multiscale combinatorial grouping. In CVPR, 2014. 3\n[4] J. Carreira, R. Caseiro, J. Batista, and C. Sminchisescu. Se-\nmantic segmentation with second-order pooling. In ECCV,\n2012. 4, 10, 11, 13, 14\n[5] J. Carreira and C. Sminchisescu.\nCPMC: Automatic ob-\nject segmentation using constrained parametric min-cuts.\nTPAMI, 2012. 2, 3\n[6] D. Cires\u00b8an, A. Giusti, L. Gambardella, and J. Schmidhu-\nber. Mitosis detection in breast cancer histology images with\ndeep neural networks. In MICCAI, 2013. 3\n[7] N. Dalal and B. Triggs. Histograms of oriented gradients for\nhuman detection. In CVPR, 2005. 1\n[8] T. Dean, M. A. Ruzon, M. Segal, J. Shlens, S. Vijaya-\nnarasimhan, and J. Yagnik.\nFast, accurate detection of\n100,000 object classes on a single machine. In CVPR, 2013.\n3\n[9] J. Deng, A. Berg, S. Satheesh, H. Su, A. Khosla, and L. Fei-\nFei. ImageNet Large Scale Visual Recognition Competition\n2012 (ILSVRC2012). http://www.image-net.org/\nchallenges/LSVRC/2012/. 1\n[10] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-\nFei. ImageNet: A large-scale hierarchical image database.\nIn CVPR, 2009. 1\n[11] J. Deng, O. Russakovsky, J. Krause, M. Bernstein, A. C.\nBerg, and L. Fei-Fei. Scalable multi-label annotation. In\nCHI, 2014. 8\n[12] J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang,\nE. Tzeng, and T. Darrell. DeCAF: A Deep Convolutional\nActivation Feature for Generic Visual Recognition. In ICML,\n2014. 2\n[13] M. Douze, H. J\u00b4egou, H. Sandhawalia, L. Amsaleg, and\nC. Schmid. Evaluation of gist descriptors for web-scale im-\nage search. In Proc. of the ACM International Conference on\nImage and Video Retrieval, 2009. 13\n[14] I. Endres and D. Hoiem. Category independent object pro-\nposals. In ECCV, 2010. 3\n[15] M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and\nA. Zisserman. The PASCAL Visual Object Classes (VOC)\nChallenge. IJCV, 2010. 1, 4\n[16] C. Farabet, C. Couprie, L. Najman, and Y. LeCun. Learning\nhierarchical features for scene labeling. TPAMI, 2013. 10\n[17] P. Felzenszwalb, R. Girshick, D. McAllester, and D. Ra-\nmanan. Object detection with discriminatively trained part\nbased models. TPAMI, 2010. 2, 4, 7, 12\n[18] S. Fidler, R. Mottaghi, A. Yuille, and R. Urtasun. Bottom-up\nsegmentation for top-down detection. In CVPR, 2013. 4, 5\n[19] K. Fukushima.\nNeocognitron:\nA self-organizing neu-\nral network model for a mechanism of pattern recogni-\ntion unaffected by shift in position. Biological cybernetics,\n36(4):193\u2013202, 1980. 1\n[20] R. Girshick, P. Felzenszwalb, and D. McAllester. Discrimi-\nnatively trained deformable part models, release 5. http:\n//www.cs.berkeley.edu/\u02dcrbg/latent-v5/.\n2,\n5, 6, 7\n[21] C. Gu, J. J. Lim, P. Arbel\u00b4aez, and J. Malik. Recognition\nusing regions. In CVPR, 2009. 2\n[22] B. Hariharan, P. Arbel\u00b4aez, L. Bourdev, S. Maji, and J. Malik.\nSemantic contours from inverse detectors. In ICCV, 2011.\n10\n[23] D. Hoiem, Y. Chodpathumwan, and Q. Dai. Diagnosing error\nin object detectors. In ECCV. 2012. 2, 7, 8\n[24] Y. Jia.\nCaffe:\nAn open source convolutional archi-\ntecture for fast feature embedding.\nhttp://caffe.\nberkeleyvision.org/, 2013. 3\n[25] A. Krizhevsky, I. Sutskever, and G. Hinton. ImageNet clas-\nsi\ufb01cation with deep convolutional neural networks. In NIPS,\n2012. 1, 3, 4, 7\n[26] Y. LeCun, B. Boser, J. Denker, D. Henderson, R. Howard,\nW. Hubbard, and L. Jackel.\nBackpropagation applied to\nhandwritten zip code recognition. Neural Comp., 1989. 1\n[27] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-\nbased learning applied to document recognition. Proc. of the\nIEEE, 1998. 1\n[28] J. J. Lim, C. L. Zitnick, and P. Doll\u00b4ar. Sketch tokens: A\nlearned mid-level representation for contour and object de-\ntection. In CVPR, 2013. 6, 7\n14\nclass\nAP class\nAP class\nAP class\nAP class\nAP\naccordion\n50.8 centipede\n30.4 hair spray\n13.8 pencil box\n11.4 snowplow\n69.2\nairplane\n50.0 chain saw\n14.1 hamburger\n34.2 pencil sharpener\n9.0 soap dispenser\n16.8\nant\n31.8 chair\n19.5 hammer\n9.9 perfume\n32.8 soccer ball\n43.7\nantelope\n53.8 chime\n24.6 hamster\n46.0 person\n41.7 sofa\n16.3\napple\n30.9 cocktail shaker\n46.2 harmonica\n12.6 piano\n20.5 spatula\n6.8\narmadillo\n54.0 coffee maker\n21.5 harp\n50.4 pineapple\n22.6 squirrel\n31.3\nartichoke\n45.0 computer keyboard 39.6 hat with a wide brim 40.5 ping-pong ball\n21.0 star\ufb01sh\n45.1\naxe\n11.8 computer mouse\n21.2 head cabbage\n17.4 pitcher\n19.2 stethoscope\n18.3\nbaby bed\n42.0 corkscrew\n24.2 helmet\n33.4 pizza\n43.7 stove\n8.1\nbackpack\n2.8 cream\n29.9 hippopotamus\n38.0 plastic bag\n6.4 strainer\n9.9\nbagel\n37.5 croquet ball\n30.0 horizontal bar\n7.0 plate rack\n15.2 strawberry\n26.8\nbalance beam 32.6 crutch\n23.7 horse\n41.7 pomegranate\n32.0 stretcher\n13.2\nbanana\n21.9 cucumber\n22.8 hotdog\n28.7 popsicle\n21.2 sunglasses\n18.8\nband aid\n17.4 cup or mug\n34.0 iPod\n59.2 porcupine\n37.2 swimming trunks\n9.1\nbanjo\n55.3 diaper\n10.1 isopod\n19.5 power drill\n7.9 swine\n45.3\nbaseball\n41.8 digital clock\n18.5 jelly\ufb01sh\n23.7 pretzel\n24.8 syringe\n5.7\nbasketball\n65.3 dishwasher\n19.9 koala bear\n44.3 printer\n21.3 table\n21.7\nbathing cap\n37.2 dog\n76.8 ladle\n3.0 puck\n14.1 tape player\n21.4\nbeaker\n11.3 domestic cat\n44.1 ladybug\n58.4 punching bag\n29.4 tennis ball\n59.1\nbear\n62.7 dragon\ufb02y\n27.8 lamp\n9.1 purse\n8.0 tick\n42.6\nbee\n52.9 drum\n19.9 laptop\n35.4 rabbit\n71.0 tie\n24.6\nbell pepper\n38.8 dumbbell\n14.1 lemon\n33.3 racket\n16.2 tiger\n61.8\nbench\n12.7 electric fan\n35.0 lion\n51.3 ray\n41.1 toaster\n29.2\nbicycle\n41.1 elephant\n56.4 lipstick\n23.1 red panda\n61.1 traf\ufb01c light\n24.7\nbinder\n6.2 face powder\n22.1 lizard\n38.9 refrigerator\n14.0 train\n60.8\nbird\n70.9 \ufb01g\n44.5 lobster\n32.4 remote control\n41.6 trombone\n13.8\nbookshelf\n19.3 \ufb01ling cabinet\n20.6 maillot\n31.0 rubber eraser\n2.5 trumpet\n14.4\nbow tie\n38.8 \ufb02ower pot\n20.2 maraca\n30.1 rugby ball\n34.5 turtle\n59.1\nbow\n9.0 \ufb02ute\n4.9 microphone\n4.0 ruler\n11.5 tv or monitor\n41.7\nbowl\n26.7 fox\n59.3 microwave\n40.1 salt or pepper shaker 24.6 unicycle\n27.2\nbrassiere\n31.2 french horn\n24.2 milk can\n33.3 saxophone\n40.8 vacuum\n19.5\nburrito\n25.7 frog\n64.1 miniskirt\n14.9 scorpion\n57.3 violin\n13.7\nbus\n57.5 frying pan\n21.5 monkey\n49.6 screwdriver\n10.6 volleyball\n59.7\nbutter\ufb02y\n88.5 giant panda\n42.5 motorcycle\n42.2 seal\n20.9 waf\ufb02e iron\n24.0\ncamel\n37.6 gold\ufb01sh\n28.6 mushroom\n31.8 sheep\n48.9 washer\n39.8\ncan opener\n28.9 golf ball\n51.3 nail\n4.5 ski\n9.0 water bottle\n8.1\ncar\n44.5 golfcart\n47.9 neck brace\n31.6 skunk\n57.9 watercraft\n40.9\ncart\n48.0 guacamole\n32.3 oboe\n27.5 snail\n36.2 whale\n48.6\ncattle\n32.3 guitar\n33.1 orange\n38.8 snake\n33.8 wine bottle\n31.2\ncello\n28.9 hair dryer\n13.0 otter\n22.2 snowmobile\n58.8 zebra\n49.6\nTable 8: Per-class average precision (%) on the ILSVRC2013 detection test set.\n[29] D. Lowe.\nDistinctive image features from scale-invariant\nkeypoints. IJCV, 2004. 1\n[30] A. Oliva and A. Torralba. Modeling the shape of the scene:\nA holistic representation of the spatial envelope. IJCV, 2001.\n13\n[31] X. Ren and D. Ramanan. Histograms of sparse codes for\n15\nlemon 0.79\nlemon 0.70\nlemon 0.56\nlemon 0.50\nperson 0.88\nperson 0.72\ncocktail shaker 0.56\ndog 0.97\ndog 0.85\ndog 0.57\nbird 0.63\ndog 0.97\ndog 0.95\ndog 0.64\nhelmet 0.65\nhelmet 0.52\nmotorcycle 0.65\nperson 0.75\nperson 0.58\nsnowmobile 0.83\nsnowmobile 0.83\nbow tie 0.86\nperson 0.82\nbird 0.61\ndog 0.66\ndog 0.61\ndomestic cat 0.57\nbird 0.96\ndog 0.91\ndog 0.77\nsofa 0.71\ndog 0.95\ndog 0.55\nladybug 1.00\nperson 0.87\ncar 0.96\ncar 0.66\ncar 0.63\nbird 0.98\nperson 0.65\nwatercraft 1.00\nwatercraft 0.69\npretzel 0.78\ncar 0.96\nperson 0.65\nperson 0.58\nperson 0.52\nperson 0.52\nbird 0.99\nbird 0.91\nbird 0.75\ndog 0.98\nflower pot 0.62\ndog 0.97\ndog 0.56\ntrain 1.00\ntrain 0.53\narmadillo 1.00\narmadillo 0.56\nbird 0.93\ndog 0.92\nswine 0.88\nbird 1.00\nbutterfly 0.96\nperson 0.90\nflower pot 0.62\nsnake 0.70\nturtle 0.54\nbell pepper 0.81\nbell pepper 0.62\nbell pepper 0.54\nruler 1.00\nantelope 0.53\nmushroom 0.93\ntv or monitor 0.82\ntv or monitor 0.76\ntv or monitor 0.54\nbird 0.89\nlipstick 0.80\nlipstick 0.61\nperson 0.58\ndog 0.97\nsoccer ball 0.90\nFigure 8: Example detections on the val2 set from the con\ufb01guration that achieved 31.0% mAP on val2. Each image was sampled randomly\n(these are not curated). All detections at precision greater than 0.5 are shown. Each detection is labeled with the predicted class and the\nprecision value of that detection from the detector\u2019s precision-recall curve. Viewing digitally with zoom is recommended.\n16\nbaby bed 0.55\nhelmet 0.51\npitcher 0.57\ndog 0.98\nhat with a wide brim 0.78\nperson 0.86\nbird 0.52\ntable 0.60\nmonkey 0.97\ntable 0.68\nwatercraft 0.55\nperson 0.88\ncar 0.61\nperson 0.87\nperson 0.51\nsunglasses 0.51\ndog 0.94\ndog 0.55\nbird 0.52\nmonkey 0.87\nmonkey 0.81\nswine 0.50\ndog 0.97\nhat with a wide brim 0.96\nsnake 0.74\ndog 0.93\nperson 0.77\ndog 0.97\nguacamole 0.64\npretzel 0.69\ntable 0.54\ndog 0.71\nperson 0.85\nladybug 0.90\nperson 0.52\nzebra 0.83\nzebra 0.80\nzebra 0.55\nzebra 0.52\ndog 0.98\nhat with a wide brim 0.60\nperson 0.85\nperson 0.81\nperson 0.73\nelephant 1.00\nbird 0.99\nperson 0.58\ndog 0.98\ncart 1.00\nchair 0.79\nchair 0.64\nperson 0.91\nperson 0.87\nperson 0.57\nperson 0.52\ncomputer keyboard 0.52\ndog 0.97\ndog 0.92\nperson 0.77\nbird 0.94\nbutterfly 0.98\nperson 0.73\nperson 0.61\nbird 1.00\nbird 0.78\nperson 0.91\nperson 0.75\nstethoscope 0.83\nbird 0.83\nFigure 9: More randomly selected examples. See Figure 8 caption for details. Viewing digitally with zoom is recommended.\n17\nperson 0.81\nperson 0.57\nperson 0.53\nmotorcycle 0.64\nperson 0.73\nperson 0.51\nbagel 0.57\npineapple 1.00\nbowl 0.63\nguacamole 1.00\ntennis ball 0.60\nlemon 0.88\nlemon 0.86\nlemon 0.80\nlemon 0.78\norange 0.78\norange 0.73\norange 0.71\ngolf ball 1.00\ngolf ball 1.00\ngolf ball 0.89\ngolf ball 0.81\ngolf ball 0.79\ngolf ball 0.76golf ball 0.60\ngolf ball 0.60\ngolf ball 0.51\nlemon 0.53\nsoccer ball 0.67\nlamp 0.61\ntable 0.59\nbee 0.85\njellyfish 0.71\nbowl 0.54\nhamburger 0.78\ndumbbell 1.00\nperson 0.52\nmicrophone 1.00\nperson 0.85\nhead cabbage 0.83\nhead cabbage 0.75\ndog 0.74\ngoldfish 0.76\nperson 0.57\nguitar 1.00\nguitar 1.00\nguitar 0.88\ntable 0.63\ncomputer keyboard 0.78\nmicrowave 0.60\ntable 0.53\ntick 0.64\nlemon 0.80\ntennis ball 0.67\nrabbit 1.00\ndog 0.98\nperson 0.81\nperson 0.92\nsunglasses 0.52\nwatercraft 0.86\nmilk can 1.00\nmilk can 1.00\nbookshelf 0.50\nchair 0.86\ngiant panda 0.61\nperson 0.87\nantelope 0.74\ncattle 0.81\ndog 0.87\nhorse 0.78\npomegranate 1.00\nchair 0.86\ntv or monitor 0.52\nantelope 0.68\nbird 0.94\nsnake 0.60\ndog 0.98\ndog 0.88\nperson 0.79\nsnake 0.76\ntable 0.62\ntv or monitor 0.80\ntv or monitor 0.58\ntv or monitor 0.54\nlamp 0.86\nlamp 0.65\ntable 0.83\nmonkey 1.00\nmonkey 1.00\nmonkey 0.90\nmonkey 0.88\nmonkey 0.52\ndog 0.88\nfox 1.00\nfox 0.81\nperson 0.88\nwatercraft 0.91\nwatercraft 0.56\nbird 0.95\nbird 0.78\nisopod 0.56\nbird 0.69\nstarfish 0.67\ndragonfly 0.70\ndragonfly 0.60\nhamburger 0.72\nhamburger 0.60\ncup or mug 0.72\nelectric fan 1.00\nelectric fan 0.83\nelectric fan 0.78\nhelmet 0.64\nsoccer ball 0.63\nFigure 10: Curated examples. Each image was selected because we found it impressive, surprising, interesting, or amusing. Viewing\ndigitally with zoom is recommended.\n18\nobject detection. In CVPR, 2013. 6, 7\n[32] H. A. Rowley, S. Baluja, and T. Kanade. Neural network-\nbased face detection. TPAMI, 1998. 2\n[33] D. E. Rumelhart, G. E. Hinton, and R. J. Williams. Learn-\ning internal representations by error propagation. Parallel\nDistributed Processing, 1:318\u2013362, 1986. 1\n[34] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus,\nand Y. LeCun. OverFeat: Integrated Recognition, Localiza-\ntion and Detection using Convolutional Networks. In ICLR,\n2014. 1, 2, 4, 10\n[35] P. Sermanet, K. Kavukcuoglu, S. Chintala, and Y. LeCun.\nPedestrian detection with unsupervised multi-stage feature\nlearning. In CVPR, 2013. 2\n[36] H. Su, J. Deng, and L. Fei-Fei. Crowdsourcing annotations\nfor visual object detection. In AAAI Technical Report, 4th\nHuman Computation Workshop, 2012. 8\n[37] K. Sung and T. Poggio. Example-based learning for view-\nbased human face detection. Technical Report A.I. Memo\nNo. 1521, Massachussets Institute of Technology, 1994. 4\n[38] C. Szegedy, A. Toshev, and D. Erhan. Deep neural networks\nfor object detection. In NIPS, 2013. 2\n[39] J. Uijlings, K. van de Sande, T. Gevers, and A. Smeulders.\nSelective search for object recognition. IJCV, 2013. 1, 2, 3,\n4, 5, 9\n[40] R. Vaillant, C. Monrocq, and Y. LeCun. Original approach\nfor the localisation of objects in images. IEE Proc on Vision,\nImage, and Signal Processing, 1994. 2\n[41] X. Wang, M. Yang, S. Zhu, and Y. Lin. Regionlets for generic\nobject detection. In ICCV, 2013. 3, 5\n[42] M. Zeiler, G. Taylor, and R. Fergus. Adaptive deconvolu-\ntional networks for mid and high level feature learning. In\nCVPR, 2011. 4\n[43] K. Simonyan and A. Zisserman.\nVery Deep Convolu-\ntional Networks for Large-Scale Image Recognition. arXiv\npreprint, arXiv:1409.1556, 2014. 6, 7, 14\n19\nperson 0.82\nsnake 0.76\nfrog 0.78\nbird 0.79\ngoldfish 0.76\ngoldfish 0.76\ngoldfish 0.58\nperson 0.94\nstethoscope 0.56\nperson 0.95\nperson 0.92\nperson 0.67\nperson 0.60\ntable 0.81\njellyfish 0.67\nlemon 0.52\nperson 0.78\nperson 0.65\nwatercraft 0.55\nbaseball 1.00\nperson 0.94\nperson 0.82\nperson 0.80\nperson 0.61\nperson 0.55\nperson 0.52\ncomputer keyboard 0.81\ndog 0.60\nperson 0.88\nperson 0.79\nperson 0.68\nperson 0.59\ntv or monitor 0.82\nlizard 0.58\nchair 0.50\nperson 0.74\ntable 0.82\nperson 0.94\nperson 0.94\nperson 0.95\nperson 0.81\nperson 0.69\nrugby ball 0.91\nperson 0.84\nperson 0.59\nvolleyball 0.70\npineapple 1.00\nbrassiere 0.71\nperson 0.95\nperson 0.94\nperson 0.94\nperson 0.81\nperson 0.80\nperson 0.80\nperson 0.79\nperson 0.79\nperson 0.69\nperson 0.66\nperson 0.58\nperson 0.56\nperson 0.54\nswimming trunks 0.56\nbaseball 0.86\nhelmet 0.74\nperson 0.75\nminiskirt 0.64\nperson 0.92\nvacuum 1.00\ndog 0.98\ndog 0.93\nperson 0.94\nperson 0.75\nperson 0.65\nperson 0.53\nski 0.80\nski 0.80\nbird 0.55\ntiger 1.00\ntiger 0.67\ntiger 0.59\nbird 0.56\nwhale 1.00\nchair 0.53\nperson 0.92\nperson 0.92\nperson 0.82\nperson 0.78\nbowl 0.52\nstrawberry 0.79\nstrawberry 0.70\nburrito 0.54\ncroquet ball 0.91\ncroquet ball 0.91\ncroquet ball 0.91\ncroquet ball 0.91\nmushroom 0.57\nwatercraft 0.91\nwatercraft 0.87\nwatercraft 0.58\nplastic bag 0.62\nplastic bag 0.62\nwhale 0.88\ncar 0.70\ndog 0.94\ntv or monitor 0.57\ncart 0.80\nperson 0.79\nperson 0.53\nhat with a wide brim 0.89\nperson 0.88\nperson 0.82\nperson 0.79\nperson 0.56\nperson 0.54\ntraffic light 0.79\nbird 0.59\ncucumber 0.53\ncucumber 0.52\nantelope 1.00\nantelope 1.00\nantelope 0.94\nantelope 0.73\nantelope 0.63\nantelope 0.63\nfox 0.57\nbalance beam 0.50\nhorizontal bar 1.00\nperson 0.80\nperson 0.90\nsnake 0.64\ndog 0.98\ndog 0.97\nhelmet 0.69\nhorse 0.92\nhorse 0.69\nperson 0.82\nperson 0.72\norange 0.79\norange 0.71\norange 0.66\norange 0.66\norange 0.59\norange 0.56\nbird 0.97\nbird 0.96\nbird 0.96\nbird 0.94\nbird 0.89\nbird 0.64\nbird 0.56\nbird 0.53\nbird 0.52\nguitar 1.00\nperson 0.82\nbicycle 0.92\nperson 0.90\nperson 0.83\ncar 1.00\ncar 0.97\ndog 0.98\ndog 0.86\ndog 0.85\ndog 0.65\ndog 0.50\nperson 0.83\nperson 0.80\nperson 0.74\nperson 0.54\nelephant 0.60\nFigure 11: More curated examples. See Figure 10 caption for details. Viewing digitally with zoom is recommended.\n20\npool5 feature: (3,3,1) (top 1 \u2212 24)\n1.0\n0.9\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\npool5 feature: (3,3,2) (top 1 \u2212 24)\n1.0\n0.9\n0.9\n0.9\n0.9\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\npool5 feature: (3,3,3) (top 1 \u2212 24)\n0.9\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.7\n0.7\n0.7\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\npool5 feature: (3,3,4) (top 1 \u2212 24)\n0.9\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.6\n0.6\n0.6\n0.6\n0.6\npool5 feature: (3,3,5) (top 1 \u2212 24)\n0.9\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\npool5 feature: (3,3,6) (top 1 \u2212 24)\n0.9\n0.8\n0.8\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\npool5 feature: (3,3,7) (top 1 \u2212 24)\n0.9\n0.8\n0.8\n0.8\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.6\n0.6\n0.6\n0.6\npool5 feature: (3,3,8) (top 1 \u2212 24)\n0.9\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\npool5 feature: (3,3,9) (top 1 \u2212 24)\n0.8\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\npool5 feature: (3,3,10) (top 1 \u2212 24)\n0.9\n0.8\n0.8\n0.7\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.5\n0.5\npool5 feature: (3,3,11) (top 1 \u2212 24)\n0.7\n0.7\n0.7\n0.7\n0.7\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\npool5 feature: (3,3,12) (top 1 \u2212 24)\n0.9\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\npool5 feature: (3,3,13) (top 1 \u2212 24)\n0.9\n0.9\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\npool5 feature: (3,3,14) (top 1 \u2212 24)\n0.9\n0.9\n0.9\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\npool5 feature: (3,3,15) (top 1 \u2212 24)\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\npool5 feature: (3,3,16) (top 1 \u2212 24)\n0.9\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\npool5 feature: (3,3,17) (top 1 \u2212 24)\n0.9\n0.9\n0.8\n0.8\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\npool5 feature: (3,3,18) (top 1 \u2212 24)\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\npool5 feature: (3,3,19) (top 1 \u2212 24)\n0.9\n0.8\n0.8\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\npool5 feature: (3,3,20) (top 1 \u2212 24)\n1.0\n0.9\n0.7\n0.7\n0.7\n0.7\n0.7\n0.7\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\n0.6\nFigure 12: We show the 24 region proposals, out of the approximately 10 million regions in VOC 2007 test, that most strongly\nactivate each of 20 units. Each montage is labeled by the unit\u2019s (y, x, channel) position in the 6 \u00d7 6 \u00d7 256 dimensional pool5 feature map.\nEach image region is drawn with an overlay of the unit\u2019s receptive \ufb01eld in white. The activation value (which we normalize by dividing by\nthe max activation value over all units in a channel) is shown in the receptive \ufb01eld\u2019s upper-left corner. Best viewed digitally with zoom.\n21\n",
        "sentence": " Previous works [6, 13, 7] analyzed the semantic meaning of various units by finding the set of inputs that maximally activate a given unit. They look for input images which maximize the activation value of this single feature [6, 13, 7, 4]. So far, unit-level inspection methods had relatively little utility beyond confirming certain intuitions regarding the complexity of the representations learned by a deep neural network [6, 13, 7, 4].",
        "context": "trainval. Six of the 256 functionally unique units are visu-\nalized (Appendix D includes more). These units were se-\nlected to show a representative sample of what the network\nlearns. In the second row, we see a unit that \ufb01res on dog\nshows what the network learned.\nThe idea is to single out a particular unit (feature) in the\nnetwork and use it as if it were an object detector in its own\nright. That is, we compute the unit\u2019s activations on a large\nby showing exactly which inputs it \ufb01res on. We avoid aver-\naging in order to see different visual modes and gain insight\ninto the invariances computed by the unit.\n4\nVOC 2010 test aero bike bird boat bottle\nbus\ncar\ncat\nchair cow table\ndog"
    },
    {
        "title": "Measuring invariances in deep networks",
        "author": [
            "Ian Goodfellow",
            "Quoc Le",
            "Andrew Saxe",
            "Honglak Lee",
            "Andrew Y Ng"
        ],
        "venue": "Advances in neural information processing systems,",
        "citeRegEx": "7",
        "shortCiteRegEx": "7",
        "year": 2009,
        "abstract": "",
        "full_text": "",
        "sentence": " Previous works [6, 13, 7] analyzed the semantic meaning of various units by finding the set of inputs that maximally activate a given unit. They look for input images which maximize the activation value of this single feature [6, 13, 7, 4]. So far, unit-level inspection methods had relatively little utility beyond confirming certain intuitions regarding the complexity of the representations learned by a deep neural network [6, 13, 7, 4].",
        "context": null
    },
    {
        "title": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups",
        "author": [
            "Geoffrey E. Hinton",
            "Li Deng",
            "Dong Yu",
            "George E. Dahl",
            "Abdel rahman Mohamed",
            "Navdeep Jaitly",
            "Andrew Senior",
            "Vincent Vanhoucke",
            "Patrick Nguyen",
            "Tara N. Sainath",
            "Brian Kingsbury"
        ],
        "venue": "IEEE Signal Process. Mag.,",
        "citeRegEx": "8",
        "shortCiteRegEx": "8",
        "year": 2012,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " Deep neural networks are powerful learning models that achieve excellent performance on visual and speech recognition problems [9, 8].",
        "context": null
    },
    {
        "title": "Imagenet classification with deep convolutional neural networks",
        "author": [
            "Alex Krizhevsky",
            "Ilya Sutskever",
            "Geoff Hinton"
        ],
        "venue": "In Advances in Neural Information Processing Systems",
        "citeRegEx": "9",
        "shortCiteRegEx": "9",
        "year": 2012,
        "abstract": "We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5% and 17.0%, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed regularization method called \"dropout\" that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3%, compared to 26.2% achieved by the second-best entry.",
        "full_text": "",
        "sentence": " Deep neural networks are powerful learning models that achieve excellent performance on visual and speech recognition problems [9, 8]. al architecture [9]. Figure 5: Adversarial examples generated for AlexNet [9]. Already, a variety of recent state of the art computer vision models employ input deformations during training for increasing the robustness and convergence speed of the models [9, 13]. For all the networks we studied (MNIST, QuocNet [10], AlexNet [9]), for each sample, we always manage to generate very close, visually indistinguishable, adversarial examples that are misclassified by the original network (see figure 5 for examples). Table 5 shows the upper and lower bounds computed from the ImageNet deep convolutional network of [9].",
        "context": null
    },
    {
        "title": "Building high-level features using large scale unsupervised learning",
        "author": [
            "Quoc V Le",
            "Marc\u2019Aurelio Ranzato",
            "Rajat Monga",
            "Matthieu Devin",
            "Kai Chen",
            "Greg S Corrado",
            "Jeff Dean",
            "Andrew Y Ng"
        ],
        "venue": "arXiv preprint arXiv:1112.6209,",
        "citeRegEx": "10",
        "shortCiteRegEx": "10",
        "year": 2011,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " \u2022 \u223c 10M image samples from Youtube (see [10]) \u2013 Unsupervised trained network with \u223c 1 billion learnable parameters. Figure 6: Adversarial examples for QuocNet [10]. For all the networks we studied (MNIST, QuocNet [10], AlexNet [9]), for each sample, we always manage to generate very close, visually indistinguishable, adversarial examples that are misclassified by the original network (see figure 5 for examples).",
        "context": null
    },
    {
        "title": "The mnist database of handwritten digits",
        "author": [
            "Yann LeCun",
            "Corinna Cortes"
        ],
        "venue": null,
        "citeRegEx": "11",
        "shortCiteRegEx": "11",
        "year": 1998,
        "abstract": "",
        "full_text": "",
        "sentence": " \u2022 For the MNIST dataset, we used the following architectures [11] \u2013 A simple fully connected, single layer network with a softmax classifier on top of it.",
        "context": null
    },
    {
        "title": "Efficient estimation of word representations in vector space",
        "author": [
            "Tomas Mikolov",
            "Kai Chen",
            "Greg Corrado",
            "Jeffrey Dean"
        ],
        "venue": "arXiv preprint arXiv:1301.3781,",
        "citeRegEx": "12",
        "shortCiteRegEx": "12",
        "year": 2013,
        "abstract": "We propose two novel model architectures for computing continuous vector\nrepresentations of words from very large data sets. The quality of these\nrepresentations is measured in a word similarity task, and the results are\ncompared to the previously best performing techniques based on different types\nof neural networks. We observe large improvements in accuracy at much lower\ncomputational cost, i.e. it takes less than a day to learn high quality word\nvectors from a 1.6 billion words data set. Furthermore, we show that these\nvectors provide state-of-the-art performance on our test set for measuring\nsyntactic and semantic word similarities.",
        "full_text": "Ef\ufb01cient Estimation of Word Representations in\nVector Space\nTomas Mikolov\nGoogle Inc., Mountain View, CA\ntmikolov@google.com\nKai Chen\nGoogle Inc., Mountain View, CA\nkaichen@google.com\nGreg Corrado\nGoogle Inc., Mountain View, CA\ngcorrado@google.com\nJeffrey Dean\nGoogle Inc., Mountain View, CA\njeff@google.com\nAbstract\nWe propose two novel model architectures for computing continuous vector repre-\nsentations of words from very large data sets. The quality of these representations\nis measured in a word similarity task, and the results are compared to the previ-\nously best performing techniques based on different types of neural networks. We\nobserve large improvements in accuracy at much lower computational cost, i.e. it\ntakes less than a day to learn high quality word vectors from a 1.6 billion words\ndata set. Furthermore, we show that these vectors provide state-of-the-art perfor-\nmance on our test set for measuring syntactic and semantic word similarities.\n1\nIntroduction\nMany current NLP systems and techniques treat words as atomic units - there is no notion of similar-\nity between words, as these are represented as indices in a vocabulary. This choice has several good\nreasons - simplicity, robustness and the observation that simple models trained on huge amounts of\ndata outperform complex systems trained on less data. An example is the popular N-gram model\nused for statistical language modeling - today, it is possible to train N-grams on virtually all available\ndata (trillions of words [3]).\nHowever, the simple techniques are at their limits in many tasks. For example, the amount of\nrelevant in-domain data for automatic speech recognition is limited - the performance is usually\ndominated by the size of high quality transcribed speech data (often just millions of words). In\nmachine translation, the existing corpora for many languages contain only a few billions of words\nor less. Thus, there are situations where simple scaling up of the basic techniques will not result in\nany signi\ufb01cant progress, and we have to focus on more advanced techniques.\nWith progress of machine learning techniques in recent years, it has become possible to train more\ncomplex models on much larger data set, and they typically outperform the simple models. Probably\nthe most successful concept is to use distributed representations of words [10]. For example, neural\nnetwork based language models signi\ufb01cantly outperform N-gram models [1, 27, 17].\n1.1\nGoals of the Paper\nThe main goal of this paper is to introduce techniques that can be used for learning high-quality word\nvectors from huge data sets with billions of words, and with millions of words in the vocabulary. As\nfar as we know, none of the previously proposed architectures has been successfully trained on more\n1\narXiv:1301.3781v3  [cs.CL]  7 Sep 2013\nthan a few hundred of millions of words, with a modest dimensionality of the word vectors between\n50 - 100.\nWe use recently proposed techniques for measuring the quality of the resulting vector representa-\ntions, with the expectation that not only will similar words tend to be close to each other, but that\nwords can have multiple degrees of similarity [20]. This has been observed earlier in the context\nof in\ufb02ectional languages - for example, nouns can have multiple word endings, and if we search for\nsimilar words in a subspace of the original vector space, it is possible to \ufb01nd words that have similar\nendings [13, 14].\nSomewhat surprisingly, it was found that similarity of word representations goes beyond simple\nsyntactic regularities. Using a word offset technique where simple algebraic operations are per-\nformed on the word vectors, it was shown for example that vector(\u201dKing\u201d) - vector(\u201dMan\u201d) + vec-\ntor(\u201dWoman\u201d) results in a vector that is closest to the vector representation of the word Queen [20].\nIn this paper, we try to maximize accuracy of these vector operations by developing new model\narchitectures that preserve the linear regularities among words. We design a new comprehensive test\nset for measuring both syntactic and semantic regularities1, and show that many such regularities\ncan be learned with high accuracy. Moreover, we discuss how training time and accuracy depends\non the dimensionality of the word vectors and on the amount of the training data.\n1.2\nPrevious Work\nRepresentation of words as continuous vectors has a long history [10, 26, 8]. A very popular model\narchitecture for estimating neural network language model (NNLM) was proposed in [1], where a\nfeedforward neural network with a linear projection layer and a non-linear hidden layer was used to\nlearn jointly the word vector representation and a statistical language model. This work has been\nfollowed by many others.\nAnother interesting architecture of NNLM was presented in [13, 14], where the word vectors are\n\ufb01rst learned using neural network with a single hidden layer. The word vectors are then used to train\nthe NNLM. Thus, the word vectors are learned even without constructing the full NNLM. In this\nwork, we directly extend this architecture, and focus just on the \ufb01rst step where the word vectors are\nlearned using a simple model.\nIt was later shown that the word vectors can be used to signi\ufb01cantly improve and simplify many\nNLP applications [4, 5, 29]. Estimation of the word vectors itself was performed using different\nmodel architectures and trained on various corpora [4, 29, 23, 19, 9], and some of the resulting word\nvectors were made available for future research and comparison2. However, as far as we know, these\narchitectures were signi\ufb01cantly more computationally expensive for training than the one proposed\nin [13], with the exception of certain version of log-bilinear model where diagonal weight matrices\nare used [23].\n2\nModel Architectures\nMany different types of models were proposed for estimating continuous representations of words,\nincluding the well-known Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA).\nIn this paper, we focus on distributed representations of words learned by neural networks, as it was\npreviously shown that they perform signi\ufb01cantly better than LSA for preserving linear regularities\namong words [20, 31]; LDA moreover becomes computationally very expensive on large data sets.\nSimilar to [18], to compare different model architectures we de\ufb01ne \ufb01rst the computational complex-\nity of a model as the number of parameters that need to be accessed to fully train the model. Next,\nwe will try to maximize the accuracy, while minimizing the computational complexity.\n1The test set is available at www.fit.vutbr.cz/\u02dcimikolov/rnnlm/word-test.v1.txt\n2http://ronan.collobert.com/senna/\nhttp://metaoptimize.com/projects/wordreprs/\nhttp://www.fit.vutbr.cz/\u02dcimikolov/rnnlm/\nhttp://ai.stanford.edu/\u02dcehhuang/\n2\nFor all the following models, the training complexity is proportional to\nO = E \u00d7 T \u00d7 Q,\n(1)\nwhere E is number of the training epochs, T is the number of the words in the training set and Q is\nde\ufb01ned further for each model architecture. Common choice is E = 3 \u221250 and T up to one billion.\nAll models are trained using stochastic gradient descent and backpropagation [26].\n2.1\nFeedforward Neural Net Language Model (NNLM)\nThe probabilistic feedforward neural network language model has been proposed in [1]. It consists\nof input, projection, hidden and output layers. At the input layer, N previous words are encoded\nusing 1-of-V coding, where V is size of the vocabulary. The input layer is then projected to a\nprojection layer P that has dimensionality N \u00d7 D, using a shared projection matrix. As only N\ninputs are active at any given time, composition of the projection layer is a relatively cheap operation.\nThe NNLM architecture becomes complex for computation between the projection and the hidden\nlayer, as values in the projection layer are dense. For a common choice of N = 10, the size of the\nprojection layer (P) might be 500 to 2000, while the hidden layer size H is typically 500 to 1000\nunits. Moreover, the hidden layer is used to compute probability distribution over all the words in the\nvocabulary, resulting in an output layer with dimensionality V . Thus, the computational complexity\nper each training example is\nQ = N \u00d7 D + N \u00d7 D \u00d7 H + H \u00d7 V,\n(2)\nwhere the dominating term is H \u00d7 V . However, several practical solutions were proposed for\navoiding it; either using hierarchical versions of the softmax [25, 23, 18], or avoiding normalized\nmodels completely by using models that are not normalized during training [4, 9]. With binary tree\nrepresentations of the vocabulary, the number of output units that need to be evaluated can go down\nto around log2(V ). Thus, most of the complexity is caused by the term N \u00d7 D \u00d7 H.\nIn our models, we use hierarchical softmax where the vocabulary is represented as a Huffman binary\ntree. This follows previous observations that the frequency of words works well for obtaining classes\nin neural net language models [16]. Huffman trees assign short binary codes to frequent words, and\nthis further reduces the number of output units that need to be evaluated: while balanced binary tree\nwould require log2(V ) outputs to be evaluated, the Huffman tree based hierarchical softmax requires\nonly about log2(Unigram perplexity(V )). For example when the vocabulary size is one million\nwords, this results in about two times speedup in evaluation. While this is not crucial speedup for\nneural network LMs as the computational bottleneck is in the N \u00d7D\u00d7H term, we will later propose\narchitectures that do not have hidden layers and thus depend heavily on the ef\ufb01ciency of the softmax\nnormalization.\n2.2\nRecurrent Neural Net Language Model (RNNLM)\nRecurrent neural network based language model has been proposed to overcome certain limitations\nof the feedforward NNLM, such as the need to specify the context length (the order of the model N),\nand because theoretically RNNs can ef\ufb01ciently represent more complex patterns than the shallow\nneural networks [15, 2]. The RNN model does not have a projection layer; only input, hidden and\noutput layer. What is special for this type of model is the recurrent matrix that connects hidden\nlayer to itself, using time-delayed connections. This allows the recurrent model to form some kind\nof short term memory, as information from the past can be represented by the hidden layer state that\ngets updated based on the current input and the state of the hidden layer in the previous time step.\nThe complexity per training example of the RNN model is\nQ = H \u00d7 H + H \u00d7 V,\n(3)\nwhere the word representations D have the same dimensionality as the hidden layer H. Again, the\nterm H \u00d7 V can be ef\ufb01ciently reduced to H \u00d7 log2(V ) by using hierarchical softmax. Most of the\ncomplexity then comes from H \u00d7 H.\n3\n2.3\nParallel Training of Neural Networks\nTo train models on huge data sets, we have implemented several models on top of a large-scale\ndistributed framework called DistBelief [6], including the feedforward NNLM and the new models\nproposed in this paper. The framework allows us to run multiple replicas of the same model in\nparallel, and each replica synchronizes its gradient updates through a centralized server that keeps\nall the parameters. For this parallel training, we use mini-batch asynchronous gradient descent with\nan adaptive learning rate procedure called Adagrad [7]. Under this framework, it is common to use\none hundred or more model replicas, each using many CPU cores at different machines in a data\ncenter.\n3\nNew Log-linear Models\nIn this section, we propose two new model architectures for learning distributed representations\nof words that try to minimize computational complexity. The main observation from the previous\nsection was that most of the complexity is caused by the non-linear hidden layer in the model. While\nthis is what makes neural networks so attractive, we decided to explore simpler models that might\nnot be able to represent the data as precisely as neural networks, but can possibly be trained on much\nmore data ef\ufb01ciently.\nThe new architectures directly follow those proposed in our earlier work [13, 14], where it was\nfound that neural network language model can be successfully trained in two steps: \ufb01rst, continuous\nword vectors are learned using simple model, and then the N-gram NNLM is trained on top of these\ndistributed representations of words. While there has been later substantial amount of work that\nfocuses on learning word vectors, we consider the approach proposed in [13] to be the simplest one.\nNote that related models have been proposed also much earlier [26, 8].\n3.1\nContinuous Bag-of-Words Model\nThe \ufb01rst proposed architecture is similar to the feedforward NNLM, where the non-linear hidden\nlayer is removed and the projection layer is shared for all words (not just the projection matrix);\nthus, all words get projected into the same position (their vectors are averaged). We call this archi-\ntecture a bag-of-words model as the order of words in the history does not in\ufb02uence the projection.\nFurthermore, we also use words from the future; we have obtained the best performance on the task\nintroduced in the next section by building a log-linear classi\ufb01er with four future and four history\nwords at the input, where the training criterion is to correctly classify the current (middle) word.\nTraining complexity is then\nQ = N \u00d7 D + D \u00d7 log2(V ).\n(4)\nWe denote this model further as CBOW, as unlike standard bag-of-words model, it uses continuous\ndistributed representation of the context. The model architecture is shown at Figure 1. Note that the\nweight matrix between the input and the projection layer is shared for all word positions in the same\nway as in the NNLM.\n3.2\nContinuous Skip-gram Model\nThe second architecture is similar to CBOW, but instead of predicting the current word based on the\ncontext, it tries to maximize classi\ufb01cation of a word based on another word in the same sentence.\nMore precisely, we use each current word as an input to a log-linear classi\ufb01er with continuous\nprojection layer, and predict words within a certain range before and after the current word. We\nfound that increasing the range improves quality of the resulting word vectors, but it also increases\nthe computational complexity. Since the more distant words are usually less related to the current\nword than those close to it, we give less weight to the distant words by sampling less from those\nwords in our training examples.\nThe training complexity of this architecture is proportional to\nQ = C \u00d7 (D + D \u00d7 log2(V )),\n(5)\nwhere C is the maximum distance of the words. Thus, if we choose C = 5, for each training word\nwe will select randomly a number R in range < 1; C >, and then use R words from history and\n4\nw(t-2)\nw(t+1)\nw(t-1)\nw(t+2)\nw(t)\nSUM\n       INPUT         PROJECTION         OUTPUT\nw(t)\n          INPUT         PROJECTION      OUTPUT\nw(t-2)\nw(t-1)\nw(t+1)\nw(t+2)\n                   CBOW                                                   Skip-gram\nFigure 1: New model architectures. The CBOW architecture predicts the current word based on the\ncontext, and the Skip-gram predicts surrounding words given the current word.\nR words from the future of the current word as correct labels. This will require us to do R \u00d7 2\nword classi\ufb01cations, with the current word as input, and each of the R + R words as output. In the\nfollowing experiments, we use C = 10.\n4\nResults\nTo compare the quality of different versions of word vectors, previous papers typically use a table\nshowing example words and their most similar words, and understand them intuitively. Although\nit is easy to show that word France is similar to Italy and perhaps some other countries, it is much\nmore challenging when subjecting those vectors in a more complex similarity task, as follows. We\nfollow previous observation that there can be many different types of similarities between words, for\nexample, word big is similar to bigger in the same sense that small is similar to smaller. Example\nof another type of relationship can be word pairs big - biggest and small - smallest [20]. We further\ndenote two pairs of words with the same relationship as a question, as we can ask: \u201dWhat is the\nword that is similar to small in the same sense as biggest is similar to big?\u201d\nSomewhat surprisingly, these questions can be answered by performing simple algebraic operations\nwith the vector representation of words. To \ufb01nd a word that is similar to small in the same sense as\nbiggest is similar to big, we can simply compute vector X = vector(\u201dbiggest\u201d)\u2212vector(\u201dbig\u201d)+\nvector(\u201dsmall\u201d). Then, we search in the vector space for the word closest to X measured by cosine\ndistance, and use it as the answer to the question (we discard the input question words during this\nsearch). When the word vectors are well trained, it is possible to \ufb01nd the correct answer (word\nsmallest) using this method.\nFinally, we found that when we train high dimensional word vectors on a large amount of data, the\nresulting vectors can be used to answer very subtle semantic relationships between words, such as\na city and the country it belongs to, e.g. France is to Paris as Germany is to Berlin. Word vectors\nwith such semantic relationships could be used to improve many existing NLP applications, such\nas machine translation, information retrieval and question answering systems, and may enable other\nfuture applications yet to be invented.\n5\nTable 1: Examples of \ufb01ve types of semantic and nine types of syntactic questions in the Semantic-\nSyntactic Word Relationship test set.\nType of relationship\nWord Pair 1\nWord Pair 2\nCommon capital city\nAthens\nGreece\nOslo\nNorway\nAll capital cities\nAstana\nKazakhstan\nHarare\nZimbabwe\nCurrency\nAngola\nkwanza\nIran\nrial\nCity-in-state\nChicago\nIllinois\nStockton\nCalifornia\nMan-Woman\nbrother\nsister\ngrandson\ngranddaughter\nAdjective to adverb\napparent\napparently\nrapid\nrapidly\nOpposite\npossibly\nimpossibly\nethical\nunethical\nComparative\ngreat\ngreater\ntough\ntougher\nSuperlative\neasy\neasiest\nlucky\nluckiest\nPresent Participle\nthink\nthinking\nread\nreading\nNationality adjective\nSwitzerland\nSwiss\nCambodia\nCambodian\nPast tense\nwalking\nwalked\nswimming\nswam\nPlural nouns\nmouse\nmice\ndollar\ndollars\nPlural verbs\nwork\nworks\nspeak\nspeaks\n4.1\nTask Description\nTo measure quality of the word vectors, we de\ufb01ne a comprehensive test set that contains \ufb01ve types\nof semantic questions, and nine types of syntactic questions. Two examples from each category are\nshown in Table 1. Overall, there are 8869 semantic and 10675 syntactic questions. The questions\nin each category were created in two steps: \ufb01rst, a list of similar word pairs was created manually.\nThen, a large list of questions is formed by connecting two word pairs. For example, we made a\nlist of 68 large American cities and the states they belong to, and formed about 2.5K questions by\npicking two word pairs at random. We have included in our test set only single token words, thus\nmulti-word entities are not present (such as New York).\nWe evaluate the overall accuracy for all question types, and for each question type separately (se-\nmantic, syntactic). Question is assumed to be correctly answered only if the closest word to the\nvector computed using the above method is exactly the same as the correct word in the question;\nsynonyms are thus counted as mistakes. This also means that reaching 100% accuracy is likely\nto be impossible, as the current models do not have any input information about word morphology.\nHowever, we believe that usefulness of the word vectors for certain applications should be positively\ncorrelated with this accuracy metric. Further progress can be achieved by incorporating information\nabout structure of words, especially for the syntactic questions.\n4.2\nMaximization of Accuracy\nWe have used a Google News corpus for training the word vectors. This corpus contains about\n6B tokens. We have restricted the vocabulary size to 1 million most frequent words. Clearly, we\nare facing time constrained optimization problem, as it can be expected that both using more data\nand higher dimensional word vectors will improve the accuracy. To estimate the best choice of\nmodel architecture for obtaining as good as possible results quickly, we have \ufb01rst evaluated models\ntrained on subsets of the training data, with vocabulary restricted to the most frequent 30k words.\nThe results using the CBOW architecture with different choice of word vector dimensionality and\nincreasing amount of the training data are shown in Table 2.\nIt can be seen that after some point, adding more dimensions or adding more training data provides\ndiminishing improvements. So, we have to increase both vector dimensionality and the amount\nof the training data together. While this observation might seem trivial, it must be noted that it is\ncurrently popular to train word vectors on relatively large amounts of data, but with insuf\ufb01cient size\n6\nTable 2:\nAccuracy on subset of the Semantic-Syntactic Word Relationship test set, using word\nvectors from the CBOW architecture with limited vocabulary. Only questions containing words from\nthe most frequent 30k words are used.\nDimensionality / Training words\n24M\n49M\n98M\n196M\n391M\n783M\n50\n13.4\n15.7\n18.6\n19.1\n22.5\n23.2\n100\n19.4\n23.1\n27.8\n28.7\n33.4\n32.2\n300\n23.2\n29.2\n35.3\n38.6\n43.7\n45.9\n600\n24.0\n30.1\n36.5\n40.8\n46.6\n50.4\nTable 3: Comparison of architectures using models trained on the same data, with 640-dimensional\nword vectors. The accuracies are reported on our Semantic-Syntactic Word Relationship test set,\nand on the syntactic relationship test set of [20]\nModel\nSemantic-Syntactic Word Relationship test set\nMSR Word Relatedness\nArchitecture\nSemantic Accuracy [%]\nSyntactic Accuracy [%]\nTest Set [20]\nRNNLM\n9\n36\n35\nNNLM\n23\n53\n47\nCBOW\n24\n64\n61\nSkip-gram\n55\n59\n56\n(such as 50 - 100). Given Equation 4, increasing amount of training data twice results in about the\nsame increase of computational complexity as increasing vector size twice.\nFor the experiments reported in Tables 2 and 4, we used three training epochs with stochastic gradi-\nent descent and backpropagation. We chose starting learning rate 0.025 and decreased it linearly, so\nthat it approaches zero at the end of the last training epoch.\n4.3\nComparison of Model Architectures\nFirst we compare different model architectures for deriving the word vectors using the same training\ndata and using the same dimensionality of 640 of the word vectors. In the further experiments, we\nuse full set of questions in the new Semantic-Syntactic Word Relationship test set, i.e. unrestricted to\nthe 30k vocabulary. We also include results on a test set introduced in [20] that focuses on syntactic\nsimilarity between words3.\nThe training data consists of several LDC corpora and is described in detail in [18] (320M words,\n82K vocabulary). We used these data to provide a comparison to a previously trained recurrent\nneural network language model that took about 8 weeks to train on a single CPU. We trained a feed-\nforward NNLM with the same number of 640 hidden units using the DistBelief parallel training [6],\nusing a history of 8 previous words (thus, the NNLM has more parameters than the RNNLM, as the\nprojection layer has size 640 \u00d7 8).\nIn Table 3, it can be seen that the word vectors from the RNN (as used in [20]) perform well mostly\non the syntactic questions. The NNLM vectors perform signi\ufb01cantly better than the RNN - this is\nnot surprising, as the word vectors in the RNNLM are directly connected to a non-linear hidden\nlayer. The CBOW architecture works better than the NNLM on the syntactic tasks, and about the\nsame on the semantic one. Finally, the Skip-gram architecture works slightly worse on the syntactic\ntask than the CBOW model (but still better than the NNLM), and much better on the semantic part\nof the test than all the other models.\nNext, we evaluated our models trained using one CPU only and compared the results against publicly\navailable word vectors. The comparison is given in Table 4. The CBOW model was trained on subset\n3We thank Geoff Zweig for providing us the test set.\n7\nTable 4: Comparison of publicly available word vectors on the Semantic-Syntactic Word Relation-\nship test set, and word vectors from our models. Full vocabularies are used.\nModel\nVector\nTraining\nAccuracy [%]\nDimensionality\nwords\nSemantic\nSyntactic\nTotal\nCollobert-Weston NNLM\n50\n660M\n9.3\n12.3\n11.0\nTurian NNLM\n50\n37M\n1.4\n2.6\n2.1\nTurian NNLM\n200\n37M\n1.4\n2.2\n1.8\nMnih NNLM\n50\n37M\n1.8\n9.1\n5.8\nMnih NNLM\n100\n37M\n3.3\n13.2\n8.8\nMikolov RNNLM\n80\n320M\n4.9\n18.4\n12.7\nMikolov RNNLM\n640\n320M\n8.6\n36.5\n24.6\nHuang NNLM\n50\n990M\n13.3\n11.6\n12.3\nOur NNLM\n20\n6B\n12.9\n26.4\n20.3\nOur NNLM\n50\n6B\n27.9\n55.8\n43.2\nOur NNLM\n100\n6B\n34.2\n64.5\n50.8\nCBOW\n300\n783M\n15.5\n53.1\n36.1\nSkip-gram\n300\n783M\n50.0\n55.9\n53.3\nTable 5: Comparison of models trained for three epochs on the same data and models trained for\none epoch. Accuracy is reported on the full Semantic-Syntactic data set.\nModel\nVector\nTraining\nAccuracy [%]\nTraining time\nDimensionality\nwords\n[days]\nSemantic\nSyntactic\nTotal\n3 epoch CBOW\n300\n783M\n15.5\n53.1\n36.1\n1\n3 epoch Skip-gram\n300\n783M\n50.0\n55.9\n53.3\n3\n1 epoch CBOW\n300\n783M\n13.8\n49.9\n33.6\n0.3\n1 epoch CBOW\n300\n1.6B\n16.1\n52.6\n36.1\n0.6\n1 epoch CBOW\n600\n783M\n15.4\n53.3\n36.2\n0.7\n1 epoch Skip-gram\n300\n783M\n45.6\n52.2\n49.2\n1\n1 epoch Skip-gram\n300\n1.6B\n52.2\n55.1\n53.8\n2\n1 epoch Skip-gram\n600\n783M\n56.7\n54.5\n55.5\n2.5\nof the Google News data in about a day, while training time for the Skip-gram model was about three\ndays.\nFor experiments reported further, we used just one training epoch (again, we decrease the learning\nrate linearly so that it approaches zero at the end of training). Training a model on twice as much\ndata using one epoch gives comparable or better results than iterating over the same data for three\nepochs, as is shown in Table 5, and provides additional small speedup.\n4.4\nLarge Scale Parallel Training of Models\nAs mentioned earlier, we have implemented various models in a distributed framework called Dis-\ntBelief. Below we report the results of several models trained on the Google News 6B data set,\nwith mini-batch asynchronous gradient descent and the adaptive learning rate procedure called Ada-\ngrad [7]. We used 50 to 100 model replicas during the training. The number of CPU cores is an\n8\nTable 6:\nComparison of models trained using the DistBelief distributed framework. Note that\ntraining of NNLM with 1000-dimensional vectors would take too long to complete.\nModel\nVector\nTraining\nAccuracy [%]\nTraining time\nDimensionality\nwords\n[days x CPU cores]\nSemantic\nSyntactic\nTotal\nNNLM\n100\n6B\n34.2\n64.5\n50.8\n14 x 180\nCBOW\n1000\n6B\n57.3\n68.9\n63.7\n2 x 140\nSkip-gram\n1000\n6B\n66.1\n65.1\n65.6\n2.5 x 125\nTable 7: Comparison and combination of models on the Microsoft Sentence Completion Challenge.\nArchitecture\nAccuracy [%]\n4-gram [32]\n39\nAverage LSA similarity [32]\n49\nLog-bilinear model [24]\n54.8\nRNNLMs [19]\n55.4\nSkip-gram\n48.0\nSkip-gram + RNNLMs\n58.9\nestimate since the data center machines are shared with other production tasks, and the usage can\n\ufb02uctuate quite a bit. Note that due to the overhead of the distributed framework, the CPU usage of\nthe CBOW model and the Skip-gram model are much closer to each other than their single-machine\nimplementations. The result are reported in Table 6.\n4.5\nMicrosoft Research Sentence Completion Challenge\nThe Microsoft Sentence Completion Challenge has been recently introduced as a task for advancing\nlanguage modeling and other NLP techniques [32]. This task consists of 1040 sentences, where one\nword is missing in each sentence and the goal is to select word that is the most coherent with the\nrest of the sentence, given a list of \ufb01ve reasonable choices. Performance of several techniques has\nbeen already reported on this set, including N-gram models, LSA-based model [32], log-bilinear\nmodel [24] and a combination of recurrent neural networks that currently holds the state of the art\nperformance of 55.4% accuracy on this benchmark [19].\nWe have explored the performance of Skip-gram architecture on this task. First, we train the 640-\ndimensional model on 50M words provided in [32]. Then, we compute score of each sentence in\nthe test set by using the unknown word at the input, and predict all surrounding words in a sentence.\nThe \ufb01nal sentence score is then the sum of these individual predictions. Using the sentence scores,\nwe choose the most likely sentence.\nA short summary of some previous results together with the new results is presented in Table 7.\nWhile the Skip-gram model itself does not perform on this task better than LSA similarity, the scores\nfrom this model are complementary to scores obtained with RNNLMs, and a weighted combination\nleads to a new state of the art result 58.9% accuracy (59.2% on the development part of the set and\n58.7% on the test part of the set).\n5\nExamples of the Learned Relationships\nTable 8 shows words that follow various relationships. We follow the approach described above: the\nrelationship is de\ufb01ned by subtracting two word vectors, and the result is added to another word. Thus\nfor example, Paris - France + Italy = Rome. As it can be seen, accuracy is quite good, although\nthere is clearly a lot of room for further improvements (note that using our accuracy metric that\n9\nTable 8: Examples of the word pair relationships, using the best word vectors from Table 4 (Skip-\ngram model trained on 783M words with 300 dimensionality).\nRelationship\nExample 1\nExample 2\nExample 3\nFrance - Paris\nItaly: Rome\nJapan: Tokyo\nFlorida: Tallahassee\nbig - bigger\nsmall: larger\ncold: colder\nquick: quicker\nMiami - Florida\nBaltimore: Maryland\nDallas: Texas\nKona: Hawaii\nEinstein - scientist\nMessi: mid\ufb01elder\nMozart: violinist\nPicasso: painter\nSarkozy - France\nBerlusconi: Italy\nMerkel: Germany\nKoizumi: Japan\ncopper - Cu\nzinc: Zn\ngold: Au\nuranium: plutonium\nBerlusconi - Silvio\nSarkozy: Nicolas\nPutin: Medvedev\nObama: Barack\nMicrosoft - Windows\nGoogle: Android\nIBM: Linux\nApple: iPhone\nMicrosoft - Ballmer\nGoogle: Yahoo\nIBM: McNealy\nApple: Jobs\nJapan - sushi\nGermany: bratwurst\nFrance: tapas\nUSA: pizza\nassumes exact match, the results in Table 8 would score only about 60%). We believe that word\nvectors trained on even larger data sets with larger dimensionality will perform signi\ufb01cantly better,\nand will enable the development of new innovative applications. Another way to improve accuracy is\nto provide more than one example of the relationship. By using ten examples instead of one to form\nthe relationship vector (we average the individual vectors together), we have observed improvement\nof accuracy of our best models by about 10% absolutely on the semantic-syntactic test.\nIt is also possible to apply the vector operations to solve different tasks. For example, we have\nobserved good accuracy for selecting out-of-the-list words, by computing average vector for a list of\nwords, and \ufb01nding the most distant word vector. This is a popular type of problems in certain human\nintelligence tests. Clearly, there is still a lot of discoveries to be made using these techniques.\n6\nConclusion\nIn this paper we studied the quality of vector representations of words derived by various models on\na collection of syntactic and semantic language tasks. We observed that it is possible to train high\nquality word vectors using very simple model architectures, compared to the popular neural network\nmodels (both feedforward and recurrent). Because of the much lower computational complexity, it\nis possible to compute very accurate high dimensional word vectors from a much larger data set.\nUsing the DistBelief distributed framework, it should be possible to train the CBOW and Skip-gram\nmodels even on corpora with one trillion words, for basically unlimited size of the vocabulary. That\nis several orders of magnitude larger than the best previously published results for similar models.\nAn interesting task where the word vectors have recently been shown to signi\ufb01cantly outperform the\nprevious state of the art is the SemEval-2012 Task 2 [11]. The publicly available RNN vectors were\nused together with other techniques to achieve over 50% increase in Spearman\u2019s rank correlation\nover the previous best result [31]. The neural network based word vectors were previously applied\nto many other NLP tasks, for example sentiment analysis [12] and paraphrase detection [28]. It can\nbe expected that these applications can bene\ufb01t from the model architectures described in this paper.\nOur ongoing work shows that the word vectors can be successfully applied to automatic extension\nof facts in Knowledge Bases, and also for veri\ufb01cation of correctness of existing facts. Results\nfrom machine translation experiments also look very promising. In the future, it would be also\ninteresting to compare our techniques to Latent Relational Analysis [30] and others. We believe that\nour comprehensive test set will help the research community to improve the existing techniques for\nestimating the word vectors. We also expect that high quality word vectors will become an important\nbuilding block for future NLP applications.\n10\n7\nFollow-Up Work\nAfter the initial version of this paper was written, we published single-machine multi-threaded C++\ncode for computing the word vectors, using both the continuous bag-of-words and skip-gram archi-\ntectures4. The training speed is signi\ufb01cantly higher than reported earlier in this paper, i.e. it is in the\norder of billions of words per hour for typical hyperparameter choices. We also published more than\n1.4 million vectors that represent named entities, trained on more than 100 billion words. Some of\nour follow-up work will be published in an upcoming NIPS 2013 paper [21].\nReferences\n[1] Y. Bengio, R. Ducharme, P. Vincent. A neural probabilistic language model. Journal of Ma-\nchine Learning Research, 3:1137-1155, 2003.\n[2] Y. Bengio, Y. LeCun. Scaling learning algorithms towards AI. In: Large-Scale Kernel Ma-\nchines, MIT Press, 2007.\n[3] T. Brants, A. C. Popat, P. Xu, F. J. Och, and J. Dean. Large language models in machine\ntranslation. In Proceedings of the Joint Conference on Empirical Methods in Natural Language\nProcessing and Computational Language Learning, 2007.\n[4] R. Collobert and J. Weston. A Uni\ufb01ed Architecture for Natural Language Processing: Deep\nNeural Networks with Multitask Learning. In International Conference on Machine Learning,\nICML, 2008.\n[5] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu and P. Kuksa. Natural Lan-\nguage Processing (Almost) from Scratch. Journal of Machine Learning Research, 12:2493-\n2537, 2011.\n[6] J. Dean, G.S. Corrado, R. Monga, K. Chen, M. Devin, Q.V. Le, M.Z. Mao, M.A. Ranzato, A.\nSenior, P. Tucker, K. Yang, A. Y. Ng., Large Scale Distributed Deep Networks, NIPS, 2012.\n[7] J.C. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and\nstochastic optimization. Journal of Machine Learning Research, 2011.\n[8] J. Elman. Finding Structure in Time. Cognitive Science, 14, 179-211, 1990.\n[9] Eric H. Huang, R. Socher, C. D. Manning and Andrew Y. Ng. Improving Word Representations\nvia Global Context and Multiple Word Prototypes. In: Proc. Association for Computational\nLinguistics, 2012.\n[10] G.E. Hinton, J.L. McClelland, D.E. Rumelhart. Distributed representations. In: Parallel dis-\ntributed processing: Explorations in the microstructure of cognition. Volume 1: Foundations,\nMIT Press, 1986.\n[11] D.A. Jurgens, S.M. Mohammad, P.D. Turney, K.J. Holyoak. Semeval-2012 task 2: Measuring\ndegrees of relational similarity. In: Proceedings of the 6th International Workshop on Semantic\nEvaluation (SemEval 2012), 2012.\n[12] A.L. Maas, R.E. Daly, P.T. Pham, D. Huang, A.Y. Ng, and C. Potts. Learning word vectors for\nsentiment analysis. In Proceedings of ACL, 2011.\n[13] T. Mikolov. Language Modeling for Speech Recognition in Czech, Masters thesis, Brno Uni-\nversity of Technology, 2007.\n[14] T. Mikolov, J. Kopeck\u00b4y, L. Burget, O. Glembek and J. \u02c7Cernock\u00b4y. Neural network based lan-\nguage models for higly in\ufb02ective languages, In: Proc. ICASSP 2009.\n[15] T. Mikolov, M. Kara\ufb01\u00b4at, L. Burget, J. \u02c7Cernock\u00b4y, S. Khudanpur. Recurrent neural network\nbased language model, In: Proceedings of Interspeech, 2010.\n[16] T. Mikolov, S. Kombrink, L. Burget, J. \u02c7Cernock\u00b4y, S. Khudanpur. Extensions of recurrent neural\nnetwork language model, In: Proceedings of ICASSP 2011.\n[17] T. Mikolov, A. Deoras, S. Kombrink, L. Burget, J. \u02c7Cernock\u00b4y. Empirical Evaluation and Com-\nbination of Advanced Language Modeling Techniques, In: Proceedings of Interspeech, 2011.\n4The code is available at https://code.google.com/p/word2vec/\n11\n[18] T. Mikolov, A. Deoras, D. Povey, L. Burget, J. \u02c7Cernock\u00b4y. Strategies for Training Large Scale\nNeural Network Language Models, In: Proc. Automatic Speech Recognition and Understand-\ning, 2011.\n[19] T. Mikolov. Statistical Language Models based on Neural Networks. PhD thesis, Brno Univer-\nsity of Technology, 2012.\n[20] T. Mikolov, W.T. Yih, G. Zweig. Linguistic Regularities in Continuous Space Word Represen-\ntations. NAACL HLT 2013.\n[21] T. Mikolov, I. Sutskever, K. Chen, G. Corrado, and J. Dean. Distributed Representations of\nWords and Phrases and their Compositionality. Accepted to NIPS 2013.\n[22] A. Mnih, G. Hinton. Three new graphical models for statistical language modelling. ICML,\n2007.\n[23] A. Mnih, G. Hinton. A Scalable Hierarchical Distributed Language Model. Advances in Neural\nInformation Processing Systems 21, MIT Press, 2009.\n[24] A. Mnih, Y.W. Teh. A fast and simple algorithm for training neural probabilistic language\nmodels. ICML, 2012.\n[25] F. Morin, Y. Bengio. Hierarchical Probabilistic Neural Network Language Model. AISTATS,\n2005.\n[26] D. E. Rumelhart, G. E. Hinton, R. J. Williams. Learning internal representations by back-\npropagating errors. Nature, 323:533.536, 1986.\n[27] H. Schwenk. Continuous space language models. Computer Speech and Language, vol. 21,\n2007.\n[28] R. Socher, E.H. Huang, J. Pennington, A.Y. Ng, and C.D. Manning. Dynamic Pooling and\nUnfolding Recursive Autoencoders for Paraphrase Detection. In NIPS, 2011.\n[29] J. Turian, L. Ratinov, Y. Bengio. Word Representations: A Simple and General Method for\nSemi-Supervised Learning. In: Proc. Association for Computational Linguistics, 2010.\n[30] P. D. Turney. Measuring Semantic Similarity by Latent Relational Analysis. In: Proc. Interna-\ntional Joint Conference on Arti\ufb01cial Intelligence, 2005.\n[31] A. Zhila, W.T. Yih, C. Meek, G. Zweig, T. Mikolov. Combining Heterogeneous Models for\nMeasuring Relational Similarity. NAACL HLT 2013.\n[32] G. Zweig, C.J.C. Burges. The Microsoft Research Sentence Completion Challenge, Microsoft\nResearch Technical Report MSR-TR-2011-129, 2011.\n12\n",
        "sentence": " [12] for word representations, where the various directions in the vector space representing the words are shown to give rise to a surprisingly rich semantic encoding of relations and analogies.",
        "context": "formed on the word vectors, it was shown for example that vector(\u201dKing\u201d) - vector(\u201dMan\u201d) + vec-\ntor(\u201dWoman\u201d) results in a vector that is closest to the vector representation of the word Queen [20].\nof in\ufb02ectional languages - for example, nouns can have multiple word endings, and if we search for\nsimilar words in a subspace of the original vector space, it is possible to \ufb01nd words that have similar\nendings [13, 14].\non the dimensionality of the word vectors and on the amount of the training data.\n1.2\nPrevious Work\nRepresentation of words as continuous vectors has a long history [10, 26, 8]. A very popular model"
    },
    {
        "title": "Visualizing and understanding convolutional neural networks",
        "author": [
            "Matthew D Zeiler",
            "Rob Fergus"
        ],
        "venue": "arXiv preprint arXiv:1311.2901,",
        "citeRegEx": "13",
        "shortCiteRegEx": "13",
        "year": 2013,
        "abstract": "",
        "full_text": "",
        "sentence": " Previous works [6, 13, 7] analyzed the semantic meaning of various units by finding the set of inputs that maximally activate a given unit. They look for input images which maximize the activation value of this single feature [6, 13, 7, 4]. So far, unit-level inspection methods had relatively little utility beyond confirming certain intuitions regarding the complexity of the representations learned by a deep neural network [6, 13, 7, 4]. Already, a variety of recent state of the art computer vision models employ input deformations during training for increasing the robustness and convergence speed of the models [9, 13].",
        "context": null
    }
]