[
    {
        "title": "Oracle inequalities for computationally adaptive model selection",
        "author": [
            "A. Agarwal",
            "P.L. Bartlett",
            "J.C. Duchi"
        ],
        "venue": "arXiv preprint arXiv:1208.0129,",
        "citeRegEx": "Agarwal et al\\.,? \\Q2012\\E",
        "shortCiteRegEx": "Agarwal et al\\.",
        "year": 2012,
        "abstract": "We analyze general model selection procedures using penalized empirical loss\nminimization under computational constraints. While classical model selection\napproaches do not consider computational aspects of performing model selection,\nwe argue that any practical model selection procedure must not only trade off\nestimation and approximation error, but also the computational effort required\nto compute empirical minimizers for different function classes. We provide a\nframework for analyzing such problems, and we give algorithms for model\nselection under a computational budget. These algorithms satisfy oracle\ninequalities that show that the risk of the selected model is not much worse\nthan if we had devoted all of our omputational budget to the optimal function\nclass.",
        "full_text": "arXiv:1208.0129v1  [stat.ML]  1 Aug 2012\nOracle inequalities for computationally adaptive model\nselection\nAlekh Agarwal\u2020\nPeter L. Bartlett\u22c6,\u2020,\u2021\nJohn C. Duchi\u2020\nalekh@eecs.berkeley.edu\nbartlett@stat.berkeley.edu\njduchi@eecs.berkeley.edu\nDepartment of Statistics\u22c6, and\nDepartment of Mathematical Sciences\u2021\nDepartment of EECS\u2020,\nQueensland University of Technology\nUniversity of California, Berkeley, CA USA\nBrisbane, Australia\nAugust 2, 2012\nAbstract\nWe analyze general model selection procedures using penalized empirical loss minimization\nunder computational constraints. While classical model selection approaches do not consider\ncomputational aspects of performing model selection, we argue that any practical model se-\nlection procedure must not only trade o\ufb00estimation and approximation error, but also the\ncomputational e\ufb00ort required to compute empirical minimizers for di\ufb00erent function classes.\nWe provide a framework for analyzing such problems, and we give algorithms for model selec-\ntion under a computational budget. These algorithms satisfy oracle inequalities that show that\nthe risk of the selected model is not much worse than if we had devoted all of our computational\nbudget to the optimal function class.\n1\nIntroduction\nIn decision-theoretic statistical settings, one receives samples {z1, . . . , zn} \u2286Z drawn i.i.d. from\nsome unknown distribution P over a sample space Z, and given a loss function \u2113, seeks a function\nf to minimize the risk\nR(f) := E[\u2113(z, f)].\n(1)\nSince R(f) is unknown, the typical approach is to compute estimates based on the empirical risk,\nbRn(f) := 1\nn\nPn\ni=1 \u2113(zi, f), over a function class F. Through this, one seeks a function fn with a risk\nclose to the Bayes risk, the minimal risk over all measurable functions, which is R0 := inff R(f).\nThere is a natural tradeo\ufb00based on the class F one chooses, since\nR(fn) \u2212R0 =\n\u0012\nR(fn) \u2212inf\nf\u2208F R(f)\n\u0013\n+\n\u0012\ninf\nf\u2208F R(f) \u2212R0\n\u0013\n,\nwhich decomposes the excess risk of fn into estimation error (left) and approximation error (right).\nA common approach to addressing this tradeo\ufb00is to express F as a union of classes\nF =\n[\nj\u22651\nFj.\n(2)\nThe model selection problem is to choose a class Fi and a function f \u2208Fi that give the best tradeo\ufb00\nbetween estimation error and approximation error. A standard approach to the model selection\nproblem is the now classical idea of complexity regularization, which arose out of early works by\n1\nMallows [21] and Akaike [1].\nThe complexity regularization approach balances two competing\nobjectives: the minimum empirical risk of a model class Fi (approximation error) and a complexity\npenalty (to control estimation error) for the class.\nDi\ufb00erent choices of the complexity penalty\ngive rise to di\ufb00erent model selection criteria and algorithms (for example, see the lecture notes by\nMassart [23] and the references therein). The complexity regularization approach uses penalties\n\u03b3i : N \u2192R+ associated with each class Fi to perform model selection, where \u03b3i(n) is a complexity\npenalty for class i when n samples are available; usually the functions \u03b3i decrease to zero in n and\nincrease in the index i. The actual algorithm is as follows: for each i, choose\n\u02c6fi \u2208argmin\nf\u2208Fi\nbRn(f)\nand select\nefn = argmin\ni=1,2,...\nn\nbRn( \u02c6fi) + \u03b3i(n)\no\n(3)\nas the output of the model selection procedure, where bRn denotes the n-sample empirical risk.\nResults of several authors [11, 20, 23] show that with appropriate penalties \u03b3i and given a dataset\nof size n, the output efn of the procedure roughly satis\ufb01es\nER( efn) \u2212R0 \u2264min\ni\n\u0014\ninf\nf\u2208Fi R(f) \u2212R0 + \u03b3i(n)\n\u0015\n+ O\n\u0012 1\n\u221an\n\u0013\n.\n(4)\nSeveral approaches to complexity regularization are possible, and an incomplete bibliography in-\ncludes the papers [28, 16, 25, 5, 11, 20].\nOracle inequalities of the form (4) show that, for a given sample size, complexity regularization\nprocedures trade o\ufb00the approximation and estimation errors, often optimally [23]. A drawback of\nthe above approaches is that in order to provide guarantees on the result of the model selection\nprocedure, one needs to be able to optimize over each model in the hierarchy (that is, compute\nthe estimates \u02c6fi for each i). This is reasonable when the sample size n is the key limitation, and\nit is computationally feasible when n is small and the samples z are low-dimensional. However,\nthe cost of \ufb01tting a large number of model classes on a large, high-dimensional dataset can be pro-\nhibitive; such data is common in modern statistical settings. In such cases, it is the computational\nresources\u2014rather than the sample size\u2014that form the key inferential bottleneck. In this paper,\nwe consider model selection from this computational perspective, viewing the amount of computa-\ntion, rather than the sample size, as the quantity whose e\ufb00ects on estimation we must understand.\nSpeci\ufb01cally, we study model selection methods that work within a given computational budget.\nAn interesting and di\ufb03cult aspect of the problem that we must address is the interaction\nbetween model class complexity and computation time. It is natural to assume that for a \ufb01xed\nsample size, it is more expensive to estimate a model from a complex class than a simple class.\nPut inversely, given a computational bound, a simple model class can \ufb01t a model to a much larger\nsample size than a rich model class. So any strategy for model selection under a computational\nconstraint should trade o\ufb00two criteria: (i) the relative training cost of di\ufb00erent model classes,\nwhich allows simpler classes to receive far more data (thus making them resilient to over\ufb01tting),\nand (ii) lower approximation error in the more complex model classes.\nIn addressing these computational and statistical issues, this paper makes two main contribu-\ntions. First, we propose a novel computational perspective on the model selection problem, which\nwe believe should be a natural consideration in statistical learning problems.\nSecondly, within\nthis framework, we provide algorithms for model selection in many di\ufb00erent scenarios, and provide\noracle inequalities on their estimates under di\ufb00erent assumptions. Our \ufb01rst two results address the\ncase where we have a model hierarchy that is ordered by inclusion, that is, F1 \u2286F2 \u2286F3 \u2286. . ..\n2\nThe \ufb01rst result provides an inequality that is competitive with an oracle knowing the optimal class,\nincurring at most an additional logarithmic penalty in the computational budget. The second result\nextends our approach to obtaining faster rates for model selection under conditions that guaran-\ntee sharper concentration results for empirical risk minimization procedures; oracle inequalities\nunder these conditions, but without computational constraints, have been obtained, for example,\nby Bartlett [8] and Koltchinskii [18]. Both of our results re\ufb01ne existing complexity-regularized risk\nminimization techniques by a careful consideration of the structure of the problem. Our third re-\nsult applies to model classes that do not necessarily share any common structure. Here we present\na novel algorithm\u2014exploiting techniques for multi-armed bandit problems\u2014that uses con\ufb01dence\nbounds based on concentration inequalities to select a good model under a given computational\nbudget. We also prove a minimax optimal oracle inequality on the performance of the selected\nmodel. All of our algorithms are computationally simple and e\ufb03cient.\nThe remainder of this paper is organized as follows. We begin in Section 2 by formalizing our\nsetting for a nested hierarchy of models, providing an estimator and oracle inequalities for the\nmodel selection problem. In Section 3, we re\ufb01ne our estimator and its analysis to obtain fast rates\nfor model selection under some additional reasonable (standard) conditions. We study the setting\nof unstructured model collections in Section 4. Detailed technical arguments and various auxilliary\nresults needed to establish our main theorems and corollaries can be found in the appendices.\n2\nModel selection over nested hierarchies\nIn many practical scenarios, the family of models with which one works has some structure. One\nof the most common model selection settings has the model classes Fi ordered by inclusion with\nincreasing complexity (e.g. [11]). In this section, we study such model selection problems; we begin\nby formally stating our assumptions and giving a few natural examples, proceeding thereafter to\noracle inequalities for a computationally e\ufb03cient model selection procedure.\n2.1\nAssumptions\nOur \ufb01rst main assumption is a natural inclusion assumption, which is perhaps the most common\nassumption in prior work on model selection (e.g. [11, 20]):\nAssumption A. The function classes Fi are ordered by inclusion:\nF1 \u2286F2 \u2286F3 \u2286. . .\n(5)\nWe provide two examples of such problems in the next section. In addition to the inclusion assump-\ntion, we make a few assumptions on the computational aspects of the problem. Most algorithms\nused in the framework of complexity regularization rely on the computation of estimators of the\nform\nbfi = argmin\nf\u2208Fi\nbRn(f),\n(6)\neither exactly or approximately, for each class i. Since the model classes are ordered by inclusion,\nit is natural to assume that the computational cost of computing an empirical risk minimizer from\nFi is higher than that for a class Fj when i > j. Said di\ufb00erently, given a \ufb01xed computational\nbudget T, it may be impossible to use as many samples to compute an estimator from Fi as it is\n3\nto compute an estimator from Fj (again, when i > j). We formalize this in the next assumption,\nwhich is stated in terms of an (arbitrary) algorithm A that selects functions f \u2208Fi for each index\ni based on a set of ni samples.\nAssumption B. Given a computational budget T, there is a sequence {ni(T)}i \u2282N such that\n(a) ni(T) > nj(T) for i < j.\n(b) The complexity penalties \u03b3i satisfy \u03b3i(ni(T)) < \u03b3j(nj(T)) for i < j.\n(c) For each class Fi, the computational cost of using the algorithm A with ni(T) samples is T.\nThat is, estimation within class Fi using ni(T) samples has the same computational complexity\nfor each i.\n(d) For all i, the output A (i, T) of the algorithm A, given a computational budget T, satis\ufb01es\nbRni(T)(A (i, T)) \u2212inf\nf\u2208Fi\nbRni(T)(f) \u2264\u03b3i(ni(T)).\n(e) As i \u2191\u221e, \u03b3i(n) \u2192\u221efor any \ufb01xed n.\nThe \ufb01rst two assumptions formalize a natural notion of computational budget in the context\nof our model selection problem: given equal computation time, a simpler model can be \ufb01t using a\nlarger number of samples than a complex model. Assumption B(c) says that the number of samples\nni(T) is chosen to roughly equate the computational complexity of estimation within each class.\nAssumption B(d) simply states that we compute approximate empirical minimizers for each class\nFi. Our choice of the accuracy of computation to be \u03b3i in part (d) is done mainly for notational\nconvenience in the statements of our results; one could use an alternate constant or function and\nachieve similar results.\nFinally part (e) rules out degenerate cases where the penalty function\nasymptotes to a \ufb01nite upper bound, and this assumption is required for our estimator to be well-\nde\ufb01ned for in\ufb01nite model hierarchies. In the sequel, we use the shorthand \u03b3i(T) to denote \u03b3i(ni(T))\nwhen the number of samples ni(T) is clear from context.\nCertainly many choices are possible for the penalty functions \u03b3i, and work studying appropriate\npenalties is classical (see e.g. [1, 21]). Our focus in this paper is on complexity estimates derived from\nconcentration inequalities, which have been extensively studied by a number of researchers [11, 23,\n4, 8, 18]. Such complexity estimates are convenient since they ensure that the penalized empirical\nrisk bounds the true risk with high probability. Formally, we have\nAssumption C. For all \u01eb > 0 and for each i, there are constants \u03ba1, \u03ba2 > 0 such that for any\nbudget T the output A (i, T) \u2208Fi satis\ufb01es,\nP\n\u0010\n| bRni(T)(A (i, T)) \u2212R(A (i, T))| > \u03b3i(T) + \u03ba2\u01eb\n\u0011\n\u2264\u03ba1 exp(\u22124ni(T)\u01eb2).\n(7)\nIn addition, for any \ufb01xed function f \u2208Fi, P(| bRni(T)(f) \u2212R(f)| > \u03ba2\u01eb) \u2264\u03ba1 exp(\u22124ni(T)\u01eb2).\n4\n2.2\nSome illustrative examples\nWe now provide two concrete examples to illustrate Assumptions A\u2013C.\nExample 1 (Linear classi\ufb01cation with nested balls). In a classi\ufb01cation problem, each sample zi\nconsists of a covariate vector x \u2208Rd and label y \u2208{\u22121, +1}. In margin-based linear classi\ufb01cation,\nthe predictions are the sign of the linear function f\u03b8(x) = \u27e8\u03b8, x\u27e9, where \u03b8 \u2208Rd. A natural sequence\nof model classes is sets {f\u03b8} indexed via norm-balls of increasing radii: Fi = {f\u03b8 : \u03b8 \u2208Rd, \u2225\u03b8\u22252 \u2264ri},\nwhere 0 \u2264r1 < r2 < . . .. By inspection, Fi \u2282Fi+1 so that this sequence satis\ufb01es Assumption A.\nThe empirical and expected risks of a function f\u03b8 are often measured using the sample av-\nerage and expectation, respectively, of a convex upper bound on the 0-1 loss 1(yf\u03b8(x)\u22640). Exam-\nples of such losses include the hinge loss, \u2113(yf\u03b8(x)) = max(0, 1 \u2212yf\u03b8(x)), or the logistic loss,\n\u2113(yf\u03b8(x)) = log(1 + exp(\u2212yf\u03b8(x))). Assume that E[\u2225x\u22252\n2] \u2264X2 and let \u03c3i be independent uniform\n{\u00b11}-valued random variables.\nThen we may use a penalty function \u03b3i based on Rademacher\ncomplexity Rn(Fi) of the class i,\nRn(Fi) :=\n\u001a 1\nnE\n\u0014\nsup\nf\u2208Fi\n\f\f\f\f\nn\nX\ni=1\n\u03c3if(Xi)\n\f\f\f\f\n\u0015\u001b\n\u22642riX\n\u221an .\nSetting \u03b3i to be the Rademacher complexity Rn(Fi) satis\ufb01es the conditions of Assumption C [9] for\nboth the logistic and the hinge losses which are 1-Lipschitz. Hence, using the standard Lipschitz\ncontraction bound [9, Theorem 12], we may take \u03b3i(T) =\n2riX\n\u221a\nni(T).\nTo illustrate Assumption B, we take stochastic gradient descent [26] as an example. Assuming\nthat the computation time to process a sample z is equal to the dimension d, then Nemirovski et\nal. [24] show that the computation time required by this algorithm to output a function f = A (i, T)\nsatisfying Assumption B(d) (that is, a \u03b3i-optimal empirical minimizer) is at most\n4r2\ni X2\n\u03b32\ni (T) \u00b7 d.\nSubstituting the bound on \u03b3i(T) above, we see that the computational time for class i is at most\ndni(T). In other words, given a computational time T, we can satisfy the Assumption B by setting\nni(T) \u221dT/d for each class i\u2014the number of samples remains constant across the hierarchy in this\nexample.\nExample 2 (Linear classi\ufb01cation in increasing dimensions). Staying within the linear classi\ufb01cation\ndomain, we index the complexity of the model classes Fi by an increasing sequence of dimensions\n{di} \u2282N. Formally, we set\nFi = {f\u03b8 : \u03b8j = 0 for j > di,\n\u2225\u03b8\u22252 \u2264ri},\nwhere 0 < r1 \u2264r2 \u2264. . .. This structure captures a variable selection problem where we have a\nprior ordering on the covariates.\nIn special scenarios, such as when the design matrix X = [x1 x2 \u00b7 \u00b7 \u00b7 xn] satis\ufb01es certain\nincoherence or irrepresentability assumptions [12], variable selection can be performed using \u21131-\nregularization or related methods. However, in general an oracle inequality for variable selection\nrequires some form of exhaustive search over subsets. In the sequel, we show that in this sim-\npler setting of variable selection over nested subsets, we can provide oracle inequalities without\ncomputing an estimator for each subset and without any assumptions on the design matrix X.\n5\nFor this function hierarchy, we consider complexity penalties arising from VC-dimension argu-\nments [27, 9], in which case we may set\n\u03b3i(T) =\ns\ndi\nni(T)\nwhich satis\ufb01es Assumption C. Using arguments similar to those for Example 1, we may conclude\nthat the computational assumption B can be satis\ufb01ed for this hierarchy, where the algorithm A\nrequires time dini(T) to select f \u2208Fi. Thus, given a computational budget T, we set the number\nof samples ni(T) for class i to be proportional to T/di.\nWe provide only classi\ufb01cation examples above since they demonstrate the essential aspects of\nour formulation.\nSimilar quantities can also be obtained for a variety of other problems, such\nas parametric and non-parametric regression, and for a number of model hierarchies including\npolynomial or Fourier expansions, wavelets, or Sobolev classes, among others (for more instances,\nsee, e.g. [23, 4, 11]).\n2.3\nThe computationally-aware model selection algorithm\nHaving speci\ufb01ed our assumptions and given examples satisfying them, we turn to describing our\n\ufb01rst computationally-aware model selection algorithm. Let us begin with the simpler scenario where\nwe have only K model classes (we extend this to in\ufb01nite classes below). Perhaps the most obvious\ncomputationally budgeted model selection procedure is the following: allocate a budget of T/K\nto each model class i. As a result, class i\u2019s estimator \u02c6fi = A (i, T/K) is computed using ni(T/K)\nsamples. Let efn denote the output of the basic model selection algorithm (3) with the choices n =\nni(T/K), using ni(T/K) samples to evaluate the empirical risk for class i, and modifying the penalty\n\u03b3i to be \u03b3i(n) = \u03b3i(n) +\np\nlog i/n. Then very slight modi\ufb01cations of standard arguments [23, 11]\nyield the oracle inequality\nR( efn) \u2264\nmin\ni=1,...,K\n \nR\u2217\ni + c\u03b3i\n\u0012 T\nK\n\u0013\n+\ns\nlog i\nni(T/K)\n!\nwith high probability, where c is a universal constant.\nThis approach can be quite poor.\nFor\ninstance, in Example 2, we have ni(T/K) = T/(Kdi), and the above inequality incurs a penalty\nthat grows as\n\u221a\nK. This is much worse than the logarithmic scaling in K that is typically possible\nin computationally unconstrained settings [11]. It is thus natural to ask whether we can use the\nnested structure of our model hierarchy to allocate computational budget more e\ufb03ciently.\nTo answer this question, we introduce the notion of coarse-grid sets, which use the growth\nstructure of the complexity penalties \u03b3i, to construct a scheme for allocating the budget across the\nhierarchy. Recall the constant \u03ba2 from Assumption C and let m > 0 be an arbitrary constant (we\nwill see that m controls the probability of error in our results). Given s \u2208N (s \u22651), we de\ufb01ne\n\u03b3i(T, s) := 2\u03b3i\n\u0012T\ns\n\u0013\n+ \u03ba2\ns\n2(m + log s)\nni(T/s)\n.\n(8)\nNotice that, to simplify the notation, we hide the dependence of \u03b3i on m. With the de\ufb01nition (8),\nwe now give a de\ufb01nition characterizing the growth characteristics of the penalties and sample sizes.\n6\ni\n\u00af\u03b3i(T)\nCoarse Grid\n1\nFj1 Fj2 Fj3\n(1 + \u03bb)j\u22121\n(1 + \u03bb)j\n(1 + \u03bb)2\n1 + \u03bb\nFjk\nFjk+1\nFigure 1: Construction of the coarse-grid set S\u03bb. The X-axis is the class index i, and the Y -axis\nrepresents the corresponding complexity \u03b3i(T). When the penalty function grows steeply early\non, we include a large number of models. The number of complex models included in S\u03bb can be\nsigni\ufb01cantly smaller as the growth of penalty function tapers out.\nDe\ufb01nition 1. Given a budget T, for a set S \u2286N, we say that S satis\ufb01es the coarse grid condition\nwith parameters \u03bb, m, and s if |S| = s and for each i there is an index j \u2208S such that\n\u03b3i(T, s) \u2264\u03b3j(T, s) \u2264(1 + \u03bb)\u03b3i(T, s).\n(9)\nFigure 1 gives an illustration of the coarse-grid set. For simplicity in presentation, we set \u03bb = 1 in\nthe statements of our results in the sequel.\nIf the coarse-grid set is \ufb01nite and, say, |S| = s, then the set S presents a natural collection of\nindices over which to perform model selection. We simply split the budget uniformly amongst the\ncoarse-grid set S, giving budget T/s to each class in the set. Indeed, the main theorem of this\nsection shows that for a large class of problems, it always su\ufb03ces to restrict our attention to a \ufb01nite\ngrid set S, allowing us to present both a computationally tractable estimator and a good oracle\ninequality for the estimator. In some cases, there may be no \ufb01nite coarse grid set. Thus we look\nfor way to restrict our selection to \ufb01nite sets, which we can do with the following assumption (the\nassumption is unnecessary if the hierarchy is \ufb01nite).\nAssumption D. (a) There is a constant B < \u221esuch that R\u2217\n1 \u2264B.\n(b) For all n \u2208N the penalty function \u03b31(n) \u22651/n.\nAssumption D(a) is satis\ufb01ed, for example, if the loss function is bounded, or even if there is a\nfunction f \u2208F1 with \ufb01nite risk. Assumption D(b) also is mild; unless the class F1 is trivial, in\ngeneral classes satisfying Assumption C have \u03b31(n) = \u2126(1/\u221an).\nUnder these assumptions, we provide our computationally budgeted model selection procedure\nin Algorithm 1. We will see in the proof of Theorem 1 below that the assumptions ensure that we\n7\nAlgorithm 1 Computationally budgeted model selection over nested hierarchies\nInput: Model hierarchy {Fi} with corresponding penalty functions \u03b3i, computational budget T,\nupper bound B on the minimum risk of class 1, and con\ufb01dence parameter m.\nConstruction of the coarse-grid set S:\nSet s = \u2308log2 (1 + Bn1(T))\u2309+ 2.\nfor k = 0 to s \u22121 do\nSet jk+1 to be the largest class for which \u03b3j(T/s) \u22642k\u03b31(T/s).\nend for\nSet S = {jk : k = 1, . . . , s}.\nModel selection estimate:\nSet \u02c6fi = A (i, T/s) for i \u2208S.\nSelect a class bi that satis\ufb01es\nbi \u2208argmin\ni\u2208S\n(\nbRni(T/s)( \u02c6fi) + \u03b3i (T/s) + \u03ba2\n2\nr\nm\nni(T/s) + \u03ba2\n2\ns\nlog s\nni(T/s)\n)\n.\n(10)\nOutput the function f = \u02c6fbi = A\n\u0010\nbi, T/s\n\u0011\n.\ncan build a coarse grid of size\ns = \u2308log2 (1 + Bn1(T))\u2309+ 2.\nIn particular, Assumption B(d) ensures that the complexity penalties continue to increase with the\nclass index i. Hence, there is a class K such that the complexity penalty \u03b3K is larger than the\npenalized risk of the smallest class F1, at which point no class larger than K can be a minimizer\nin the oracle inequality. The above choice of s ensures that there is at least one class j \u2208S so that\nj \u2265K, allowing us to restrict our attention only to the function classes {Fi | i \u2208S}.\n2.4\nMain result and some consequences\nWith the above de\ufb01nitions in place, we can now provide an oracle inequality on the performance of\nthe model selected by Algorithm 1. We start with our main theorem, and then provide corollaries\nto help explain various aspects of it.\nTheorem 1. Let f = A(bi, T/s) be the output of the algorithm A for the class bi speci\ufb01ed by the\nprocedure (10). Let Assumptions A\u2013D be satis\ufb01ed. With probability at least 1 \u22122\u03ba1 exp(\u2212m)\nR(f) \u2264\nmin\ni=1,2,3,...\n(\nR\u2217\ni + 4\u03b3i\n\u0012T\ns\n\u0013\n+ \u03ba2\ns\n8(m + log s)\nni(T/s)\n)\n.\n(11)\nFurthermore, if n1(T) = O(T) then s = O(log T).\nThe assumption that n1(T) is linear is mild: unless F1 is trivial, any algorithm for F1 must at\nleast observe the data, and hence must use computation at least linear in the sample size.\nRemarks:\nTo better understand the result of Theorem 1, we turn to a few brief remarks.\n8\n(a) We may ask what an omniscient oracle with access to the same computational algorithm A\ncould do. Such an oracle would know the optimal class i\u2217and allocate the entire budget T to\ncompute A (i\u2217, T). By Assumption C, the output f of this oracle satis\ufb01es, with probability at\nleast 1 \u2212\u03ba1 exp(\u2212m),\nR(f) \u2264R\u2217\ni\u2217+ \u03b3i\u2217(T) + \u03ba2\nr\nm\nni\u2217(T) =\nmin\ni=1,2,3,...\n\u001a\nR\u2217\ni + \u03b3i(T) + \u03ba2\nr\nm\nni(T)\n\u001b\n.\n(12)\nComparing this to the right hand side of the inequality of Theorem 1, we observe that not\nknowing the optimal class incurs a penalty in the computational budget of roughly a factor of\ns. This penalty is only logarithmic in the computational budget in most settings of interest.\n(b) Algorithm 1 and Theorem 1, as stated, require a priori knowledge of the computational budget\nT. We can address this using a standard doubling argument (see e.g. [13, Sec. 2.3]). Initially\nwe assume T = 1 and run Algorithm 1 accordingly.\nIf we do not exhaust the budget, we\nassume T = 2, and rerun Algorithm 1 for another round. If there is more computational time\nat our disposal, we update our guess to T = 4 and so on. Suppose the real budget is T0 with\n2k \u22121 < T0 \u22642k+1 \u22121. After i rounds of this doubling strategy, we have exhausted a budget\nof 2i\u22121, with the last round getting a budget of 2i\u22122 for i \u22652. In particular, the last round\nwith a net budget of T0 is of length at least T0/4. Since Theorem 1 applies to each individual\nround, we obtain an oracle inequality where we replace T0 with T0/4; we can be agnostic to\nthe prior knowledge of the budget at the expense of slightly worse constants.\n(c) For ease of presentation, Algorithm 1 and Theorem 1 use a speci\ufb01c setting of the coarse-grid\nsize, which corresponds to setting \u03bb = 1 in De\ufb01nition 1. In our proofs, we establish the theorem\nfor arbitrary \u03bb > 0. As a consequence, to obtain slightly sharper bounds, we may optimize this\nchoice of \u03bb; we do not pursue this here.\nNow let us turn to a specialization of Theorem 1 to the settings outlined in Examples 1 and 2.\nThe following corollary shows oracle inequalities under the computational restrictions that are only\nlogarithmically worse than those possible in the computationally unconstrained model selection\nprocedure (3).\nCorollary 1. Let m \u22650 be a speci\ufb01ed constant.\n(a) In the setting of Example 1, de\ufb01ne n so that nT/d is the number of samples that can be processed\nby the inference algorithm A using T units of computation. Assume that T is large enough that\nnT \u2265d/B and nT \u2265d/(4r2\n1X2). With probability at least 1 \u22122\u03ba1 exp(\u2212m), the output f of\nAlgorithm 1 satis\ufb01es\nR(f) \u2264\ninf\ni=1,2,...\n(\nR\u2217\ni +\nr\nd log2(16BnT/d)\nnT\n\u0010\n8riX +\n\u221a\n8\u03ba2\np\nm + log log2(16BnT/d)\n\u0011)\n.\n(b) In the setting of Example 2, de\ufb01ne n so that nT/di is the number of samples that can be\nprocessed by the inference algorithm A using T units of computation. Assume that T is large\nenough that nT \u22651 and nT \u2265d1/B. With probability at least 1 \u22122\u03ba1 exp(\u2212m), the output f\nof Algorithm 1 satis\ufb01es\nR(f) \u2264\ninf\ni=1,2,...\n(\nR\u2217\ni +\nr\ndi log2(16BnT/d1)\nnT\n\u0010\n4\np\ndi +\n\u221a\n8\u03ba2\np\nm + log log2(16BnT/d1)\n\u0011)\n.\n9\n2.5\nProofs\nAs remarked after Theorem 1, we will present our proofs for general settings of \u03bb > 0. For the\nproofs of Theorem 1 and Corollary 1 in this slight generalization, we de\ufb01ne S\u03bb as a set satisfying\nthe coarse grid condition with parameters \u03bb, m and s(\u03bb), with s(\u03bb) satisfying\ns(\u03bb) \u2265\n\uf8ee\n\uf8ef\uf8ef\uf8ef\nlog\n\u0010\n1 +\nB\n\u03b31(T,s(\u03bb))\n\u0011\nlog(1 + \u03bb)\n\uf8f9\n\uf8fa\uf8fa\uf8fa\n+ 2.\n(13)\nFirst, we show that this inequality is ensured by the choice given in Algorithm 1. To see this,\nnotice that\n\uf8ee\n\uf8ef\uf8ef\uf8ef\nlog\n\u0010\n1 +\nB\n\u03b31(T,s(\u03bb))\n\u0011\nlog(1 + \u03bb)\n\uf8f9\n\uf8fa\uf8fa\uf8fa\n+ 2 \u2264\n\uf8ee\n\uf8ef\uf8ef\uf8ef\nlog\n\u0010\n1 +\nB\n\u03b31(T,1)\n\u0011\nlog(1 + \u03bb)\n\uf8f9\n\uf8fa\uf8fa\uf8fa\n+ 2\n=\n\u0018log (1 + Bn1(T))\nlog(1 + \u03bb)\n\u0019\n+ 2.\nThus, for \u03bb = 1, choosing s(\u03bb) = \u2308log2 (1 + Bn1(T))\u2309+ 2 su\ufb03ces.\nWe require the additional notation\nK(\u03bb) := max{j : j \u2208S\u03bb},\n(14)\nwhere\nS\u03bb = {j1, . . . , js(\u03bb)}\n(15)\nis the natural generalization of the set S de\ufb01ned in Algorithm 1: jk+1 is chosen as the largest index\nfor which \u03b3j(T/s(\u03bb)) \u2264(1+ \u03bb)k\u03b31(T/s(\u03bb)). We begin the proof of Theorem 1 by showing that any\ns(\u03bb) satisfying (13) ensures that any class j > K(\u03bb) must have penalty too large to be optimal,\nso we can focus on classes j \u2264K(\u03bb). We then show that the output f of Algorithm 1 satis\ufb01es\nan oracle inequality for each class in S\u03bb, which is possible by an adaptation of arguments in prior\nwork [11]. Using the de\ufb01nition of our coarse grid set (De\ufb01nition 1), we can then infer an oracle\ninequality that applies to each class j \u2264K(\u03bb), and our earlier reduction to a \ufb01nite model hierarchy\ncompletes the argument.\n2.5.1\nProof of Theorem 1\nFirst we show that the selection of the set S\u03bb satis\ufb01es De\ufb01nition 1.\nLemma 1. Let {\u03b3i} be a sequence of increasing positive numbers and for each k \u2208{0, . . . , s \u22121}\nset jk+1 to be the largest index j such that \u03b3j \u2264(1 + \u03bb)k\u03b31. Then for each i \u2208N such that i \u2264jk,\nthere exists a j \u2208{j1, . . . , jk} such that \u03b3i \u2264\u03b3j \u2264(1 + \u03bb)\u03b3i.\nProof. Let i \u2264jk and choose the smallest j \u2208{j1, j2, . . . , jk} such that \u03b3i \u2264\u03b3j. Assume for the sake\nof contradiction that (1+\u03bb)\u03b3i < \u03b3j. There exists some k\u2032 \u2208{0, . . . , s\u22121} such that \u03b3j \u2264(1+\u03bb)k\u2032\u03b31\nand \u03b3j \u2265(1 + \u03bb)k\u2032\u22121\u03b31, and thus we obtain\n\u03b3i <\n\u03b3j\n1 + \u03bb \u2264(1 + \u03bb)k\u2032\u22121\u03b31.\n(16)\n10\nLet j\u2032 be the largest element smaller than j in the collection {j1, j2, . . . , jk}. Then by our construc-\ntion, j\u2032 is the largest index satisfying \u03b3j\u2032 \u2264(1 + \u03bb)k\u2032\u22121\u03b31. In particular, combining with our earlier\ninequality (16) leads to the conclusion that i \u2264j\u2032, which contradicts the fact that j is the smallest\nindex in {j1, . . . , jk} satisfying \u03b3i \u2264\u03b3j.\nNext, we show that, for s(\u03bb) satisfying (13), once the complexity penalty of a class becomes\ntoo large, it can never be the minimizer of the penalized risk in the oracle inequality (11). See\nAppendix A for the proof.\nLemma 2. Fix \u03bb > 0 and m > 0, recall the de\ufb01nition (14) of K(\u03bb), and let i\u2217be a class that\nattains the minimum in the right side of the bound (11). We have i\u2217\u2264K(\u03bb).\nEquipped with the lemmas, we can restrict our attention only to classes i \u2208S\u03bb. To that end, the\nnext result establishes an oracle inequality for our algorithm compared to all the classes in this set.\nProposition 1. Let f = \u02c6fbi be the function chosen from the class bi selected by the procedure (10),\nwhere S = S\u03bb and s = s(\u03bb). Under the conditions of Theorem 1, with probability at least 1 \u2212\n2\u03ba1 exp(\u2212m)\nR(f) \u2264min\ni\u2208S\u03bb\n(\nR\u2217\ni + 2\u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\ns\n2(m + log s(\u03bb))\nni(T/s(\u03bb))\n)\n.\nThe proof of the proposition follows from an argument similar to that given in [11], though we\nmust carefully reason about the di\ufb00erent number of independent samples used to estimate within\neach class Fi. We present a proof in Appendix A. We can now complete the proof of Theorem 1\nusing the proposition.\nProof of Theorem 1:\nLet i be any class (not necessarily in S\u03bb) and j \u2208S\u03bb be the smallest\nclass satisfying j \u2265i. Then, by construction of S\u03bb, we know from Lemma 1 that\n2\u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\ns\n2(m + log s(\u03bb))\nni(T/s(\u03bb))\n\u22642\u03b3j\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\ns\n2(m + log s(\u03bb))\nnj(T/s(\u03bb))\n\u2264(1 + \u03bb)\n\"\n2\u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\ns\n2(m + log s(\u03bb))\nni(T/s(\u03bb))\n#\n.\nIn particular, we can lower bound the penalized risk of class i as\nR\u2217\ni + (1 + \u03bb)\n\"\n2\u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\ns\n2(m + log s(\u03bb))\nni(T/s(\u03bb))\n#\n\u2265R\u2217\nj + 2\u03b3j\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\ns\n2(m + log s(\u03bb))\nnj(T/s(\u03bb))\n,\nwhere we used the inclusion assumption A to conclude that R\u2217\nj \u2264R\u2217\ni . Now applying Proposition 1,\nthe above lower bound, and Lemma 2 in turn, we see that with probability at least 1\u22122\u03ba1 exp(\u2212m)\nR(f) \u2264min\nj\u2208S\u03bb\n(\nR\u2217\nj + 2\u03b3j\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\ns\n2(m + log s(\u03bb))\nnj(T/s(\u03bb))\n)\n\u2264\nmin\ni=1,2,...,K(\u03bb)\n(\nR\u2217\ni + (1 + \u03bb)\n \n2\u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\ns\n2(m + log s(\u03bb))\nni(T/s(\u03bb))\n!)\n\u2264\ninf\ni=1,2,3,...\n(\nR\u2217\ni + (1 + \u03bb)\n \n2\u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\ns\n2(m + log s(\u03bb))\nni(T/s(\u03bb))\n!)\n.\n11\nFor \u03bb = 1 (which we have seen satis\ufb01es (13)), this is the desired statement of the theorem.\n2.5.2\nProof of Corollary 1\nUnder the conditions of Example 1, and the assumption that nT \u2265d/(4r2\n1X2), Assumptions A-D\nare satis\ufb01ed with ni(T) = nT/d and \u03b3i(T) = 2riX\np\nd/(nT).\n(In particular, nT \u2265d/(4r2\n1X2)\nimplies that \u03b31 satis\ufb01es Assumption D(b).) Also, since nT \u2265d/B, we have\ns =\n\u0018\nlog2\n\u0012\n1 + BnT\nd\n\u0013\u0019\n+ 2 \u2264log2(2BnT/d) + 3 = log2(16BnT/d).\nSubstituting into Theorem 1 gives the \ufb01rst part of the corollary.\nSimilarly, under the conditions of Example 2 and the assumption that nT \u22651, Assumptions A-\nD are satis\ufb01ed with ni(T) = nT/di and \u03b3i(T) = di/\n\u221a\nnT. (In particular, nT \u22651 implies that\n\u03b31 satis\ufb01es Assumption D(b).) Also, since nT \u2265d1/B, we have s \u2264log2(16BnT/d) as before.\nSubstituting into Theorem 1 gives the second part of the corollary.\n3\nFast rates for model selection\nLooking at the result given by Theorem 1, we observe that irrespective of the dependence of the\npenalties \u03b3i on the sample size, there are terms in the oracle inequality that always decay as\nO(1/\np\nni(T/s(\u03bb))). A similar phenomenon is noted in [8] for classical model selection results in\ncomputationally unconstrained settings; under conditions similar to Assumption C, this inverse-root\ndependence on the number of samples is the best possible, due to lower bounds on the \ufb02uctuations\nof the empirical process (e.g. [10, Theorem 2.3]). On the other hand, under suitable low noise\nconditions [22] or curvature properties of the risk functional [6, 18, 7], it is possible to obtain\nestimation guarantees of the form\nR( \u02c6f) = R(f \u2217) + Op\n\u0012 1\nn\n\u0013\n,\nwhere \u02c6f (approximately) minimizes the n-sample empirical risk. Under suitable assumptions, com-\nplexity regularization can also achieve fast rates for model selection [8, 17]. In this section, we show\nthat similar results can be obtained in computationally constrained inferential settings.\n3.1\nAssumptions and example\nWe begin by modifying our concentration assumption and providing a motivating example.\nAssumption E. For each i, let f \u2217\ni \u2208argminf\u2208Fi R(f). Then there are constants \u03ba1, \u03ba2 > 0 such\nthat for any budget T and the corresponding sample size ni(T)\nP\n\"\nsup\nf\u2208Fi\n\u0010\nR(f) \u2212R(f \u2217\ni ) \u22122( bRni(T)(f) \u2212bRni(T)(f \u2217\ni ))\n\u0011\n> \u03b3i(T) + \u03ba2\u01eb\n#\n\u2264\u03ba1 exp(\u2212ni(T)\u01eb).\n(17a)\nP\n\"\nsup\nf\u2208Fi\n\u0010\nbRni(T)(f) \u2212bRni(T)(f \u2217\ni ) \u22122(R(f) \u2212R(f \u2217\ni ))\n\u0011\n> \u03b3i(T) + \u03ba2\u01eb\n#\n\u2264\u03ba1 exp(\u2212ni(T)\u01eb).\n(17b)\n12\nContrasting this with our earlier Assumption C, we see that the probability bounds (17a) and (17b)\ndecay exponentially in \u01eb rather than \u01eb2, which leads to faster sub-exponential rates for estimation\nprocedures. Concentration inequalities of this form are now well known [6, 18, 7], and the paper [8]\nuses an identical assumption.\nBefore continuing, we give an example to illustrate the assumption.\nExample 3 (Fast rates for classi\ufb01cation). We consider the function class hierarchy based on in-\ncreasing dimensions of Example 2. We assume that the risk R(f\u03b8) = E[\u2113(y, f\u03b8(x))] and that the loss\nfunction \u2113is either the squared loss \u2113(y, f\u03b8(x)) = (y \u2212f\u03b8(x))2 or the exponential loss from boosting\n\u2113(y, f\u03b8(x)) = exp(\u2212yf\u03b8(x)). Each of these examples satis\ufb01es Assumption E with\n\u03b3i(T) = c di log(ni(T)/di)\nni(T)\n,\n(18)\nfor a universal constant c. This follows from Theorem 3 of [8] (which in turn follows from Theorem\n3.3 in [6] combined with an argument based on Dudley\u2019s entropy integral [15]). The other parameter\nsettings and computational considerations are identical to those of Example 2.\nIf we de\ufb01ne \u02c6fi = A (i, T), then using Assumption B(d) (that bRni(T)( \u02c6fi)\u2212bRni(T)(f \u2217\ni ) \u2264\u03b3i(T)) in\nconjunction with Assumption (17a), we can conclude that for any time budget T, with probability\nat least 1 \u2212\u03ba1 exp(\u2212m),\nR( \u02c6fi) \u2264R(f \u2217\ni ) + 3\u03b3i(T) + \u03ba2m\nni(T).\n(19)\nOne might thus expect that by following arguments similar to those in [8], it would be possible\nto show fast rates for model selection based on Algorithm 1.\nUnfortunately, the results of [8]\nheavily rely on the fact that the data used for computing the estimators \u02c6fi is the same for each\nclass i, so that the \ufb02uctuations of the empirical processes corresponding to the di\ufb00erent classes are\npositively correlated. In our computationally constrained setting, however, each class\u2019s estimator\nis computed on a di\ufb00erent sample. It is thus more di\ufb03cult to relate the estimators than in previous\nwork, necessitating a modi\ufb01cation of our earlier Algorithm 1 and a new analysis, which follows.\n3.2\nAlgorithm and oracle inequality\nAs in Section 2, our approach is based on performing model selection over a coarsened version of\nthe collection F1, F2, . . .. To construct the coarser collection of indices, we de\ufb01ne the composite\npenalty term (based on Assumption E)\n\u03b3i(T, s) := 20\u03b3i\n\u0012T\ns\n\u0013\n+ 8\u03ba2m + 2 log s\nni(T/s)\n.\n(20)\nBased on the above penalty term, we de\ufb01ne our analogue of the coarse grid set (9).\nWe give our modi\ufb01ed model selection procedure in Algorithm 2. In the algorithm and in our\nsubsequent analysis, we use the shorthand bRi(f) to denote the empirical risk of the function f on\nthe ni(T) samples associated with class i. Our main oracle inequality is the following:\nTheorem 2. Let f = A(bi, T/s(\u03bb)) be the output of the algorithm A for class bi speci\ufb01ed by the pro-\ncedure (21). Let Assumptions A, B, D and E be satis\ufb01ed. With probability at least 1\u22122\u03ba1 exp(\u2212m)\nR(f) \u2264\ninf\ni=1,2,3,...\n\u001a\nR\u2217\ni + 40s\u03b3i\n\u0012T\ns\n\u0013\n+ 10s\u03ba2\nm + log s\nni(T/s)\n\u001b\n.\n(22)\n13\nAlgorithm 2 Computationally budgeted model selection over hierarchies with fast concentration\nInput: Model hierarchy {Fi} with corresponding penalty functions \u03b3i, computational budget T,\nupper bound B on the minimum risk of class 1, and con\ufb01dence parameter m > 0.\nConstruction of the coarse-grid set S:\nSet s = \u2308log2 (1 + Bn1(T))\u2309+ 2.\nfor k = 0 to s \u22121 do\nSet jk+1 to be the largest class for which \u03b3j(T/s) \u22642k\u03b31(T/s).\nend for\nSet S = {jk : k = 1, . . . , s}.\nModel selection estimate:\nSet \u02c6fi = A (i, T/s) for i \u2208S.\nSelect the class bi \u2208S\u03bb to be the largest class that satis\ufb01es\nbRbi( \u02c6fbi) + 17\n2 \u03b3bi\n\u0012T\ns\n\u0013\n+ 9\n2\u03ba2\n\u0012m + log s\nnbi(T/s)\n\u0013\n\u2264bRbi( \u02c6fj) + 17\n2 \u03b3j\n\u0012T\ns\n\u0013\n(21)\nfor all j \u2208S such that j < bi.\nOutput the function A\n\u0010\nbi, T/s\n\u0011\n.\nFurthermore, if n1(T) = O(T) then s = O(log T).\nBy inspection of the bound (19)\u2014achieved by devoting the full computational budget T to the\noptimal class\u2014we see that Theorem 2\u2019s oracle inequality has dependence on the computational\nbudget within logarithmic factors of the best possible.\nThe following corollary shows the application of Theorem 2 to the classi\ufb01cation problem we\ndiscuss in Example 3.\nCorollary 2. In the setting of Example 3, de\ufb01ne n so that nT/di is the number of samples that can\nbe processed by the inference algorithm A using T units of computation. Assume that nT \u2265ed2\n1,\nnT \u2265d1/B, and choose the constant c in the de\ufb01nition (18) of \u03b3i(T) such that c \u22651/d1. With\nprobability at least 1 \u22124\u03ba1 exp(\u2212m), the output f of Algorithm 2 satis\ufb01es\nR(f) \u2264\ninf\ni=1,2,...\n\u001a\nR\u2217\ni + 10di log2\n2(16BnT/d1)\nnT\n\u0012\n4cdi log\n\u0012\nnT\nd2\n1 log2(16BnT/d1)\n\u0013\n+ \u03ba2 (m + log log2(16BnT/d1))\n!)\n.\n3.3\nProofs of main results\nIn this section, we provide proofs of Theorem 2 and Corollary 2.\nLike our previous proof for\nTheorem 1, we again provide the proof of Theorem 2 for general settings of \u03bb > 0. The proof of\nTheorem 2 broadly follows that of Theorem 1, in that we establish an analogue of Proposition 1,\nwhich provides an oracle inequality for each class in the coarse-grid set S\u03bb. We then extend the\nproven inequality to apply to each function class Fi in the hierarchy using the de\ufb01nition (9) of the\ngrid set.\n14\nProof of Theorem 2:\nLet ni be shorthand for ni(T/s(\u03bb)), the number of samples available to\nclass i, and let bRi(f) denote the empirical risk of the function f using the ni samples for class i. In\naddition, let \u03b3i(ni) be shorthand for \u03b3i(ni(T/s(\u03bb))), the penalty value for class i using ni(T/s(\u03bb))\nsamples. With these de\ufb01nitions, we adopt the following shorthand for the events in the probability\nbounds (17a) and (17b).\nLet \u01eb = {\u01ebi} be an s(\u03bb)-dimensional vector with (arbitrary for now)\npositive entries. For each pair of indices i and j de\ufb01ne\nEij\n1 (\u01ebi) :=\n\u001a\nsup\nf\u2208Fj\n\u0010\nR(f) \u2212R(f \u2217\nj ) \u22122\n\u0010\nbRi(f) \u2212bRi(f \u2217\nj )\n\u0011\u0011\n\u2264\u03b3j(ni) + \u03ba2\u01ebi\n\u001b\n(23a)\nEij\n2 (\u01ebi) :=\n\u001a\nsup\nf\u2208Fj\n\u0010\nbRi(f) \u2212bRi(f \u2217\nj ) \u22122\n\u0000R(f) \u2212R(f \u2217\nj )\n\u0001\u0011\n\u2264\u03b3j(ni) + \u03ba2\u01ebi\n\u001b\n,\n(23b)\nand de\ufb01ne the joint events\nE1(\u01eb) :=\n[\ni\u2208S\u03bb\n[\nj\u2208S\u03bb\nEij\n1 (\u01ebi)\nand\nE2(\u01eb) :=\n[\ni\u2208S\u03bb\n[\nj\u2208S\u03bb\nEij\n2 (\u01ebi) .\n(24)\nWith the \u201cgood\u201d events (24) de\ufb01ned, we turn to the two technical lemmas, which relate the risk\nof the chosen function \u02c6fbi to f \u2217\ni for each i \u2208S\u03bb. We provide proofs of both lemmas in Appendix B.\nTo make the proofs of each of the lemmas cleaner and see the appropriate choices of constants, we\nreplace the selection strategy (21) with one whose constants have not been speci\ufb01ed. Speci\ufb01cally,\nwe select bi as the largest class that satis\ufb01es\nbRbi( \u02c6fbi) + c1\u03b3bi\n\u0012 T\ns(\u03bb)\n\u0013\n+ c2\u03ba2\u01ebbi \u2264bRbi( \u02c6fj) + c1\u03b3j\n\u0012 T\ns(\u03bb)\n\u0013\n(25)\nfor j \u2208S with j \u2264bi.\nLemma 3. Let the events (23a) and (23b) hold for all i, j \u2208S\u03bb, that is, E1(\u01eb) and E2(\u01eb) hold. Then\nusing the selection strategy (25), for each j \u2264bi with j \u2208S\u03bb we have\nR( \u02c6fbi) \u2264R(f \u2217\nj ) + 1\n2\n\u0014\u001217\n2 \u2212c1\n\u0013\n\u03b3bi(nbi) + (6 + c1)\u03b3j(nj) + 2\u03ba2\u01ebj +\n\u00129\n2 \u2212c2\n\u0013\n\u03ba2\u01ebbi\n\u0015\n.\nWe require a di\ufb00erent argument for the case that j \u2265bi, and the constants are somewhat worse.\nLemma 4. Let the events (23a) and (23b) hold for all i, j \u2208S\u03bb, that is, E1(\u01eb) and E2(\u01eb) hold.\nAssume also that c1 \u226517/2 and c2 \u22657/2. Then using the selection strategy (25), for each j \u2265bi\nwith j \u2208S\u03bb we have\nR( \u02c6fbi) \u2264R(f \u2217\nj ) + s(\u03bb) [(2c1 + 3)\u03b3j(nj) + (2c2 + 1)\u01ebj] .\nWe use Lemmas 3 and 4 to complete the proof of the theorem. When Assumption E holds, the\nprobability that one of the events E1(\u01eb) and E2(\u01eb) fails to hold is upper bounded by\nP(E1(\u01eb)c \u222aE2(\u01eb)c) \u2264\nX\ni,j\u2208S\u03bb\nP(Eij\n1 (\u01ebi)c) +\nX\ni,j\u2208S\u03bb\nP(Eij\n2 (\u01ebi)c) \u22642\u03ba1\nX\ni,j\u2208S\u03bb\nexp(\u2212ni(T/s(\u03bb))\u01ebi)\n15\nby a union bound. Thus, we see that if we de\ufb01ne the constants\n\u01ebi = 2 \u00b7 m + log(s(\u03bb))\nni(T/s(\u03bb)) ,\nwe obtain that all of the events Eij\n1 (\u01ebi) and Eij\n2 (\u01ebi) hold with probability at least 1 \u22122\u03ba1 exp(\u2212m).\nApplying Lemmas 3 and 4 with the choices c1 = 17\n2 and c2 = 9\n2, we obtain that with probability at\nleast 1 \u22122\u03ba1 exp(\u2212m)\nR( \u02c6fbi) \u2264min\ni\u2208S\u03bb\n\u001a\nR(f \u2217\ni ) + s(\u03bb)\n\u0012\n20\u03b3i(ni) + 10m + log(s(\u03bb))\nni(T/s(\u03bb))\n\u0013\u001b\n.\n(26)\nThe inequality (26) is the analogue of Proposition 1 in the current setting. Given the inequality,\nthe remainder of the proof of Theorem 2 follows the same recipe as that of Theorem 1. Recalling\nthe notation (14) de\ufb01ning K(\u03bb), we apply the inequality (26) with the de\ufb01nition of the grid set (15)\nto obtain an oracle inequality compared to all classes i \u2264K(\u03bb). Then provided that\ns(\u03bb) \u2265\n\uf8ee\n\uf8ef\uf8ef\uf8ef\nlog\n\u0010\n1 +\nB\ns(\u03bb)\u03b31(T,s(\u03bb))\n\u0011\nlog(1 + \u03bb)\n\uf8f9\n\uf8fa\uf8fa\uf8fa\n+ 2,\nwe can transfer the result to the entire model hierarchy as before. For \u03bb = 1, the choice of s\nemployed in Algorithm 2 again su\ufb03ces for this.\nProof of Corollary 2:\nIn the setting of Example 3, we set ni(T) = nT/di and\n\u03b3i(T) = cdi log(ni(T)/di)\nni(T)\n= cd2\ni log(nT/d2\ni )\nnT\n.\nIt is straightforward to verify that the conditions of the corollary ensure that Assumptions A, B, D\nand E are satis\ufb01ed. In particular, nT \u2265ed2\n1 and c \u22651/d1 ensure that \u03b31(T) \u22651/n1(T). Also,\nnT \u2265d1/B ensures that s \u2264log2(16BnT/d1). Substituting \u03b3i, ni and s into Theorem 2 gives the\nresult.\n4\nOracle inequalities for unstructured models\nTo this point, our results have addressed the model selection problem in scenarios where we have\na nested collection of models. In the most general case, however, the collection of models may be\nquite heterogeneous, with no relationship between the di\ufb00erent model families. In classi\ufb01cation,\nfor instance, we may consider generalized linear models with di\ufb00erent link functions, decision trees,\nrandom forests, or other families among our collection of models. For a non-parametric regression\nproblem, we may want to select across a collection of dictionaries such as wavelets, splines, and\npolynomials. While this more general setting is obviously more challenging than the structured cases\nin the prequel, we would like to study the e\ufb00ects that limiting computation has on model selection\nproblems, understanding when it is possible to outperform computation-agnostic strategies.\n16\n4.1\nProblem setting and algorithm\nWhen no structure relates the models under consideration, it is impossible to work with an in\ufb01nite\ncollection of classes within a \ufb01nite computational time\u2014any estimator must evaluate each class\n(that is, at least one sample must be allocated to each class, as any class could be signi\ufb01cantly\nbetter than the others). As a result, we restrict ourselves to \ufb01nite model collections in this section,\nso that we have a sequence F1, . . . , FK of models from which we wish to select. Our approach to the\nunstructured case is to incrementally allocate computational quota amongst the function classes,\nwhere we trade o\ufb00receiving samples for classes that have good risk performance against exploring\nclasses for which we have received few data points. More formally, with T available quanta of\ncomputation, it is natural to view the model selection problem as a T round game, where in each\nround a procedure selects a function class i and allocates it one additional quantum of computation.\nWith this setup, we turn to stating a few natural assumptions. We assume that the computa-\ntional complexity of \ufb01tting a model grows linearly and incrementally with the number of samples,\nwhich means that allocating an additional quantum of training time allows the learning algorithm A\nto process an additional ni samples for class Fi. In the context of Sections 2 and 3, this means that\nwe assume ni(t) = tni for some \ufb01xed number ni speci\ufb01c to class i. This linear growth assumption\nis satis\ufb01ed, for instance, when the loss function \u2113is convex and the black-box learning algorithm\nA is a stochastic or online convex optimization procedure [13, 24]. We also require assumptions\nsimilar to Assumptions B and C:\nAssumption F. Let A (i, T) \u2208Fi denote the output of algorithm A when executed for class Fi\nwith a computational budget T.\n(a) For each i, there exists an ni \u2208N such that in T units of time, algorithm A can compute\nA (i, T) using niT samples.\n(b) For each i \u2208[K], there is a function \u03b3i and constants \u03ba1, \u03ba2 > 0 such that for any T \u2208N,\nP\n\u0010\n| bRniT (A (i, T)) \u2212R(A (i, T))| > \u03b3i(niT) + \u03ba2\u01eb\n\u0011\n\u2264\u03ba1 exp(\u22124niT\u01eb2).\n(27)\n(c) The output A (i, T) is a \u03b3i(niT)-minimizer of bRniT , that is,\nbRniT (A (i, niT)) \u2212inf\nf\u2208Fi\nbRniT (f) \u2264\u03b3i(niT).\n(d) For each i, the function \u03b3i satis\ufb01es \u03b3i(n) \u2264cin\u2212\u03b1i for some \u03b1i > 0.\n(e) For any \ufb01xed function f \u2208Fi, P(| bRn(f) \u2212R(f)| > \u03ba2\u01eb) \u2264\u03ba1 exp(\u22124n\u01eb2).\nComparing to Assumptions B and C, we see that the main di\ufb00erence is in the linear time assump-\ntion (a) and growth assumption (d). In addition, the complexity penalties and function classes\ndiscussed in our earlier examples satisfy Assumption F.\nWe now present our algorithm for successively allocating computational quanta to the function\nclasses. To choose the class i receiving computation at iteration t, the procedure must balance\ncompeting goals of exploration, evaluating each function class Fi adequately, and exploitation,\ngiving more computation to classes with low empirical risk. To promote exploration, we use an\n17\nAlgorithm 3 Multi-armed bandit algorithm for selection of best class bi.\nFor each i \u2208[K], query ni examples from class Fi.\nfor t = K + 1 to T do\nLet ni(t) be the number of examples seen for class i until time t\nLet it = argmini\u2208[K] R(j, ni(t)) \u2212\nq\nlog t\nni(t).\nQuery nit examples for class it.\nend for\nOutput bi, the index of the most frequently queried class.\noptimistic selection criterion to choose class i, which\u2014assuming that Fi has seen n samples at this\npoint\u2014is\nR(i, n) = bRn(A (i, n)) \u2212\u03b3i(n) \u2212\nr\nlog K\nn\n+ \u03b3i(Tni).\n(28)\nThe intuition behind the de\ufb01nition of R(i, n) is that we would like the algorithm to choose func-\ntions f and classes i that minimize bRn(f) + \u03b3i(Tni) \u2248R(f) + \u03b3i(Tni), but the negative \u03b3i(n)\nand\np\nlog K/n terms lower the criterion signi\ufb01cantly when n is small and thus encourage initial\nexploration. The criterion (28) essentially combines a penalized model-selection objective with an\noptimistic criterion similar to those used in multi-armed bandit algorithms [2]. Algorithm 3 con-\ntains the formal description of our bandit procedure for model selection. Algorithm 3 begins by\nreceiving ni samples for each of the K classes Fi to form the preliminary empirical estimates (28);\nwe then use the optimistic selection criterion until the computational budget is exhausted.\n4.2\nMain results and some consequences\nThe goal of the selection procedure is to \ufb01nd the best penalized class i\u2217: a class satisfying\ni\u2217\u2208argmin\ni\u2208[K]\n\u001a\ninf\nf\u2208Fi R(f) + \u03b3i(Tni)\n\u001b\n= argmin\ni\u2208[K]\n{R\u2217\ni + \u03b3i(Tni)} .\nTo present our main results for Algorithm 3, we de\ufb01ne the excess penalized risk \u2206i of class i:\n\u2206i := R\u2217\ni + \u03b3i(Tni) \u2212R\u2217\ni\u2217\u2212\u03b3i\u2217(Tni\u2217) \u22650.\n(29)\nWithout loss of generality, we assume that the in\ufb01mum in R\u2217\ni = inff\u2208Fi R(f) is attained by\na function f \u2217\ni (if not, we use a limiting argument, choosing some \ufb01xed f \u2217\ni such that R(f \u2217\ni ) \u2264\ninff\u2208Fi R(f) + \u03b4 for an arbitrarily small \u03b4 > 0).\nThe gains of a computationally adaptive strategy over na\u00a8\u0131ve strategies are clearest when the\ngap (29) is non-zero for each i, though in the sequel, we forgo this requirement.\nUnder this\nassumption, we can follow the ideas of Auer et al. [2] to show that the fraction of the computational\nbudget allocated to any suboptimal class i \u0338= i\u2217goes quickly to zero as T grows. We provide the\nproof of the following theorem in Section 4.3.\nTheorem 3. Let Alg. 3 be run for T rounds, and let Ti(t) be the number of times class i is queried\nthrough round t. Let \u2206i be de\ufb01ned as in (29) and Assumption F hold, and assume that T \u2265K.\n18\nDe\ufb01ne \u03b2i = max{1/\u03b1i, 2}. There is a constant C such that\nE[Ti(T)] \u2264C\nni\n\u0012ci + \u03ba2\n\u221alog T\n\u2206i\n\u0013\u03b2i\nand\nP\n \nTi(T) > C\nni\n\u0012ci + \u03ba2\n\u221alog T\n\u2206i\n\u0013\u03b2i!\n\u2264\n\u03ba1\nTK4 ,\nwhere ci and \u03b1i are the constants in the de\ufb01nition F(d) of the concentration function \u03b3i.\nAt a high level, this result shows that the fraction of budget allocated to any suboptimal class\ngoes to 0 at the rate\n1\nniT\n\u0010\u221alog T\n\u2206i\n\u0011\u03b2i. Hence, asymptotically in T, the procedure performs almost as\nif all the computational budget were allocated to class i\u2217. To see an example of concrete rates that\ncan be concluded from the above result, let F1, . . . , FK be model classes with \ufb01nite VC-dimension,1\nso that Assumption F is satis\ufb01ed with \u03b1i = 1\n2. Then we have\nCorollary 3. Under the conditions of Theorem 3, assume F1, . . . , FK are model classes of \ufb01nite\nVC-dimension, where Fi has dimension di. Then there is a constant C such that\nE[Ti(T)] \u2264C max{di, \u03ba2\n2 log T}\n\u22062\ni ni\nand\nP\n\u0012\nTi(T) > C max{di, \u03ba2\n2 log T}\n\u22062\ni ni\n\u0013\n\u2264\n\u03ba1\nTK4.\nA lower bound by Lai and Robbins [19] for the multi-armed bandit problem shows that Corol-\nlary 3 is nearly optimal in general. To see the connection, let Fi correspond to the ith arm in a\nmulti-armed bandit problem and the risk R\u2217\ni be the expected reward of arm i and assume w.l.o.g.\nthat R\u2217\ni \u2208[0, 1]. In this case, the complexity penalty \u03b3i for each class is 0. Let pi be a distribution\non {0, 1}, where pi(1) = R\u2217\ni and pi(0) = 1 \u2212R\u2217\ni (let pi = pi(1) for shorthand). Lai and Robbins\ngive a lower bound that shows that the expected number of pulls of any suboptimal arm is at least\nE[Ti(T)] = \u2126(log T/ KL (pi||pi\u2217)), where pi and pi\u2217are the reward distributions for the ith and\noptimal arms, respectively. An asymptotic expansion shows that KL (pi||pi\u2217) = \u22062\ni /(2pi(1 \u2212pi)),\nplus higher order terms, in this case; Corollary 3 is essentially tight.\nThe condition that the gap \u2206i > 0 may not always be satis\ufb01ed, or \u2206i may be so small as to\nrender the bound in Theorem 3 vacuous. Nevertheless, it is intuitive that our algorithm can quickly\n\ufb01nd a small set of \u201cgood\u201d classes\u2014those with small penalized risk\u2014and spend its computational\nbudget to try to distinguish amongst them. In this case, Algorithm 3 does not visit suboptimal\nclasses and so can output a function f satisfying good oracle bounds. In order to prove a result\nquantifying this intuition, we \ufb01rst upper bound the regret of Algorithm 3, that is, the average\nexcess risk su\ufb00ered by the algorithm over all iterations, and then show how to use this bound for\nobtaining a model with a small risk. For the remainder of the section, we simplify the presentation\nby assuming that \u03b1i \u2261\u03b1 and de\ufb01ne \u03b2 = max{1/\u03b1, 2}.\nProposition 2. Use the same assumptions as Theorem 3, but further assume that \u03b1i \u2261\u03b1 for all\ni. With probability at least 1 \u2212\u03ba1/TK3, the regret (average excess risk) of Algorithm 3 satis\ufb01es\nK\nX\ni=1\n\u2206iTi(T) \u22642eT 1\u22121/\u03b2\n \nC\nK\nX\ni=1\n(ci + \u03ba2\n\u221alog T)\u03b2\nni\n!1/\u03b2\nfor a constant C dependent on \u03b1.\n1Similar corollaries hold for any model class whose metric entropy grows polynomially in log 1\n\u01eb .\n19\nOur \ufb01nal main result builds on Proposition 2 to show that when it is possible to average\nfunctions across classes Fi, we can aggregate all the \u201cplayed\u201d functions ft, one for each iteration\nt, to obtain a function with small risk. Indeed, setting ft = A (it, nit(t)), we obtain the following\ntheorem (whose proof, along with that of Proposition 2, we provide in Appendix D):\nTheorem 4. Use the conditions of Proposition 2. Let the risk function R be convex on F1\u222a. . .\u222aFK,\nand let ft be the function chosen by algorithm A at round t of Alg. 3. De\ufb01ne the average function\nbfT =\n1\nT\nPT\nt=1 ft. There are constants C, C\u2032 (dependent on \u03b1) such that with probability greater\nthan 1 \u22122\u03ba2/(TK3),\nR( bfT ) \u2264R\u2217+ \u03b3i\u2217(Tni\u2217) + 2e\u03ba2T \u2212\u03b2p\nlog T\n K\nX\ni=1\nC\nni\n!1/\u03b2\n+ C\u2032 T \u22121/\u03b2\n K\nX\ni=1\n\u0014\ncin\u2212\u03b1\ni\n+ \u03ba2n\n\u22121\n2\ni\np\nlog K + \u03ba2n\n\u22121\n2\ni\np\nlog T\n\u0015\u03b2!1/\u03b2\n.\nLet us interpret the above bound and discuss its optimality. When \u03b1 = 1\n2 (e.g., for VC classes),\nwe have \u03b2 = 2; moreover, it is clear that PK\ni=1\nC\nni = O(K). Thus, to within constant factors,\nR( bfT ) = R\u2217\ni\u2217+ \u03b3i\u2217(Tni\u2217) + O\n p\nK max{log T, log K}\n\u221a\nT\n!\n.\nIgnoring logarithmic factors, the above bound is minimax optimal, which follows by a reduction\nof our model selection problem to the special case of a multi-armed bandit problem. In this case,\nTheorem 5.1 of Auer et al. [3] shows that for any set of K, T values, there is a distribution over the\nrewards of arms which forces \u2126(\n\u221a\nKT) regret, that is, the average excess risk of the classes chosen\nby Alg. 3 must be \u2126(\n\u221a\nKT), matching Proposition 2 and Theorem 4.\nThe scaling O(\n\u221a\nK) is essentially as bad as splitting the computational budget T uniformly\nacross each of the K classes, which yields (roughly) an oracle inequality of the form\nR(f) = R\u2217\ni\u2217+ \u03b3i\u2217(Tni\u2217/K) + O\n\u0012\u221aK log K\n\u221aTni\u2217\n\u0013\n.\nComparing this bound to Theorem 4, we see that the penalty \u03b3i in the theorem is smaller. The other\nkey distinction between the two bounds (ignoring logarithmic factors) is the di\ufb00erence between\nK\nX\ni=1\n1\nni\nand\nK\nni\u2217.\nWhen the left quantity is smaller than the right, the bandit-based Algorithm 3 and the extension\nindicated by Theorem 4 give improvements over the na\u00a8\u0131ve strategy of uniformly splitting the budget\nacross classes. However, if each class has similar computational cost ni, no strategy can outperform\nthe na\u00a8\u0131ve one.\nWe also observe that we can apply the online procedure of Algorithm 3 to the nested setup of\nSections 2 and 3 as well. In this case, by applying Algorithm 3 only to elements of the coarse-grid\nset S\u03bb, we can replace K in the bounds of Theorems 3 and 4 with s(\u03bb), which gives results similar\nto our earlier Theorems 1 and 2. In particular, if we are in the setup of Theorem 3 with a large\nseparation between penalized risks, then Algorithm 3 applied to the coarse-grid set is expected to\noutperform a uniform allocation of budget within the set as in Sections 2 and 3.\n20\n4.3\nProof of Theorem 3\nAt a high level, the proof of this theorem involves combining the techniques for analysis of multi-\narmed bandits developed by Auer et al. [2] with Assumption F. We start by giving a lemma that\nwill be useful to prove the theorem. The lemma states that after a su\ufb03cient number of initial\niterations \u03c4, the probability that Algorithm 3 chooses to receive samples for a sub-optimal function\nclass i \u0338= i\u2217is extremely small. Recall also our notational convention that \u03b2i = max{1/\u03b1i, 2}.\nLemma 5. Let Assumption F hold. For any class i, any si \u2208[1, T] and si\u2217\u2208[\u03c4, T] where \u03c4 satis\ufb01es\n\u03c4 > 2\u03b2i(ci + \u03ba2\n\u221alog T + \u03ba2\n\u221alog K)\u03b2i\nni\u2206\u03b2i\ni\n,\nwe have\nP\n \nR(i, nisi) \u2212\u03ba2\nr\nlog T\nnisi\n\u2264R(i\u2217, ni\u2217si\u2217) \u2212\u03ba2\nr\nlog T\nni\u2217si\u2217\n!\n\u2264\n2\u03ba1\n(TK)4 .\nWe defer the proof of the lemma to Appendix C, though at a high level the proof works as\nfollows. The \u201cbad event\u201d in Lemma 5, which corresponds to Algorithm 3 selecting a sub-optimal\nclass i \u0338= i\u2217, occurs only if one of the following three errors occurs: the empirical risk of class i\nis much lower than its true risk, the empirical risk of class i\u2217is higher than its true risk, or si is\nnot large enough to actually separate the true penalized risks from one another. The assumptions\nof the lemma make each of these three sub-events quite unlikely. Now we turn to the proof of\nTheorem 3, assuming the lemma.\nLet it denote the model class index i chosen by Algorithm 3 at time t, and let si(t) denote\nthe number of times class i has been selected at round t of the algorithm. When no time index is\nneeded, si will denote the same thing. Note that if it = i and the number of times class i is queried\nexceeds \u03c4 > 0, then by the de\ufb01nition of the selection criterion (28) and choice of it in Alg. 3, for\nsome si \u2208{\u03c4, . . . , t \u22121} and si\u2217\u2208{1, . . . , t \u22121} we have\nR(i, nisi) \u2212\u03ba2\nr\nlog T\nnisi\n\u2264R(i\u2217, ni\u2217si\u2217) \u2212\u03ba2\nr\nlog T\nni\u2217si\u2217.\nHere we interpret R(i, nisi) to mean a random realization of the observed risk consistent with the\nsamples we observe. Using the above implication, we thus have\nTi(T) = 1 +\nT\nX\nt=K+1\nI (it = i)\n\u2264\n\u03c4 +\nT\nX\nt=K+1\nI (it = i, Ti(t \u22121) \u2265\u03c4)\n\u2264\u03c4 +\nT\nX\nt=K+1\nI\n \nmin\n\u03c4\u2264si<t R(i, nisi) \u2212\u03ba2\nr\nlog T\nnisi\n\u2264max\n0<s<t R(i\u2217, ni\u2217si\u2217) \u2212\u03ba2\nr\nlog T\nni\u2217si\u2217\n!\n\u2264\u03c4 +\nT\nX\nt=1\nt\u22121\nX\nsi\u2217=1\nt\u22121\nX\nsi=\u03c4\nI\n \nR(i, nisi) \u2212\u03ba2\nr\nlog T\nnisi\n\u2264R(i\u2217, ni\u2217si\u2217) \u2212\u03ba2\nr\nlog T\nni\u2217si\u2217\n!\n.\n(30)\nTo control the last term, we invoke Lemma 5 and obtain that\n\u03c4 > 2\u03b2i(ci + \u03ba2\n\u221alog T + \u03ba2\n\u221alog K)\u03b2i\nni\u2206\u03b2i\ni\n\u21d2\nE[Ti(T)] \u2264\u03c4 +\nT\nX\nt=1\nt\u22121\nX\ns=1\nt\u22121\nX\nsi=\u03c4\n2\n\u03ba1\n(TK)4 \u2264\u03c4 +\n\u03ba1\nTK4 .\n21\nHence for any suboptimal class i \u0338= i\u2217, E[Ti(n)] \u2264\u03c4i +\u03ba1/(TK4), where \u03c4i satis\ufb01es the lower bound\nof Lemma 5 and is thus logarithmic in T. Under the assumption that T \u2265K, for i \u0338= i\u2217,\nE[Ti(T)] \u2264C (ci + \u03ba2\n\u221alog T)max{1/\u03b1i,2}\nni\u2206max{1/\u03b1i,2}\ni\n(31)\nfor a constant C \u22642 \u00b7 4max{1/\u03b1i,2}. Now we prove the high-probability bound. For this part, we\nneed only concern ourselves with the sum of indicators from (30). Markov\u2019s inequality shows that\nP\n \nT\nX\nt=K+1\nI (it = i, Ti(t \u22121) \u2265\u03c4) \u22651\n!\n\u2264\n\u03ba1\nTK4 .\nThus we can assert that the bound (31) on Ti(T) holds with high probability.\nRemark:\nBy examining the proof of Theorem 3, it is straightforward to see that if we modify\nthe multipliers on the square root terms in the criterion (28) by m\u03ba2 instead of \u03ba2, we get that the\nprobability bound is of the order T 3\u22124m2K\u22124m2, while the bound on Ti(T) is scaled by m1/\u03b1i.\n5\nDiscussion\nIn this paper, we have presented a new framework for model selection with computational con-\nstraints. The novelty of our setting is the idea of using computation\u2014rather than samples\u2014as the\nquantity against which we measure the performance of our estimators.\nAs our main contribution,\nwe have presented algorithms for model selection in several scenarios, and the common thread in\neach is that we attain good performance by evaluating only a small and intelligently-selected set\nof models, allocating samples to each model based on computational cost. For model selection\nover nested hierarchies, this takes the form of a new estimator based on a coarse gridding of the\nmodel space, which is competitive (up to logarithmic factors) with an omniscient oracle. A minor\nextension of our algorithm is adaptive to problem complexity, since it yields fast rates for model\nselection when the underlying estimation problems have appropriate curvature or low-noise prop-\nerties. We also presented an exploration-exploitation algorithm for model selection in unstructured\ncases, showing that it obtains (in some sense) nearly optimal performance.\nThere are certainly many possible extensions and open questions that our work raises. We\naddress the setting where the complexity penalties are known and can be computed easily in\nclosed form. Often it is desirable to use data-dependent penalties [20, 6, 23], since they adapt\nto the particular problem instance and data distribution. It appears to be somewhat di\ufb03cult to\nextend such penalties to the procedures we have developed in this paper, but we believe it would\nbe quite interesting. Another natural question to ask is whether there exist intermediate model\nselection problems between a nested sequence of classes and a completely unstructured collection.\nIdentifying other structures\u2014and obtaining the corresponding oracle inequalities and understanding\ntheir dependence on computation\u2014would be an interesting extension of the results presented here.\nMore broadly, we believe the idea of using computation, in addition to the number of samples\navailable for a statistical inference problem, to measure the performance of statistical procedures\nis appealling for a much broader class of problems. In large data settings, one would hope that\nmore data would always improve the risk performance of statistical procedures, even with a \ufb01xed\n22\ncomputational budget. We hope that extending these ideas to other problems, and understanding\nhow computation interacts with and a\ufb00ects the quality of statistical estimation more generally, will\nbe quite fruitful.\nAcknowledgements\nWe gratefully acknowledge illuminating discussions with Cl\u00b4ement Levrard, who helped us with\nearlier versions of this work and whose close reading helped us clarify (and correct problems with)\nmany of our arguments. In performing this research, Alekh Agarwal was supported by a Microsoft\nResearch Fellowship and Google PhD Fellowship, and John Duchi was supported by the National\nDefense Science and Engineering Graduate Fellowship (NDSEG) Program. Alekh Agarwal and\nPeter Bartlett gratefully acknowledge the support of the NSF under award DMS-0830410 and of\nthe ARC under award FL1110281.\nA\nAuxiliary results for Theorem 1 and Corollary 1\nWe start by establishing Lemma 2. To prove the lemma, we \ufb01rst need a simple claim.\nLemma 6. Let c1 > c2 > 0, s > 0, and de\ufb01ne\ni\u2217\n1 = argmin\ni=1,2,3,...\n(\nR\u2217\ni + c1\n \n\u03b3i\n\u0012T\ns\n\u0013\n+ \u03ba2\ns\n2(m + log s)\nni(T/s)\n!)\n,\ni\u2217\n2 = argmin\ni=1,2,3,...\n(\nR\u2217\ni + c2\n \n\u03b3i\n\u0012T\ns\n\u0013\n+ \u03ba2\ns\n2(m + log s)\nni(T/s)\n!)\n.\nThen under the monotonicity assumptions B, we have i\u2217\n1 \u2264i\u2217\n2.\nProof. Recall the shorthand de\ufb01nition (8) of \u03b3i. Under the monotonicity assumptions B(a)\u2013(b), \u03b3i\nis monotone increasing in i. By the de\ufb01nitions of i\u2217\n1 and i\u2217\n2 we have\nR\u2217\ni1 + c1\u03b3i\u2217\n1 (T, s) \u2264R\u2217\ni2 + c1\u03b3i\u2217\n2 (T, s)\nand\nR\u2217\ni2 + c2\u03b3i\u2217\n2 (T, s) \u2264R\u2217\ni1 + c2\u03b3i\u2217\n1 (T, s) .\nAdding the two inequalities we obtain\n(c1 \u2212c2)\u03b3i\u2217\n1 (T, s) \u2264(c1 \u2212c2)\u03b3i\u2217\n2 (T, s) .\nSince c1 \u2212c2 > 0 by assumption, the monotonicity of \u03b3i guarantees i\u2217\n1 \u2264i\u2217\n2.\nProof of Lemma 2:\nLemma 6 allows us to establish a simpler version of Lemma 2. Since\n1 + \u03bb > 1, it su\ufb03ces to establish i0 \u2264K(\u03bb), where\ni0 = argmin\ni=1,2,3,...\n(\nR\u2217\ni + \u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\ns\n2(m + log s(\u03bb))\nni(T/s(\u03bb))\n)\n.\nLet \u03b3i be shorthand for the quantity (8) as usual. Recalling the construction of S\u03bb in (15), we\nobserve that any class i > K(\u03bb) satis\ufb01es\n(1 + \u03bb)s(\u03bb)\u22122 \u03b31 (T, s(\u03bb)) < \u03b3i (T, s(\u03bb))\n23\nThe setting (13) of s(\u03bb) ensures that\n(1 + \u03bb)s(\u03bb)\u22122 \u2265(1 + \u03bb)\u2308log(1+B/\u03b31(T,s(\u03bb)))/ log(1+\u03bb)\u2309\u2265exp\n\u0012\nlog\n\u0012\n1 +\nB\n\u03b31(T, s(\u03bb))\n\u0013\u0013\nso that\n(1 + \u03bb)s(\u03bb)\u22122 \u03b31 (T, s(\u03bb)) \u2265B + \u03b31 (T, s(\u03bb)) \u2265R\u2217\n1 + \u03b31 (T, s(\u03bb)) \u2265inf\ni {R\u2217\ni + \u03b3i (T, s(\u03bb))} .\nHence we observe that for i > K(\u03bb),\nR\u2217\ni + \u03b3i (T, s(\u03bb)) \u2265\u03b3i (T, s(\u03bb))\n> (1 + \u03bb)s(\u03bb)\u22122 \u03b31 (T, s(\u03bb))\n\u2265\ninf\nj\u2208{1,2,...}\n\b\nR\u2217\nj + \u03b3j (T, s(\u03bb))\n\t\n.\nWe must thus have i0 \u2264K(\u03bb), and Lemma 6 further implies that i\u2217\u2264K(\u03bb).\nWe \ufb01nally provide a proof for Proposition 1.\nProof of Proposition 1:\nSince for any a, b \u22650, \u221aa +\n\u221a\nb \u2264\np\n2(a + b), it su\ufb03ces to control\nthe probability of the event\nR(f) > min\ni\u2208S\n\u001a\nR\u2217\ni + 2\u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\ns\nlog s(\u03bb)\nni(T/s(\u03bb)) + \u03ba2\nr\nm\nni(T/s(\u03bb))\n\u001b\n.\n(32)\nFor the event (32) to occur, at least one of\nR(f) > min\ni\u2208S\n(\nbRni(T/s(\u03bb))( \u02c6fi) + \u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\n2\nr\nm\nni(T/s(\u03bb)) + \u03ba2\n2\ns\nlog s(\u03bb)\nni(T/s(\u03bb))\n)\n(33a)\nor\nmin\ni\u2208S\n(\nbRni(T/s(\u03bb))( \u02c6fi) + \u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\n2\ns\nlog s(\u03bb)\nni(T/s(\u03bb)) + \u03ba2\n2\nr\nm\nni(T/s(\u03bb))\n)\n> min\ni\u2208S\n(\nR\u2217\ni + 2\u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\ns\nlog s(\u03bb)\nni(T/s(\u03bb)) + \u03ba2\nr\nm\nni(T/s(\u03bb))\n)\n(33b)\nmust occur. We bound the probabilities of the events (33a) and (33b) in turn.\nIf the event (33a) occurs, by de\ufb01nition of the selection strategy (10), it must be the case that\nfor some i \u2208S (namely i = bi)\nR( \u02c6fi) > bRni(T/s(\u03bb))( \u02c6fi) + \u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\n2\nr\nm\nni(T/s(\u03bb)) + \u03ba2\n2\ns\nlog s(\u03bb)\nni(T/s(\u03bb))\n24\nsince the chosen f minimizes the right side of this display over the classes Fi for i \u2208S. By a union\nbound, we see that\nP\n\"\nR(f) > min\ni\u2208S\n(\nbRni(T/s(\u03bb))( \u02c6fi) + \u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\n2\nr\nm\nni(T/s(\u03bb)) + \u03ba2\n2\ns\nlog s(\u03bb)\nni(T/s(\u03bb))\n)#\n\u2264P\n\"\n\u2203i \u2208S s.t. R( \u02c6fi) > bR( \u02c6fi) + \u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n+ \u03ba2\n2\nr\nm\nni(T/s(\u03bb)) + \u03ba2\n2\ns\nlog s(\u03bb)\nni(T/s(\u03bb))\n#\n\u2264\u03ba1\nX\ni\u2208S\nexp (\u2212m \u2212log s(\u03bb)) = \u03ba1 exp(\u2212m),\nwhere the \ufb01nal inequality follows from Assumption C.\nNow we bound the probability of the event (33b), noting that the event implies that\nmax\ni\u2208S\n(\nbRni(T/s(\u03bb))( \u02c6fi) \u2212R\u2217\ni \u2212\u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n\u2212\u03ba2\n2\ns\nlog s(\u03bb)\nni(T/s(\u03bb)) \u2212\u03ba2\n2\nr\nm\nni(T/s(\u03bb))\n)\n> 0.\nWe can thus apply a union bound to see that the probability of the event (33b) is bounded by\nP\n\"\nmax\ni\u2208S\n(\nbRni(T/s(\u03bb))( \u02c6fi) \u2212R\u2217\ni \u2212\u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n\u2212\u03ba2\n2\ns\nlog s(\u03bb)\nni(T/s(\u03bb)) \u2212\u03ba2\n2\nr\nm\nni(T/s(\u03bb))\n)\n> 0\n#\n\u2264\nX\ni\u2208S\nP\n\"\nbRni(T/s(\u03bb))( \u02c6fi) \u2212R\u2217\ni \u2212\u03b3i\n\u0012 T\ns(\u03bb)\n\u0013\n\u2212\u03ba2\n2\ns\nlog s(\u03bb)\nni(T/s(\u03bb)) \u2212\u03ba2\n2\nr\nm\nni(T/s(\u03bb)) > 0\n#\n\u2264\nX\ni\u2208S\nP\n\"\nbR(f \u2217\ni ) \u2212R\u2217\ni > \u03ba2\n2\ns\nlog s(\u03bb)\nni(T/s(\u03bb)) + \u03ba2\n2\nr\nm\nni(T/s(\u03bb))\n#\n,\n(34)\nwhere the \ufb01nal inequality uses Assumption B(d), which states that A outputs a \u03b3i-minimizer of\nthe empirical risk. Now we can bound the deviations using the second part of Assumption C, since\nf \u2217\ni is non-random: the quantity (34) is bounded by\nX\ni\u2208S\n\u03ba1 exp\n\u0012\n\u2212ni(T/s(\u03bb))\n\u0012\nlog s(\u03bb)\nni(T/s(\u03bb)) +\nm\nni(T/s(\u03bb))\n\u0013\u0013\n\u2264\u03ba1 exp(\u2212m).\nCombining the two events (33a) and (33b) completes the proof of the proposition.\nB\nAuxilliary results for Theorem 2\nProof of Lemma 3:\nIn the proof of the lemma, assume that both of the events (24) hold.\nRecall that we de\ufb01ne \u02c6fj = A (j, nj), so that by the de\ufb01nition (23a) and Assumption B that \u02c6fj is a\n\u03b3j-accurate minimizer of the empirical risk, we have\nR( \u02c6fj) \u2264R(f \u2217\nj ) + 3\u03b3j(nj) + \u03ba2\u01ebj\n(35)\n25\nfor any j. By our assumption that the index j \u2264bi, we have \u02c6fj \u2208Fbi, and since the event (23b)\nholds for the classes bi and j (i.e. E\nbij\n2\n\u0000\u01ebbi\n\u0001\noccurs), we further obtain that\nbRbi( \u02c6fj) \u2212bRbi(f \u2217\nj ) \u22642\n\u0010\nR( \u02c6fj) \u2212R(f \u2217\nj )\n\u0011\n+ \u03b3j(nbi) + \u03ba2\u01ebbi.\n(36)\nApplying the earlier bound (35) on R( \u02c6fj) \u2212R(f \u2217\nj ) to the inequality (36), we see that\nbRbi( \u02c6fj) \u2212bRbi(f \u2217\nj ) \u22646\u03b3j(nj) + 2\u03ba2\u01ebj + \u03b3j(nbi) + \u03ba2\u01ebbi.\n(37)\nNow we again use the fact that the event (23b) holds so that Ebibi\n2\n\u0000\u01ebbi\n\u0001\noccurs. Using f = f \u2217\nj in the\nevent since f \u2217\nj \u2208Fbi, we see that\n2\n\u0010\nR(f \u2217\nj ) \u2212R(f \u2217\nbi )\n\u0011\n\u2265\n\u0010\nbRbi(f \u2217\nj ) \u2212bRbi(f \u2217\nbi )\n\u0011\n\u2212\u03b3bi(nbi) \u2212\u03ba2\u01ebbi.\nNow apply the inequality (37) to lower bound bRbi(f \u2217\nj ) to see that\n2\n\u0010\nR(f \u2217\nj ) \u2212R(f \u2217\nbi )\n\u0011\n\u2265bRbi( \u02c6fj) \u2212bRbi(f \u2217\nbi ) \u22126\u03b3j(nj) \u22122\u03ba2\u01ebj \u2212\u03b3j(nbi) \u2212\u03b3bi(nbi) \u22122\u03ba2\u01ebbi\n\u2265bRbi( \u02c6fj) \u2212bRbi(f \u2217\nbi ) \u22126\u03b3j(nj) \u22122\u03ba2\u01ebj \u22122\u03b3bi(nbi) \u22122\u03ba2\u01ebbi,\nwhere we have used the fact that j \u2264bi so \u03b3bi(nbi) \u2265\u03b3j(nbi). Using the condition (25) that de\ufb01nes\nthe selected index bi, we obtain\n2\n\u0010\nR(f \u2217\nj ) \u2212R(f \u2217\nbi )\n\u0011\n\u2265bRbi( \u02c6fbi) + c1\u03b3bi(nbi) + c2\u03ba2\u01ebbi \u2212c1\u03b3j(nj) \u2212bRbi(f \u2217\nbi ) \u22126\u03b3j(nj) \u22122\u03ba2\u01ebj \u22122\u03b3bi(nbi) \u22122\u03ba2\u01ebbi\n= bRbi( \u02c6fbi) \u2212bRbi(f \u2217\nbi ) + (c1 \u22122)\u03b3bi(nbi) \u2212(6 + c1)\u03b3j(nj) \u22122\u03ba2\u01ebj + (c2 \u22122)\u03ba2\u01ebbi.\nFinally, we note that by the event (23a), since R(f \u2217\nj ) \u2212R(f) \u22640 for all f \u2208Fj, we have\nbRbi(f \u2217\nbi ) \u2264bRbi( \u02c6fbi) + 1\n2\u03b3bi(nbi) + 1\n2\u03ba2\u01ebbi,\nwhence we obtain\n2\n\u0010\nR(f \u2217\nj ) \u2212R(f \u2217\nbi )\n\u0011\n\u2265(c1 \u22125/2) \u03b3bi(nbi) \u2212(6 + c1)\u03b3j(nj) \u22122\u03ba2\u01ebj + (c2 \u22125/2)\u03ba2\u01ebbi.\n(38)\nApplying the inequality (35) for the class bi, we have\nR(f \u2217\nj ) \u2212R( \u02c6fbi) \u2265R(f \u2217\nj ) \u2212R(f \u2217\nbi ) \u22123\u03b3bi(nbi) \u2212\u03ba2\u01ebbi,\nand combining this inequality with the earlier guarantee (38), we \ufb01nd that\n2\n\u0010\nR(f \u2217\nj ) \u2212R( \u02c6fbi)\n\u0011\n\u2265(c1 \u221217/2)\u03b3bi(nbi) \u2212(6 + c1)\u03b3j(nj) \u22122\u03ba2\u01ebj + (c2 \u22129/2)\u03ba2\u01ebbi\nRearranging terms, we obtain the statement of the lemma.\nIn order to prove Lemma 4, we need one more result:\n26\nLemma 7. Let the joint events (24) hold (i.e. E1(\u01eb) and E2(\u01eb)). For i, j \u2208S\u03bb such that i \u2265j and\nbRi( \u02c6fj) + c1\u03b3j(nj) \u2264bRi( \u02c6fi) + c1\u03b3i(ni) + c2\u03ba2\u01ebi\nwe have\nR( \u02c6fj) \u2264R(f \u2217\ni ) + (2c1 + 3)\u03b3i(ni) + (2c2 + 1)\u03ba2\u01ebi.\nProof. We begin by noting that since i \u2265j, we have \u02c6fj \u2208Fi, and since the event (23a) holds by\nassumption, we have\nR( \u02c6fj) \u2212R(f \u2217\ni ) \u22642\n\u0010\nbRi( \u02c6fj) \u2212bRi(f \u2217\ni )\n\u0011\n+ \u03b3i(ni) + \u03ba2\u01ebi.\nRecalling the inequality assumed in the condition of the lemma, we see that\nR( \u02c6fj) \u2212R(f \u2217\ni ) \u22642\n\u0010\nbRi( \u02c6fi) + c1\u03b3i(ni) + c2\u03ba2\u01ebi \u2212c1\u03b3j(nj) \u2212bRi(f \u2217\ni )\n\u0011\n+ \u03b3i(ni) + \u03ba2\u01ebi.\nApplying Assumption B(d) on the empirical minimizers, we have bRi( \u02c6fi) \u2212bRi(f \u2217\ni ) \u2264\u03b3i(ni), so\nR( \u02c6fj) \u2212R(f \u2217\ni ) \u22642 ((c1 + 1)\u03b3i(ni) + c2\u03ba2\u01ebi \u2212c1\u03b3j(nj)) + \u03b3i(ni) + \u03ba2\u01ebi.\nIgnoring the negative term \u2212c1\u03b3j(nj) yields the lemma.\nProof of Lemma 4:\nFor j \u2208S\u03bb, de\ufb01ne S\u03bb(j) to be the position of class j in the coarse-grid\nset (that is, S\u03bb(1) = 1, the next class j \u2208S\u03bb has S\u03bb(j) = 2 and so on). We prove the lemma by\ninduction on the class j for j \u2265bi, j \u2208S\u03bb. Our inductive hypothesis is that\nR( \u02c6fbi) \u2264R(f \u2217\nj ) + (S\u03bb(j) \u2212S\u03bb(bi) + 1) [(2c1 + 3)\u03b3j(nj) + (2c2 + 1)\u03ba2\u01ebj] .\n(39)\nThe base case for j = bi is immediate since by assumption, the event (23a) holds, so we obtain the\ninequality (35).\nFor the inductive step, we assume that the claim holds for all bi \u2264k \u2264j \u22121 such that k \u2208S\u03bb\nand establish the claim for j. Since bi is the largest class in S\u03bb satisfying the condition (25) and\nj \u2265bi, there must exist a class k < j in S\u03bb for which\nbRj( \u02c6fk) + c1\u03b3k(nk) < bRj( \u02c6fj) + c1\u03b3j(nj) + c2\u03ba2\u01ebj.\n(40)\nBy inspection, this is precisely the condition of Lemma 7, so\nR(f \u2217\nk) \u2264R( \u02c6fk) \u2264R(f \u2217\nj ) + (2c1 + 3)\u03b3j(nj) + (2c2 + 1)\u03ba2\u01ebj.\nNow there are two possibilities. If k \u2264bi, Lemma 3 applies, and we recall the assumptions on c1\nand c2, which guarantee 2c1 + 3 \u22656+ c1 and 2c2 + 1 \u22652. If k \u2265bi, then we can apply our inductive\nhypothesis since k < j. In either case, we conclude that\nR( \u02c6fbi) \u2264R(f \u2217\nk) + (S\u03bb(k) \u2212S\u03bb(bi) + 1) [(2c1 + 3)\u03b3k(nk) + (2c2 + 1)\u03ba2\u01ebk]\n\u2264R(f \u2217\nk) + (S\u03bb(j) \u22121 \u2212S\u03bb(bi) + 1) [(2c1 + 3)\u03b3j(nj) + (2c2 + 1)\u03ba2\u01ebj] ,\nwhere the \ufb01nal inequality uses S\u03bb(k) \u2264S\u03bb(j) \u22121 and the monotonicity assumptions B(a)-(b). Ap-\nplying the relationship (40) of the risk of f \u2217\nk to that of f \u2217\nj shows that the inductive hypothesis (39)\nholds at i. Noting that s(\u03bb) \u2265S\u03bb(j) \u2212S\u03bb(bi) + 1 completes the proof.\n27\nC\nProof of Lemma 5\nFollowing [2], we show that the event in the lemma occurs with very low probability by breaking it\nup into smaller events more amenable to analysis. Recall that we are interested in controlling the\nprobability of the event\nR(i, nisi) \u2212\u03ba2\nr\nlog T\nnisi\n\u2264R(i\u2217, ni\u2217si\u2217) \u2212\u03ba2\nr\nlog T\nni\u2217si\u2217\n(41)\nFor this bad event to happen, at least one of the following three events must happen:\nbRnisi(A (i, nisi)) \u2212inf\nf\u2208Fi R(f) \u2264\u2212\u03b3i(nisi) \u2212\u03ba2\nr\nlog K\nnisi\n\u2212\u03ba2\nr\nlog T\nnisi\n(42a)\nbRni\u2217si\u2217(A (i\u2217, ni\u2217si\u2217)) \u2212inf\nf\u2208Fi\u2217R(f) \u2265\u03b3i(ni\u2217si\u2217) + \u03ba2\nr\nlog K\nni\u2217si\u2217+ \u03ba2\nr\nlog T\nni\u2217si\u2217\n(42b)\nR\u2217\ni + \u03b3i(Tni) \u2264R\u2217+ \u03b3i\u2217(Tni\u2217) + 2\n \n\u03b3i(nisi) + \u03ba2\nr\nlog K\nnisi\n+ \u03ba2\nr\nlog T\nnisi\n!\n.\n(42c)\nTemporarily use the shorthand fi = A (i, nisi) and fi\u2217= A (i\u2217, ni\u2217si\u2217). The relationship between\nEqs. (42a)\u2013(42c) and the event in (41) follows from the fact that if none of (42a)\u2013(42c) occur, then\nR(i, nisi) \u2212\u03ba2\nr\nlog T\nnisi\n= bRnisi(fi) + \u03b3i(Tni) \u2212\u03b3i(nisi) \u2212\u03ba2\nr\nlog K\nnisi\n\u2212\u03ba2\nr\nlog T\nnisi\n(42a)\n>\ninf\nf\u2208Fi R(f) + \u03b3i(Tni) \u22122\n \n\u03b3i(nisi) + \u03ba2\nr\nlog K\nnisi\n+ \u03ba2\nr\nlog t\nnisi\n!\n(42c)\n>\ninf\nf\u2208Fi\u2217R(f) + \u03b3i\u2217(Tni\u2217) + 2\n \n\u03b3i(nisi) + \u03ba2\nr\nlog K\nnisi\n+ \u03ba2\nr\nlog T\nnisi\n!\n\u22122\n \n\u03b3i(nisi) + \u03ba2\nr\nlog K\nnisi\n+ \u03ba2\nr\nlog n\nnisi\n!\n(42b)\n>\nbRni\u2217si\u2217(fi\u2217) + \u03b3i\u2217(Tni\u2217) \u2212\u03b3i(ni\u2217si\u2217) \u2212\u03ba2\nr\nlog K\nni\u2217si\u2217\u2212\u03ba2\nr\nlog t\nni\u2217si\u2217\n= R(i\u2217, ni\u2217si\u2217) \u2212\u03ba2\nr\nlog t\nni\u2217si\u2217.\nFrom the above string of inequalities, to show that the event (41) has low probability, we need\nsimply show that each of (42a), (42b), and (42c) have low probability.\nTo prove that each of the bad events have low probability, we note the following consequences\nof Assumption C. Recall the de\ufb01nition of f \u2217\ni as the minimizer of R(f) over the class Fi. Then by\nAssumption C(b),\nR(f \u2217\ni ) \u2212\u03b3i(n) \u2212\u03ba2\u01eb \u2264R(A (i, n)) \u2212\u03b3i(n) \u2212\u03ba2\u01eb < bRn(A (i, n)),\nwhile Assumptions C(c) and C(e) imply\nbRn(A (i, n)) \u2264bRn(f \u2217\ni ) + \u03b3i(n) \u2264R(f \u2217\ni ) + \u03b3i(n) + \u03ba2\u01eb,\n28\neach with probability at least 1 \u2212\u03ba1 exp(\u22124n\u01eb2). In particular, we see that the events (42a) and\n(42b) have low probability:\nP\n\"\nbRnisi(A (i, nisi)) \u2212R(f \u2217\ni ) \u2264\u2212\u03b3i(nisi) \u2212\u03ba2\nr\nlog K\nnisi\n\u2212\u03ba2\nr\nlog T\nnisi\n#\n\u2264\u03ba1 exp\n\u0012\n\u22124nisi\n\u0012log K\nnisi\n+ log t\nnisi\n\u0013\u0013\n=\n\u03ba1\n(tK)4\nP\n\"\nbRni\u2217si\u2217(A (i\u2217, ni\u2217si\u2217)) \u2212R\u2217\u2265\u03b3i\u2217(ni\u2217si\u2217) + \u03ba2\nr\nlog K\nni\u2217si\u2217+ \u03ba2\nr\nlog T\nni\u2217si\u2217\n#\n\u2264\u03ba1 exp\n\u0012\n\u22124ni\u2217si\u2217\n\u0012 log K\nni\u2217si\u2217+ log T\nni\u2217si\u2217\n\u0013\u0013\n=\n\u03ba1\n(tK)4 .\nWhat remains is to show that for large enough \u03c4, (42c) does not happen. Recalling the de\ufb01nition\nthat R\u2217+ \u03b3i\u2217(Tni\u2217) = R\u2217\ni + \u03b3i(Tni) \u2212\u2206i, we see that for (42c) to fail it is su\ufb03cient that\n\u2206i > 2\u03b3i(\u03c4ni) + 2\u03ba2\nr\nlog K\nni\u03c4\n+ 2\u03ba2\nr\nlog T\nni\u03c4 .\nLet x \u2227y := min{x, y} and x \u2228y := max{x, y}. Since \u03b3i(n) \u2264cin\u2212\u03b1i, the above is satis\ufb01ed when\n\u2206i\n2 > ci(\u03c4ni)\u2212(\u03b1i\u22271\n2) + \u03ba2\np\nlog K(\u03c4ni)\u2212(\u03b1i\u22271\n2) + \u03ba2\np\nlog T(\u03c4ni)\u2212(\u03b1i\u22271\n2 )\n(43)\nWe can solve (43) above and see immediately that if\n\u03c4i > 21/\u03b1i\u22282(ci + \u03ba2\n\u221alog T + \u03ba2\n\u221alog K)1/\u03b1i\u22282\nni\u22061/\u03b1i\u22282\ni\n,\nthen\nR\u2217\ni > R\u2217+ 2\n \n\u03b3i(ni\u03c4i) + \u03ba2\nr\nlog K\nni\u03c4i\n+ \u03ba2\nr\nlog T\nni\u03c4i\n!\n.\n(44)\nThus the event in (42c) fails to occur, completing the proof of the lemma.\nD\nProofs of Proposition 2 and Theorem 4\nIn this section we provide proofs for Proposition 2 and Theorem 4. The proof of the proposition\nfollows by dividing the model clases into two groups: those for which \u2206i > \u03b3, and those with small\nexcess risk, i.e. \u2206i < \u03b3. Theorem 3 provides an upper bound on the fraction of budget allocated to\nmodel classes of the \ufb01rst type. For the model classes with small excess risk, all of them are nearly\nas good as i\u2217in the regret criterion of Proposition 2. Combining the two arguments gives us the\ndesired result.\nOf course, the proposition has the drawback that it does not provide us with a prescription\nto select a good model or even a model class. This shortcoming is addressed by Theorem 4. The\ntheorem relies on an averaging argument used quite frequently to extract a good solution out of\nonline learning or stochastic optimization algorithms [14, 24].\n29\nD.1\nProof of Proposition 2\nDe\ufb01ne \u03b2i = max{1/\u03b1i, 2} as in the conclusion of Theorem 3, and let bi = ci + \u03ba2\n\u221alog T. Dividing\nthe regret into classes with high and low excess penalized risk \u2206i, for any threshold \u03b3 \u22650 we have\nby a union bound that with probability at least 1 \u2212\u03ba1/TK3,\nK\nX\ni=1\n\u2206iTi(T) =\nX\n{i|\u2206i\u2265\u03b3}\n\u2206iTi(T) +\nX\n{i|\u2206i\u2264\u03b3}\n\u2206iTi(T)\n\u2264C\nX\n{i|\u2206i\u2265\u03b3}\n\u2206i\nb\u03b2i\ni\nni\u2206\u03b2i\ni\n+ \u03b3T \u2264C\nK\nX\ni=1\nb\u03b2i\ni\nni\u03b3\u03b2i\u22121 + \u03b3T.\nTo simplify this further, we use the assumption that \u03b1i \u2261\u03b1 for all i. Hence the complexity\npenalties of the classes di\ufb00er only in the sampling rates ni, that is,\nK\nX\ni=1\n\u2206iTi(T) \u2264\n1\n\u03b3\u03b2\u22121\nK\nX\ni=1\nCb\u03b2i\ni\nni\n+ \u03b3T.\n(45)\nMinimizing the bound (45) over \u03b3 by taking derivatives, we get\n\u03b3 = T \u22121\n\u03b2 (\u03b2 \u22121)\n1\n\u03b2\n K\nX\ni=1\nCb\u03b2\ni\nni\n! 1\n\u03b2\n,\nwhich, when plugged back into (45), gives\nK\nX\ni=1\n\u2206iTi(T) \u22642\n K\nX\ni=1\nCb\u03b2\ni\nni\n!1/\u03b2\n(\u03b2 \u22121)1/\u03b2T 1\u22121/\u03b2.\nNoting that 1\n\u03b2 log(\u03b2 \u22121) \u2264\u03b2\u22122\n\u03b2\n< 1, we see that (\u03b2 \u22121)1/\u03b2 < exp(1). Plugging the de\ufb01nition of\n\u03b2 = max{1/\u03b1, 2}, so that 1/\u03b2 = min{\u03b1, 1\n2}, gives the result of the proposition.\nD.2\nProof of Theorem 4\nBefore proving the theorem, we state a technical lemma that makes our argument somewhat simpler.\nLemma 8. For 0 < p < 1 and a \u227b0, consider the optimization problem\nmax\nx\nK\nX\ni=1\naixp\ni\ns.t.\nK\nX\ni=1\nxi \u2264T, xi \u22650.\nThe solution of the problem is to take xi \u221da1/(1\u2212p)\ni\n, and the optimal value is\nT p\n K\nX\ni=1\na\n1\n1\u2212p\ni\n!1\u2212p\n.\n30\nProof. Reformulating the problem to make it a minimization problem, that is, our objective is\n\u2212PK\ni=1 aixp\ni , we have a convex problem. Introducing Lagrange multipliers \u03b8 \u22650 and \u03bd \u2208RK\n+ for\nthe inequality constraints, we have Lagrangian\nL(x, \u03b8, \u03bd) = \u2212\nK\nX\ni=1\naixp\ni + \u03b8\n K\nX\ni=1\nxi \u2212T\n!\n\u2212\u27e8\u03bd, x\u27e9.\nTo \ufb01nd the in\ufb01mum of the Lagrangian over x, we take derivatives and see that \u2212aipxp\u22121\ni\n+\u03b8\u2212\u03bdi = 0,\nor that xi = a\u22121/(p\u22121)\ni\np\u22121/(p\u22121)(\u03b8 \u2212\u03bdi)1/(p\u22121). Since ai > 0, the complimentary slackness conditions\nfor \u03bd are satis\ufb01ed with \u03bd = 0, and we see that \u03b8 is simply a multiplier to force the sum PK\ni=1 xi = T.\nThat is, xi \u221da1/(1\u2212p)\ni\n, and normalizing appropriately, xi = Ta1/(1\u2212p)\ni\n/ PK\nj=1 a1/(1\u2212p)\nj\n. By plugging\nxi into the objective, we have\nK\nX\ni=1\naixp\ni = T p\nPK\ni=1 aiap/(1\u2212p)\ni\n\u0010PK\nj=1 a1/(1\u2212p)\nj\n\u0011p = T p\nPK\ni=1 a1/(1\u2212p)\ni\n\u0010PK\nj=1 a1/(1\u2212p)\nj\n\u0011p = T p\n K\nX\ni=1\na1/(1\u2212p)\ni\n!1\u2212p\nWith the Lemma 8 in hand, we proceed with the proof of Theorem 4. As before, we use the\nshorthand \u03b2 = max{1/\u03b1, 2} throughout the proof to reduce clutter. We also let si(t) be the number\nof times class i was selected by time t. Recalling the de\ufb01nition of the regret from (29) and the\nresult of the previous proposition, we have with probability at least 1 \u2212\u03ba1/(TK3)\n1\nT\nT\nX\nt=1\n[R\u2217\nit + \u03b3it(Tnit)] \u2264R\u2217+ \u03b3i\u2217(Tni\u2217) + 2e\u03ba2T \u22121/\u03b2p\nlog T\n K\nX\ni=1\nC\nni\n!1/\u03b2\n.\nUsing the de\ufb01nition of f \u2217\ni as the minimizer of R(f) over Fi, we use Assumptions C(c) and C(e) to\nsee that for \ufb01xed si, with probability at least 1 \u2212\u03ba1/(TK)4,\nbRnisi(A (i, nisi)) \u2264bRnisi(f \u2217\ni ) + \u03b3i(nisi) \u2264R(f \u2217\ni ) + \u03b3i(nisi) + \u03ba2\nr\nlog K\nnisi\n+ \u03ba2\nr\nlog T\nnisi\n.\n(46)\nDenote by ft the output of A on round t, that is, ft = A (it, nitsit(t)). By the previous equation (46),\nwe can use a union bound and the regret bound from Proposition 2 to conclude that with probability\nat least 1 \u2212\u03ba1/(TK3) \u2212\u03ba1/(T 3K3),\n1\nT\nT\nX\nt=1\nbRnitsit(t)(ft) + \u03b3it(Tnit)\n\u22641\nT\nT\nX\nt=1\n\"\n\u03b3i(nitsit(t)) + \u03ba2\ns\nlog K\nnitsit(t) + \u03ba2\ns\nlog T\nnitsit(t)\n#\n+ 1\nT\nT\nX\nt=1\n\u0002\nR\u2217\nit + \u03b3it(Tnit)\n\u0003\n\u22641\nT\nT\nX\nt=1\n\"\n\u03b3i(nitsit(t)) + \u03ba2\ns\nlog K\nnitsit(t) + \u03ba2\ns\nlog T\nnitsit(t)\n#\n+ R(f \u2217\ni ) + \u03b3i(nisi)\n+ 2e\u03ba2T \u22121/\u03b2p\nlog T\n K\nX\ni=1\nC\nni\n!1/\u03b2\n.\n(47)\n31\nNow we again make use of Assumption C(b) to note that with probability at least 1\u2212\u03ba1/(T 4K4),\nR(ft) \u2264bRnitsit(t)(ft) + \u03b3it(nitsit(t)) + \u03ba2\ns\nlog K\nnitsit(t) + \u03ba2\ns\nlog T\nnitsit(t).\nUsing a union bound and applying the empirical risk bound (47), we drop the positive \u03b3it(Tnit)\nterms from the left side of the bound and see that with probability at least 1 \u2212\u03ba1/(TK3) \u2212\n2\u03ba1/(T 3K3),\n1\nT\nT\nX\nt=1\nR(ft) \u2264R\u2217+ \u03b3i\u2217(Tni\u2217) + 2e\u03ba2T \u22121/\u03b2p\nlog T\n K\nX\ni=1\nC\nni\n!1/\u03b2\n+ 2\nT\nT\nX\nt=1\n\"\n\u03b3i(nitsit(t)) + \u03ba2\ns\nlog K\nnitsit(t) + \u03ba2\ns\nlog T\nnitsit(t)\n#\n.\n(48)\nDe\ufb01ning bfT := 1\nT\nPT\nt=1 ft, we use Jensen\u2019s inequality to see that R( bfT ) \u22641\nT\nPT\nt=1 R(ft). Thus,\nall that remains is to control the last sum in (48). Using the de\ufb01nition of \u03b3i, we replace the sum\nwith\nT\nX\nt=1\ncin\u2212\u03b1\nit sit(t)\u2212\u03b1 + n\n\u22121\n2\nit sit(t)\u22121\n2 \u03ba2\nhp\nlog K +\np\nlog T\ni\n\u2264\nT\nX\nt=1\n\u0014\ncin\u2212\u03b1\nit\n+ \u03ba2n\n\u22121\n2\nit\np\nlog K + \u03ba2n\n\u22121\n2\nit\np\nlog T\n\u0015\nsit(t)\u2212min{\u03b1, 1\n2}.\nNoting that\nX\nt:it=i\nsit(t)\u2212min{\u03b1, 1\n2} =\nTi(T)\nX\nt=1\nt\u22121/\u03b2 \u2264C\u2032 Ti(T)1\u22121/\u03b2\nfor some constant C\u2032 dependent on \u03b1, we can upper bound the last sum in (48) by\nT\nX\nt=1\n\"\n\u03b3i(nitsit(t)) + \u03ba2\ns\nlog K\nnitsit(t) + \u03ba2\ns\nlog T\nnitsit(t)\n#\n\u2264C\u2032\nK\nX\ni=1\n\u0014\ncin\u2212\u03b1\ni\n+ \u03ba2n\n\u22121\n2\ni\np\nlog K + \u03ba2n\n\u22121\n2\ni\np\nlog T\n\u0015\nTi(T)1\u22121/\u03b2.\n(49)\nNow that we have a sum of order K with terms Ti(T) that are bounded by T, that is, PK\ni=1 Ti(T) =\nK, we can apply Lemma 8.\nIndeed, we set p = 1 \u22121/\u03b2 = 1 \u2212min{\u03b1, 1\n2} and ai = cin\u2212\u03b1\ni\n+\n\u03ba2n\n\u22121\n2\ni\n[\u221alog K + \u221alog T] in the lemma, and we see immediately that (49) is upper bounded by\nC\u2032 T 1\u2212min{\u03b1, 1\n2 }\n K\nX\ni=1\n\u0014\ncin\u2212\u03b1\ni\n+ \u03ba2n\n\u22121\n2\ni\np\nlog K + \u03ba2n\n\u22121\n2\ni\np\nlog T\n\u0015max{1/\u03b1,2}!min{\u03b1, 1\n2}\n.\nDividing by T completes the proof that the average bfT has good risk properties with probability\nat least 1 \u2212\u03ba1/(TK3) \u22122\u03ba1(T 3K3) > 1 \u22122\u03ba1/(TK3).\n32\nReferences\n[1] H. Akaike. A new look at the statistical model identi\ufb01cation. IEEE Transactions on Automatic\nControl, 19(6):716\u2013723, December 1974.\n[2] P. Auer, N. Cesa-Bianchi, and P. Fischer.\nFinite-time analysis of the multiarmed bandit\nproblem. Mach. Learn., 47(2-3):235\u2013256, 2002. ISSN 0885-6125.\n[3] P. Auer, N. Cesa-Bianchi, Y. Freund, and R. E. Schapire.\nThe nonstochastic multiarmed\nbandit problem. SIAM J. Comput., 32(1):48\u201377, 2003.\n[4] A. Barron, L. Birg\u00b4e, and P. Massart. Risk bounds for model selection via penalization. Prob-\nability Theory and Related Fields, 113:301\u2013413, 1999.\n[5] A. R. Barron. Complexity regularization with application to arti\ufb01cial neural networks. In\nNonparametric functional estimation and related topics, pages 561\u2013576. Kluwer Academic,\n1991.\n[6] P. Bartlett, O. Bousquet, and S. Mendelson. Local rademacher complexities. Annals of Statis-\ntics, 33(4):1497\u20131537, 2005.\n[7] P. Bartlett, M. Jordan, and J. McAuli\ufb00e. Convexity, classi\ufb01cation, and risk bounds. Journal\nof the American Statistical Association, 101:138\u2013156, 2006.\n[8] P. L. Bartlett.\nFast rates for estimation error and oracle inequalities for model selection.\nEconometric Theory, 24(2):545\u2013552, 2008.\n[9] P. L. Bartlett and S. Mendelson. Rademacher and Gaussian complexities: Risk bounds and\nstructural results. Journal of Machine Learning Research, 3:463\u2013482, 2002.\n[10] P. L. Bartlett and S. Mendelson. Empirical minimization. Probability Theory and Related\nFields, 135(3):311\u2013334, 2006.\n[11] P. L. Bartlett, S. Boucheron, and G. Lugosi. Model selection and error estimation. Machine\nLearning, 48:85\u2013113, 2002.\n[12] P. B\u00a8uhlmann and S. van de Geer. Statistics for High-Dimensional Data. Springer, 2011.\n[13] N. Cesa-Bianchi and G. Lugosi.\nPrediction, Learning, and Games.\nCambridge University\nPress, 2006.\n[14] N. Cesa-Bianchi, A. Conconi, and C. Gentile. On the generalization ability of on-line learning\nalgorithms. IEEE Transactions on Information Theory, 50(9):2050\u20132057, September 2004.\n[15] R. M. Dudley. Uniform Central Limit Theorems. Cambridge Univ. Press, 1999.\n[16] S. Geman and C. R. Hwang. Nonparametric maximum likelihood estimation by the method\nof sieves. Annals of Statistics, 10:401\u2013414, 1982.\n[17] V. Koltchinskii.\nRejoinder: Local Rademacher complexities and oracle inequalities in risk\nminimization. The Annals of Statistics, 34(6):2697\u20132706, 2006.\n33\n[18] V. Koltchinskii. Local Rademacher complexities and oracle inequalities in risk minimization.\nThe Annals of Statistics, 34(6):2593\u20132656, 2006.\n[19] T. L. Lai and H. Robbins. Asymptotically e\ufb03cient adaptive allocation rules. Advances in\nApplied Mathematics, 6:4\u201322, 1985.\n[20] G. Lugosi and M. Wegkamp. Complexity regularization via localized random penalties. Annals\nof Statistics, 32(4):1679\u20131697, 2004.\n[21] C. L. Mallows. Some comments on Cp. Technometrics, 15(4):661\u2013675, 1973.\n[22] E. Mammen and A. B. Tsybakov. Smooth discrimination analysis. The Annals of Statistics,\n27(6):1808\u20131829, 1999.\n[23] P. Massart. Concentration inequalities and model selection. In J. Picard, editor, Ecole d\u2019Et\nde Probabilits de Saint-Flour XXXIII - 2003 Series. Springer, 2003.\n[24] A. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro. Robust stochastic approximation ap-\nproach to stochastic programming. SIAM Journal on Optimization, 19(4):1574\u20131609, 2009.\n[25] J. Rissanen. A universal prior for integers and estimation by minimum description length. The\nAnnals of Statistics, 11(2):416\u2013431, 1983.\n[26] H. Robbins and S. Monro.\nA stochastic approximation method.\nAnnals of Mathematical\nStatistics, 22:400\u2013407, 1951.\n[27] V. N. Vapnik and A. Y. Chervonenkis. On the uniform convergence of relative frequencies of\nevents to their probabilities. Theory of Probability and its Applications, XVI(2):264\u2013280, 1971.\n[28] V. N. Vapnik and A. Y. Chervonenkis. Theory of Pattern Recognition. Nauka, Moscow, 1974.\n(In Russian).\n34\n",
        "sentence": " As a solution, recent advances in learning theory introduce hierarchies of algorithmic solutions, ordered by the respective computational complexity, for several fundamental machine learning applications in (Bousquet and Bottou, 2008; Shalev-Shwartz and Srebro, 2008; Chandrasekaran and Jordan, 2013; Agarwal et al., 2012; Lucic et al., 2015).",
        "context": "in computationally unconstrained settings [11]. It is thus natural to ask whether we can use the\nnested structure of our model hierarchy to allocate computational budget more e\ufb03ciently.\nthat the computational assumption B can be satis\ufb01ed for this hierarchy, where the algorithm A\nrequires time dini(T) to select f \u2208Fi. Thus, given a computational budget T, we set the number\nof samples ni(T) for class i to be proportional to T/di.\nproblem is the now classical idea of complexity regularization, which arose out of early works by\n1\nMallows [21] and Akaike [1].\nThe complexity regularization approach balances two competing"
    },
    {
        "title": "Meil\u0103. Experiments with kemeny ranking: What works when",
        "author": [
            "M.A. Ali"
        ],
        "venue": "Mathematical Social Sciences,",
        "citeRegEx": "Ali,? \\Q2012\\E",
        "shortCiteRegEx": "Ali",
        "year": 2012,
        "abstract": "",
        "full_text": "",
        "sentence": " This is different from learning Mallows models in Ali and Meil\u0103 (2012) where peaked distributions are easier to learn, and is related to the fact that we are not only interested in recovering the (ordinal) ranking but also the (cardinal) weight.",
        "context": null
    },
    {
        "title": "Random utility theory for social choice",
        "author": [
            "H. Azari Soufiani",
            "D.C. Parkes",
            "L. Xia"
        ],
        "venue": "In NIPS,",
        "citeRegEx": "Soufiani et al\\.,? \\Q2012\\E",
        "shortCiteRegEx": "Soufiani et al\\.",
        "year": 2012,
        "abstract": "Random utility theory models an agent's preferences on alternatives by\ndrawing a real-valued score on each alternative (typically independently) from\na parameterized distribution, and then ranking the alternatives according to\nscores. A special case that has received significant attention is the\nPlackett-Luce model, for which fast inference methods for maximum likelihood\nestimators are available. This paper develops conditions on general random\nutility models that enable fast inference within a Bayesian framework through\nMC-EM, providing concave loglikelihood functions and bounded sets of global\nmaxima solutions. Results on both real-world and simulated data provide support\nfor the scalability of the approach and capability for model selection among\ngeneral random utility models including Plackett-Luce.",
        "full_text": "Random Utility Theory for Social Choice\nHossein Azari Sou\ufb01ani\nSEAS, Harvard University\nazari@fas.harvard.edu\nDavid C. Parkes\nSEAS, Harvard University\nparkes@eecs.harvard.edu\nLirong Xia\nSEAS, Harvard University\nlxia@seas.harvard.edu\nAbstract\nRandom utility theory models an agent\u2019s preferences on alternatives by drawing\na real-valued score on each alternative (typically independently) from a param-\neterized distribution, and then ranking the alternatives according to scores. A\nspecial case that has received signi\ufb01cant attention is the Plackett-Luce model, for\nwhich fast inference methods for maximum likelihood estimators are available.\nThis paper develops conditions on general random utility models that enable fast\ninference within a Bayesian framework through MC-EM, providing concave log-\nlikelihood functions and bounded sets of global maxima solutions. Results on\nboth real-world and simulated data provide support for the scalability of the ap-\nproach and capability for model selection among general random utility models\nincluding Plackett-Luce.\n1\nIntroduction\nProblems of learning with rank-based error metrics [16] and the adoption of learning for the purpose\nof rank aggregation in social choice [7, 8, 23, 25, 29, 30] are gaining in prominence in recent years.\nIn part, this is due to the explosion of socio-economic platforms, where opinions of users need to be\naggregated; e.g., judges in crowd-sourcing contests, ranking of movies or user-generated content.\nIn the problem of social choice, users submit ordinal preferences consisting of partial or total ranks\non the alternatives and a single rank order must be selected to be representative of the reports.\nSince Condorcet [6], one approach to this problem is to formulate social choice as the problem\nof estimating a true underlying world state (e.g., a true quality ranking of alternatives), where the\nindividual reports are viewed as noisy data in regard to the true state. In this way, social choice can\nbe framed as a problem of inference.\nIn particular, Condorcet assumed the existence of a true ranking over alternatives, with a voter\u2019s pref-\nerence between any pair of alternatives a, b generated to agree with the true ranking with probability\np > 1/2 and disagree otherwise. Condorcet proposed to choose as the outcome of social choice the\nranking that maximizes the likelihood of observing the voters\u2019 preferences. Later, Kemeny\u2019s rule\nwas shown to provide the maximum likelihood estimator (MLE) for this model [32].\nBut Condorcet\u2019s probabilistic model assumes identical and independent distributions on pairwise\ncomparisons. This ignores the strength in agents\u2019 preferences (the same probability p is adopted\nfor all pairwise comparisons), and allows for cyclic preferences. In addition, computing the winner\nthrough the Kemeny rule is \u0398P\n2 -complete [13].\nTo overcome the \ufb01rst criticism, a more recent literature adopts the random utility model (RUM)\nfrom economics [26]. Consider C = {c1, .., cm} alternatives. In RUM, there is a ground truth\nutility (or score) associated with each alternative. These are real-valued parameters, denoted by\n\u20d7\u03b8 = (\u03b81, . . . , \u03b8m). Given this, an agent independently samples a random utility (Xj) for each\nalternative cj with conditional distribution \u00b5j(\u00b7|\u03b8j).\n1\narXiv:1211.2476v1  [cs.MA]  11 Nov 2012\nUsually \u03b8j is the mean of \u00b5j(\u00b7|\u03b8j).1 Let \u03c0 denote a permutation of {1, . . . , m}, which naturally\ncorresponds to a linear order: [c\u03c0(1) \u227bc\u03c0(2) \u227b\u00b7 \u00b7 \u00b7 \u227bc\u03c0(m)]. Slightly abusing notation, we also use\n\u03c0 to denote this linear order. Random utility (X1, . . . , Xm) generates a distribution on preference\norders, as\nPr(\u03c0 | \u20d7\u03b8) = Pr(X\u03c0(1) > X\u03c0(2) > . . . > X\u03c0(m))\n(1)\nThe generative process is illustrated in Figure 1.\nFigure 1: The generative process for RUMs.\nAdopting RUMs rules out cyclic preferences, because each agent\u2019s outcome corresponds to an order\non real numbers, and it also captures the strength of preference, and thus overcomes the second\ncriticism, by assigning a different parameter (\u03b8j) to each alternative.\nA popular RUM is Plackett-Luce (P-L) [18, 21], where the random utility terms are generated ac-\ncording to Gumbel distributions with \ufb01xed shape parameter [2,31]. For P-L, the likelihood function\nhas a simple analytical solution, making MLE inference tractable. P-L has been extensively applied\nin econometrics [1, 19], and more recently in machine learning and information retrieval (see [16]\nfor an overview). Ef\ufb01cient methods of EM inference [5, 14], and more recently expectation propa-\ngation [12], have been developed for P-L and its variants.\nIn application to social choice, the P-L model has been used to analyze political elections [10]. EM\nalgorithm has also been used to learn the Mallows model, which is closely related to the Condorcet\u2019s\nprobabilistic model [17].\nAlthough P-L overcomes the two dif\ufb01culties of the Condorcet-Kemeny approach, it is still quite\nrestricted, by assuming that the random utility terms are distributed as Gumbel, with each alternative\nis characterized by one parameter, which is the mean of its corresponding distribution. In fact, little\nis known about inference in RUMs beyond P-L. Speci\ufb01cally, we are not aware of either an analytical\nsolution or an ef\ufb01cient algorithm for MLE inference for one of the most natural models proposed by\nThurstone [26], where each Xj is normally distributed.\n1.1\nOur Contributions\nIn this paper we focus on RUMs in which the random utilities are independently generated with\nrespect to distributions in the exponential family (EF) [20]. This extends the P-L model, since\nthe Gumbel distribution with \ufb01xed shape parameters belonging to the EF. Our main theoretical\ncontributions are Theorem 1 and Theorem 2, which propose conditions such that the log-likelihood\nfunction is concave and the set of global maxima solutions is bounded for the location family, which\nare RUMs where the shape of each distribution \u00b5j is \ufb01xed and the only latent variables are the\nlocations, i.e., the means of \u00b5j\u2019s. These results hold for existing special cases, such as the P-L\nmodel, and many other RUMs, for example the ones where each \u00b5j is chosen from Normal, Gumbel,\nLaplace and Cauchy.\n1\u00b5j(\u00b7|\u03b8j) might be parameterized by other parameters, for example variance.\n2\nWe also propose a novel application of MC-EM. We treat the random utilities ( \u20d7X) as latent variables,\nand adopt the Expectation Maximization (EM) method to estimate parameters \u20d7\u03b8. The E-step for\nthis problem is not analytically tractable, and for this we adopt a Monte Carlo approximation. We\nestablish through experiments that the Monte-Carlo error in the E-step is controllable and does not\naffect inference, as long as numerical parameterizations are chosen carefully. In addition, for the E-\nstep we suggest a parallelization over the agents and alternatives and a Rao-Blackwellized method,\nwhich further increases the scalability of our method.\nWe generally assume that the data provides total orders on alternatives from voters, but comment on\nhow to extend the method and theory to the case where the input preferences are partial orders.\nWe evaluate our approach on synthetic data as well as two real-world datasets, a public election\ndataset and one involving rank preferences on sushi. The experimental results suggest that the\napproach is scalable despite providing signi\ufb01cantly improved modeling \ufb02exibility over existing ap-\nproaches.\nFor the two real-world datasets we have studied, we compare RUMs with normal distributions and\nP-L in terms of four criteria: log-likelihood, predictive log-likelihood, Akaike information criterion\n(AIC), and Bayesian information criterion (BIC). We observe that when the amount of data is not\ntoo small, RUMs with normal distributions \ufb01t better than P-L. Speci\ufb01cally, for the log-likelihood,\npredictive log-likelihood, and AIC criteria, RUMs with normal distributions outperform P-L with\n95% con\ufb01dence in both datasets.\n2\nRUMs and Exponential Families\nIn social choice, each agent i \u2208{1, . . . , n} has a strict preference order on alternatives. This\nprovides the data for an inferential approach to social choice. In particular. let L(C) denote the set\nof all linear orders on C. Then, a preference-pro\ufb01le, D, is a set of n preference orders, one from\neach agent, so that D \u2208L(C)n.\nA voting rule r is a mapping that assigns to each preference-pro\ufb01le a set of winning rankings,\nr : L(C)n 7\u2192(2L(C) \\ \u2205). In particular, in the case of ties the set of winning rankings may include\nmore than a singleton ranking. In the maximum likelihood (MLE) approach to social choice, the\npreference pro\ufb01le is viewed as data, D = {\u03c01, . . . , \u03c0n}.\nGiven this, the probability (likelihood) of the data given ground truth \u20d7\u03b8 (and for a particular \u20d7\u00b5) is\nPr(D | \u20d7\u03b8) = Qn\ni=1 Pr(\u03c0i | \u20d7\u03b8), where,\nP(\u03c0|\u20d7\u03b8)=\nZ \u221e\nx\u03c0(n)=\u2212\u221e\nZ \u221e\nx\u03c0(n\u22121)=x\u03c0(n)\n..\nZ \u221e\nx\u03c0(1)=x\u03c0(2)\n\u00b5\u03c0(n)(x\u03c0(n))..\u00b5\u03c0(1)(x\u03c0(1))dx\u03c0(1)dx\u03c0(2)..dx\u03c0(n) (2)\nThe MLE approach to social choice selects as the winning ranking that which corresponds to the \u20d7\u03b8\nthat maximizes Pr(D | \u20d7\u03b8). In the case of multiple parameters that maximize the likelihood then the\nMLE approach returns a set of rankings, one ranking corresponding to each parameterization.\nIn this paper, we focus on probabilistic models where each \u00b5j belongs to the exponential family\n(EF). The density function for each \u00b5 in EF has the following format:\nPr(X = x) = \u00b5(x) = e\u03b7(\u03b8)T (x)\u2212A(\u03b8)+B(x),\n(3)\nwhere \u03b7(\u00b7) and A(\u00b7) are functions of \u03b8, B(\u00b7) is a function of x, and T(x) denotes the suf\ufb01cient\nstatistics for x, which could be multidimensional.\nExample 1 (Plackett-Luce as an RUM [2]) In the RUM, let \u00b5j\u2019s be Gumbel distributions. That\nis, for alternative j \u2208{1, . . . , m} we have \u00b5j(xj|\u03b8j) = e\u2212(xj\u2212\u03b8j)e\u2212e\u2212(xj \u2212\u03b8j ). Then, we have:\nPr(\u03c0 | \u20d7\u03bb) = Pr(x\u03c0(1) > x\u03c0(2) > .. > x\u03c0(m)) = Qm\nj=1\n\u03bb\u03c0(j)\nPm\nj\u2032=j \u03bb\u03c0(j\u2032) , where \u03b7(\u03b8j) = \u03bbj = e\u03b8j,\nT(xj) = \u2212e\u2212xj, B(xj) = \u2212xj and A(\u03b8j) = \u2212\u03b8j.This gives us the Plackett-Luce model.\n3\nGlobal Optimality and Log-Concavity\nIn this section, we provide a condition on distributions that guarantees that the likelihood function (2)\nis log-concave in parameters \u20d7\u03b8. We also provide a condition under which the set of MLE solutions\n3\nis bounded when any one latent parameter is \ufb01xed. Together, this guarantees the convergence of our\nMC-EM approach to a global mode with an accurate enough E-step. We focus on the location family,\nwhich is a subset of RUMs where the shapes of all \u00b5j\u2019s are \ufb01xed, and the only parameters are the\nmeans of the distributions. For the location family, we can write Xj = \u03b8j +\u03b6j, where Xj \u223c\u00b5j(\u00b7|\u03b8j)\nand \u03b6j = Xj \u2212\u03b8j is a random variable whose mean is 0 and models an agent\u2019s subjective noise.\nThe random variables \u03b6j\u2019s do not need to be identically distributed for all alternatives j; e.g., they\ncan be normal with different \ufb01xed variances.\nWe focus on computing solutions (\u20d7\u03b8) to maximize the log-likelihood function,\nl(\u20d7\u03b8; D) =\nn\nX\ni=1\nlog Pr(\u03c0i | \u20d7\u03b8)\n(4)\nTheorem 1 For the location family, if for every j \u2264m the probability density function for \u03b6j is\nlog-concave, then l(\u20d7\u03b8; D) is concave.\nProof sketch: The theorem is proved by applying the following lemma, which is Theorem 9 in [22].\nLemma 1 Suppose g1(\u20d7\u03b8, \u20d7\u03b6), ..., gR(\u20d7\u03b8, \u20d7\u03b6) are concave functions in R2m where \u20d7\u03b8 is the vector of m\nparameters and \u20d7\u03b6 is a vector of m real numbers that are generated according to a distribution whose\npdf is logarithmic concave in Rm. Then the following function is log-concave in Rm.\nLi(\u20d7\u03b8, G) = Pr(g1(\u20d7\u03b8, \u20d7\u03b6) \u22650, ..., gR(\u20d7\u03b8, \u20d7\u03b6) \u22650), \u20d7\u03b8 \u2208Rm\n(5)\nTo apply Lemma 1, we de\ufb01ne a set Gi of function gi\u2019s that is equivalent to an order \u03c0i in the sense of\ninequalities implied by RUM for \u03c0i and Gi (the joint probability in (5) for Gi to be the same as the\nprobity of \u03c0i in RUM with parameters \u20d7\u03b8). Suppose gi\nr(\u20d7\u03b8, \u20d7\u03b6) = \u03b8\u03c0i(r) + \u03b6i\n\u03c0i(r) \u2212\u03b8\u03c0i(r+1) \u2212\u03b6i\n\u03c0i(r+1)\nfor r = 1, .., m \u22121.\nThen considering that the length of order \u03c0i is R + 1, we have:\nLi(\u20d7\u03b8, \u03c0i) = Li(\u20d7\u03b8, Gi) = Pr(gi\n1(\u20d7\u03b8, \u20d7\u03b6) \u22650, ..., gi\nR(\u20d7\u03b8, \u20d7\u03b6) \u22650), \u20d7\u03b8 \u2208Rm\n(6)\nThis is because gi\nr(\u20d7\u03b8, \u20d7\u03b6) \u22650 is equivalent to that in \u03c0i alternative \u03c0i(r) is preferred to alternative\n\u03c0i(r + 1) in the RUM sense.\nTo see how this extends to the case where preferences are speci\ufb01ed as partial orders, we consider\nin particular an interpretation where an agent\u2019s report for the ranking of mi alternatives implies that\nall other alternatives are worse for the agent, in some unde\ufb01ned order. Given this, de\ufb01ne gi\nr(\u20d7\u03b8, \u20d7\u03b6) =\n\u03b8\u03c0i(r) + \u03b6i\n\u03c0i(r) \u2212\u03b8\u03c0i(r+1) \u2212\u03b6i\n\u03c0i(r+1) for r = 1, .., mi \u22121 and gi\nr(\u20d7\u03b8, \u20d7\u03b6) = \u03b8\u03c0i(mi) + \u03b6i\n\u03c0i(mi) \u2212\n\u03b8\u03c0i(r+1) \u2212\u03b6i\n\u03c0i(r+1) for r = mi, .., m \u22121. Considering that gi\nr(\u00b7)s are linear (hence, concave) and\nusing log concavity of the distributions of \u20d7\u03b6i = (\u03b6i\n1, \u03b6i\n2, .., \u03b6i\nm)\u2019s, we can apply Lemma 1 and prove\nlog-concavity of the likelihood function.\n\u25a1\nIt is not hard to verify that pdfs for normal and Gumbel are log-concave under reasonable conditions\nfor their parameters, made explicit in the following corollary.\nCorollary 1 For the location family where each \u03b6j is a normal distribution with mean zero and\nwith \ufb01xed variance, or Gumbel distribution with mean zeros and \ufb01xed shape parameter, l(\u20d7\u03b8; D) is\nconcave. Speci\ufb01cally, the log-likelihood function for P-L is concave.\nThe concavity of log-likelihood of P-L has been proved [9] using a different technique. Using Fact\n3.5. in [24], the set of global maxima solutions to the likelihood function, denoted by SD, is convex\nsince the likelihood function is log-concave. However, we also need that SD is bounded, and would\nfurther like that it provides one unique order as the estimation for the ground truth.\nFor P-L, Ford, Jr. [9] proposed the following necessary and suf\ufb01cient condition for the set of global\nmaxima solutions to be bounded (more precisely, unique) when Pm\nj=1 e\u03b8j = 1.\nCondition 1 Given the data D, in every partition of the alternatives C into two nonempty subsets\nC1 \u222aC2, there exists c1 \u2208C1 and c2 \u2208C2 such that there is at least one ranking in D where c1 \u227bc2.\n4\nWe next show that Condition 1 is also a necessary and suf\ufb01cient condition for the set of global\nmaxima solutions SD to be bounded in location families, when we set one of the values \u03b8j to be 0\n(w.l.o.g., let \u03b81 = 0). If we do not bound any parameter, then SD is unbounded, because for any \u20d7\u03b8,\nany D, and any number s \u2208R, l(\u20d7\u03b8; D) = l(\u20d7\u03b8 + s; D).\nTheorem 2 Suppose we \ufb01x \u03b81 = 0. Then, the set SD of global maxima solutions to l(\u03b8; D) is\nbounded if and only if the data D satis\ufb01es Condition 1.\nProof sketch:\nIf Condition 1 does not hold, then SD is unbounded because the parameters for all alternatives in\nC1 can be increased simultaneously to improve the log-likelihood. For suf\ufb01ciency, we \ufb01rst present\nthe following lemma.\nLemma 2 If alternative j is preferred to alternative j\u2032 in at least in one ranking then the difference\nof their mean parameters \u03b8j\u2032 \u2212\u03b8j is bounded from above (\u2203Q where \u03b8j\u2032 \u2212\u03b8j < Q) for all the \u20d7\u03b8\nthat maximize the likelihood function.\nProof: Suppose that j \u227bj\u2032 in rank i, then for any \u20d7\u03b8 \u2208Rm:\nLi(\u20d7\u03b8, \u03c0i) = Li(\u20d7\u03b8, Gi) = Pr(g1(\u20d7\u03b8, \u20d7\u03b6) \u22650, ..., gR(\u20d7\u03b8, \u20d7\u03b6) \u22650)\n\u2264Pr(g\u03c0i(r)(\u20d7\u03b8, \u20d7\u03b6) \u22650, g\u03c0i(r+1)(\u20d7\u03b8, \u20d7\u03b6) \u22650, . . . , g\u03c0i(r\u2032)(\u20d7\u03b8, \u20d7\u03b6) \u22650) \u2264Pr(\u03b6j \u2212\u03b6j\u2032 \u2265\u03b8j\u2032 \u2212\u03b8j), (7)\nwhere j = \u03c0i(r) and j\u2032 = \u03c0i(r\u2032).\nLet K = l(\u20d70; D). Since the log-likelihood is always smaller than 0, it follows that for any \u20d7\u03b8 \u2208SD\nand any i \u2264n, Li(\u20d7\u03b8; \u03c0i) \u2265K.\nHence, Pr(\u03b6j \u2212\u03b6j\u2032 \u2265\u03b8j\u2032 \u2212\u03b8j) \u2265K.\nTherefore, there exists K\u2032 such that \u03b8j\u2032 \u2212\u03b8j < K\u2032, where K\u2032 depends on the \ufb01xed \u03b6j\u2032 and \u03b6j.\n\u25a1\nNow consider a directed graph GD, where the nodes are the alternatives, and there is an edge be-\ntween cj to cj\u2032 if in at least one ranking cj \u227bcj\u2032. By Condition 1, for any pair j \u0338= j\u2032, there is a path\nfrom cj to cj\u2032 (and conversely, a path from cj\u2032 to cj). To see this, consider building a path between\nj and j\u2032 by starting from a partition with C1 = {j} and following an edge from j to j1 in the graph\nwhere j1 is an alternatives in C2 for which there must be such an edge, by Condition 1. Consider the\npartition with C1 = {j, j1}, and repeat until an edge can be followed to vertex j\u2032 \u2208C2. It follows\nfrom Lemma 2 that for any \u20d7\u03b8 \u2208SD we have |\u03b8j \u2212\u03b8j\u2032| < Qm, using the telescopic sum of bounded\nvalues of the difference of mean parameters along the edges of the path, since the length of the path\nis no more than m (and tracing the path from j to j\u2032 and j\u2032 to j), meaning that SD is bounded.\n\u25a1\nNow that we have the log concavity and bounded property, we need to declare conditions under\nwhich the bounded convex space of estimated parameters corresponds to a unique order. The next\ntheorem provides a necessary and suf\ufb01cient condition for all global maxima to correspond to the\nsame order on alternatives. Suppose that we order the alternatives based on estimated \u03b8\u2019s (meaning\nthat cj is ranked higher than cj\u2032 iff \u03b8j > \u03b8j\u2032).\nTheorem 3 The order over parameters is strict and is the same across all \u20d7\u03b8 \u2208SD if, for all \u20d7\u03b8 \u2208SD\nand all alternatives j \u0338= j\u2032, \u03b8j \u0338= \u03b8j\u2032.\nProof: Suppose for the sake of contradiction there exist two maxima, \u20d7\u03b8, \u20d7\u03b8\u2217\u2208SD and a pair of\nalternatives j \u0338= j\u2032 such that \u03b8j > \u03b8j\u2032 and \u03b8\u2217\nj\u2032 > \u03b8\u2217\nj . Then, there exists an \u03b1 < 1 such that the jth\nand j\u2032th components of \u03b1\u20d7\u03b8 + (1 \u2212\u03b1)\u20d7\u03b8\u2217are equal, which contradicts the assumption.\n\u25a1\nHence, if there is never a tie in the scores in any \u20d7\u03b8 \u2208SD, then any vector in SD will reveal the\nunique order.\n4\nMonte Carlo EM for Parameter Estimation\nIn this section, we propose an MC-EM algorithm for MLE inference for RUMs where every \u00b5j\nbelongs to the EF.2\n2Our algorithm can be naturally extended to compute a maximum a posteriori probability (MAP) estimate,\nwhen we have a prior over the parameters \u20d7\u03b8. Still, it seems hard to motivate the imposition of a prior on\nparameters in many social choice domains.\n5\nThe EM algorithm determines the MLE parameters \u20d7\u03b8 iteratively, and proceeds as follows. In each\niteration t + 1, given parameters \u20d7\u03b8t from the previous iteration, the algorithm is composed of an\nE-step and an M-step. For the E-step, for any given \u20d7\u03b8 = (\u03b81, . . . , \u03b8m), we compute the conditional\nexpectation of the complete-data log-likelihood (latent variables \u20d7x and data D), where the latent\nvariables \u20d7x are distributed according to data D and parameters \u20d7\u03b8t from the last iteration.\nFor the M-step, we optimize \u20d7\u03b8 to maximize the expected log-likelihood computed in the E-step, and\nuse it as the input \u20d7\u03b8t+1 for the next iteration:\nE-Step : Q(\u20d7\u03b8, \u20d7\u03b8t) = E \u20d7\nX\n(\nlog\nn\nY\ni=1\nPr(\u20d7xi, \u03c0i | \u20d7\u03b8) | D, \u20d7\u03b8t\n)\nM-step : \u20d7\u03b8t+1 \u2208arg max\n\u20d7\u03b8\nQ(\u20d7\u03b8, \u20d7\u03b8t)\n4.1\nMonte Carlo E-step by Gibbs sampler\nThe E-step can be simpli\ufb01ed using (3) as follows:\nE \u20d7\nX{log\nn\nY\ni=1\nPr(\u20d7xi, \u03c0i | \u20d7\u03b8) | D, \u20d7\u03b8t} = E \u20d7\nX{log\nn\nY\ni=1\nPr(\u20d7xi| \u20d7\u03b8) Pr(\u03c0i|\u20d7xi) | D, \u20d7\u03b8t}\n=\nn\nX\ni=1\nm\nX\nj=1\nEXi\nj{log \u00b5j(xi\nj|\u03b8j) | \u03c0i, \u20d7\u03b8t} =\nn\nX\ni=1\nm\nX\nj=1\n(\u03b7(\u03b8j)EXi\nj{T(xi\nj) | \u03c0i, \u20d7\u03b8t} \u2212A(\u03b8j) + W,\nwhere W = EXi\nj{B(xi\nj) | \u03c0i, \u20d7\u03b8t} only depends on \u20d7\u03b8t and D (not on \u20d7\u03b8), which means that it can\nbe treated as a constant in the M-step. Hence, in the E-step we only need to compute Si,t+1\nj\n=\nEXi\nj{T(xi\nj) | \u03c0i, \u20d7\u03b8t} where T(xi\nj) is the suf\ufb01cient statistic for the parameter \u03b8j in the model. We\nare not aware of an analytical solution for EXi\nj{T(xi\nj) | \u03c0i, \u20d7\u03b8t}. However, we can use a Monte\nCarlo approximation, which involves sampling \u20d7xi from the distribution Pr(\u20d7xi | \u03c0i, \u20d7\u03b8t) using a Gibbs\nsampler, and then approximates Si,t+1\nj\nby\n1\nN\nPN\nk=1 T(xi,k\nj ) where N is the number of samples in\nthe Gibbs sampler.\nIn each step of our Gibbs sampler for voter i, we randomly choose a position j in \u03c0i and\nsample xi\n\u03c0i(j) according to a TruncatedEF distribution Pr(\u00b7| x\u03c0i(\u2212j), \u20d7\u03b8t, \u03c0i), where x\u03c0i(\u2212j) =\n( x\u03c0i(1), . . . , x\u03c0i(j\u22121), x\u03c0i(j+1), . . . , x\u03c0i(m)). The TruncatedEF is obtained by truncating the tails\nof \u00b5\u03c0i(j)(\u00b7|\u03b8t\n\u03c0i(j)) at x\u03c0i(j\u22121) and x\u03c0i(j+1), respectively. For example, a truncated normal distribu-\ntion is illustrated in Figure 2.\nFigure 2: A truncated normal distribution.\nRao-Blackwellized:\nTo further improve the\nGibbs sampler, we use Rao-Blackwellized [4]\nestimation\nusing\nE{T(xi,k\nj )\n|\nxi,k\n\u2212j, \u03c0i, \u20d7\u03b8t}\ninstead of the sample xi,k\nj , where xi,k\n\u2212j is all\nof \u20d7xi,k except for xi,k\nj .\nFinally,\nwe esti-\nmate E{T(xi,k\nj ) | xi,k\n\u2212j, \u03c0i, \u20d7\u03b8t} in each step\nof the Gibbs sampler using M\nsamples as\nSi,t+1\nj\n\u2243\n1\nN\nPN\nk=1 E{T(xi,k\nj ) | xk\n\u2212j, \u03c0i, \u20d7\u03b8t} \u2243\n1\nNM\nPN\nk=1\nPM\nl=1 T(xil,k\nj\n),\nwhere\nxil,k\nj\n\u223c\nPr(xil,k\nj\n| xi,k\n\u2212j, \u03c0i, \u20d7\u03b8).\nRao-Blackwellization\nreduces\nthe\nvariance\nof\nthe\nestimator\nbe-\ncause\nof\nconditioning\nand\nexpectation\nin\nE{T(xi,k\nj ) | xi,k\n\u2212j, \u03c0i, \u20d7\u03b8t}.\n6\n4.2\nM-step\nIn the E-step we have (approximately) computed Si,t+1\nj\n. In the M-step we compute \u20d7\u03b8t+1 to max-\nimize Pn\ni=1\nPm\nj=1(\u03b7(\u03b8j)EXi\nj{T(xi\nj) | \u03c0i, \u20d7\u03b8t} \u2212A(\u03b8j) + EXi\nj{B(xi\nj) | \u03c0i, \u20d7\u03b8t}). Equivalently, we\ncompute \u03b8t+1\nj\nfor each j \u2264m separately to maximize Pn\ni=1{\u03b7(\u03b8j)EXi\nj{T(xi\nj) | \u03c0i, \u20d7\u03b8t}\u2212A(\u03b8j)} =\n\u03b7(\u03b8j) Pn\ni=1 Si,t+1\nj\n\u2212nA(\u03b8j).\nFor the case of the normal distribution with \ufb01xed variance, where \u03b7(\u03b8j) = 2\u03b8j and A(\u03b8j) = (\u03b8j)2,\nwe have \u03b8t+1\nj\n= 1\nn\nPn\ni=1 Si,t+1\nj\n. The algorithm is illustrated in Figure 3.\nFigure 3: The MC-EM algorithm for normal distribution.\n4.3\nConvergence\nIn the last section we showed that if the RUM satis\ufb01es the premise in Theorem 1 and Theorem 2 the\ndata satis\ufb01es Condition 1, then the log-likelihood function is concave, and the set of global maxima\nsolutions is bounded. This guarantee the convergence of MC-EM for an exact E-step.\nIn general, MC-EM methods do not have the uniform convergence property of EM methods. In\norder to control the error of approximation in the MC-E step we can increase the number of samples\nwith the iterations [28]. However, in our application, we are not concerned with the exact estimation\nof \u20d7\u03b8, as we are only interested in their orders relative to each-other. Therefore, as long as the\napproximation error remains relatively small, such that the differences of \u03b8js are much larger than\nthe error, we are safe to stop.\nA known problem with Gibbs sampling is that it can introduce correlation among samples. To\naddress this, we sub-sample the samples to reduce the correlation, and call the ratio of sub-sampling\nthe thinning factor (0 < F \u22641). A suitable thinning ratio can be set using empirical results from\nthe sampler.\nWith an approach similar to [3], we can derive a relationship between the variance of error in \u20d7\u03b8t+1\nand the Monte-Carlo error in the E-step approximation:\nVar(\u03b8j\nt+1) = 1\nn2\nn\nX\ni=1\nVar(Si,t+1\nj\n) =\n1\nMNn2\nn\nX\ni=1\nVar(xi\nj) \u2264\nFV\nMNn,\n(8)\nwhere N is number of samples in Gibbs sampler, M is the number of samples for Rao-\nBlackwellization, n is number of agents, F is the thinning factor and V = maxj(Var x\u223c\u00b5j(x)),\nand samples xi\nj are assumed to be independent. Given, T, V and n, we can make Var(\u03b8j\nt+1)\narbitrarily small by increasing MN.\n5\nExperimental Results\nWe evaluate the proposed MC-EM algorithm on synthetic data as well as two real world data sets,\nnamely an election data set and a dataset representing preference orders on sushi. For simulated data\n7\nwe use the Kendall correlation [11] between two rank orders (typically between the true order and\nthe method\u2019s result) as a measure of performance.\n5.1\nExperiments for Synthetic Data\nWe \ufb01rst generate data from Normal models for the random utility terms, with means \u03b8j = j and\nequal variance for all terms, for different choices of variance (Var = 2, 4). We evaluate the perfor-\nmance of the method as the number of agents n varies. The results show that a limited number of\niterations in the EM algorithm (at most 3), and samples MN = 4000 (M=5, N=800) are suf\ufb01cient\nfor inferring the order in most cases. The performance in terms of Kendall correlation for recovering\nground truth improves for larger number of agents, which corresponds to more data. See Figure 4,\nwhich shows the asymptotic behavior of the maximum likelihood estimator in recovering the true\nparameters. Figure 4 left and middle panels show that the more the size of dataset the better the\nperformance of the method.\nMoreover, for large variances in data generation, due to increasing noise in the data, the rate that\nperformance gets better is slower than that for the case for smaller variances. Notice that the scales\non the y-axis are different in the left and middle panels.\nFigure 4: Left and middle panel: Performance for different number of agents n on synthetic data for m = 5, 10\nand Var = 2, 4, with speci\ufb01cations MN = 4000, EMiterations = 3. Right panel: Performance given\naccess to sub-samples of the data in the public election dataset, x-axis: size of sub-samples, y-axis: Kendall\nCorrelation with the order obtained from the full data-set. Dashed lines are the 95% con\ufb01dence intervals.\n5.2\nExperiments for Model Robustness\nWe apply our method to a public election dataset collected by Nicolaus Tideman [27], where the\nvoters provided partial orders on candidates. A partial order includes comparisons among a subset\nof alternative, and the non-mentioned alternatives in the partial order are considered to be ranked\nlower than the lowest ranked alternative among mentioned alternatives.\nThe total number of votes are n = 280 and the number of alternatives m = 15. For the purpose of\nour experiments, we adopt the order on alternatives obtained by applying our method on the entire\ndataset as an assumed ground truth, since no ground truth is given as part of the data. After \ufb01nding\nthe ground truth by using all 280 votes (and adopting a normal model), we compare the performance\nof our approach as we vary the amount of data available. We evaluate the performance for sub-\nsamples consisting of 10, 20, . . . , 280 of samples randomly chosen from the full dataset. For each\nsub-sample size, the experiment is repeated 200 times and we report the average performance and\nthe variance. See the right panel in Figure 4. This experiment shows the robustness of the method,\nin the sense that the result of inference on a subset of the dataset shows consistent behavior with the\ncase that the result on the full dataset. For example, the ranking obtained by using half of the data\ncan still achieve a fair estimate to the results with full data, with an average Kendall correlation of\ngreater than 0.4.\n5.3\nExperiments for Model Fitness\nIn addition to a public election dataset, we have tested our algorithm on a sushi dataset, where 5000\nusers give rankings over 10 different kinds of sushi [15]. For each experiment we randomly choose\n8\nn \u2208{10, 20, 30, 40, 50} rankings, apply our MC-EM for RUMs with normal distributions where\nvariances are also parameters.\nIn the former experiments, both the synthetic data generation and the model for election data, the\nvariances were \ufb01xed to 1 and hence we had the theoretical guarantees for the convergence to global\noptimal solutions by Theorem 1 and Theorem 2. When we let the variances to be part of parametriza-\ntion we lose the theoretical guarantees. However, the EM algorithm can still be applied, and since\nthe variances are now parameters (rather than being \ufb01xed to 1), the model \ufb01ts better in terms of\nlog-likelihood.\nFor this reason, we adopt RUMs with normal distributions in which the variance is a parameter that\nis \ufb01t by EM along with the mean. We call this model a normal model. We compute the difference\nbetween the normal model and P-L in terms of four criteria: log-likelihood (LL), predictive log-\nlikelihood (predictive LL), AIC, and BIC. For (predictive) log-likelihood, a positive value means\nthat normal model \ufb01ts better than P-L, whereas for AIC and BIC, a negative number means that\nnormal model \ufb01ts better than P-L. Predictive likelihood is different from likelihood in the sense\nthat we compute the likelihood of the estimated parameters for a part of the data that is not used for\nparameter estimation.3 In particular, we compute predictive likelihood for a randomly chosen subset\nof 100 votes. The results and standard deviations for n = 10, 50 are summarized in Table 1.\nn = 10\nn = 50\nDataset\nLL\nPred. LL\nAIC\nBIC\nLL\nPred. LL\nAIC\nBIC\nSushi\n8.8(4.2) -56.1(89.5) -7.6(8.4) 5.4(8.4)\n22.6(6.3) 40.1(5.1) -35.2(12.6) -6.1(12.6)\nElection\n9.4(10.6) 91.3(103.8) -8.8(21.2) 4.2(21.2) 44.8(15.8) 87.4(30.5) -79.6(31.6) -50.5(31.6)\nTable 1: Model selection for the sushi dataset and election dataset. Cases where the normal model \ufb01ts better\nthan P-L statistically with 95% con\ufb01dence are in bold.\nWhen n is small (n = 10), the variance is high and we are unable to obtain statistically signi\ufb01cant\nresults in comparing \ufb01tness. When n is not too small (n = 50), RUMs with normal distributions\n\ufb01t better than P-L. Speci\ufb01cally, for log-likelihood, predictive log-likelihood, and AIC, RUMs with\nnormal distributions outperform P-L with 95% con\ufb01dence in both datasets.\n5.4\nImplementation and Run Time\nThe running time for our MC-EM algorithm scales linearly with number of agents on real world\ndata (Election Data) with slope 13.3 second per agent on an Intel i5 2.70GHz PC. This is for 100\niterations of EM algorithm with Gibbs sampling number increasing with iterations as 2000 + 300 \u2217\niteration steps.\nAcknowledgments\nThis work is supported in part by NSF Grant No. CCF- 0915016. Lirong Xia is supported by NSF\nunder Grant #1136996 to the Computing Research Association for the CIFellows Project. We thank\nCraig Boutilier, Jonathan Huang, Tyler Lu, Nicolaus Tideman, Paolo Viappiani, and anonymous\nNIPS-12 reviewers for helpful comments and suggestions, or help on the datasets.\nReferences\n[1] Steven Berry, James Levinsohn, and Ariel Pakes. Automobile prices in market equilibrium. Economet-\nrica, 63(4):841\u2013890, 1995.\n[2] Henry David Block and Jacob Marschak. Random orderings and stochastic theories of responses. In\nContributions to Probability and Statistics, pages 97\u2013132, 1960.\n[3] James G. Booth and James P. Hobert. Maximizing Generalized Linear Mixed Model Likelihoods with an\nAutomated Monte Carlo EM Algorithm. JRSS. Series B, 61(1):265\u2013285, 1999.\n[4] Steve Brooks, Andrew Gelman, Galin Jones, and Xiao-Li Meng, editors. Handbook of Markov Chain\nMonte Carlo. Chapman and Hall/CRC, 2011.\n3The use of predictive likelihood allows us to evaluate the performance of the estimated parameters on the\nrest of the data, and is similar in this sense to cross validation for supervised learning.\n9\n[5] Francois Caron and Arnaud Doucet. Ef\ufb01cient Bayesian Inference for Generalized Bradley-Terry Models.\nJournal of Computational and Graphical Statistics, 21(1):174\u2013196, 2012.\n[6] Marquis de Condorcet. Essai sur l\u2019application de l\u2019analyse `a la probabilit\u00b4e des d\u00b4ecisions rendues `a la\npluralit\u00b4e des voix. Paris: L\u2019Imprimerie Royale, 1785.\n[7] Vincent Conitzer, Matthew Rognlie, and Lirong Xia. Preference functions that score rankings and maxi-\nmum likelihood estimation. In Proc. IJCAI, pages 109\u2013115, 2009.\n[8] Vincent Conitzer and Tuomas Sandholm. Common voting rules as maximum likelihood estimators. In\nProc. UAI, pages 145\u2013152, 2005.\n[9] Lester R. Ford, Jr. Solution of a ranking problem from binary comparisons. The American Mathematical\nMonthly, 64(8):28\u201333, 1957.\n[10] Isobel Claire Gormley and Thomas Brendan Murphy.\nA grade of membership model for rank data.\nBayesian Analysis, 4(2):265\u2013296, 2009.\n[11] Przemyslaw Grzegorzewski. Kendall\u2019s correlation coef\ufb01cient for vague preferences. Soft Computing,\n13(11):1055\u20131061, 2009.\n[12] John Guiver and Edward Snelson. Bayesian inference for Plackett-Luce ranking models. In Proc. ICML,\npages 377\u2013384, 2009.\n[13] Edith Hemaspaandra, Holger Spakowski, and J\u00a8org Vogel. The complexity of Kemeny elections. Theoret-\nical Computer Science, 349(3):382\u2013391, December 2005.\n[14] David R. Hunter. MM algorithms for generalized Bradley-Terry models. In The Annals of Statistics,\nvolume 32, pages 384\u2013406, 2004.\n[15] Toshihiro Kamishima. Nantonac collaborative \ufb01ltering: Recommendation based on order responses. In\nProc. KDD, pages 583\u2013588, 2003.\n[16] Tie-Yan Liu. Learning to Rank for Information Retrieval. Springer, 2011.\n[17] Tyler Lu and Craig Boutilier. Learning mallows models with pairwise preferences. In Proc. ICML, pages\n145\u2013152, 2011.\n[18] R. Duncan Luce. Individual Choice Behavior: A Theoretical Analysis. Wiley, 1959.\n[19] Daniel McFadden. Conditional logit analysis of qualitative choice behavior. In Frontiers of Econometrics,\npages 105\u2013142, New York, NY, 1974. Academic Press.\n[20] Carl N. Morris. Natural Exponential Families with Quadratic Variance Functions. Annals of Statistics,\n10(1):65\u201380, 1982.\n[21] R. L. Plackett. The analysis of permutations. JRSS. Series C, 24(2):193\u2013202, 1975.\n[22] Andr\u00b4s Pr\u00b4ekopa. Logarithmic concave measures and related topics. In Stochastic Programming, pages\n63\u201382. Academic Press, 1980.\n[23] Ariel D. Procaccia, Sashank J. Reddi, and Nisarg Shah. A maximum likelihood approach for selecting\nsets of alternatives. In Proc. UAI, 2012.\n[24] Frank Proschan and Yung L. Tong. Chapter 29. log-concavity property of probability measures. FSU\ntechinical report Number M-805, pages 57\u201368, 1989.\n[25] Magnus Roos, J\u00a8org Rothe, and Bj\u00a8orn Scheuermann. How to calibrate the scores of biased reviewers by\nquadratic programming. In Proc. AAAI, pages 255\u2013260, 2011.\n[26] Louis Leon Thurstone. A law of comparative judgement. Psychological Review, 34(4):273\u2013286, 1927.\n[27] Nicolaus Tideman. Collective Decisions and Voting: The Potential for Public Choice. Ashgate Publishing,\n2006.\n[28] Greg C. G. Wei and Martin A. Tanner. A Monte Carlo Implementation of the EM Algorithm and the Poor\nMan\u2019s Data Augmentation Algorithms. JASA, 85(411):699\u2013704, 1990.\n[29] Lirong Xia and Vincent Conitzer. A maximum likelihood approach towards aggregating partial orders. In\nProc. IJCAI, pages 446\u2013451, 2011.\n[30] Lirong Xia, Vincent Conitzer, and J\u00b4er\u02c6ome Lang. Aggregating preferences in multi-issue domains by using\nmaximum likelihood estimators. In Proc. AAMAS, pages 399\u2013406, 2010.\n[31] John I. Jr. Yellott. The relationship between Luce\u2019s Choice Axiom, Thurstone\u2019s Theory of Comparative\nJudgment, and the double exponential distribution. J. of Mathematical Psychology, 15(2):109\u2013144, 1977.\n[32] H. Peyton Young. Optimal voting rules. Journal of Economic Perspectives, 9(1):51\u201364, 1995.\n10\n",
        "sentence": " Azari Soufiani et al. (2014) showed that if we include all paired comparisons, then the resulting estimate can be statistically inconsistent due to the ignored correlations among the paired orderings, even with infinite samples. Azari Soufiani et al. (2014) showed that if we include all paired comparisons, then the resulting estimate can be statistically inconsistent due to the ignored correlations among the paired orderings, even with infinite samples. In the example from Figure 1, there are 12 paired relations implied by the DAG: (i6 \u227a i5), (i6 \u227a i4), (i6 \u227a i3), . . . , (i3 \u227a i1), (i4 \u227a i1). In order to get a consistent estimate, Azari Soufiani et al. (2014) provide a rule for choosing which pairs to include, and Khetan and Oh (2016) provide an estimator that optimizes how to weigh each of those chosen pairs to get the best finite sample complexity bound. Azari Soufiani et al. (2014) showed that if we include all paired comparisons, then the resulting estimate can be statistically inconsistent due to the ignored correlations among the paired orderings, even with infinite samples. In the example from Figure 1, there are 12 paired relations implied by the DAG: (i6 \u227a i5), (i6 \u227a i4), (i6 \u227a i3), . . . , (i3 \u227a i1), (i4 \u227a i1). In order to get a consistent estimate, Azari Soufiani et al. (2014) provide a rule for choosing which pairs to include, and Khetan and Oh (2016) provide an estimator that optimizes how to weigh each of those chosen pairs to get the best finite sample complexity bound. Azari Soufiani et al. (2014) showed that if we include all paired comparisons, then the resulting estimate can be statistically inconsistent due to the ignored correlations among the paired orderings, even with infinite samples. In the example from Figure 1, there are 12 paired relations implied by the DAG: (i6 \u227a i5), (i6 \u227a i4), (i6 \u227a i3), . . . , (i3 \u227a i1), (i4 \u227a i1). In order to get a consistent estimate, Azari Soufiani et al. (2014) provide a rule for choosing which pairs to include, and Khetan and Oh (2016) provide an estimator that optimizes how to weigh each of those chosen pairs to get the best finite sample complexity bound. However, such a consistent pairwise rank-breaking results in throwing away many of the ordered relations, resulting in significant loss in accuracy. For example, Including a paired relation from Gj in the example results in a biased estimator. None of the pairwise orderings can be used from Gj , without making the estimator inconsistent as shown in Azari Soufiani et al. (2013). Whether we include all paired comparisons or only a subset of consistent ones, there is a significant loss in accuracy as illustrated in Figure 3. Although, statistical and computational tradeoffs have been investigated under other popular choice models such as the Mallows models by Betzler et al. (2014) or stochastically transitive models by Shah et al. Although, statistical and computational tradeoffs have been investigated under other popular choice models such as the Mallows models by Betzler et al. (2014) or stochastically transitive models by Shah et al. (2015b), the algorithmic solutions do not apply to random utility models and the analysis techniques do not extend. However, it is also known from Azari Soufiani et al. (2014), that for general RUMs there is no consistent rank-breaking, and the proposed approach does not generalize. In a special case when M = 1, this can be transformed into the traditional pairwise rank-breaking, where (i) this is a concave maximization; (ii) the estimate is (asymptotically) unbiased and consistent as shown in Azari Soufiani et al. (2013, 2014); and (iii) and the finite sample complexity have been analyzed in Khetan and Oh (2016). Although, this order-1 rank-breaking provides a significant gain in computational efficiency, the information contained in higher-order edges are unused, resulting in a significant loss in accuracy. As predicted by Azari Soufiani et al. (2014), this results in an inconsistent estimate, whose error does not vanish as we increase the sample size. A similar technique was used to prove concavity when |T (e)| = 1 in Azari Soufiani et al. (2012).",
        "context": "But Condorcet\u2019s probabilistic model assumes identical and independent distributions on pairwise\ncomparisons. This ignores the strength in agents\u2019 preferences (the same probability p is adopted\nfor all pairwise comparisons), and allows for cyclic preferences. In addition, computing the winner\nthrough the Kemeny rule is \u0398P\n2 -complete [13].\nTo overcome the \ufb01rst criticism, a more recent literature adopts the random utility model (RUM)\nfor inferring the order in most cases. The performance in terms of Kendall correlation for recovering\nground truth improves for larger number of agents, which corresponds to more data. See Figure 4,"
    },
    {
        "title": "Generalized method-of-moments for rank aggregation",
        "author": [
            "H. Azari Soufiani",
            "W. Chen",
            "D. C Parkes",
            "L. Xia"
        ],
        "venue": "In Advances in Neural Information Processing Systems",
        "citeRegEx": "Soufiani et al\\.,? \\Q2013\\E",
        "shortCiteRegEx": "Soufiani et al\\.",
        "year": 2013,
        "abstract": "",
        "full_text": "",
        "sentence": "",
        "context": null
    },
    {
        "title": "Computing parametric ranking models via rank-breaking",
        "author": [
            "H. Azari Soufiani",
            "D. Parkes",
            "L. Xia"
        ],
        "venue": "In Proceedings of The 31st International Conference on Machine Learning,",
        "citeRegEx": "Soufiani et al\\.,? \\Q2014\\E",
        "shortCiteRegEx": "Soufiani et al\\.",
        "year": 2014,
        "abstract": "",
        "full_text": "",
        "sentence": " Chen and Suh (2015) introduced Spectral MLE that applies Rank Centrality followed by MLE, and showed that the resulting estimate is optimal in L\u221e error as well as the previously analyzed L2 error. Chen and Suh (2015) introduced Spectral MLE that applies Rank Centrality followed by MLE, and showed that the resulting estimate is optimal in L\u221e error as well as the previously analyzed L2 error. Shah et al. (2015a) study a new measure of the error induced by the Laplacian of the comparisons graph and prove a sharper upper and lower bounds that match up to a constant factor.",
        "context": null
    },
    {
        "title": "Theoretical and empirical evaluation of data reduction for exact kemeny rank aggregation",
        "author": [
            "N. Betzler",
            "R. Bredereck",
            "R. Niedermeier"
        ],
        "venue": "Autonomous Agents and Multi-Agent Systems,",
        "citeRegEx": "Betzler et al\\.,? \\Q2014\\E",
        "shortCiteRegEx": "Betzler et al\\.",
        "year": 2014,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " posed in Ford Jr. (1957) and Hunter (2004), which iteratively finds the fixed point of the KKT condition. posed in Ford Jr. (1957) and Hunter (2004), which iteratively finds the fixed point of the KKT condition. posed in Ford Jr. (1957) and Hunter (2004), which iteratively finds the fixed point of the KKT condition. Negahban et al. (2014) introduce Rank Centrality, a novel spectral ranking algorithm which formulates a random walk from the given data, and show that the stationary distribution provides accurate estimates of the PL weights. posed in Ford Jr. (1957) and Hunter (2004), which iteratively finds the fixed point of the KKT condition. Negahban et al. (2014) introduce Rank Centrality, a novel spectral ranking algorithm which formulates a random walk from the given data, and show that the stationary distribution provides accurate estimates of the PL weights. Maystre and Grossglauser (2015) provide a connection between those previous approaches, and give a unified random walk approach that finds the fixed point of the KKT conditions. posed in Ford Jr. (1957) and Hunter (2004), which iteratively finds the fixed point of the KKT condition. Negahban et al. (2014) introduce Rank Centrality, a novel spectral ranking algorithm which formulates a random walk from the given data, and show that the stationary distribution provides accurate estimates of the PL weights. Maystre and Grossglauser (2015) provide a connection between those previous approaches, and give a unified random walk approach that finds the fixed point of the KKT conditions. On the theoretical side, when samples consist of pairwise comparisons, Simons and Yao (1999) first established consistency and asymptotic normality of the maximum likelihood estimate when all teams play against each other. posed in Ford Jr. (1957) and Hunter (2004), which iteratively finds the fixed point of the KKT condition. Negahban et al. (2014) introduce Rank Centrality, a novel spectral ranking algorithm which formulates a random walk from the given data, and show that the stationary distribution provides accurate estimates of the PL weights. Maystre and Grossglauser (2015) provide a connection between those previous approaches, and give a unified random walk approach that finds the fixed point of the KKT conditions. On the theoretical side, when samples consist of pairwise comparisons, Simons and Yao (1999) first established consistency and asymptotic normality of the maximum likelihood estimate when all teams play against each other. For a broader class of scenarios where we allow for sparse observations, where the number of total comparisons grow linearly in the number of teams, Negahban et al. (2014) show that Rank Centrality achieves optimal sample complexity by comparing it to a lower bound on the minimax rate. posed in Ford Jr. (1957) and Hunter (2004), which iteratively finds the fixed point of the KKT condition. Negahban et al. (2014) introduce Rank Centrality, a novel spectral ranking algorithm which formulates a random walk from the given data, and show that the stationary distribution provides accurate estimates of the PL weights. Maystre and Grossglauser (2015) provide a connection between those previous approaches, and give a unified random walk approach that finds the fixed point of the KKT conditions. On the theoretical side, when samples consist of pairwise comparisons, Simons and Yao (1999) first established consistency and asymptotic normality of the maximum likelihood estimate when all teams play against each other. For a broader class of scenarios where we allow for sparse observations, where the number of total comparisons grow linearly in the number of teams, Negahban et al. (2014) show that Rank Centrality achieves optimal sample complexity by comparing it to a lower bound on the minimax rate. For a more general class of traditional observations, including pairwise comparisons, Hajek et al. (2014) provide similar optimal guarantee for the maximum likelihood estimator.",
        "context": null
    },
    {
        "title": "The tradeoffs of large scale learning",
        "author": [
            "O. Bousquet",
            "L. Bottou"
        ],
        "venue": "In Advances in neural information processing systems,",
        "citeRegEx": "Bousquet and Bottou.,? \\Q2008\\E",
        "shortCiteRegEx": "Bousquet and Bottou.",
        "year": 2008,
        "abstract": "",
        "full_text": "",
        "sentence": " As a solution, recent advances in learning theory introduce hierarchies of algorithmic solutions, ordered by the respective computational complexity, for several fundamental machine learning applications in (Bousquet and Bottou, 2008; Shalev-Shwartz and Srebro, 2008; Chandrasekaran and Jordan, 2013; Agarwal et al., 2012; Lucic et al., 2015). In the application of supervised learning, Bousquet and Bottou (2008) proposed the idea that weaker approximate optimization algorithms are sufficient for learning when more data is available. In the application of supervised learning, Bousquet and Bottou (2008) proposed the idea that weaker approximate optimization algorithms are sufficient for learning when more data is available. Various gradient based algorithms are analyzed that show the time-accuracy-sample tradeoff. In a similar context, Shalev-Shwartz and Srebro (2008) analyze a particular implementation of support vector machine and show that the target accuracy can be achieved faster when more data is available, by running the iterative algorithm for shorter amount of time. In the application of supervised learning, Bousquet and Bottou (2008) proposed the idea that weaker approximate optimization algorithms are sufficient for learning when more data is available. Various gradient based algorithms are analyzed that show the time-accuracy-sample tradeoff. In a similar context, Shalev-Shwartz and Srebro (2008) analyze a particular implementation of support vector machine and show that the target accuracy can be achieved faster when more data is available, by running the iterative algorithm for shorter amount of time. In the application of de-noising, Chandrasekaran and Jordan (2013) provide a hierarchy of convex relaxations where constraints are defined by convex geometry with increasing complexity. In the application of supervised learning, Bousquet and Bottou (2008) proposed the idea that weaker approximate optimization algorithms are sufficient for learning when more data is available. Various gradient based algorithms are analyzed that show the time-accuracy-sample tradeoff. In a similar context, Shalev-Shwartz and Srebro (2008) analyze a particular implementation of support vector machine and show that the target accuracy can be achieved faster when more data is available, by running the iterative algorithm for shorter amount of time. In the application of de-noising, Chandrasekaran and Jordan (2013) provide a hierarchy of convex relaxations where constraints are defined by convex geometry with increasing complexity. For unsupervised learning, Lucic et al. (2015) introduce a hierarchy of data representations that provide more representative elements when more data is available at no additional computation.",
        "context": null
    },
    {
        "title": "Computational and statistical tradeoffs via convex relaxation",
        "author": [
            "V. Chandrasekaran",
            "M.I. Jordan"
        ],
        "venue": "Proceedings of the National Academy of Sciences,",
        "citeRegEx": "Chandrasekaran and Jordan.,? \\Q2013\\E",
        "shortCiteRegEx": "Chandrasekaran and Jordan.",
        "year": 2013,
        "abstract": "In modern data analysis, one is frequently faced with statistical inference\nproblems involving massive datasets. Processing such large datasets is usually\nviewed as a substantial computational challenge. However, if data are a\nstatistician's main resource then access to more data should be viewed as an\nasset rather than as a burden. In this paper we describe a computational\nframework based on convex relaxation to reduce the computational complexity of\nan inference procedure when one has access to increasingly larger datasets.\nConvex relaxation techniques have been widely used in theoretical computer\nscience as they give tractable approximation algorithms to many computationally\nintractable tasks. We demonstrate the efficacy of this methodology in\nstatistical estimation in providing concrete time-data tradeoffs in a class of\ndenoising problems. Thus, convex relaxation offers a principled approach to\nexploit the statistical gains from larger datasets to reduce the runtime of\ninference algorithms.",
        "full_text": "arXiv:1211.1073v2  [math.ST]  26 Nov 2012\nComputational and Statistical Tradeo\ufb00s via Convex Relaxation\nVenkat Chandrasekaranc and Michael I. Jordanb \u2217\nc Department of Computing and Mathematical Sciences\nCalifornia Institute of Technology\nPasadena, CA 91125 USA\nb Departments of Statistics and of Electrical Engineering and Computer Sciences\nUniversity of California \u2013 Berkeley\nBerkeley, CA 94720 USA\nNovember 26, 2012\nAbstract\nIn modern data analysis, one is frequently faced with statistical inference problems involving\nmassive datasets. Processing such large datasets is usually viewed as a substantial computational\nchallenge. However, if data are a statistician\u2019s main resource then access to more data should be\nviewed as an asset rather than as a burden. In this paper we describe a computational framework\nbased on convex relaxation to reduce the computational complexity of an inference procedure\nwhen one has access to increasingly larger datasets. Convex relaxation techniques have been\nwidely used in theoretical computer science as they give tractable approximation algorithms to\nmany computationally intractable tasks. We demonstrate the e\ufb03cacy of this methodology in\nstatistical estimation in providing concrete time-data tradeo\ufb00s in a class of denoising problems.\nThus, convex relaxation o\ufb00ers a principled approach to exploit the statistical gains from larger\ndatasets to reduce the runtime of inference algorithms.\nKeywords: massive datasets; high-dimensional statistics; convex relaxation; convex geometry\nIntroduction\nThe rapid growth in the size and scope of datasets in science and technology has created a need\nfor novel foundational perspectives on data analysis that blend computer science and statistics.\nThat classical perspectives from these \ufb01elds are not adequate to address emerging problems in\n\u201cBig Data\u201d is apparent from their sharply divergent nature at an elementary level\u2014in computer\nscience, the growth of the number of data points is a source of \u201ccomplexity\u201d that must be tamed via\nalgorithms or hardware, whereas in statistics, the growth of the number of data points is a source\nof \u201csimplicity\u201d in that inferences are generally stronger and asymptotic results can be invoked. In\nclassical statistics, where one considers the increase in inferential accuracy as the number of data\npoints grows, there is little or no consideration of computational complexity. Indeed, if one imposes\nthe additional constraint\u2014prevalent in real-world applications\u2014that a certain level of inferential\naccuracy be achieved within a limited time budget, classical theory provides no guidance as to how\n\u2217Email: venkatc@caltech.edu, jordan@cs.berkeley.edu\n1\nto design an inferential strategy.1 In classical computer science, practical solutions to large-scale\nproblems are often framed in terms of approximations to idealized problems, but even when such\napproximations are sought, they are rarely expressed in terms of the coin of the realm of the theory\nof inference\u2014the statistical risk function. Thus there is little or no consideration of the idea that\ncomputation can be simpli\ufb01ed in large datasets because of the enhanced inferential power in the\ndata. In general, in computer science, datasets are not viewed formally as a resource on a par with\ntime and space (such that the more of the resource the better).\nOn intuitive grounds it is not implausible that strategies can be designed that yield mono-\ntonically improving risk as data accumulate, even in the face of a time budget. In particular, if\nan algorithm simply ignores all future data once a time budget is exhausted, then statistical risk\nwill not increase (under various assumptions that may not be desirable in practical applications).\nAlternatively, one might allow linear growth in the time budget (for example, in a real-time set-\nting), and attempt to achieve such growth via a subsampling strategy where some fraction of the\ndata are dropped. Executing such a strategy may be di\ufb03cult, however, in that the appropriate\nfraction depends on the risk function and thus on a mathematical analysis that may be di\ufb03cult to\ncarry out. Moreover, subsampling is a limited strategy for controlling computational complexity.\nMore generally, one would like to consider some notion of \u201calgorithm weakening,\u201d where as data\naccumulate one can back o\ufb00to simpler algorithmic strategies that nonetheless achieve a desired\nrisk. The challenge is to do this in a theoretically sound manner.\nWe base our approach to this problem on the notion of a \u201ctime-data complexity class.\u201d In\nparticular, we de\ufb01ne a class TD(t(p), n(p), \u01eb(p)) of parameter estimation problems in which a p-\ndimensional parameter underlying an unknown population can be estimated with a risk of \u01eb(p)\ngiven n(p) i.i.d. samples using an inference procedure with runtime t(p). Our de\ufb01nition parallels\nthe de\ufb01nition of the TISP complexity class in computational complexity theory for describing\nalgorithmic tradeo\ufb00s between time and space resources [4]. In this formalization, classical results\nin estimation theory can be viewed as emphasizing the tradeo\ufb00s between the second and third\nparameters (amount of data and risk). Our focus in this paper is to \ufb01x \u01eb(p) to some desired level\nof accuracy and to investigate the tradeo\ufb00s between the \ufb01rst two parameters, namely runtime and\ndataset size.\nAlthough classical statistics gave little consideration to computational complexity, computa-\ntional issues have come increasingly to the fore in modern \u201chigh-dimensional statistics\u201d [13], where\nthe number of parameters p is relatively large and the number of data points n relatively small. In\nthis setting, methods based on convex optimization have been emphasized (in particular methods\nbased on \u21131 penalties). This is due in part to the favorable analytic properties of convex functions\nand convex sets, but also due to the fact that such methods tend to have favorable computational\nscaling. However, the treatment of computation has remained informal, with no attempt to char-\nacterize tradeo\ufb00s between computation time and estimation quality. In our work we aim explicitly\nat such tradeo\ufb00s, in the setting in which both n and p are large.\nTo develop a notion of \u201calgorithm weakening\u201d that combines computational and statistical con-\nsiderations, we consider estimation procedures for which we can characterize the computational\nbene\ufb01ts as well as the loss in estimation performance due to the use of weaker algorithms. Re\ufb02ect-\ning the fact that the space of all algorithms is poorly understood, we retain the focus on convex\noptimization from high-dimensional statistics, but we consider parameterized hierarchies of opti-\nmization procedures in which a form of algorithm weakening is obtained by employing successively\n1Note that classical statistics contains a branch known as sequential analysis that does discuss methods that\nstop collecting data points after a target error level has been reached (see, e.g., [35]), but this is di\ufb00erent from the\ncomputational complexity guarantees (the number of steps that a computational procedure requires) that are our\nfocus.\n2\nweaker outer approximations to convex sets. Such convex relaxations have been widely used to\ngive e\ufb03cient approximation algorithms for intractable problems in computer science [53]. As we\nwill discuss, a precise characterization of both the estimation performance and the computational\ncomplexity of employing a particular relaxation of a convex set can be obtained by appealing to\nconvex geometry and to results on the complexity of solving convex programs. Speci\ufb01cally, the\ntighter relaxations in these families o\ufb00er better approximation quality (and in our context better\nestimation performance) but such relaxations are computationally more complex. On the other\nhand the weaker relaxations are computationally more tractable, and they can provide the same\nestimation performance as the tighter ones but with access to more data. In this manner, convex\nrelaxations provide a principled mechanism to weaken inference algorithms in order to reduce the\nruntime in processing larger datasets.\nTo demonstrate explicit tradeo\ufb00s in high-dimensional, large-scale inference, we focus for sim-\nplicity and concreteness on estimation in sequence models [31]:\ny = x\u2217+ \u03c3z,\n(1)\nwhere \u03c3 > 0, the noise vector z \u2208Rp is standard normal, and the unknown parameter x\u2217belongs\nto a known subset S \u2282Rp. The objective is to estimate x\u2217based on n independent observations\n{yi}n\ni=1 of y. This denoising setup has a long history and has been at the center of some remarkable\nresults in the high-dimensional setting over the past two decades beginning with the papers of\nDonoho and Johnstone [17, 19]. The estimators discussed next proceed by \ufb01rst computing the\nsample mean \u00afy = Pn\ni=1 yi and then using \u00afy as input to a suitable convex program. Of course, this\nis equivalent to a denoising problem in which the noise variance is \u03c32/n and we are given just one\nsample. The reason we consider the elaborate two-step procedure is to account more accurately\nboth for data aggregation and for subsequent processing in our runtime calculations. Indeed, in a\nreal-world setting one is typically faced with a massive dataset in unaggregated form, and when\nboth p and n may be large, summarizing the data before any further processing can itself be an\nexpensive computation. As will be seen in concrete calculations of time-data tradeo\ufb00s, the number\nof operations corresponding to data aggregation is sometimes comparable to or even larger than\nthe number of operations required for subsequent processing in a massive data setting.\nIn order to estimate x\u2217, we consider the following natural shrinkage estimator given by a pro-\njection of the sample mean \u00afy onto a convex set C that is an outer approximation to S, i.e., S \u2282C:\n\u02c6xn(C) = arg min\nx\u2208Rp\n1\n2 \u2225\u00afy \u2212x\u22252\n\u21132\ns.t.\nx \u2208C.\n(2)\nWe study the estimation performance of a family of shrinkage estimators {\u02c6xn(Ci)} that employ as\nthe convex constraint one of a sequence of convex outer approximations {Ci} with C1 \u2283C2 \u2283\u00b7 \u00b7 \u00b7 \u2283S.\nGiven the same number of samples, using a weaker relaxation such as C1 leads to an estimator with\na larger risk than would result from using a tighter relaxation such as C2. On the other hand, given\naccess to more data samples the weaker approximations provide the same estimation guarantees\nas the tighter ones.\nIn settings in which computing a weaker approximation is more tractable\nthan computing a tighter one, a natural computation/sample tradeo\ufb00arises. We characterize this\ntradeo\ufb00in a number of stylized examples, motivated by problems such as collaborative \ufb01ltering,\nlearning an ordering of a collection of random variables, and inference in networks.\nMore broadly, this paper highlights the role of computation in estimation by jointly studying\nboth the computational and the statistical aspects of high-dimensional inference. Such an under-\nstanding is particularly of interest in modern inferential tasks in data-rich settings. Further, an\nobservation from our examples on time-data tradeo\ufb00s is that in many contexts one does not need\n3\ntoo many extra data samples in order to go from a computationally ine\ufb03cient estimator based on\na tight relaxation to an extremely e\ufb03cient estimator based on a weaker relaxation. Consequently,\nin application domains in which obtaining more data is not too expensive it may be preferable to\nacquire more data with the upshot being that the computational infrastructure can be relatively\nless sophisticated.\nWe should note that we investigate only one algorithm weakening mechanism, namely convex\nrelaxation, and one class of statistical estimation problems, namely denoising in a high-dimensional\nsequence model. There is reason to believe, however, that the principles described in this paper are\nrelevant more generally. Convex-optimization-based procedures are employed in a variety of large-\nscale data analysis tasks [11, 13], and it is likely to be interesting to explore hierarchies of convex\nrelaxations in such tasks. In addition, there are a number of potentially interesting mechanisms\nbeyond convex relaxation for weakening inference procedures such as dimensionality reduction or\nother forms of data quantization, and approaches based on clustering or coresets. We discuss these\nand other research directions in the Conclusions.\nRelated work\nA number of papers have considered computational and sample complexity trade-\no\ufb00s in the setting of learning binary classi\ufb01ers. Speci\ufb01cally, several authors have described settings\nunder which speedups in running time of a classi\ufb01er learning algorithm are possible given a sub-\nstantial increase in dataset size [48, 16, 47].\nIn contrast, in the denoising setup considered in\nthis paper, several of our examples of time-data tradeo\ufb00s demonstrate signi\ufb01cant computational\nspeedups with just a constant factor increase in dataset size. Another attempt in the binary clas-\nsi\ufb01er learning setting, building on earlier work on classi\ufb01er learning in data-rich problems [10], has\nshown that modest improvements in runtime (of constant factors) may be possible with access to\nmore data by employing the stochastic gradient descent method [49]. Time-data tradeo\ufb00s have also\nbeen characterized in Boolean network training from time series data [42], but the computational\nspeedups o\ufb00ered there are from exponential-time algorithms to slightly faster but still exponential-\ntime algorithms. Two recent papers [3, 34] have considered time-data tradeo\ufb00s in sparse principal\ncomponent analysis (PCA) and in biclustering, in which a sparse rank-one matrix is corrupted by\nnoise and the objective is to recover the support of the matrix. We also study time-data tradeo\ufb00s in\nthe estimation of a sparse rank-one matrix, but from a denoising perspective. In our discussion of\nExample 3 below we discuss the di\ufb00erences between our problem setup and these latter two papers.\nAs a general contrast to all these previous results, a major contribution of the present paper is the\ndemonstration of the e\ufb03cacy of convex relaxation as a powerful algorithm weakening mechanism\nfor processing massive datasets in a broad range of settings.\nPaper outline\nThe main sections of this paper proceed in the following sequence. The next\nsection describes a framework for formally stating results on time-data tradeo\ufb00s. Then we provide\nsome background on convex optimization and relaxations of convex sets. Following this we inves-\ntigate in detail the denoising problem (1), and characterize the risk obtained when one employs a\nconvex programming estimator of the type (2). Subsequently, we give several examples of time-data\ntradeo\ufb00s in concrete denoising problems. Finally, we conclude with a discussion of directions for\nfurther research.\nFormally Stating Time-Data Tradeo\ufb00s\nIn this section we describe a framework to state results on computational and statistical tradeo\ufb00s\nin estimation. Our discussion is relevant to general parameter estimation problems and inference\n4\nFigure 1: The tradeo\ufb00plot between the runtime and sample complexity in a typical parameter\nestimation problem. Here the risk is assumed to be \ufb01xed to some desired level, and the points\nin the plot refer to di\ufb00erent algorithms that require a certain runtime and a certain number of\nsamples in order to achieve the desired risk. The vertical and horizontal lines refer to lower bounds\nin sample complexity and in runtime, respectively.\nprocedures; one may keep in mind the denoising problem (1) for concreteness. Consider a sequence\nof estimation problems indexed by the dimension p of the parameter to be estimated. Fix a risk\nfunction \u01eb(p) that speci\ufb01es the desired error of an estimator. For example, in the denoising problem\n(1) the error of an estimator of the form (2) may be speci\ufb01ed as the worst case mean squared error\ntaken over all elements of the set S, i.e., supx\u2217\u2208S E\n\u0002\n\u2225x\u2217\u2212\u02c6xn(C)\u22252\n\u21132\n\u0003\n.\nOne can informally view an estimation algorithm that achieves a risk of \u01eb(p) by processing n(p)\nsamples with runtime t(p) as a point on a two-dimensional plot such as Figure 1, with one axis\nrepresenting the runtime and the other representing the sample complexity. To be precise the axes\nin the plot index functions (of p) that represent runtime and number of samples, but we do not\nemphasize such formalities and rather use these plots to provide a useful qualitative comparison of\ninference algorithms. In Figure 1, procedure A requires fewer samples than procedure C to achieve\nthe same error, but this reduction in sample complexity comes at the expense of a larger runtime.\nProcedure B has both a larger sample complexity and a larger runtime than procedure C, and thus\nit is strictly dominated by procedure C.\nGiven an error function \u01eb(p), there is a lower bound on the number of samples n(p) re-\nquired to achieve this error using any computational procedure (i.e., no constraints on t(p))\u2014such\ninformation-theoretic or minimax risk lower bounds correspond to \u201cvertical lines\u201d in the plot in\nFigure 1. Characterizing these fundamental limits on sample complexity has been a traditional\nfocus in the estimation theory literature with a fairly complete set of results available in many set-\ntings. One can imagine asking for similar lower bounds on the computational side, corresponding\nto \u201chorizontal\u201d lines in the plot in Figure 1\u2014given a desired risk \u01eb(p) and access to an unbounded\nnumber of samples, what is a non-trivial lower bound on the runtime t(p) of any inference algo-\nrithm that achieves a risk of \u01eb(p)? Such complexity-theoretic lower bounds are signi\ufb01cantly harder\nto obtain, and they remain a central open problem in computational complexity theory.\nThis research landscape informs the qualitative nature of the statements on time-data tradeo\ufb00s\nwe make in this paper. First, we will not attempt to prove combined lower bounds\u2014as is tradition-\nally done in the characterization of tradeo\ufb00s between physical quantities\u2014involving n(p) and t(p)\njointly; this is because obtaining a lower bound just on t(p) remains a substantial challenge. Hence,\nour time-data tradeo\ufb00results on the use of more e\ufb03cient algorithms for larger datasets refer to a\nreduction in the upper bounds on runtimes of estimation procedures with increases in dataset size.\n5\nSecond, in any setting in which there is a computational cost associated with touching each data\nsample and in which the samples are exchangeable, there is a sample threshold beyond which it\nis computationally more e\ufb03cient to throw away excess data samples than to process them in any\nform. This observation suggests that there is a \u201c\ufb02oor,\u201d as in Figure 1 with procedures E, F, G and\nH, beyond which additional data do not lead to a reduction in runtime. Precisely characterizing\nthis sample threshold is in general very hard as it depends on di\ufb03cult-to-obtain computational\nlower bounds for estimation tasks and also on the particular space of estimation algorithms that\none may employ. We will comment further on this point when we consider concrete examples of\ntime-data tradeo\ufb00s.\nIn order to formally state our results concerning time-data tradeo\ufb00s, we de\ufb01ne a resource class\nconstrained by runtime and sample complexity as follows.\nDe\ufb01nition 1. Consider a sequence of parameter estimation problems indexed by the dimension\np of the space of parameters that index an underlying population.\nThis sequence of estimation\nproblems belongs to a time-data class TD(t(p), n(p), \u01eb(p)) if there exists an inference procedure for\nthe sequence of problems with runtime upper-bounded by t(p), with the number of i.i.d. samples\nprocessed bounded by n(p), and which achieves a risk bounded by \u01eb(p).\nWe note that our de\ufb01nition of a time-data resource class parallels the time-space resource classes\nconsidered in complexity theory [4]\u2014in that literature TISP(t(p), s(p)) denotes a class of problems\nof input size p that can be solved by some algorithm using t(p) operations and utilizing s(p) units\nof space.\nWith this formalism, classical minimax bounds can be stated as follows. Given some function\n\u00afn(p) for the number of samples, suppose a parameter estimation problem has a minimax risk of\n\u01ebminimax(p) (which depends on the function \u00afn(p)). If an estimator achieving a risk of \u01ebminimax(p)\nis computable with runtime \u00aft(p), then this estimation problem lies in TD(\u00aft(p), \u00afn(p), \u01ebminimax(p)).\nThus the emphasis is fundamentally on the relationship between \u00afn(p) and \u01ebminimax(p), without\nmuch focus on the computational procedure that achieves the minimax risk bound. Our interest\nin this paper is to \ufb01x the risk \u01eb(p) = \u01ebdesired(p) to be equal to some desired level of accuracy, and\nto investigate the tradeo\ufb00s between t(p) and n(p) so that a parameter estimation problem lies in\nTD(t(p), n(p), \u01ebdesired(p)).\nConvex Relaxation\nIn this section we describe the particular algorithmic toolbox on which we focus, namely convex\nprograms. Convex optimization methods o\ufb00er a powerful framework for statistical inference due to\nthe broad class of estimators that can be e\ufb00ectively modeled as convex programs. Further the theory\nof convex analysis is useful both for characterizing the statistical properties of convex programming\nbased estimators as well as for developing methods to compute such estimators e\ufb03ciently. Most\nimportantly from our viewpoint, convex optimization methods provide a principled and general\nframework for algorithm weakening based on relaxations of convex sets. We brie\ufb02y discuss the key\nideas from this literature that are relevant to this paper in this section. A central notion to the\ngeometric viewpoint adopted in this section is that of a convex cone, which is a convex set that is\nclosed under nonnegative linear combinations.\nRepresentation of Convex Sets\nConvex programs refer to a class of optimization problems in which we seek to minimize a convex\nfunction over a convex constraint set [11]. For example linear programming and semide\ufb01nite pro-\n6\ngramming are two prominent subclasses in which linear functions are minimized over constraint\nsets given by a\ufb03ne spaces intersecting the nonnegative orthant (in linear programming) and the\npositive semide\ufb01nite cone (in semide\ufb01nite programming). Roughly speaking convex programs are\ntractable to solve computationally if the convex objective function can be computed e\ufb03ciently, and\nif membership in the convex constraint sets can be certi\ufb01ed e\ufb03ciently2; we will informally refer\nto this latter operation as computing the convex constraint set. It is then clear that the main\ncomputational bottleneck associated with solving convex programs of the form (2) is the e\ufb03ciency\nof computing the constraint sets.\nA central insight from the literature on convex optimization is that the complexity of computing\na convex set is closely linked to how e\ufb03ciently the set can be represented. Speci\ufb01cally, if a convex\nset can be expressed as the intersection of a small number of \u201cbasic\u201d or \u201celementary\u201d convex sets,\neach of which is tractable to compute, then the original convex set is also tractable to compute and\none can in turn optimize over this set e\ufb03ciently. Examples of \u201cbasic\u201d convex sets include a\ufb03ne\nspaces or cones such as the nonnegative orthant and the cone of positive semide\ufb01nite matrices.\nIndeed, a canonical method to represent a convex set is to express the set as the intersection of a\ncone and an a\ufb03ne space. In what follows we will consider such conic representations of convex sets\nin Rp.\nDe\ufb01nition 2. Let C \u2208Rp be a convex set and let K \u2208Rp be a convex cone. Then C is said to be\nK-representable if C can be expressed as follows for A \u2208Rm\u00d7p, b \u2208Rm:\nC = {x|x \u2208K, Ax = b}.\n(3)\nSuch a representation of C is called a K-representation.\nInformally, if K is the nonnegative orthant (or the semide\ufb01nite cone) we will refer to the re-\nsulting representations as LP representations (or SDP representations), following commonly used\nterminology in the literature. A virtue of conic representations of convex sets based on the orthant\nor the semide\ufb01nite cone is that these representations lead to a numerical recipe for solving convex\noptimization problems of the form (2) via a natural associated barrier penalty [38]. The compu-\ntational complexity of these procedures is polynomial in the dimension of the cone and we discuss\nruntimes for speci\ufb01c instances in our discussion of concrete examples of time-data tradeo\ufb00s.\nExample 1. The p-dimensional simplex is an example of an LP representable set:\n\u2206p = {x|1\u2032x = 1, x \u22650},\n(4)\nwhere 1 \u2208Rp is the all ones vector.\nThe p-simplex is the set of probability vectors in Rp. The next example is one of an SDP-\nrepresentable set that is commonly encountered both in optimization and in statistics.\nExample 2. The elliptope, or the set of correlation matrices, in the space of m \u00d7 m symmetric\nmatrices is de\ufb01ned as follows:\nEm\u00d7m = {X|X \u2ab00, Xii = 1 \u2200i}.\n(5)\n2More precisely, one requires an e\ufb03cient separation oracle that responds YES if the point is in the convex set,\nand otherwise provides a hyperplane that separates the point from the convex set.\n7\nConic representations are somewhat limited in their modeling capacity, and an important gener-\nalization is obtained by considering lifted representations. In particular the notion of lift-and-project\nplays a critical role in many examples of e\ufb03cient representations of convex sets. The lift-and-project\nconcept is simple\u2014we wish to express a convex set C \u2208Rp as the projection of a convex set C\u2032 \u2208Rp\u2032\nin some higher-dimensional space (i.e., p\u2032 > p). The complexity of solving the associated convex\nprograms is now a function of the lifting dimension p\u2032. Thus, lift-and-project techniques are useful\nif p\u2032 is not too much larger than p and if C\u2032 has an e\ufb03cient representation in the higher-dimensional\nspace Rp\u2032. Lift-and-project provides a very powerful representation tool, as seen in the following\nexample.\nExample 3. The cross-polytope is the unit ball of the \u21131-norm:\nBp\n\u21131 =\n(\nx \u2208Rp |\nX\ni\n|xi| \u22641\n)\n.\nThe \u21131-norm has been the focus of much attention recently in statistical model selection and feature\nselection due to its sparsity-inducing properties [14, 18]. While the cross-polytope has 2p vertices,\na direct speci\ufb01cation in terms of linear constraints involves 2p inequalities:\nBp\n\u21131 =\n(\nx \u2208Rp |\nX\ni\nzixi \u22641, \u2200z \u2208{\u22121, +1}p\n)\n.\nHowever we can obtain a tractable representation by lifting to R2p and then projecting onto the \ufb01rst\np coordinates:\nBp\n\u21131 =\n(\nx \u2208Rp | \u2203z \u2208Rp s.t. \u2212zi \u2264xi \u2264zi \u2200i,\nX\ni\nzi \u22641\n)\n.\nNote that in R2p with the additional variables z, we have only 2p + 1 inequalities.\nAnother example of a polytope that requires many inequalities in a direct description is the\npermutahedron [54]\u2014the convex hull of all the permutations of the vector [1, . . . , p]\u2032 \u2208Rp. In fact\nthe permutahedron requires exponentially many linear inequalities in a direct description, while a\nlifted representation involves O(p log(p)) additional variables and about O(p log(p)) inequalities in\nthe higher-dimensional space [25]. We refer the reader to the literature on conic representations for\nother examples (see [27] and the references therein), including lifted semide\ufb01nite representations.\nHierarchies of Convex Relaxations\nIn many cases of interest, convex sets may not have tractable representations. Lifted representations\nin such cases have lifting dimensions that are super-polynomially large in the dimension of the\noriginal convex set, and thus the associated numerical techniques lead to intractable computational\nprocedures that have super-polynomial runtime with respect to the dimension of the original set.\nA prominent example of a convex set that is di\ufb03cult to compute is the cut polytope:\nCUTm\u00d7m = conv{mm\u2032 | m \u2208{\u22121, +1}m}.\n(6)\nRank-one signed matrices and their convex combinations are of interest in collaborative \ufb01ltering and\nclustering problems (see the section on time-data tradeo\ufb00s). There is no known tractable represen-\ntation of the cut polytope\u2014lifted linear or semide\ufb01nite representations have lifting dimensions that\n8\nare super-polynomial in size. Such computational issues have led to a large literature on approxi-\nmating intractable convex sets by tractable ones. For the purposes of this paper, and following the\ndominant trend in the literature, we focus on outer approximations. For example, the elliptope (5)\nis an outer relaxation of the cut polytope, and it has been employed in approximation algorithms\nfor intractable combinatorial optimization problems such as \ufb01nding the maximum-weight cut in a\ngraph [26]. More generally, one can imagine a hierarchy of increasingly tighter approximations {Ci}\nof a convex set C as follows:\nC \u2286\u00b7 \u00b7 \u00b7 \u2286C3 \u2286C2 \u2286C1.\nThere exist several mechanisms for deriving such hierarchies, and we describe three frameworks\nhere.\nIn the \ufb01rst framework, which was developed by Sherali and Adams [50], the set C is assumed\nto be polyhedral and each element of the family {Ci} is also polyhedral. Speci\ufb01cally, each Ci is\nexpressed via a lifted LP representation.\nTighter approximations are obtained by resorting to\nlarger-sized lifts so that the lifting dimension increases with the level i in the hierarchy.\nThe\nsecond framework is similar in spirit to the \ufb01rst one, but now the set C is a convex basic, closed\nsemialgebraic set3 and the approximations {Ci} are given by lifted SDP representations. Again the\nlifting dimension increases with the level i in the hierarchy. This method was initially pioneered\nby Parrilo [40, 41] and by Lasserre [36], and it was studied in greater detail subsequently by\nGouveia et al. [28]. Both these \ufb01rst and second frameworks are similar in spirit in that tighter\napproximations are obtained by via lifted representations with successively larger lifting dimensions.\nThe third framework we mention here is qualitatively di\ufb00erent from the \ufb01rst two. Suppose C is a\nconvex set that has a K-representation\u2014by successively weakening the cone K itself one obtains\nincreasingly weaker approximations to C. Speci\ufb01cally, we consider the setting in which the cone\nK is a hyperbolicity cone [43]. Such cones have rich geometric and algebraic structure, and their\nboundary is given in terms of the vanishing of hyperbolic polynomials. They include the orthant\nand the semide\ufb01nite cone as special cases. We do not go into further technical details and formal\nde\ufb01nitions of these cones here, and instead refer the interested reader to [43]. The main idea is\nthat one can obtain a family of relaxations {Ki} to a hyperbolicity cone K \u2286Rp where each Ki is\na convex cone (in fact, hyperbolic) and is a subset of Rp:\nK \u2286\u00b7 \u00b7 \u00b7 \u2286K3 \u2286K2 \u2286K1.\n(7)\nThese outer conic approximations are obtained by taking certain derivatives of the hyperbolic\npolynomial used to de\ufb01ne the original cone K\u2014see [43] for more details. One then constructs a\nhierarchy of approximations {Ci} to C by replacing the cone K in the representation of C by the\nfamily of conic approximations {Ki}. From (3) and (7) it is clear that the {Ci} so de\ufb01ned satisfy\nC \u2286\u00b7 \u00b7 \u00b7 \u2286C3 \u2286C2 \u2286C1.\nThe important point in these three frameworks is that the family of approximations {Ci} ob-\ntained in each case is ordered both by approximation quality as well as by computational complexity;\nthat is, the weaker approximations in the hierarchy are also the ones that are more tractable to\ncompute. This observation leads to an algorithm weakening mechanism that is useful for processing\nlarger datasets more coarsely. As demonstrated concretely in the next section, the estimator (2)\nbased on a weaker approximation to C can provide the same statistical performance as one based\non a stronger approximation to C provided the former estimator is evaluated with more data. The\nupshot is that the \ufb01rst estimator is more tractable to compute than the second. Thus, we obtain\na technique for reducing the runtime required to process a larger dataset.\n3A basic, closed semialgebraic set is the collection of solutions of a system of polynomial equations and polynomial\ninequalities [9].\n9\nEstimation via Convex Optimization\nIn this section we investigate the statistical properties of the estimator (2) for the denoising problem\n(1). The signal set S in (1) di\ufb00ers based on the application of interest. For example S may be the set\nof sparse vectors in a \ufb01xed basis, which could correspond to the problem of denoising sparse vectors\nin wavelet bases [17]. The signal set S may be the set of low-rank matrices, which leads to problems\nof collaborative \ufb01ltering [52]. Finally, S may be a set of permutation matrices corresponding to\nrankings over a collection of items. Our analysis in this section is general, and is applicable to\nthese and other settings (see the section on time-data tradeo\ufb00s for concrete examples). In some\ndenoising problems, one is interested in noise models other than Gaussian. We comment on the\nperformance of the estimator (2) in settings with non-Gaussian noise, although we primarily focus\non the Gaussian case for simplicity.\nConvex Programming Estimators\nIn order to analyze the performance of the estimator (2), we introduce a few concepts from convex\nanalysis [44]. Given a closed convex set C \u2208Rp and a point a \u2208C we de\ufb01ne the tangent cone at a\nwith respect to C as\nTC(a) = cone{b \u2212a | b \u2208C}.\n(8)\nHere cone(\u00b7) refers to the conic hull of a set obtained by taking nonnegative linear combinations of\nelements of the set. The cone TC(a) is the set of directions to points in C from the point a. The\npolar K\u2217\u2286Rp of a cone K \u2286Rp is the cone\nK\u2217= {h \u2208Rp | \u27e8h, d\u27e9\u22640 \u2200d \u2208K}.\nThe normal cone NC(a) at a with respect to the convex set C is the polar cone of the tangent cone\nTC(a):\nNC(a) = TC(a)\u2217.\n(9)\nThus, the normal cone consists of vectors that form an obtuse angle with every vector in the tangent\ncone TC(x). Both the tangent and normal cones are convex cones.\nA key quantity that will appear in our error bounds is the following notion of the \u201ccomplexity\u201d\nor \u201csize\u201d of a tangent cone:\nDe\ufb01nition 3. The Gaussian squared-complexity of a set D \u2208Rp is de\ufb01ned as:\ng(D) = E\n\u0014\nsup\na\u2208D\n\u27e8a, g\u27e92\n\u0015\n,\nwhere the expectation is with respect to g \u223cN(0, Ip\u00d7p).\nThis quantity is closely related to the Gaussian complexity of a set [20, 5] which consists of\nno squaring of the term inside the expectation. The Gaussian squared-complexity shares many\nproperties in common with the Gaussian complexity, and we describe those that are relevant to\nthis paper in the next subsection. Speci\ufb01cally, we discuss methods to estimate this quantity for\nsets D that have some structure.\nWith these de\ufb01nitions and letting Bp\n\u21132 denote the \u21132 ball in Rp, we have the following result on\nthe error between \u02c6xn(C) and x\u2217:\nProposition 4. For x\u2217\u2208S \u2282Rp and with C \u2286Rp convex such that S \u2286C, we have the error\nbound\nE\n\u0002\n\u2225x\u2217\u2212\u02c6xn(C)\u22252\n\u21132\n\u0003\n\u2264\u03c32\nn g(TC(x\u2217) \u2229Bp\n\u21132).\n10\nProof: We have that \u00afy = x\u2217+\n\u03c3\n\u221anz.\nWe begin by establishing a bound that is derived by\nconditioning on z = \u02dcz. Subsequently, taking expectations concludes the proof. We have from the\noptimality conditions [44] of the convex program (2) that\nx\u2217+ \u03c3\nn\u02dcz \u2212\u02c6xn(C)|z=\u02dcz \u2208NC(\u02c6xn(C)|z=\u02dcz).\nHere \u02c6xn(C)|z=\u02dcz represents the optimal value of (2) conditioned on z = \u02dcz. As x\u2217\u2208S \u2286C, we have\nthat x\u2217\u2212\u02c6xn(C)|z=\u02dcz \u2208TC(\u02c6xn(C)|z=\u02dcz). Since the normal and tangent cones are polar to each other,\nwe have that\n\u27e8x\u2217+\n\u03c3\n\u221an\u02dcz \u2212\u02c6xn(C)|z=\u02dcz, x\u2217\u2212\u02c6xn(C)|z=\u02dcz\u27e9\u22640.\nIt then follows that\n\u2225x\u2217\n\u2212\n\u02c6xn(C)|z=\u02dcz\u22252\n\u21132\n\u2264\n\u03c3\n\u221an \u27e8\u02c6xn(C)|z=\u02dcz \u2212x\u2217, \u02dcz\u27e9\n=\n\u03c3\n\u221an\u2225\u02c6xn(C)|z=\u02dcz \u2212x\u2217\u2225\u21132\n\u001c\n\u02c6xn(C)|z=\u02dcz \u2212x\u2217\n\u2225\u02c6xn(C)|z=\u02dcz \u2212x\u2217\u2225\u21132\n, \u02dcz\n\u001d\n\u2264\n\u03c3\n\u221an\u2225\u02c6xn(C)|z=\u02dcz \u2212x\u2217\u2225\u21132\n\"\nsup\nd\u2208TC(x\u2217),\u2225d\u2225\u21132\u22641\n\u27e8d, \u02dcz\u27e9\n#\n.\nDividing both sides by \u2225\u02c6xn(C)|z=\u02dcz \u2212x\u2217\u2225\u21132, then squaring both sides, and \ufb01nally taking expectations\ncompletes the proof. \u25a1\nNote that the basic structure of the error bound provided by the estimator (2) in fact holds for\nan arbitrary distribution on the noise z with the Gaussian squared-complexity suitably modi\ufb01ed.\nHowever, we focus for the rest of this paper on the Gaussian case, z \u223cN(0, Ip\u00d7p).\nTo summarize in words, the mean squared error is bounded by the noise variance times the\nGaussian squared-complexity of the normalized tangent cone with respect to C at the true parameter\nx\u2217. Essentially it measures the amount of noise restricted to the tangent cone, which is intuitively\nreasonable as only the noise that moves one away from x\u2217in a feasible direction in C must contribute\ntowards the error. Therefore, if the convex constraint set C is \u201csharp\u201d at x\u2217so that the cone TC(x\u2217)\nis \u201cnarrow,\u201d then the error is small. At the other extreme, if the constraint set C = Rp then the\nerror is \u03c32\nn p as one would expect.\nWhile Proposition 4 is useful and indeed it will su\ufb03ce for the purposes of demonstrating time-\ndata tradeo\ufb00s in the next section, there are a couple of shortcomings in the result as stated.\nFirst, suppose the signal set S is contained in a ball around the origin with the radius of the ball\nbeing small relative to the noise variance \u03c32\nn . In such a setting, the estimator \u02c6x = 0 leads to a\nsmaller mean squared error than one would obtain from Proposition 4. Second, and somewhat\nmore subtly, suppose that one doesn\u2019t have a perfect bound on the size of the signal set.\nFor\nconcreteness, consider a setting in which S is a set of sparse vectors with bounded \u21131 norm, in\nwhich case a good choice for the constraint set C in the estimator (1) is an appropriately scaled\n\u21131 ball. However, if we do not know the \u21131 norm of x\u2217a priori, then we may end up employing a\nconstraint set C such that x\u2217does not belong to C (so x\u2217is an infeasible solution) or that x\u2217lies\nstrictly in the interior of C (hence, TC(x\u2217) is all of Rp). Both these situations are undesirable as\nthey limit the applicability of Proposition 4 and provide very loose error bounds. The following\nresult addresses these shortcomings by weakening the assumptions of Proposition 4:\nProposition 5. Let x\u2217\u2208S \u2282Rp and let C \u2286Rp. Suppose there exists a point \u02dcx \u2208C such that\nC \u2212\u02dcx = Q1 \u2295Q2, with Q1, Q2 lying in orthogonal subspaces of Rp and Q2 \u2286\u03b1Bp\n\u21132 for \u03b1 \u22650. Then\n11\nwe have that\nE\n\u0002\n\u2225x\u2217\u2212\u02c6xn(C)\u22252\n\u21132\n\u0003\n\u22646\nh\n\u03c32\nn g(cone(Q1) \u2229Bp\n\u21132) +\n\u2225x\u2217\u2212\u02dcx\u22252\n\u21132 + \u03b12i\n.\nHere cone(Q1) is the conic hull of Q1.\nThe proof of this result is presented in the Supplementary Information. A number of remarks\nare in order here. With respect to the \ufb01rst shortcoming in Proposition 4 stated above, if C is\nchosen such that S \u2282C one can set \u02dcx = x\u2217, Q1 = 0, and Q2 = C \u2212\u02dcx in Proposition 5, and readily\nobtain a bound that scales only with the diameter of the convex constraint set C. With regard to\nthe second shortcoming in Proposition 4 described above, if a point \u02dcx \u2208C near x\u2217has a narrow\ntangent cone TC(\u02dcx), then one can provide an error bound with respect to g(TC(\u02dcx)) with an extra\nadditive term that depends on \u2225x\u2217\u2212\u02dcx\u22252\n\u21132\u2014this is done by setting Q1 = C \u2212\u02dcx and Q2 = 0 (thus,\n\u03b1 = 0) in Proposition 5. More generally, Proposition 5 incorporates both these improvements in\na single error bound with respect to an arbitrary point \u02dcx \u2208C; thus, one can further optimize the\nerror bound over the choice of \u02dcx \u2208C (as well as the choice of the decomposition Q1 and Q2).\nProperties and Computation of Gaussian Squared-Complexity\nWe record some properties of the Gaussian squared-complexity that are subsequently useful when\nwe demonstrate concrete time-data tradeo\ufb00s. It is clear that g(\u00b7) is monotonic with respect to\nset nesting, i.e., g(D1) \u2264g(D2) for sets D1 \u2286D2. If D is a subspace then one can check that\ng(D) = dim(D). In order to estimate squared-complexities of families of cones, one can imagine\nappealing to techniques similar to those used for estimating Gaussian complexities of sets [20, 5].\nMost prominent among these are arguments based on covering number and metric entropy bounds.\nHowever, these arguments are frequently not sharp and introduce extraneous log-factors in the\nresulting error bounds.\nIn a recent paper [15], sharp upper bounds on the Gaussian complexities of normalized cones\nhave been established for families of cones of interest in a class of linear inverse problems. The\n(square of the) Gaussian complexity can be upper bounded by the Gaussian squared-complexity\ng(D) via Jensen\u2019s inequality:\nE\n\u0014\nsup\nd\u2208D\n\u27e8d, g\u27e9\n\u00152\n\u2264g(D),\nwhere g is a standard normal vector. In fact most of these bounds in [15] were obtained by bounding\ng(D) and thus they are directly relevant to our setting. In the rest of this section we present the\nbounds on g(D) from [15] that will be used in this paper, deferring to that paper for proofs in most\ncases. In some cases the proofs do require modi\ufb01cations with respect to their counterparts in [15],\nand for these cases we give full proofs in the Supplementary Information.\nThe \ufb01rst result is a direct consequence of convex duality and provides a fruitful general technique\nto compute sharp estimates of Gaussian squared-complexities. Let dist(a, D) denote the \u21132 distance\nfrom a point a to the set D.\nLemma 1. [15] Let K \u2286Rp be a convex cone and let K\u2217\u2286Rp be its polar. Then we have for any\na \u2208Rp that\nsup\nd\u2208K\u2229Bp\n\u21132\n\u27e8d, a\u27e9= dist(a, K\u2217).\nTherefore we have the following result as a simple corollary.\n12\nCorollary 6. Let K \u2286Rp be a convex cone and let K\u2217\u2286Rp be its polar. For g \u223cN(0, Ip\u00d7p) we\nhave that\ng(K \u2229Bp\n\u21132) = E\n\u0002\ndist(g, K\u2217)2\u0003\n.\nBased on the duality result of Lemma 1 and Corollary 6, one can compute the following sharp\nbounds on the Gaussian squared-complexities of tangent cones with respect to the \u21131 norm and\nnuclear norm balls. These are especially relevant when one wishes to estimate sparse signals or\nlow-rank matrices\u2014in these settings the \u21131 and nuclear norm balls serve as useful constraint sets for\ndenoising as the tangent cones with respect to these sets at sparse vectors and at low-rank matrices\nare particularly narrow. Both these results are used when we describe time-data tradeo\ufb00s.\nProposition 7. [15] Let x \u2208Rp be a vector containing s nonzero entries. Let T be the tangent\ncone at x with respect to an \u21131 norm ball scaled so that x lies on the boundary of the ball, i.e., a\nscaling of the unit \u21131 norm ball by a factor \u2225x\u2225\u21131. Then\ng(T \u2229Bp\n\u21132) \u22642s log(p\ns) + 5\n4s.\nNext we state a result for low-rank matrices and the nuclear norm ball.\nProposition 8. [15] Let X \u2208Rm1\u00d7m2 be matrix of rank r. Let T be the tangent cone at X with\nrespect to a nuclear norm ball scaled so that X lies on the boundary of the ball, i.e., a scaling of\nthe unit nuclear norm ball by a factor equal to the nuclear norm of X. Then\ng(T \u2229Bm1m2\n\u21132\n) \u22643r(m1 + m2 \u2212r).\nNext we state and prove a result that allows us to estimate Gaussian squared-complexities of\ngeneral cones. The bound is based on the volume of the dual of the cone of interest, and the proof\ninvolves an appeal to Gaussian isoperimetry [37]. A similar result on Gaussian complexities of cones\n(without the square) was proved in [15], but that result does not directly imply our statement and\nwe therefore give a complete self-contained proof in the Supplementary Information. The volume\nof a cone is assumed to be normalized (between zero and one) so we consider the relative fraction\nof a unit Euclidean sphere that is covered by a cone:\nProposition 9. Let K \u2282Rp be a cone such that its polar K\u2217\u2282Rp has a normalized volume of\n\u00b5 \u2208(1\n4 exp{\u2212p/20},\n1\n4e2). For p \u226512, we have that\ng(K \u2229Bp\n\u21132) \u226420 log\n\u0010\n1\n4\u00b5\n\u0011\n.\nIf a cone is narrow then its polar will be wide leading to a large value of \u00b5 and hence a small\nquantity of the right-hand-side of the bound. This result leads to bounds on Gaussian squared-\ncomplexity in settings in which one can easily obtain estimates of volumes. One setting in which\nsuch estimates are easily obtained is the case of tangent cones with respect to vertex transitive\npolytopes. We recall that a vertex transitive polytope [54] is one in which there exists a symmetry\nof the polytope for each pair of vertices mapping the two vertices isomorphically to each other.\nRoughly speaking, all the vertices in such polytopes are the same. Some examples include the\ncross-polytope (the \u21131 norm ball), the simplex (4), the hypercube (the \u2113\u221enorm ball), and many\npolytopes generated by the action of groups [46]. We will see many examples of such polytopes in\nour examples on time-data tradeo\ufb00s, and thus we will appeal to the following corollary repeatedly:\nCorollary 10. Suppose that P \u2208Rp is a vertex transitive polytope with v vertices and let x be a\nvertex of this polytope. If 4e2 \u2264v \u22644 exp{p/20} then\ng(TP(x)) \u226420 log(v/4).\n13\nFigure 2: (left) A signal set S consisting of x\u2217; (middle) Two convex constraint sets C and C\u2032, where\nC is the convex hull of S and C\u2032 is a relaxation that is more e\ufb03ciently computable than C; (right)\nThe tangent cone TC(x\u2217) is contained inside the tangent cone TC\u2032(x\u2217). Consequently, the Gaussian\nsquared-complexity g(TC(x\u2217) \u2229Bp\n\u21132) is smaller than the complexity g(TC\u2032(x\u2217) \u2229Bp\n\u21132), so that the\nestimator \u02c6xn(C) requires fewer samples than the estimator \u02c6xn(C\u2032) for a risk of at most 1.\nProof: The normal cones at the vertices of P partition Rp. If the polytope is vertex-transitive, then\nthe normal cones are all equivalent to each other (up to orthogonal transformations). Consequently,\nthe (normalized) volume of the normal cone at any vertex is 1/v. Since the normal cone at a vertex\nis polar to the tangent cone, we have the desired result from Proposition 9. \u25a1\nTime-Data Tradeo\ufb00s\nPreliminaries\nWe now turn our attention to giving examples of time-data tradeo\ufb00s in denoising problems via\nconvex relaxation. As described previously, we must set a desired risk in order to realize a time-\ndata tradeo\ufb00\u2014in the examples in the rest of this section, we will \ufb01x the desired risk to be equal\nto 1 independent of the problem dimension p. Thus, these denoising problems lie in the time-data\ncomplexity classes TD(t(p), n(p), 1) for di\ufb00erent runtime constraints t(p) and sample budgets n(p).\nThe following corollary gives the number of samples required to obtain a mean squared error of 1\nvia convex optimization in our denoising setup:\nCorollary 11. For x\u2217\u2208S and with S \u2286C, if\nn \u2265\u03c32g(TC(x\u2217) \u2229Bp\n\u21132),\nthen E\n\u0002\n\u2225x\u2217\u2212\u02c6xn(C)\u22252\n\u21132\n\u0003\n\u22641.\nProof: The result follows by a rearrangement of the terms in the bound in Proposition 4. \u25a1\nThis corollary states that if we have access to a dataset with n samples, then we can use any\nconvex constraint set C such that the term on the right-hand-side in the corollary is smaller than n.\nRecalling that larger constraint sets C lead to larger tangent cones TC, we observe that if n is large\none can potentially use very weak (and computationally inexpensive) relaxations and still obtain\na risk of 1. This observation, combined with the important point that the hierarchies of convex\nrelaxations described previously are simultaneously ordered both by approximation quality and by\ncomputational tractability, allows us to realize a time-data tradeo\ufb00by using convex relaxation as\nan algorithm weakening mechanism. See Figure 2 for a simple demonstration.\n14\nWe further consider settings with \u03c32 = 1 and in which our signal sets S \u2286Rp consist of\nelements that have Euclidean norm on the order of \u221ap (measured from the centroid of S). In such\nregimes the James-Stein shrinkage estimator [30] o\ufb00ers about the same level of performance as the\nmaximum-likelihood estimator, and both these are outperformed in statistical risk by nonlinear\nestimators of the form (2) based on convex optimization.\nFinally, we brie\ufb02y remark on the runtimes of our estimators.\nThe runtime for each of the\nprocedures below is calculated by adding the number of operations required to compute the sample\nmean \u00afy and the number of operations to solve (2) to some accuracy.\nHence if the number of\nsamples used is n and if fC(p) denotes the number of operations required to project \u00afy onto C, then\nthe total runtime is np+fC(p). Thus the number of samples enters the runtime calculations as just\nan additive term. As we process larger datasets, the \ufb01rst term in this calculation becomes larger\nbut this increase is o\ufb00set by a more substantial decrease in the second term due to the use of a\ncomputationally tractable convex relaxation. We note that such a runtime calculation extends to\nmore general inference problems in which one employs estimators of the form (2) but with di\ufb00erent\nloss functions in the objective\u2014speci\ufb01cally, the runtime is calculated as above so long as the loss\nfunction depends only on some su\ufb03cient statistic computed from the data. If the loss function is\ninstead of the form Pn\ni=1 \u2113(x; yi) and it cannot be summarized via a su\ufb03cient statistic of the data\n{yi}n\ni=1, then the number of samples enters the runtime computation in a multiplicative manner in\nthe number of operations fC(p) required to compute the convex programming estimator.\nExample 1: Denoising Signed Matrices\nWe consider the problem of recovering signed matrices corrupted by noise:\nS = {aa\u2032 | a \u2208{\u22121, +1}\n\u221ap}.\nWe have a \u2208R\n\u221ap so that S \u2286Rp. Inferring such signals is of interest in collaborative \ufb01ltering where\none wishes to approximate matrices as the sum of a small number of rank-one signed matrices [52].\nSuch matrices may represent, for example, the movie preferences of users as in the Net\ufb02ix problem.\nThe tightest convex constraint that one could employ in this case is C = conv(S), which is\nthe cut polytope (6). In order to obtain a risk of 1 with this constraint, one requires n = c1\u221ap\nby applying Corollary 10 and Corollary 11 based on the symmetry of the cut polytope. The cut\npolytope is in general intractable to compute. Hence the best known algorithms to project onto\nC would require runtime that is super-polynomial in p. Consequently, the total runtime of this\nalgorithm is c1p1.5 + super-poly(p).\nA commonly used tractable relaxation of the cut polytope is the elliptope (5). By computing\nthe Gaussian squared-complexity of the tangent cones at rank-one signed matrices with respect to\nthis set, it is possible to show that n = c2\u221ap leads to a risk of 1 (with c2 > c1). Further, interior-\npoint based convex optimization algorithms for solving (2) that exploit the special structure of\nthe elliptope require O(p2.25) operations4 [11, 7, 29]. Hence the total runtime of this procedure is\nc2p1.5 + O(p2.25).\nFinally, an even weaker relaxation of the cut polytope than the elliptope is the unit ball of the\nnuclear norm scaled by a factor of \u221ap\u2014one can verify that the elements of S lie on the boundary\nof this set, and are in fact extreme points. Appealing to Proposition 8 (using the fact that the\nelements of S are rank-one matrices) and Corollary 11, we conclude that n = c3\u221ap samples provide\na mean-squared error of 1 (with c3 > c2). Projecting onto the scaled nuclear norm ball can be done\n4The exponent is a result of the manner in which we de\ufb01ne our signal set so that a rank-one signed matrix lives\nin Rp.\n15\nby computing a singular value decomposition (SVD), and then truncating the sequence of singular\nvalues in descending order when their cumulative sum exceeds \u221ap (in e\ufb00ect projecting the vector\nof singular values onto an \u21131 ball of size \u221ap). This operation requires O(p1.5) operations, and thus\nthe total runtime is c3p1.5 + O(p1.5).\nTo summarize, the cut-matrix denoising problem lives in the time-data class TD(super-poly(p),\nc1\u221ap, 1), in TD(O(p2.25), c2\u221ap, 1), and in TD(O(p1.5), c3\u221ap, 1), with constants c1 < c2 < c3.\nExample 2: Ordering Variables\nIn many data analysis tasks, one is given a collection of variables that are suitably ordered so\nthat the population covariance is banded. Under such a constraint, thresholding the entries of\nthe empirical covariance matrix based on their distance from the diagonal has been shown to be\na powerful method for estimation in the high-dimensional setting [8].\nHowever, if an ordering\nof the variables is not known a priori, then one must jointly learn an ordering for the variables\nand estimate their underlying covariance. As a stylized version of this variable ordering problem,\nlet M \u2208R\n\u221ap\u00d7\u221ap be a known tridiagonal matrix (with Euclidean norm O(\u221ap)) and consider the\nfollowing signal set:\nS = {\u03a0M\u03a0\u2032 | \u03a0 is a \u221ap \u00d7 \u221ap permutation matrix}.\nThe matrix M here is to be viewed as a covariance matrix. Thus, the corresponding denoising\nproblem (1) is that we wish to estimate a covariance matrix in the absence of knowledge of the\nordering of the underlying variables. In a real-world scenario one might wish to consider covariance\nmatrices M that belong to some class of banded matrices and then construct S as done here, but\nwe stick with the case of a \ufb01xed M for simplicity.\nFurther, the noise in a practical setting is\nbetter modeled as coming from a Wishart distribution\u2014again, we focus on the Gaussian case for\nsimplicity.\nThe tightest convex constraint set that one could employ in this case is the convex hull of S,\nwhich is in general intractable to compute for arbitrary matrices M. For example, if one were\nable to compute this set in polynomial time for any tridiagonal matrix M, one would be able to\nsolve the intractable longest path problem [24] (\ufb01nding the longest path between any two vertices\nin a graph) in polynomial time. With this convex constraint set, we \ufb01nd using Corollary 10 and\nCorollary 11 that n = c1\u221ap log(p) samples would lead to a risk of 1. This follows from the fact\nthat conv(S) is a vertex-transitive polytope with about (\u221ap)! vertices. Thus, the total runtime is\nc1p1.5 log(p) + super-poly(p).\nAn e\ufb03ciently computable relaxation of conv(S) is a scaled \u21131 ball (scaled by the \u21131 norm of\nM). Appealing to Proposition 7 on tangent cones with respect to the \u21131 ball and to Corollary 11,\nwe \ufb01nd that n = c2\u221ap log(p) samples su\ufb03ce to provide a risk of 1. In applying Proposition 7, we\nnote that M is assumed to be tridiagonal and therefore has O(\u221ap) nonzero entries. The runtime\nof this procedure is c2p1.5 log(p) + O(p log(p)).\nThus the variable ordering denoising problem belongs to TD(super-poly(p), c1\u221ap log(p), 1) and\nto TD(O(p1.5 log(p)), c2\u221ap log(p), 1), with constants c1 < c2.\nExample 3: Sparse PCA and Network Activity Identi\ufb01cation\nAs our third example, we consider sparse PCA in which one wishes to learn from samples a sparse\neigenvector that contains most of the energy of a covariance matrix. As a simpli\ufb01ed version of this\nproblem, one can imagine a matrix M \u2208R\n\u221ap\u00d7\u221ap with entries equal to \u221ap/k in the top-left k \u00d7 k\n16\nblock and zeros elsewhere (so that the Euclidean norm of M is \u221ap), and with S de\ufb01ned as:\nS = {\u03a0M\u03a0\u2032 | \u03a0 is a \u221ap \u00d7 \u221ap permutation matrix}.\nIn addition to sparse PCA, such signal sets are also of interest in identifying activity in noisy\nnetworks [33], as well as in related combinatorial optimization problems such as the planted clique\nproblem [24]. In the sparse PCA context, Amini and Wainwright [3] study time-data tradeo\ufb00s by\ninvestigating the sample complexities of two procedures, a simple one based on thresholding and a\nmore sophisticated one based on semide\ufb01nite programming. Kolar et al. [33] investigate the sample\ncomplexities of a number of procedures ranging from a combinatorial search method, thresholding,\nand sparse SVD. We note that the time-data tradeo\ufb00s studied in these two papers [3, 33] relate to\nthe problem of learning the support of the leading sparse eigenvector; in contrast in our setup the\nobjective is to simply denoise an element of S. Further while the Gaussian noise setting is of interest\nin some of these domains, in a more realistic sparse PCA problem (such as the one considered in\n[3]) the noise is Wishart rather than Gaussian as considered here. Nevertheless, we stick with our\nstylized problem setting as it provides some useful insights on time-data tradeo\ufb00s. Finally, the size\nof the block k \u2208{1, . . . , \u221ap} depends on the application of interest and it is typically far from the\nextremes 1 and \u221ap\u2014we will consider the case k \u223cp1/4 for concreteness.5\nAs usual, the tightest convex constraint set one can employ in this setting is the convex hull of\nS, which is in general intractable to compute\u2014an e\ufb03cient characterization of this polytope would\nlead to an e\ufb03cient solution of the intractable planted-clique problem (\ufb01nding a fully connected\nsubgraph inside a larger graph). Using this convex constraint set gives an estimator that requires\nabout n = O(p1/4 log(p)) samples in order to produce a risk-1 estimate. We obtain this threshold\nby appealing to Corollary 10 and to Corollary 11, and the observation that conv(S) is a vertex-\ntransitive polytope with about\n\u0000 \u221ap\np1/4\n\u0001\nvertices. Thus, the overall runtime is O(p5/4 log(p)) + super-\npoly(p).\nA convex relaxation of conv(S) is the nuclear norm ball scaled by a factor of \u221ap so that the\nelements of S lie on the boundary.\nFrom Proposition 8 (observing that the elements of S are\nrank-one matrices) and Corollary 11, we have that n = c\u221ap samples give a risk-1 estimate with\nthis procedure. As computed in the example with cut matrices, the overall runtime of this nuclear\nnorm procedure is cp1.5 + O(p1.5).\nIn conclusion the denoising version of sparse PCA lies in TD(super-poly(p), O(p1/4 log(p)), 1)\nand in TD(O(p1.5), O(\u221ap), 1).\nExample 4: Estimating Matchings\nAs our \ufb01nal example, we consider signals that represent the set of all perfect matchings in the\ncomplete graph. A matching is any subset of edges of a graph such that no node of the graph\nis incident to more than one edge in the subset, and a perfect matching is a subset of edges in\nwhich every node is incident to exactly one edge in the subset. Graph matchings arise in a range\nof inference problems such as in chemical structure analysis [45] and in network monitoring [51].\nLetting M be the adjacency matrix of some perfect matching in the complete graph on \u221ap nodes,\nour signal set in this case is de\ufb01ned as follows:\nS = p1/4{\u03a0M\u03a0\u2032 | \u03a0 is a \u221ap \u00d7 \u221ap permutation matrix}.\n5This setting is an interesting threshold case in the planted clique context [1, 22, 2] where k = p1/4 is the square-\nroot of the number of nodes \u221ap of the graph represented by M (viewed as an adjacency matrix).\n17\nThe scaling of p1/4 ensures that the elements of S have Euclidean norm of \u221ap. Note that S \u2282Rp.\nThe number of elements in S is\n(\u221ap)!\n\u0012 \u221ap\n2\n\u0013\n! 2\n\u221ap/2 when \u221ap is an even number (this number is obtained\nby computing the product of all the odd integers up to \u221ap).\nThe tightest convex relaxation in this case is the convex hull of S. Unlike the previous three\ncases, projecting onto this convex set is in fact a polynomial-time operation,6 with runtime about\nO(p5).\nAppealing to Corollary 10, to Corollary 11, and to the fact that conv(S) is a vertex-\ntransitive polytope, we have that n = c1\u221ap log(p) samples provides a risk-1 estimate. Hence the\noverall runtime is c1p1.5 log(p) + O(p5).\nA tractable relaxation of the perfect matching polytope is a hypersimplex [54], obtained by\ntaking the convex hull of all \u221ap \u00d7 \u221ap matrices consisting of \u221ap ones and the other entries being\nequal to zero. We scale this hypersimplex by a factor of p1/4 so that the elements of S are on\nthe boundary.\nThe hypersimplex is also a vertex-transitive polytope like the perfect matching\npolytope, but with about\n\u0000 p\n\u221ap\n\u0001\nentries. Hence from Corollary 10 and from Corollary 11, we have that\nn = c2\u221ap log(p) samples will provide a risk-1 estimate. Further, projecting onto the hypersimplex\nis a very e\ufb03cient operation based on sorting and has a runtime of O(p log(p)). Consequently the\ntotal runtime of this procedure is c2p1.5 log(p) + O(p log(p)).\nIn summary, the matching estimation problem is a member of TD(O(p5), c1\u221ap log(p), 1) and of\nTD(O(p1.5 log(p)), c2\u221ap log(p), 1) with constants c1 < c2.\nSome Observations\nA curious observation that we may take away from these examples is that it is possible to obtain\nsubstantial speedups computationally with just a constant factor increase in the size of the dataset.\nThis suggests that in settings in which obtaining additional data is inexpensive, it may be more\neconomical to procure more data and employ a more basic computational infrastructure rather\nthan to process limited data using powerful and expensive computers.\nOur second observation is relevant to all the examples above but we highlight it in the context\nof denoising cut matrices. In that setting one can use an even weaker relaxation of the cut polytope\nthan the nuclear norm ball, such as the Euclidean ball (suitably scaled). While projection onto this\nset is extremely e\ufb03cient (requiring O(p) operations as opposed to O(p1.5) operations for projecting\nonto the nuclear norm ball), the number of samples required to achieve a risk of 1 with this\napproach is O(p)\u2014computing the sample mean with so many samples requires O(p2) operations,\nwhich leads to an overall runtime that is greater than the runtime O(p1.5) for the nuclear norm\napproach.\nThis point highlights an important tradeo\ufb00\u2014if our choice of algorithms is between\nnuclear norm projection and Euclidean projection, and if we are in fact given access to O(p)\ndata samples, it makes sense computationally to retain only O(\u221ap) samples for the nuclear norm\nprocedure and throw away the remaining data. This provides a concrete illustration of several key\nissues. Aggregating massive datasets can frequently be very expensive computationally (relative\nto the other subsequent processing), and the number of operations required for this step must be\ntaken into account.7\nConsequently, in some cases it may make sense to throw away some data\nif preprocessing the full massive dataset is time-consuming. Hence, one may not be able to avail\n6Edmonds\u2019 blossom algorithm [21] for computing maximum-weight matchings in polynomial time leads to a sep-\naration oracle for this perfect matching polytope. Subsequently, Padberg and Rao [39] developed a faster separation\noracle for the perfect matching polytope. These separation oracles in turn lead to polynomial-time projection algo-\nrithms via the ellipsoid method [7].\n7Note that the aggregation step is more time-consuming than the subsequent projection step in the \u21131-ball pro-\njection procedure for ordering variables and in the hypersimplex projection method for denoising matchings.\n18\noneself of weaker post-aggregation algorithms if these methods require such a large amount of data\nto achieve a desired risk that the aggregation step is expensive. This point goes back to the \u201c\ufb02oor\u201d\nin Figure 1 in which one imagines a cuto\ufb00in the number of samples beyond which more data are\nnot helpful in reducing computational runtime. Such a threshold, of course, depends on the space of\nalgorithms one employs, and in the cut polytope context with the particular algorithms considered\nhere the threshold occurs at O(\u221ap) samples.\nConclusions\nIn this paper we considered the problem of reducing the computational complexity of an inference\ntask as one has access to larger datasets. The traditional goal in the theory of statistical inference\nis to understand the tradeo\ufb00in an estimation problem between the amount of data available and\nthe risk attainable via some class of procedures. In an age of plentiful data in many settings and\ncomputational resources being the principal bottleneck, we believe that an increasingly important\nobjective is to investigate the tradeo\ufb00s between computational and sample complexities. As one\npursues this line of thinking, it becomes clear that a central theme must be the ability to weaken an\ninference procedure as one has access to larger datasets. Accordingly, we proposed convex relaxation\nas an algorithm weakening mechanism, and we investigated its e\ufb03cacy in a class of denoising tasks.\nOur results suggest that such methods are especially e\ufb00ective in achieving time-data tradeo\ufb00s in\nhigh-dimensional parameter estimation.\nWe close our discussion by outlining some exciting future research directions. As algorithm\nweakening is central to the viewpoint described in this paper, it should come as no surprise that\nseveral of the directions listed below involve interaction with important themes in computer science.\nComputation with streaming data\nIn many massive data problems, one is presented with\na stream of input data rather than a large \ufb01xed dataset, and an estimate may be desired after a\n\ufb01xed amount of time independent of the rate of the input stream. In such a setting an alternative\nviewpoint to the one presented in this paper might be more appropriate. Speci\ufb01cally, rather than\nkeeping the risk \ufb01xed, one would keep the runtime \ufb01xed and trade o\ufb00the risk with the rate of\nthe input stream. One can imagine algorithm weakening mechanisms, dependent on the rate of\nthe data stream, in which the initial data points are processed using sophisticated algorithms and\nsubsequent samples are processed more coarsely. Understanding the tradeo\ufb00s in such a setting is\nof interest in a range of applications.\nAlternative algorithm weakening mechanisms\nThe notion of weakening an inference algo-\nrithm is key to realizing a time-data tradeo\ufb00. While convex relaxation methods provide a powerful\nand general approach, a number of other weakening mechanisms are potentially relevant. For ex-\nample, processing data more coarsely by quantization, dimension reduction, and clustering may\nbe natural in some contexts. Coresets, which originated in the computational geometry commu-\nnity, summarize a large set of points via a small collection (see, for example, [23] and the references\ntherein), and they could also provide a powerful algorithm weakening mechanism. Finally, we would\nlike to mention a computer hardware concept that has implications for massive data analysis. A\nrecent approach to designing computer chips is premised on the idea that many tasks do not require\nextremely accurate computation [6]. If one is willing to tolerate small, random errors in arithmetic\ncomputations (e.g., addition, multiplication), it may be possible to design chips that consume less\npower and are faster than traditional, more accurate chips. Translated to a data analysis context,\nsuch design principles may provide a hardware-based algorithm weakening mechanism.\n19\nMeasuring quality of approximation of convex sets\nIn the mathematical optimization and\ntheoretical computer science communities, relaxations of convex sets have provided a powerful tool-\nbox for designing approximation algorithms for intractable problems, most notably those arising\nin combinatorial optimization. The manner in which the quality of a relaxation translates to the\nquality of an approximation algorithm is usually quanti\ufb01ed based on the integrality gap between\nthe original convex set and its approximation [53]. However, the quantity of interest in a statisti-\ncal inference context in characterizing the quality of approximations is based on ratios of Gaussian\nsquared-complexities of tangent cones. These two quanti\ufb01cations can be radically di\ufb00erent\u2014indeed,\nseveral of the relaxations presented in our time-data tradeo\ufb00examples that are useful in an in-\nferential setting would provide poor performance in a combinatorial optimization context. More\nbroadly, those examples demonstrate that weak relaxations frequently provide as good estimation\nperformance as tighter ones with just an increase of a constant factor in the number of data samples.\nThis observation suggests a potentially deeper result along the following lines\u2014many computation-\nally intractable convex sets for which there exist no tight e\ufb03ciently-computable approximations as\nmeasured by integrality gap can nonetheless be well-approximated by computationally tractable\nconvex sets, if the quality of approximation is measured based on statistical inference objectives.\nAcknowledgments\nThis material is based upon work supported in part by the U. S. Army Research Laboratory and\nthe U. S. Army Research O\ufb03ce under contract/grant number W911NF-11-1-0391. We are grateful\nto Pablo Parrilo, Benjamin Recht, and Parikshit Shah for many insightful conversations. We would\nalso like to thank Alekh Agarwal, Emmanuel Cand`es, James Saunderson, Leonard Schulman, and\nMartin Wainwright for helpful questions and discussions.\nReferences\n[1] N. Alon, M. Krivelevich, and B. Sudakov. Finding a large hidden clique in a random graph.\nRandom Structures and Algorithms, 13:457\u2013466, 1998.\n[2] B. P. W. Ames and S. A. Vavasis. Nuclear norm minimization for the planted clique and\nbiclique problems. Mathematical Programming, Series B, 129:69\u201389, 2011.\n[3] A. Amini and M. Wainwright. High-dimensional analysis of semide\ufb01nite programming relax-\nations for sparse principal component analysis. Annals of Statistics, 37:2877\u20132921, 2009.\n[4] S. Arora and B. Barak. Computational Complexity: A Modern Approach. Cambridge Univer-\nsity Press, 2009.\n[5] P. Bartlett and S. Mendelson.\nRademacher and Gaussian complexities: Risk bounds and\nstructural results. Journal of Machine Learning Research, 3:463\u2013482, 2002.\n[6] Joseph Bates. See http://web.media.mit.edu/ bates/summary.html.\n[7] A. Ben Tal and A. Nemirovskii. Lectures on Modern Convex Optimization. Society for Indus-\ntrial and Applied Mathematics, 2001.\n[8] P. Bickel and L. Levina.\nRegularized estimation of large covariance matrices.\nAnnals of\nStatistics, 36:199\u2013227, 2008.\n20\n[9] J. Bochnak, M. Coste, and M. Roy. Real Algebraic Geometry. Springer, 1988.\n[10] L. Bottou and O. Bousquet. The Tradeo\ufb00s of Large Scale Learning. In Neural Information\nProcessing Systems, 2008.\n[11] S. P. Boyd and L. Vandenberghe. Convex Optimization. Cambridge University Press, 2004.\n[12] A. Brieden, P. Gritzmann, R. Kannan, V. Klee, L. Lovasz, and M. Simonovits. Approximation\nof diameters: Randomization doesn\u2019t help. In Proceedings of the 39th Annual Symposium on\nFoundations of Computer Science, pages 244\u2013251, 1998.\n[13] Peter B\u00a8uhlmann and Sara van de Geer. Statistics for High-Dimensional Data: Methods, Theory\nand Applications. Springer, Berlin, 2011.\n[14] E. J. Cand`es, J. Romberg, and T. Tao. Robust uncertainty principles: exact signal recon-\nstruction from highly incomplete frequency information. IEEE Transactions on Information\nTheory, 52:489\u2013509, 2006.\n[15] V. Chandrasekaran, B. Recht, P. Parrilo, and A. Willsky.\nThe convex geometry of linear\ninverse problems. Foundations of Computational Mathematics, 12:805\u2013849, 2012.\n[16] S. Decatur, O. Goldreich, and D. Ron. Computational sample complexity. SIAM Journal on\nComputing, 29:854\u2013879, 1998.\n[17] D. L. Donoho. Denoising by soft thresholding. IEEE Transactions on Information Theory,\n41:613\u2013627, 1995.\n[18] D. L. Donoho. Compressed sensing. IEEE Transactions on Information Theory, 52:1289\u20131306,\n2006.\n[19] D. L. Donoho and I. M. Johnstone. Minimax estimation via wavelet shrinkage. Annals of\nStatistics, 26:879\u2013921, 1998.\n[20] R. M. Dudley.\nThe sizes of compact subsets of Hilbert space and continuity of Gaussian\nprocesses. Journal of Functional Analysis, 1:290\u2013330, 1967.\n[21] J. Edmonds. Maximum matching and a polyhedron with 0-1 vertices. Journal of Research of\nthe National Bureau of Standards, 69B:125\u2013130, 1965.\n[22] U. Feige and R. Krauthgamer. Finding and certifying a large hidden clique in a semirandom\ngraph. Random Structures and Algorithms, 16:195\u2013208, 2000.\n[23] D. Feldman and M. Langberg. A uni\ufb01ed framework for approximating and clustering data. In\nSymposium on the Theory of Computing, pages 569\u2013578, 2011.\n[24] M.R. Garey and D.S. Johnson. Computers and Intractability: A Guide to the Theory of NP-\nCompleteness. W. H. Freeman, 1979.\n[25] M. Goemans. Smallest compact formulation for the permutahedron. 2009.\n[26] M. Goemans and D. Williamson. Improved approximation algorithms for maximum cut and\nsatis\ufb01ability problems using semide\ufb01nite programming. Journal of the ACM, 42:1115\u20131145,\n1995.\n21\n[27] J. Gouveia, P. Parrilo, and R. Thomas. Lifts of convex sets and cone factorizations. to appear\nin Mathematics of Operations Research.\n[28] J. Gouveia, P. Parrilo, and R. Thomas. Theta bodies for polynomial ideals. SIAM Journal on\nOptimization, 20:2097\u20132118, 2010.\n[29] N.J. Higham.\nComputing the nearest correlation matrix \u2013 a problem from \ufb01nance.\nIMA\nJournal of Numerical Analysis, 22:329\u2013343, 2002.\n[30] W. James and C. Stein. Estimation with quadratic loss. In Proceedings of the 4th Berkeley\nSymposium on Mathematical Statistics and Probability, pages 361\u2013379, 1961.\n[31] I. M. Johnstone. Function estimation and Gaussian sequence models. Available at http://www-\nstat.stanford.edu/ imj.\n[32] D. Klain and G. Rota. Introduction to geometric probability. Cambridge University Press,\n1997.\n[33] M. Kolar, S. Balakrishnan, A. Rinaldo, and A. Singh.\nMinimax localization of structural\ninformation in large noisy matrices. In Neural Information Processing Systems, 2011.\n[34] T. Kolda. Orthogonal tensor decompositions. SIAM Journal on Matrix Analysis, 23:243\u2013255,\n2001.\n[35] T. L. Lai.\nSequential Analysis: Some Classical Problems and New Challenges.\nStatistica\nSinica, 11:303\u2013408, 2001.\n[36] J. B. Lasserre. Global optimization with polynomials and the problem of moments. SIAM\nJournal on Optimization, 11:796\u2013817, 2001.\n[37] M. Ledoux. The Concentration of Measure Phenomenon. American Mathematical Society,\n2000.\n[38] Y. Nesterov and A. Nemirovskii. Interior-Point Polynomial Algorithms in Convex Program-\nming. Society for Industrial and Applied Mathematics, 1995.\n[39] M.W. Padberg and M.R. Rao.\nOdd minimum cut-sets and b-matchings.\nMathematics of\nOperations Research, 7:67\u201380, 1982.\n[40] P. A. Parrilo. Structured semidenite programs and semialgebraic geometry methods in robust-\nness and optimization. PhD thesis, California Institute of Technology, 2000.\n[41] P. A. Parrilo. Semide\ufb01nite programming relaxations for semialgebraic problems. Mathematical\nProgramming, 96:293\u2013320, 2003.\n[42] T. J. Perkins and M. T. Hallett. A trade-o\ufb00between sample complexity and computational\ncomplexity in learning Boolean networks from time-series data. IEEE/ACM Transactions on\nComputational Biology and Bioinformatics, 7:118\u2013125, 2010.\n[43] J. Renegar. Hyperbolic programs and their derivative relaxations. Foundations of Computa-\ntional Mathematics, 6:59\u201379, 2006.\n[44] R. T. Rockafellar. Convex Analysis. Princeton University Press, 1970.\n22\n[45] D. H. Rouvray and A. T. Balaban. Chemical applications of graph theory. Applications of\nGraph Theory, pages 177\u2013221, 1979.\n[46] R. Sanyal, F. Sottile, and B. Sturmfels. Orbitopes. Mathematika, 57:275\u2013314, 2011.\n[47] R. Servedio. Computational sample complexity and attribute-e\ufb03cient learning. Journal of\nComputer and Systems Sciences, 60:161\u2013178, 2000.\n[48] S. Shalev-Shwartz, O. Shamir, and E. Tromer. Using more data to speed up training time. In\nConference on Arti\ufb01cial Intelligence and Statistics, 2012.\n[49] S. Shalev-Shwartz and N. Srebro. SVM optimization: Inverse dependence on training set size.\nIn International Conference on Machine Learning, 2008.\n[50] H. D. Sherali and W. P. Adams.\nA hierarchy of relaxations between the continuous and\nconvex hull representations for zero-one programming problems. SIAM Journal on Discrete\nMathematics, 3:411\u2013430, 1990.\n[51] P. Shoubridge, M. Krarne, and D. Ray. Detection of abnormal change in dynamic networks.\nIn Proceedings of Information, Decision, and Control, 1999.\n[52] N. Srebro and A. Shraibman. Rank, trace-norm and max-norm. In 18th Annual Conference\non Learning Theory (COLT), 2005.\n[53] V. Vazirani. Approximation Algorithms. Springer, 2004.\n[54] G. Ziegler. Lectures on Polytopes. Springer, 1995.\n23\nSupplementary Information\nProof of Proposition 5\nAs with the proof of Proposition 4, we condition on z = \u02dcz.\nSetting \u03b4 = x \u2212\u02dcx and setting\n\u02c6\u03b4n(C) = \u02c6xn(C)|z=\u02dcz \u2212\u02dcx, we can rewrite the problem (2) as follows:\n\u02c6\u03b4n(C) = arg min\n\u03b4\u2208Rp\n1\n2\n\r\r\r(x\u2217\u2212\u02dcx) +\n\u03c3\n\u221an\u02dcz \u2212\u03b4\n\r\r\r\n2\n\u21132\ns.t.\n\u03b4 \u2208C \u2212\u02dcx.\nLetting R1 and R2 denote orthogonal subspaces that contain Q1 and Q2, i.e., Q1 \u2286R1 and Q2 \u2286R2,\nand letting \u03b4(1) = PR1(\u03b4), \u03b4(2) = PR2(\u03b4), \u02c6\u03b4\n(1)\nn (C) = PR1(\u02c6\u03b4n(C)), \u02c6\u03b4\n(2)\nn (C) = PR2(\u02c6\u03b4n(C)) denote the\nprojections of \u03b4, \u02c6\u03b4n(C) onto R1, R2, we can rewrite the above reformulated optimization problem\nas:\nh\n\u02c6\u03b4\n(1)\nn (C), \u02c6\u03b4\n(2)\nn (C)\ni\n= arg\nmin\n\u03b4(1)\u2208Q1,\u03b4(2)\u2208Q2\n1\n2\n\r\r\rPR1\nh\n(x\u2217\u2212\u02dcx) +\n\u03c3\n\u221an\u02dcz\ni\n\u2212\u03b4(1)\r\r\r\n2\n\u21132\n+ 1\n2\n\r\r\rPR2\nh\n(x\u2217\u2212\u02dcx) +\n\u03c3\n\u221an\u02dcz\ni\n\u2212\u03b4(2)\r\r\r\n2\n\u21132\n.\nAs the sets Q1, Q2 live in orthogonal subspaces, the two variables \u03b4(1), \u03b4(2) in this problem can be\noptimized separately. Consequently, we have that \u2225\u02c6\u03b4\n(2)\nn (C)\u2225\u21132 \u2264\u03b1 and that\n\u2225\u02c6\u03b4\n(1)\nn (C)\u2225\u21132 \u2264\nsup\n\u00af\u03b4\u2208cone(Q1)\u2229Bp\n\u21132\n\u27e8\u00af\u03b4,\n\u03c3\n\u221an\u02dcz + (x\u2217\u2212\u02dcx)\u27e9.\nThis bound can be established following the same sequence of steps as in the proof of Proposition 4.\nCombining the two bounds on \u02c6\u03b4\n(1)\nn (C) and \u02c6\u03b4\n(2)\nn (C), one can then check that\n\u2225\u02c6\u03b4\n(1)\nn (C)\u22252\n\u21132 + \u2225\u02c6\u03b4\n(2)\nn (C)\u22252\n\u21132 \u22642\nh\n\u03c32\nn g(cone(Q1) \u2229Bp\n\u21132) + \u2225x\u2217\u2212\u02dcx\u22252\n\u21132\ni\n+ \u03b12.\nTo obtain a bound on \u2225\u02c6xn(C)|z=\u02dcz \u2212x\u2217\u22252\n\u21132 we note that\n\u2225\u02c6xn(C)|z=\u02dcz \u2212x\u2217\u22252\n\u21132\n\u2264\n2\n\u0002\n\u2225\u02c6xn(C)|z=\u02dcz \u2212\u02dcx\u22252\n\u21132 + \u2225x\u2217\u2212\u02dcx\u22252\n\u21132\n\u0003\n\u2264\n2\u2225\u02c6\u03b4\n(1)\nn (C)\u22252\n\u21132 + 2\u2225\u02c6\u03b4\n(2)\nn (C)\u22252\n\u21132 + 2\u2225x\u2217\u2212\u02dcx\u22252\n\u21132.\nTaking expectations concludes the proof. \u25a1\nProof of Proposition 9\nThe main steps of this proof follow the steps of a similar result in [15], with the principal di\ufb00erence\nbeing that we wish to bound Gaussian squared-complexity rather than Gaussian complexity. A\ncentral theme in this proof is the appeal to Gaussian isoperimetry. Let Sp\u22121 denote the sphere in p\ndimensions. Then in bounding the expected squared-distance to the dual cone K\u2217with K\u2217\u2229Sp\u22121\nhaving a volume of \u00b5, we need only consider the extremal case of a spherical cap in Sp\u22121 having\na volume of \u00b5. The manner in which this is made precise will become clear in the proof. Before\nproceeding with the main proof, we state and derive a result on the solid angle subtended by a\nspherical cap in Sp\u22121 to which we will need to appeal repeatedly:\n24\nLemma 2. Let \u03c8(\u00b5) denote the solid angle subtended by a spherical cap in Sp\u22121 with volume\n\u00b5 \u2208\n\u0000 1\n4 exp{\u2212p/20},\n1\n4e2\n\u0001\n. Then\n\u03c8(\u00b5) \u2265\u03c0\n2\n\uf8eb\n\uf8ec\n\uf8ec\n\uf8ed1 \u2212\nv\nu\nu\nt2 log\n\u0010\n1\n4\u00b5\n\u0011\np \u22121\n\uf8f6\n\uf8f7\n\uf8f7\n\uf8f8\nProof of Lemma 2: Consider the following de\ufb01nition of a spherical cap, parametrized by height\nh:\nJ = {a \u2208Sp\u22121 | a1 \u2265h}.\nHere a1 denotes the \ufb01rst coordinate of a \u2208Rp. Given a spherical cap of height h \u2208[0, 1], the solid\nangle \u03c8 is given by:\n\u03c8 = \u03c0\n2 \u2212sin\u22121(h).\n(10)\nWe can thus obtain bounds on the solid angle of a spherical cap via bounds on its height. The\nfollowing result from [12] relates the volume of a spherical cap to its height:\nLemma 3. [12] For\n2\n\u221ap \u2264h \u22641 the volume \u02dc\u00b5(p, h) of a spherical cap of height h in Sp\u22121 is bounded\nas\n1\n10h\u221ap(1 \u2212h2)\np\u22121\n2\n\u2264\u02dc\u00b5(p, h) \u2264\n1\n2h\u221ap(1 \u2212h2)\np\u22121\n2\nContinuing with the proof of Lemma 2, note that for\n2\n\u221ap \u2264h \u22641\n1\n2h\u221ap(1 \u2212h2)\np\u22121\n2\n\u22641\n4(1 \u2212h2)\np\u22121\n2\n\u22641\n4 exp\n\u0010\n\u2212p\u22121\n2 h2\u0011\n.\nChoosing h =\nr\n2 log\n\u0010 1\n4\u00b5\n\u0011\np\u22121\nwe have\n2\n\u221ap \u2264h \u22641 based on the assumption \u00b5 \u2208\n\u00001\n4 exp{\u2212p/20},\n1\n4e2\n\u0001\n.\nConsequently, we can apply Lemma 3 with this value of h combined with (10) to conclude that\n\u02dc\u00b5\n\uf8eb\n\uf8ec\n\uf8ec\n\uf8edp,\nv\nu\nu\nt2 log\n\u0010\n1\n4\u00b5\n\u0011\np \u22121\n\uf8f6\n\uf8f7\n\uf8f7\n\uf8f8\u2264\u00b5.\nHence the solid angle \u03c8\n \n\u02dc\u00b5\n \np,\nr\n2 log\n\u0010 1\n4\u00b5\n\u0011\np\u22121\n!!\nis less than the solid angle \u03c8(\u00b5). Consequently, we\nuse (10) to conclude that\n\u03c8(\u00b5) \u2265\u03c0\n2 \u2212sin\u22121\n\uf8eb\n\uf8ec\n\uf8ec\n\uf8ed\nv\nu\nu\nt2 log\n\u0010\n1\n4\u00b5\n\u0011\np \u22121\n\uf8f6\n\uf8f7\n\uf8f7\n\uf8f8.\nUsing the bound sin\u22121(h) \u2264\u03c0\n2h, we obtain the desired bound. \u25a1\nProof of Proposition 9: We bound the Gaussian squared-complexity of K by bounding the\nexpected squared-distance to the polar cone K\u2217.\nLet \u00af\u00b5(U; t) for U \u2286Sp\u22121 and t > 0 denote\nthe volume of the set of points in Sp\u22121 that are within a Euclidean distance of at most t from\nU (recall that the volume of this set is equivalent to the measure of the set with respect to the\n25\nnormalized Haar measure on Sp\u22121). We have the following sequence of relations by appealing to\nthe independence of the direction g/\u2225g\u2225\u21132 and of the length \u2225g\u2225\u21132 of a standard normal vector g:\nE[dist(g, K\u2217)2]\n=\nE[\u2225g\u22252\n\u21132dist(g/\u2225g\u2225\u21132, K\u2217)2]\n=\np E[dist(g/\u2225g\u2225\u21132, K\u2217)2]\n\u2264\np E[dist(g/\u2225g\u2225\u21132, K\u2217\u2229Sp\u22121)2]\n=\np\nZ \u221e\n0\nP[dist(g/\u2225g\u2225\u21132, K\u2217\u2229Sp\u22121)2 > t]dt\n=\np\nZ \u221e\n0\nP[dist(g/\u2225g\u2225\u21132, K\u2217\u2229Sp\u22121) >\n\u221a\nt]dt\n=\n2p\nZ \u221e\n0\nsP[dist(g/\u2225g\u2225\u21132, K\u2217\u2229Sp\u22121) > s]ds\n=\n2p\nZ \u221e\n0\ns[1 \u2212\u00af\u00b5(K\u2217\u2229Sp\u22121; s)]ds.\nHere the third equality follows based on the integral version of the expected value. Let V \u2286Sp\u22121\ndenote a spherical cap with the same volume \u00b5 as K\u2217\u2229Sp\u22121. Then we have by spherical isoperimetry\nthat \u00af\u00b5(V ; s) \u2265\u00af\u00b5(K\u2217\u2229Sp\u22121; s) for all s \u22650 [37]. Thus\nE[dist(g, K\u2217)2] \u22642p\nZ \u221e\n0\ns[1 \u2212\u00af\u00b5(V ; s)]ds.\n(11)\nFrom here onward, we focus exclusively on bounding the integral.\nLet \u03c4(\u03c8) denote the volume of a spherical cap subtending a solid angle of \u03c8 radians. Recall\nthat \u03c8 is a quantity between 0 and \u03c0. As in Lemma 2 let \u03c8(\u00b5) denote the solid angle of a spherical\ncone subtending a solid angle of \u00b5. Since the Euclidean distance between points on a sphere is\nalways smaller than the geodesic distance, we have that \u00af\u00b5(V ; s) \u2265\u03c4(\u03c8(\u00b5) + s). Further, we have\nthe following explicit formula for \u03c4(\u03c8) [32]:\n\u03c4(\u03c8) = \u03c9\u22121\np\nZ \u03c8\n0\nsinp\u22121(v)dv,\nwhere \u03c9p =\nR \u03c0\n0 sinp\u22121(v)dv is the normalization constant. Combining these latter two observations,\nwe can bound the integral in (11) as:\nZ \u221e\n0\ns[1 \u2212\u00af\u00b5(V ; s)]ds\n\u2264\nZ \u221e\n0\ns[1 \u2212\u03c4(\u03c8(\u00b5) + s)]ds\n=\nZ \u03c0\u2212\u03c8(\u00b5)\n0\ns[1 \u2212\u03c4(\u03c8(\u00b5) + s)]ds\n=\n(\u03c0 \u2212\u03c8(\u00b5))2\n2\n\u2212\nZ \u03c0\u2212\u03c8(\u00b5)\n0\ns\u03c4(\u03c8(\u00b5) + s)ds\n=\n(\u03c0 \u2212\u03c8(\u00b5))2\n2\n\u2212\u03c9\u22121\np\nZ \u03c0\u2212\u03c8(\u00b5)\n0\nZ \u03c8(\u00b5)+s\n0\ns sinp\u22121(v)dvds\n26\nNext we change the order of integration to obtain:\nZ \u221e\n0\ns[1 \u2212\u00af\u00b5(V ; s)]ds\n\u2264\n(\u03c0 \u2212\u03c8(\u00b5))2\n2\n\u2212\u03c9\u22121\np\nZ \u03c0\n0\nZ \u03c0\u2212\u03c8(\u00b5)\nmax{v\u2212\u03c8(\u00b5),0}\nsinp\u22121(v)sdsdv\n=\n(\u03c0 \u2212\u03c8(\u00b5))2\n2\n\u2212\u03c9\u22121\np\nZ \u03c0\n0\n1\n2\n\u0002\n(\u03c0 \u2212\u03c8(\u00b5))2 \u2212(max{v \u2212\u03c8(\u00b5), 0})2\u0003\nsinp\u22121(v)dv\n=\n\u03c9\u22121\np\n2\nZ \u03c0\n0\n(max{v \u2212\u03c8(\u00b5), 0})2 sinp\u22121(v)dv\n=\n\u03c9\u22121\np\n2\nZ \u03c0\n\u03c8(\u00b5)\n(v \u2212\u03c8(\u00b5))2 sinp\u22121(v)dv.\nWe now appeal to the inequalities \u03c9\u22121\np\n\u2264\u221ap \u22121/2 and sin(x) \u2264exp(\u2212(x \u2212\u03c0\n2 )2/2) for x \u2208[0, \u03c0] to\nobtain\nZ \u221e\n0\ns[1 \u2212\u00af\u00b5(V ; s)]ds\n\u2264\n\u221ap \u22121\n2\nZ \u03c0\n\u03c8(\u00b5)\n(v \u2212\u03c8(\u00b5))2 exp\nh\n\u2212p\u22121\n2 (v \u2212\u03c0\n2 )2i\ndv.\nPerforming a change of variables with a = \u221ap \u22121(v \u2212\u03c0\n2 ), we have\nZ \u221e\n0\ns[1 \u2212\u00af\u00b5(V ; s)]ds\n\u2264\n1\n2\nZ \u221ap\u22121\u03c0/2\n\u221ap\u22121(\u03c8(\u00b5)\u2212\u03c0/2)\n(\na\n\u221ap\u22121 + (\u03c0\n2 \u2212\u03c8(\u00b5)))2 exp[\u2212a2\n2 ]da\n=\n1\n2\nZ \u221ap\u22121\u03c0/2\n\u221ap\u22121(\u03c8(\u00b5)\u2212\u03c0/2)\nh\na2\np\u22121 + (\u03c0\n2 \u2212\u03c8(\u00b5))2 +\n2a\n\u221ap\u22121(\u03c0\n2 \u2212\u03c8(\u00b5))\ni\nexp[\u2212a2\n2 ]da\n\u2264\n1\n2\n\u0014Z \u221e\n\u2212\u221e\na2\np\u22121 exp[\u2212a2\n2 ]da +\nZ \u221e\n\u2212\u221e\n(\u03c0\n2 \u2212\u03c8(\u00b5))2 exp[\u2212a2\n2 ]da +\nZ \u221e\n0\n2a\n\u221ap\u22121(\u03c0\n2 \u2212\u03c8(\u00b5)) exp[\u2212a2\n2 ]da\n\u0015\n=\n1\n2\nh \u221a\n2\u03c0\np\u22121 +\n\u221a\n2\u03c0(\u03c0\n2 \u2212\u03c8(\u00b5))2 +\n2\n\u221ap\u22121(\u03c0\n2 \u2212\u03c8(\u00b5)) \u00b7 (\u2212exp[\u2212a2\n2 ])|\u221e\n0\ni\n=\n1\n2\nh \u221a\n2\u03c0\np\u22121 +\n\u221a\n2\u03c0(\u03c0\n2 \u2212\u03c8(\u00b5))2 +\n2\n\u221ap\u22121(\u03c0\n2 \u2212\u03c8(\u00b5))\ni\nHere the inequality was obtained by suitably changing the limits of integration. We now employ\nLemma 2 to obtain the \ufb01nal bound:\ng(K \u2229Bp\n\u21132)\n\u2264\np\n\uf8ee\n\uf8f0\n\u221a\n2\u03c0\np\u22121 +\n\u221a\n2\u03c0\n\uf8eb\n\uf8ed\u03c0\n2\nr\n2 log\n\u0010 1\n4\u00b5\n\u0011\np\u22121\n\uf8f6\n\uf8f8\n2\n+\n2\n\u221ap\u22121\n\uf8eb\n\uf8ed\u03c0\n2\nr\n2 log\n\u0010 1\n4\u00b5\n\u0011\np\u22121\n\uf8f6\n\uf8f8\n\uf8f9\n\uf8fb\n=\np\n\u221a\n2\u03c0\np\u22121\n\"\n1 + \u03c0 log\n\u0010\n1\n4\u00b5\n\u0011\n+ \u221a\u03c0\nr\nlog\n\u0010\n1\n4\u00b5\n\u0011#\n\u2264\n20 log\n\u0010\n1\n4\u00b5\n\u0011\n.\nHere the \ufb01nal bound holds because \u00b5 < 1/4e2 and p \u226512. \u25a1\n27\n",
        "sentence": " As a solution, recent advances in learning theory introduce hierarchies of algorithmic solutions, ordered by the respective computational complexity, for several fundamental machine learning applications in (Bousquet and Bottou, 2008; Shalev-Shwartz and Srebro, 2008; Chandrasekaran and Jordan, 2013; Agarwal et al., 2012; Lucic et al., 2015).",
        "context": "graph [26]. More generally, one can imagine a hierarchy of increasingly tighter approximations {Ci}\nof a convex set C as follows:\nC \u2286\u00b7 \u00b7 \u00b7 \u2286C3 \u2286C2 \u2286C1.\nThere exist several mechanisms for deriving such hierarchies, and we describe three frameworks\nhere.\nwidely used in theoretical computer science as they give tractable approximation algorithms to\nmany computationally intractable tasks. We demonstrate the e\ufb03cacy of this methodology in\ntradeo\ufb00in a number of stylized examples, motivated by problems such as collaborative \ufb01ltering,\nlearning an ordering of a collection of random variables, and inference in networks."
    },
    {
        "title": "Spectral mle: Top-k rank aggregation from pairwise comparisons",
        "author": [
            "Y. Chen",
            "C. Suh"
        ],
        "venue": null,
        "citeRegEx": "Chen and Suh.,? \\Q2015\\E",
        "shortCiteRegEx": "Chen and Suh.",
        "year": 2015,
        "abstract": "",
        "full_text": "",
        "sentence": " (2014); Chen and Suh (2015), which we explain in detail in Section 1. (2014); Chen and Suh (2015), which we explain in detail in Section 1.1. However, modern datasets are unstructured and heterogeneous. As Khetan and Oh (2016) show, this can lead to significant increase in the computational complexity, requiring exponential run-time in the size of the problem in the worst case.",
        "context": null
    },
    {
        "title": "Improved sum-of-squares lower bounds for hidden clique and hidden submatrix problems",
        "author": [
            "Y. Deshpande",
            "A. Montanari"
        ],
        "venue": "arXiv preprint arXiv:1502.06590,",
        "citeRegEx": "Deshpande and Montanari.,? \\Q2015\\E",
        "shortCiteRegEx": "Deshpande and Montanari.",
        "year": 2015,
        "abstract": "",
        "full_text": "",
        "sentence": " For such traditional preferences, efficient schemes for learning to rank have been proposed, such as Ford Jr. (1957); Hunter (2004); Hajek et al. For such traditional preferences, efficient schemes for learning to rank have been proposed, such as Ford Jr. (1957); Hunter (2004); Hajek et al. For such traditional preferences, efficient schemes for learning to rank have been proposed, such as Ford Jr. (1957); Hunter (2004); Hajek et al. (2014); Chen and Suh (2015), which we explain in detail in Section 1. planted clique problem (Deshpande and Montanari, 2015; Meka et al., 2015).",
        "context": null
    },
    {
        "title": "Solution of a ranking problem from binary comparisons",
        "author": [
            "L.R. Ford Jr."
        ],
        "venue": "The American Mathematical Monthly,",
        "citeRegEx": "Jr.,? \\Q1957\\E",
        "shortCiteRegEx": "Jr.",
        "year": 1957,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": "",
        "context": null
    },
    {
        "title": "Eigentaste: A constant time collaborative filtering algorithm",
        "author": [
            "K. Goldberg",
            "T. Roeder",
            "D. Gupta",
            "C. Perkins"
        ],
        "venue": "Information Retrieval,",
        "citeRegEx": "Goldberg et al\\.,? \\Q2001\\E",
        "shortCiteRegEx": "Goldberg et al\\.",
        "year": 2001,
        "abstract": "",
        "full_text": "",
        "sentence": " On sushi preferences (Kamishima, 2003) and jester dataset (Goldberg et al., 2001), we improve over pairwise breaking and achieves same performance as the oracle MLE. On sushi preferences (Kamishima, 2003) and jester dataset (Goldberg et al., 2001), we improve over pairwise breaking and achieves same performance as the oracle MLE. Full rankings over \u03ba = 10 types of sushi are randomly chosen from d = 100 types of sushi are provided by n = 5000 individuals. As the ground truth \u03b8\u2217, we use the ML estimate of PL weights over the entire data. In Figure 5, left panel, for each m \u2208 {3, 4, 5, 6, 7}, we remove the known ordering among the top-m and bottom-(10 \u2212m) sushi in each set, and run our estimator with one breaking edge between top-m and bottom-(10\u2212m) items. We compare our algorithm with inconsistent pairwise breaking (using optimal choice of parameters from Khetan and Oh (2016)) and the oracle MLE.",
        "context": null
    },
    {
        "title": "Minimax-optimal inference from partial rankings",
        "author": [
            "B. Hajek",
            "S. Oh",
            "J. Xu"
        ],
        "venue": "In Advances in Neural Information Processing Systems",
        "citeRegEx": "Hajek et al\\.,? \\Q2014\\E",
        "shortCiteRegEx": "Hajek et al\\.",
        "year": 2014,
        "abstract": "",
        "full_text": "",
        "sentence": " Hajek et al. (2014) provides full analysis of the statistical complexity of this MLE under traditional structures.",
        "context": null
    },
    {
        "title": "A large-deviation inequality for vector-valued martingales",
        "author": [
            "T.P. Hayes"
        ],
        "venue": "Combinatorics, Probability and Computing,",
        "citeRegEx": "Hayes.,? \\Q2005\\E",
        "shortCiteRegEx": "Hayes.",
        "year": 2005,
        "abstract": "",
        "full_text": "",
        "sentence": " 8, Hayes (2005)], we have",
        "context": null
    },
    {
        "title": "Mm algorithms for generalized bradley-terry models",
        "author": [
            "D.R. Hunter"
        ],
        "venue": "Ann. of Stat., pages 384\u2013406,",
        "citeRegEx": "Hunter.,? \\Q2004\\E",
        "shortCiteRegEx": "Hunter.",
        "year": 2004,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " comparisons in (Ford Jr., 1957; Hunter, 2004; Negahban et al., 2014; Shah et al., 2015a; Maystre and Grossglauser, 2015).",
        "context": null
    },
    {
        "title": "Nantonac collaborative filtering: recommendation based on order responses",
        "author": [
            "T. Kamishima"
        ],
        "venue": "In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,",
        "citeRegEx": "Kamishima.,? \\Q2003\\E",
        "shortCiteRegEx": "Kamishima.",
        "year": 2003,
        "abstract": "",
        "full_text": "",
        "sentence": " On sushi preferences (Kamishima, 2003) and jester dataset (Goldberg et al.",
        "context": null
    },
    {
        "title": "Data-driven rank breaking for efficient rank aggregation",
        "author": [
            "A. Khetan",
            "S. Oh"
        ],
        "venue": "In International Conference on Machine Learning,",
        "citeRegEx": "Khetan and Oh.,? \\Q2016\\E",
        "shortCiteRegEx": "Khetan and Oh.",
        "year": 2016,
        "abstract": "",
        "full_text": "",
        "sentence": " For the precise condition for consistent rank-breaking we refer to (Azari Soufiani et al., 2013, 2014; Khetan and Oh, 2016). The proof sketch is inspired from Khetan and Oh (2016). The main difference and technical challenge is in showing the strict concavity of LRB(\u03b8) when restricted to \u03a9b.",
        "context": null
    },
    {
        "title": "Tradeoffs for space, time, data and risk in unsupervised learning",
        "author": [
            "M. Lucic",
            "M.I. Ohannessian",
            "A. Karbasi",
            "A. Krause"
        ],
        "venue": "In AISTATS,",
        "citeRegEx": "Lucic et al\\.,? \\Q2015\\E",
        "shortCiteRegEx": "Lucic et al\\.",
        "year": 2015,
        "abstract": "Faced with massive data, is it possible to trade off (statistical) risk, and\n(computational) space and time? This challenge lies at the heart of large-scale\nmachine learning. Using k-means clustering as a prototypical unsupervised\nlearning problem, we show how we can strategically summarize the data (control\nspace) in order to trade off risk and time when data is generated by a\nprobabilistic model. Our summarization is based on coreset constructions from\ncomputational geometry. We also develop an algorithm, TRAM, to navigate the\nspace/time/data/risk tradeoff in practice. In particular, we show that for a\nfixed risk (or data size), as the data size increases (resp. risk increases)\nthe running time of TRAM decreases. Our extensive experiments on real data sets\ndemonstrate the existence and practical utility of such tradeoffs, not only for\nk-means but also for Gaussian Mixture Models.",
        "full_text": "Tradeoffs for Space, Time, Data and Risk in Unsupervised Learning\nMario Lucic\nMesrob I. Ohannessian\nAmin Karbasi\nAndreas Krause\nETH Z\u00fcrich\nUniversity of California, San Diego\nYale University\nETH Z\u00fcrich\nAbstract\nFaced with massive data, is it possible to trade\noff (statistical) risk, and (computational) space\nand time?\nThis challenge lies at the heart of\nlarge-scale machine learning.\nUsing k-means\nclustering as a prototypical unsupervised learn-\ning problem, we show how we can strategi-\ncally summarize the data (control space) in or-\nder to trade off risk and time when data is\ngenerated by a probabilistic model. Our sum-\nmarization is based on coreset constructions\nfrom computational geometry.\nWe also de-\nvelop an algorithm, TRAM, to navigate the\nspace/time/data/risk tradeoff in practice. In par-\nticular, we show that for a \ufb01xed risk (or data\nsize), as the data size increases (resp. risk in-\ncreases) the running time of TRAM decreases.\nOur extensive experiments on real data sets\ndemonstrate the existence and practical utility of\nsuch tradeoffs, not only for k-means but also for\nGaussian Mixture Models.\n1\nINTRODUCTION\nThe computational and statistical performance of any\nlearning algorithm for a given data set can be described in\nterms of three parameters: risk, running time, and space\nusage.\nThe massive growth in datasets, coupled with\nlimited resources in terms of time and space, raises new\nchallenging questions on the accuracy of learning that can\nbe achieved. At the heart of this challenge is to identify the\nrelationships between risk e, and the resources we have\navailable, namely, time t, space s, and data n. Most of clas-\nsical learning theory centers around the question of how\nrisk scales with dataset (or sample) size: How much data n\nis needed in order to achieve a certain level of risk e (i.e.,\nwhat is the sample complexity of a given learning task)? In\ncontrast, and from a practical point of view, increasing the\ndata size is a source of computational complexity which\nAppearing in Proceedings of the 18th International Conference on\nArti\ufb01cial Intelligence and Statistics (AISTATS) 2015, San Diego,\nCA, USA. JMLR: W&CP volume 38. Copyright 2015 by the\nauthors.\ntypically translates into higher running time t. From this\nperspective, large data is considered a nuisance rather than\na resource for achieving lower risk. As a result, most prac-\ntical algorithms accumulate data until they exhaust either\nthe time or space constraints and drop the data afterwards.\nRelated Work.\nAn alternative direction is to investigate\ncomputational and statistical tradeoffs: using data as a\ncomputational resource when available beyond the sample\ncomplexity of the learning task.\nPioneering this effort,\nDecatur et al. [2000] and Servedio [1999] showed tradeoffs\nin the realizable PAC learning model.\nExploring these\ntradeoffs has gained much recent attention due to emerging\nproblems in big data. For instance, Bottou and Bousquet\n[2008], Shalev-Shwartz and Srebro [2008] and Birnbaum\nand Shwartz [2012] showed the existence of such tradeoffs\nfor learning linear classi\ufb01ers as the data size increases.\nThese tradeoffs are generally achieved by leveraging the\nfact that as we accumulate more data, the desired risk e\nbecomes easier to reach, thus computationally cheaper but\nless accurate algorithms can be employed. This idea of\nalgorithmic weakening was explored more systematically\nby Chandrasekaran and Jordan [2013] using convex\nrelaxations.\nOur Contributions.\nExisting approaches in computa-\ntional and statistical tradeoffs consider only three of the\nfour parameters: for a desired level of risk e they iden-\ntify tradeoffs between running time t and data size n. Our\nprimary goal in this paper is to study how summariza-\ntion (i.e., controlling space) can help navigate the trade-\noff between time, data size and risk. In other words, we\npresent a weakening mechanism, akin to Chandrasekaran\nand Jordan [2013], albeit in a different direction. Instead\nof weakening learning algorithms, we consider weakening\nthe data representation. As more data becomes available,\nmore representative elements can be extracted, without in-\ncurring much computational cost. Our approach is based\non novel computational geometric techniques, called core-\nsets (Agarwal et al. [2005]), where a small amount of most\nrelevant data is extracted from the dataset, while perform-\ning the computation on this extracted data guarantees an\napproximate solution to the original problem. To the best\nof our knowledge, this paper is a \ufb01rst effort in introducing a\nmethodological data-summarization approach for studying\nand navigating space/time/data/risk tradeoffs.\narXiv:1605.00529v1  [stat.ML]  2 May 2016\nTradeoffs for Space, Time, Data and Risk in Unsupervised Learning\nAs a prototypical unsupervised learning problem, we focus\non k-means clustering, also known as vector quantization,\ndue to its simplicity and practical importance. In this prob-\nlem, a set of k centers is sought to minimize the expected\n(squared) distance between data points and the closest cen-\nter. Finding the optimal centers is NP-hard, but good ap-\nproximation algorithms are known, e.g., Lloyd\u2019s algorithm\n(Lloyd [1982]). We show how coreset constructions for\nk-means (Kanungo et al. [2002], Har-Peled and Mazumdar\n[2004], Agarwal et al. [2005], Feldman et al. [2007, 2013])\ncan be used to strategically summarize the data: in order\nto achieve a \ufb01xed precision, the running time can be made\nto decrease as the data set grows, by carefully controlling\nspace usage. We also provide a practical algorithm TRAM\nthat uses existing algorithms for solving k-means (e.g.,\nLloyd\u2019s algorithm, or k-means++) in order to realize this\ntradeoff in practice. We demonstrate the effectiveness of\nour summarization strategy on several synthetic and real\ndata sets. We should highlight that k-means clustering is\na non-convex problem, thus prior computational-statistical\ntradeoff strategies that heavily relied on convexity cannot\nbe applied in this setting. While we focus on k-means,\ncoresets are available for many other unsupervised learn-\ning tasks (Feldman et al. [2013]), and we believe that\nour approach can be applied much more generally.\nIn\nparticular, we empirically demonstrate how such tradeoffs\ncan be achieved for Gaussian Mixture Models (GMMs).\n2\nTHE STATISTICAL k-MEANS\nPROBLEM\nTypically, k-means is viewed as a (combinatorial) op-\ntimization problem.\nWe focus instead on the statistical\nvariant.\nIn particular, we assume that an underlying\ndistribution generates i.i.d. samples, and we seek centers\nthat generalize well. More formally, let P be an unknown\ndistribution on Rd where we assume that it is supported\non a ball of radius B at the origin, i.e., for X \u21e0P we have\nP(kX k2\uf8ffB) = 1 (this assumption can be relaxed under\nother regularity conditions, see, for example Telgarsky\nand Dasgupta [2013]).\nIn k-means clustering, any data\npoint x 2 Rd is associated with the closest among a set of\nk centers c = {c1,\u00b7\u00b7\u00b7 ,ck}, where ci 2 Rd. We judge the\nquality of this association by a risk de\ufb01ned as\nR(c) = EX\u21e0P[d2(c,X)]\nbetween\nc\nand\na\nsample\nX\nfrom\nP,\nwhere\nd2(c,X) = mink\ni=1 ||ci \u2212X||2\n2.\nLet C be the set of all\nk centers in the ball of radius B at the origin. The optimal\ncenters are those that minimize this risk:\nc? = argmin\nc2C\nR(c).\nThe solution to this minimization may not be unique, but\nfor the ease of presentation we assume it is. We further\nmake the realistic assumption that R := R(c?) > 0 which\nis satis\ufb01ed for any distribution supported on more than k\npoints. Since P is unknown, we seek centers for a dataset\nof n samples X1,...,Xn drawn i.i.d. from P. Any choice of\na sequence of functions \u02dccn, from Rd\u21e5n ! Rd\u21e5k is called a\nk-means procedure. Out of all such choices, of particular\nimportance is the one that minimizes the empirical risk, to\nobtain the empirically optimal centers:\nRn(c) = 1\nn\nn\n\u00c2\ni=1\nd2(c,Xi),\n\u02c6cn = argmin\nc2C\nRn(c).\n(1)\nThe properties of the empirically optimal centers have\nbeen extensively studied in the literature ([Kanungo et al.,\n2002, Ben-David, 2007]). In particular, \ufb01nding empirically\noptimal centers is a daunting task and often approximate\nprocedures are used.\nOf particular interest to us is a\nclass of algorithms (Kanungo et al. [2002], Har-Peled and\nMazumdar [2004], Agarwal et al. [2005], Feldman et al.\n[2007, 2013]) that solve the k-means problem by \ufb01rst\nsummarizing the data and then \ufb01nding the centers on the\nsummarized data. This decoupling principle allows these\nalgorithms to invest most of their running time only on a\nsmall set of points and, at the same time, to save space.\n3\nDATA SUMMARIZATION\nData summarization refers to a procedure that takes a data\nset of size n and replaces it with a smaller set of size sproc,\nwhich (approximately) suf\ufb01ces for solving the learning task\nat hand. This summarization may simply be a truncation\nwithout any consideration to the inherent structure of the\ndata (a simple method that is often practiced), or it may\nbe a combination of truncation and strategic sampling that\nadapts to structure in the data. We denote the truncation\nsize by mproc. One of the main advantages of having sum-\nmarized data, apart from saving space, is the substantial\nreduction in running time. For this reason, truncation must\nbe allowed, as otherwise the running time of any learning\nalgorithm would grow with the data size. We now formally\npresent these two strategies.\nUniform Subsampling This is the simplest form of data\nsummarization: start with a data set of size n, preserve\nonly the \ufb01rst ssubs \uf8ffn points, and then solve the learning\nproblem by minimizing the empirical risk. In the k-means\nproblem, this amounts to\n\u02dccsubs = argminc2C Rssubs(c)\nwhere Rssubs(c) =\n1\nssubs \u00c2ssubs\ni=1 d2(c,Xi).\nFor the uniform\nsubsampler the summarization and truncation sizes are\nidentical, ssubs = msubs.\nLarger values of ssubs promote\nlower statistical risk but are more expensive to compute.\nConversely, computation on a smaller set may be fast but\nresults in higher risk. The uniform subsampler may tune\nssubs to balance risk with running time.\nStrategic Sampling Coresets are data summaries that\nare constructed via adaptive sampling, in the spirit of\nimportance sampling. As with the uniform subsampler, we\nstart with data of size n, then truncate it to mcore points.\nNow, instead of using the truncation as is, we perform\nLucic, Ohannessian, Karbasi and Krause\nstrategic sampling to propose a set of score representative\npoints (Yj)j=1,\u00b7\u00b7\u00b7,score, each associated with a non-negative\nweight w j, and we solve the learning problem not on the\nempirical risk, but on a weighted variant. In the k-means\nproblem, this amounts to \u02dcccore = argminc2C Rw\nscore(c) where\nRw\nscore(c) = \u00c2score\nj=1 w jd2(c,Yj). Coresets strive to be a more\nfaithful/concise representation of the data than uniform\nsamples.\nNaturally, their properties depend on how the\nstrategic sampling is performed. The hallmark property of\ncoresets is their ability to approximate the empirical risk,\nde\ufb01ned in (1), optimized over the starting mcore data points.\nDe\ufb01nition 1.\nA coreset construction is a (1 + h)-\napproximation, with h a function of the coreset size\nscore, if the centers \u02dcccore satisfy Rmcore(\u02dcccore) \uf8ff(1 +\nh(score))Rmcore(\u02c6cmcore). 1\nA coreset procedure could start out with a moderately\nlarger truncation mcore > msubs, and yet produce a represen-\ntation that is signi\ufb01cantly smaller score \u2327ssubs, all while\nmaintaining a comparable risk. Note again that without\nperforming truncation, the running time of \ufb01nding a core-\nset of size score using the whole dataset grows with the data\nsize. A number of ef\ufb01cient (1 + h)-coreset constructions\nfor k-means are known, as reviewed in Section 5.2. We\nstudy a particularly practical variant in Section 7. Addition-\nally, it is worth noting that coresets have the advantage of\nadmitting streaming and parallel constructions (Har-Peled\nand Mazumdar [2004], Balcan et al. [2013]), which makes\nthem particularly suited for massive datasets.\n4\nSPACE-TIME-DATA-RISK TRADEOFF\nOur goal now is to give a precise de\ufb01nition of tradeoffs:\nhow data summarization may lead to trading off representa-\ntion space, running time, data size, and statistical risk. Let\n\u02dccproc(n,mproc,sproc), or \u02dccproc for short, denote a k-means\nprocedure based on data summarization, such as uniform\nsubsampling or coreset summarization. Recall that such a\nprocedure starts with n data points, truncates them to mproc\npoints, summarizes these to sproc (possibly weighted) rep-\nresentative points, and optimizes the (possibly weighted)\nempirical risk to obtain the set of centers \u02dccproc. The running\ntime, which we denote by tproc, may be further decomposed\ninto: summarization time tsum\nproc and the time tsolver for empir-\nical risk optimization. The former depends on the particular\nprocedure, but the latter can be a generic solver across\nprocedures. We assume that the act of truncation (for both\nthe uniform subsampler and the coreset procedure) has no\ncomputational cost. The statistical risk of the procedure,\nwhich we denote by Rproc, is the expected risk, where the\nexpectation is taken with respect to the sample. That is,\n1Coresets conventionally require approximating the risk at all\nc: for e 2 (0,1), 8c 2 C , |Rwscore(c)/Rm(c)\u22121| \uf8ffe. This implies\na (1+h)-approximation with h = 2e/(1\u2212e).\nRproc := E[R(\u02dccproc)]. We can decompose it as follows:\nRproc\n\uf8ff\nR(c?)\n| {z }\nemodel\n+E[R(\u02c6cmproc)]\u2212R(c?)\n|\n{z\n}\neest\n+\n|E[R(\u02dccproc)]\u2212E[R(\u02c6cmproc)]|\n|\n{z\n}\nesum\n,\n(2)\nwhere emodel, eest, and esum are the modeling, estimation,\nand summarization errors, respectively.\nThe modeling\nerror is the best risk achieved by any k centers (limitation\nof the model). The estimation error is incurred due to using\nthe empirically optimal centers (limitation of estimating\nfrom data).\nLastly, we have the error of approximate\ndata summarization.\nFor coresets it depends on h (cf.\nProposition 4).\nHow to trade off\nThe four dimensions space, time, data,\nand risk put forth in this paper can now be represented\nby the four parameters (sproc,tproc,mproc,Rproc). We can\nobtain a variety of tradeoffs by constraining some dimen-\nsions and optimizing others. Of course, not all (s,t,m,R)-\ntuples are attainable: for instance, classical sample com-\nplexity bounds constrain what risks are attainable at what\ndata sizes. We call a subset of the dimensions feasible for\na procedure, if there exist values of the others that lead\nto attainable tuples. By exploring the feasible landscape,\none can harness various trends. For example, based on the\nrisk decomposition stated above, as we decrease sproc, the\nrisk Rproc increases due to the increase in esum. In contrast,\nsolving the optimization becomes computationally cheaper\nwith smaller sproc. These interactions, illustrated schemat-\nically in Figure 1b give rise to various tradeoffs. Some of\nthese are listed in Figure 1a.\nIn this paper, we are mainly interested in (a) data-time\ntradeoffs: for Rproc \ufb01xed below some etotal, can tproc de-\ncrease as n increases?\nand (b) risk-time tradeoffs: for\nsome \ufb01xed n, can tproc decrease as Rproc increases? These\ntwo tradeoffs are listed respectively in the \ufb01rst and sec-\nond rows of the table in Figure 1a. Data summarization\ngives us a natural framework to answer those questions:\nwe could achieve such gains by optimizing summariza-\ntion space sproc. This captures the weakening-through-data-\nsummarization mechanism that we advocate in this paper.\nFormally, given a data size n and risk etotal, the optimal\nrunning time function is:\nt?\nproc(n,etotal) = minmproc,sproc tproc(n,mproc,sproc),\n(3)\ns.t. Rproc(mproc,sproc) \uf8ffetotal,mproc \uf8ffn.\nObserve that for \ufb01xed etotal and as n varies, the optimal\nrunning time t?\nproc is non-increasing in n by construction.\nSimilarly, for \ufb01xed n and as etotal varies, the optimal run-\nning time t?\nproc is non-increasing in etotal.\nDe\ufb01nition 2. We say that a k-means procedure offers a\n(non-trivial) data-time tradeoff if, for a given desired to-\ntal risk etotal, the running time t?\nproc(\u00b7,etotal) is decreasing\nTradeoffs for Space, Time, Data and Risk in Unsupervised Learning\nTradeoff\nSpace\nTime\nData\nRisk\nData-Time\nTune\nObjective\nVary\nFixed\nRisk-Time\nTune\nObjective\nFixed\nVary\nSpace-Risk\nVary\nTune\nFixed\nObjective\nData-Risk\nTune\nFixed\nVary\nObjective\nSpace-Time\nVary\nObjective\nTune\nFixed\n(a) Tradeoffs\nCost\nk%\nn%\ns%\nemodelling\n&\neestimation\n%\n&\nesummarization\n%\n!\n&\nt\n%\n%\n%\n(b) Trends\n0\n500\n1000\n1500\n2000\n0\n0.2\n0.4\n0.6\n0.8\n1\nRunning Time\nData size\nCoreset\nUniform\n(c) Data-Time\n200\n300\n400\n500\n0\n1\n2\n3\n4\n5\n6\nRunning time\nRisk\nCoreset\nUniform\n(d) Risk-Time\nFigure 1: (a) Examples of Space-Time-Data-Risk-Tradeoffs, each realized by trading off two parameters (green and gray), by con-\nstraining (red) and tuning (blue) the remaining ones. (b) Effect of increasing k, n and s on the various errors and running time t. (c)\nCoreset (red) data-time tradeoffs versus subsampler (black). The plots represent best running time for \ufb01xed risk tolerance when varying\nthe data size, as predicted by our theory (Section 5). (d) Risk-time tradeoff, i.e., best achievable running time for \ufb01xed data size when\nvarying the allowed risk. [Time units normalized to the median subsampler time.]\nfor some range of n. We say that the procedure offers a\n(non-trivial) risk-time tradeoff if, for a given data size n,\nt?\nproc(n,\u00b7) is decreasing for some range of etotal. In other\nwords, these tradeoffs correspond to (non-\ufb02at) Pareto opti-\nmal frontiers of t?\nproc, as either of the arguments is \ufb01xed.\nTradeoffs divide the landscape into various operation\nregimes.\nFor data-time tradeoffs, before n reaches the\nfeasible range for etotal, we are in a \u201cdata-bounded\u201d regime\n(cf., Shalev-Shwartz and Srebro [2008]). We cannot get\nthe desired risk etotal, and have to invest all of the data\nand computation to driving the risk as low as possible.\nOn the other extreme, very large data sizes are bound to\nlead to a point where more data can safely be discarded\nwith no further impact on risk and computation time. This\nis the \u201cdata-laden\u201d regime. In our framework, it means\nthat in the data-laden regime t?\nproc(\u00b7,etotal) \ufb02attens. Lastly,\nthere is an \u201cintermediate regime\u201d where all of the available\ndata is used, but there is maneuvering room to drive the\ncomputation time down or in other words t?\nproc(\u00b7,etotal)\ndecreases. A lot of the subtlety of the tradeoffs happens in\nthis regime. We see this phenomenon manifest itself both\nanalytically, in Section 5, and experimentally, in Section 7.\nExtensions\nOur methodology is formalized for the k-\nmeans problem, but the framework is much richer. For\nexample, spectral clustering methods that can be mapped\nto k-means are bound to pro\ufb01t directly from our results. A\nconcrete extension consists of Gaussian Mixture Models,\nby using the negative log-likelihood as the risk and coreset\nconstruction by Feldman et al. [2011]. We do not formalize\nthis, but we demonstrate it experimentally in Section 7.\n5\nANALYSIS\nWe have thus far motivated and laid out a clear paradigm\nof tradeoffs via data summarization. But are such tradeoffs\neven possible? In this section, we show that the answer is\nyes. To keep our exposition concise, we focus in particu-\nlar on showing that nontrivial data-time tradeoffs (De\ufb01ni-\ntion 2) do indeed exist. For this we need to characterize\nt?\nproc(n,etotal) as n varies, for a \ufb01xed desired risk level etotal.\nFor the uniform subsampler the data-time tradeoff is neces-\nsarily trivial. To see this, let nf(etotal) be the smallest data\nsize n when etotal becomes feasible. Then for all n \u2265nf we\nhave emodel + eest(n) \uf8ffetotal but the uniform subsampler\nhas no incentive to use more than msubs = nf samples, since\notherwise its running time would be greater (for unneeded\nrisk reduction). This means that t?\nsubs(\u00b7,etotal) is unde\ufb01ned\nfor n < nf(etotal), and is \ufb02at beyond that. In the language of\nSection 4, the uniform subsampler switches abruptly from\nthe \u201cdata-bounded\u201d to the \u201cdata-laden\u201d regime.\nThe more interesting question is thus: Can coreset proce-\ndures give non-trivial data-time tradeoffs that improve on\nthe uniform subsampler?\nIn particular, can we observe\nan \u201cintermediate regime\u201d where t?\ncore(\u00b7,etotal) curves down,\nbefore reaching the data-laden regime? Our main result\nanswers these questions in the af\ufb01rmative. Informally, we\nhave the following.\nMain Result (Existence of Tradeoffs). Let the following\nconditions hold for a coreset procedure:\n(a) The summarization is time-ef\ufb01cient (its running time is\nnegligible relative to that of the solver).\n(b) The summarization is sample-ef\ufb01cient (the approxima-\ntion factor vs. summarization size decays faster than\nthe estimation error vs. sample size).\n(c) The estimation error decays fast (\u21e0power law).\n(d) The solver is slow (at least super-linear).\nThen, for small enough risks, the procedure admits a non-\ntrivial tradeoff, and its optimal running time dominates (is\nless than) that of the uniform subsampler for large enough\ndata sizes.\nMoreover, existing bounds and coreset con-\nstructions do satisfy these conditions.\nIn what follows, we proceed to formalize this result. In Sec-\ntion 5.1 we give the suf\ufb01cient conditions and in Section 5.2\nwe af\ufb01rm that these conditions are satis\ufb01ed in practice, by\ngiving existing risk bounds and coreset constructions. We\nalso provide some numerical illustrations of tradeoffs using\nthese bounds. In Section 7 we demonstrate these tradeoffs\nexperimentally.\nLucic, Ohannessian, Karbasi and Krause\n5.1\nSuf\ufb01cient Conditions for Tradeoffs\nRecall \ufb01rst some notation from Section 4. When a core-\nset summarization procedure has a total risk (Rcore), it can\nbe decomposed into modeling (emodel), estimation (eest),\nand summarization errors (esum). The latter depends on the\ncoreset approximation that results from a choice of a given\nsummarization size (h(score)) (Proposition 4 makes this\nprecise). The total running time of the procedure tproc can\nbe decomposed into summarization time (tsum\nproc) and empir-\nical risk minimization time (tsolver). The latter is attributed\nto a generic solver, and it depends only on the size (sproc)\nof its input. For the former, we add some further notation\ndue to \u201cbicriteria\u201d-type coreset constructions (Feldman and\nLangberg [2011]), where the summarization stage itself is\ndecoupled into two: initialization, taking time tinit\ncore(mcore)\nthat depends only on the (truncated) data size, followed by\nadaptive sampling, with time tsamp\ncore (score) that depends only\non the coreset summarization size. We are now ready to\nformally state our main result\u2019s conditions.\nTheorem 1. Let tsolver(\u00b7), tinit\ncore(\u00b7), tsamp\ncore (\u00b7) be increasing,\nand eest(\u00b7) and h(\u00b7) be decreasing functions of their argu-\nments. Let the setting of the coreset procedure be such that\nthe following are satis\ufb01ed:\n(a) tinit\ncore(\u00b7) is linear and tsamp\ncore (x) = o(tsolver(x)),\n(b) 9a,b > 0 such that for large enough x, 2h(x) \uf8ff\n(1/emodel \u2212a)eest((1+b)x).\n(c) 8L(x) ! \u2022, no matter how slowly, eest(xL(x))\neest(x)\n! 0, as\nx ! \u2022,\n(d) tsolver(\u00b7) is bounded from below by a convex super-\nlinear function, i.e. tsolver(x)\nx\n! \u2022, as x ! \u2022,\nThen there exists a small enough risk e0, such that for all\ndesired risks etotal \uf8ffe0, there exists a large enough sample\nsize n0, beyond which for all n > n0 we have t?\ncore(n,etotal) <\nt?\nsubs(n,etotal).\nSince the coreset procedure cannot be faster than the sub-\nsampler at a sample size at the threshold of feasibility, the\ntheorem implies that for all etotal \uf8ffe0 the coreset proce-\ndure achieves a non-trivial tradeoff with an \u201cintermediate\nregime\u201d, eventually dominating the uniform subsampler for\nlarge enough sample sizes.\nCondition (a) asks for the solver\u2019s running time to over-\nshadow that of summarization (how could one bene\ufb01t\nfrom summarization otherwise?). Slower solvers can only\n\u201chelp\u201d satisfy this condition. Condition (b) is more subtle,\nthough it can be understood as follows: if larger summaries\ndo not drive the summarization error down as fast as larger\nsample sizes drive the estimation error down, then summa-\nrization loses its competitive advantage against truncation.\nAs for Conditions (c) and (d), they are primarily used in\na technical context, to balance asymptotic expressions. As\nwe outline in Section 5.2, these conditions are natural be-\nhaviors for the estimation error and solver respectively.\nProof sketch of Theorem 1. To prove this theorem, it suf-\n\ufb01ces to show that for a large enough sample size x we can\n\ufb01nd a (possibly suboptimal) coreset size s such that the\nresulting procedure has etotal = emodel + eest(x) while its\nrunning time is less than tsolver(x). This is because x and\ntsolver(x) represent respectively the feasibility threshold and\nthe optimal running time of the uniform subsampler that\nachieves a risk of etotal. To maintain a risk of etotal, the\ncorset procedure needs to choose an appropriate truncation\nsize m slightly larger than x, and the result would only hold\nfor n \u2265m, thus allowing enough samples for summariza-\ntion.\nWe make a simple choice, s = t\u22121\nsolver((1\u22122d)tsolver(x)) for\nsome d > 0, ignoring rounding.\nThis implies a perfor-\nmance gap tsolver(x)\u2212tsolver(s) of 2dtsolver(x) within which\nwe can maneuver. Then Condition (a) implies that for large\nenough x the sampling stage will occupy less than dt(x) of\nthis gap. On the other hand, the initialization stage depends\nlinearly on the resulting m. Condition (b) then intervenes\nto show that the impact of this stage remains also within\nanother dt(x), thus establishing the theorem. This, how-\never, also requires x to be large enough to align with the\nconstants of Condition (b), and for that we invoke Condi-\ntions (c) and (d). The details can be found in the supple-\nments.\n5.2\nExistence of Tradeoffs\nWe now af\ufb01rm that the conditions of Theorem 1 are met by\nexisting constructions.\nProposition 1. Under known risk bounds (Propositions 2\nand 3) and coreset constructions (Feldman and Langberg\n[2011]), and when using a super-linear polynomial-time or\nslower solver, the conditions of Theorem 1 are satis\ufb01ed.\nWe can illustrate this result visually via simulations: we\nperform numerical optimization using the risk, running\ntime, and summarization bounds given in this section. The\ndetails can be found in the supplements. We plot a rep-\nresentative data-time tradeoff of both the subsampler (in\nblack) and the coreset procedure (in red) in Figure 1c. Note\nthat the coreset procedure dominates. The same type of nu-\nmerical optimization can be done to obtain other tradeoffs:\nwe plot the risk-time tradeoff of the same problem in Figure\n1d. As Theorem 1 predicts, the coreset dominates primarily\nfor smaller values of the risk. The proof of Proposition 1,\nalso in the supplments, is a direct veri\ufb01cation of the condi-\ntions of Theorem 1. We give here an account of the invoked\nbounds and coreset construction.\nRisk Bounds\nThe following bounds characterize the\nrisks in terms of the parameters of the problem: the di-\nmension d, radius B, and number of clusters k. Note that\nthe modeling error does not depend on the procedure, the\nestimation error only depends on the procedure through the\ntruncation size mproc, and the summarization errors depend\nmore closely on the speci\ufb01cs of the summarization. The\nTradeoffs for Space, Time, Data and Risk in Unsupervised Learning\nfollowing bound on the modeling error is minimax up to\nconstants (Graf and Luschgy [2000]).\nProposition 2 (Modeling Error). The modeling error sat-\nis\ufb01es emodel \uf8ffB2d\nk2/d .\nThe estimation error has been extensively studied in statis-\ntics. We have the following (Antos et al. [2005]):\nProposition 3 (Estimation Error). The estimation error\nsatis\ufb01es eest \uf8ffsB2\np\nkd\npmproc , for some s > 0. Furthermore,\nwe have a lower bound: there exists s > 0 such that when-\never k \u22653, we may \ufb01nd P for which for large enough mproc\nwe have: eest \u2265sB2\np\nk1\u22124/d\npmproc .\nThe summarization error depends on the particular sum-\nmarization procedure.\nFor uniform subsampling, since\n\u02dccsubs = \u02c6cmsubs, it is trivially zero (cf. Equation (2)). For a\ncoreset procedure, it depends on the coreset size or equiva-\nlently the approximation factor h.\nProposition 4 (Summarization Error). Given a (1 + h)-\napproximation coreset, when h(score) \u2265h0 > 0, then\nesum < 2(emodel +eest)h(score) for large enough m.\nPropositions 2 and 3 are restatements. On the other hand,\nProposition 4 is new. The proof relies on uniform concen-\ntration, and is detailed in the supplements.\nRunning Time Bounds\nSolving for the exact empiri-\ncally optimal centers is NP-hard, with the running time of\nknown exact algorithms being tsolver(s) = W(skd) (cf., In-\naba et al. [1994]). There are various popular heuristics,\nincluding Lloyd\u2019s (\u201cthe k-means\u201d) algorithm, and on typi-\ncal inputs these have polynomial running times tsolver(s) =\nW(poly(k)poly(d)poly(s)). Under further conditions they\ncan be exact (Meyerson et al. [2004]). Even these opti-\nmistic polynomial running times are suf\ufb01cient for us.\nThe uniform subsampler performs no summarization be-\nyond truncation, ssubs = msubs. Thus tsum\nsubs = 0, and:\ntsubs(n,msubs,ssubs) = tsolver(ssubs).\nFor coresets, we use the above-mentioned \u201cbicriteria\u201d con-\nstruction by Feldman and Langberg [2011]. We have:\ntcore(n,mcore,score) = tsolver(score)+tinit\ncore(mcore)\n+tsamp\ncore (score).\n(4)\nLike the risks, these initialization and sampling times de-\npend on the various parameters of the problem, and in par-\nticular the dimension d and the number of clusters k. In\nmany constructions, these are linear functions of their ar-\nguments. In particular, the coreset construction of Feld-\nman and Langberg [2011] is a (1+h)-approximation with\ntinit\ncore(mcore) = O(dkmcore) and tsamp\ncore (score) = O(score).\nCoreset Approximation\nThe last component of Propo-\nsition 1, needed to fully characterize a coreset approxi-\nmation, is the functional relationship between the approx-\nimation factor h and the coreset size score.\nIn partic-\nular, we note that Feldman and Langberg [2011] gives\na (1 + h)-approximation with a coreset of size score =\nO(dk(2+h)2/h2) (see1 for reference). We may thus write\nh(score) = O\n\u21e3p\ndk/(pscore \u2212\np\ndk)\n\u2318\n.\n6\nDATA-DRIVEN TRADEOFF\nNAVIGATION\nSo far we demonstrated tradeoffs in k-means by consid-\nering analytical models. In practice, however, even if a\ntradeoff exists, it is a priori unclear how to harness it:\none would seemingly need a \u201ctuning oracle\u201d to adjust the\nprocedure to yield an optimal tradeoff, by selecting optimal\ntruncation and summarization sizes. An exhaustive search\nfor such an adjustment is useful for illustration, but it\ndefeats the purpose of the endeavor, which is to yield a\npractical algorithm whose running time decreases with\nmore data. In this section, we address this challenge by\nproposing a TRadeoff nAvigation algorithM (TRAM). It\nuses a limited amount of additional validation data to\nexplore the summarization landscape, and leads to a sum-\nmarization that exhibits acceptable loss in risk etotal, time\nt?, and space s?, thus effectively approximating a tuning\noracle. We focus speci\ufb01cally on data-time tradeoffs via\ncoreset data-summarization schemes, though the approach\nis potentially extensible to other tradeoffs and procedures.\nTheoretical Setting\nWe design and study our algorithm\nunder the following assumptions.\n(A) The running time of the coreset procedure is known,\nup to scaling. In particular, we consider a polynomial\ntime solver and take tcore = am+sb for known a,b >\n1.\n(B) Evaluating the empirical risk using a data set of size a\ntakes a running time of ka.\n(C) Let m? and s? be the solutions of Equation (3) real-\nizing the optimal time t? = t?\ncore(n,etotal). We have\nR(\u02dcc(m,s)) \uf8ffetotal for all m \u2265m?, s \u2265s?, with proba-\nbility at least 1\u2212l.\n(D) We have access to additional samples from the distri-\nbution P, beyond the data size n.\nAssumption (A) maps to the framework of Section 5.2:\ntinit\ncore(m) is linear in m, tsamp\ncore\nis absorbed into tsolver, tsolver\nis polynomial, and both are normalized to maintain only\na single constant.\nAssumption (B) is trivial, except for\nabsorbing the dimension and leading constants into k. (C)\nis a monotonicity assumption, requiring that with some\nprobability 1 \u2212l not just the optimal coreset size but also\nall larger summaries are below the base risk etotal. The\nalgorithm does not use l, it is there only for performance\nanalysis. Lastly, Assumption (D) uses separate data to vali-\ndate in order to both use independence from the data itself,\nand allow to derive sample complexities for validation us-\ning basic concentration inequalities. Theorem 2 shows that\nonly a small number of such points are needed. In practice,\nthe data itself is partitioned to provide these points.\nLucic, Ohannessian, Karbasi and Krause\nA TRadeoff nAvigation algorithM (TRAM)\nThe idea\nof TRAM is as follows: search for a good summariza-\ntion by starting small then growing until the desired risk\nis achieved. The challenge is that the risk cannot be known\nexactly and needs to be tested using data. We therefore\nhave a compromise: if we stop too early we miss the target,\nand if we stop too late we spend too much on computation.\nThe analysis shows that the algorithm achieves a certain\nbalance.\nAlgorithm TRadeoff nAvigation algorithM (TRAM)\n1: Input: Data of size n; risk level etotal; validation data\nof size a; accuracy parameter d > 0.\n2: Initialization: Start with a truncation of size m[0] < n\nand a coreset size of s[0].\n3: repeat\n4:\nIteration step i: Summarize the m[i]-truncation to\na coreset of size s[i], and solve for the centers \u02dcc[i].\nIncrement m[i] to m[i + 1], and s[i] to s[i + 1]. Use\na portion a[i] of the validation data to evaluate the\nempirical risk of \u02dcc[i].\n5: until Ra[i](\u02dcc[i]) \uf8fft.\n6: Output: The last set of centers \u02dcc[i].\nThe validation data is a growing sequence drawn from the\npoints described in Assumption (D).\nMore speci\ufb01cally,\n4blog(1/d)/etotal2 additional points are used at each iter-\nation, where b = 2B2, and thus a[i] = 4iblog(1/d)/etotal2.\nThe size increments happen multiplicatively: m[i + 1]  \ngmm[i] ^ n and s[i + 1]  gss[i].\nIn particular, we take\ngm = 2 and gs = 21/b. Lastly, the threshold (in step 5) is\nt = 3etotal/2.\nTheorem 2. Let T and J denote the running time and num-\nber of iterations of TRAM respectively. Under assumptions\n(A) to (D), given data of size n, a base risk etotal, and pa-\nrameter d < 1\n5, with probability at least (1 \u2212l)(1 \u22125d),\nTRAM:\n. runs for time T \uf8ff4t?2 +\n8bk\netotal2 log 1\nd log2\n2t?,\n. uses a[J] \uf8ff\n8b\netotal2 log 1\nd log2t? validation points,\n. and produces centers \u02dcc with risk R(\u02dcc) \uf8ff2etotal.\nProof sketch. Using the validation test at every step, grow-\ning the set to compensate for dependencies, we control\nthe errors of stopping too far before and too far after the\noptimal truncation and coreset sizes. The threshold that\nis slightly larger than the base risk gives us a detection\nmargin. If these errors are not too large, the polynomial\nstructure of the running time of the coreset procedure com-\npounds with the geometric incrementing scheme, to lead to\na computational overhead that remains reasonably close to\nthe optimal.\nNote that the search does come with a penalty (the run-\nning time is squared). However, the analysis is very con-\nservative and none of the constants depend on the data size\nn. Thus TRAM does indeed reproduce the qualitative be-\nhavior of the tradeoff, i.e. the running time decays as the\ndata size increases, while the guaranteed risk remains ef-\nfectively constant.\n7\nEXPERIMENTAL RESULTS\nWe now empirically establish the existence of tradeoffs and\nevaluate the performance of TRAM.\nSetup\nGiven a dataset X \u2713Rd and some etotal, we wish\nto \ufb01nd the minimum computational cost of obtaining a\nk-means solution with risk less than or equal to etotal. We\ninterpret P as the uniform distribution over X , hence we\ncan compute the risk exactly. We simulate various dataset\nsizes by restricting individual experiments to a random\nsubset of X .\nFor each pair of data size ni 2 N\nand\nsummary size s j 2 S we sample ni instances i.i.d. from\nX and summarize the sample with a summary of size sj\nand solve the problem on the summary. We repeat the latter\n50 times and report the average time and risk obtained.\nFor the uniform subsampler, sj refers to the subsample\nsize, and for the coresets it refers to the size of the coreset.\nWe denote the cumulative running time of summarizing\nand solving the problem on the summary by t(ni,sj) and\nthe obtained risk by R(ni,sj).\nFor each procedure, let\nLproc = {(n,t(n,s),R(n,s)) | n 2 N ,s 2 S }.\nWe can now leverage Lproc to characterize various trade-\noffs. For example, to capture the data-time tradeoff for a\nparticular size n we \ufb01nd the minimum running time t0 such\nthat 9(m,t0,R) 2 Lproc, with m < n and R \uf8ffetotal. Search-\ning Lproc yields Pareto-optimal boundaries of two ora-\ncles: coreset-based (ORACLE-C) and uniform-sampling-\nbased (ORACLE-U).\nTo show that one can navigate the\nspace/time/data/risk tradeoffs in practice using TRAM, we\nshowcase it alongside the oracles in Figure 2. Finding the\noracles is computationally prohibitive as it entails a full\ngrid search over N and S . Nevertheless, the reported\ntimes assume the oracles simply know the best summariza-\ntion.\nDatasets\nSYNTHETIC \u2014 We generate synthetic data of\n100,000 points in R100 from a mixture of Gaussians. We\nchoose k = 100 centers in [0,100]100 and set them as means\nfor the k spherical Gaussian distributions with S = 5I. The\nrelative magnitudes of the clusters are sampled from an ex-\nchangeable Dirichlet distribution with parameter 1/20.\nKDD2004BIO \u2014 The dataset of the Protein Homology Pre-\ndiction Task in KDD Cup 2004, with 145,751 instances\nand 74 attributes that describe the match between two pro-\nteins. We \ufb01t k-means with k = 150.\nCSN \u2014 The Community Seismic Network (CSN) uses\nsmart phones with accelerometers as inexpensive seis-\nmometers for earthquake detection. Faulkner et al. [2011]\ncompiled 7 GB of acceleration data and computed 17-\ndimensional feature vectors. We \ufb01t k-means with k = 200.\nTradeoffs for Space, Time, Data and Risk in Unsupervised Learning\n214\n215\n216\n217\nDataset Size\n0\n2\n4\n6\nRunning Time [s]\nTRAM\nORACLE-U\nORACLE-C\nR=800.86\n213\n214\n215\n216\n217\nDataset Size\n0\n1\n2\n3\n4\n5\n6\n7\n8\nRunning Time [s]\nTRAM\nORACLE-C\nORACLE-U\nR=1.27e+06\n214\n215\n216\n217\nDataset Size\n0\n1\n2\nRunning Time [s]\nTRAM\nORACLE-C\nORACLE-U\nR=5.23\n213\n215\n217\n219\n221\n223\n225\nDataset Size\n10\n15\n20\n25\n30\nRunning time [s]\nORACLE-C\nTRAM\nORACLE-U\nLL=-10.58917\n785\n795\n805\n815\n825\nRisk\n0\n2\n4\n6\n8\nRunning Time [s]\nORACLE-C\nTRAM\nORACLE-U\nN=100000\n1.20\n1.21\n1.22\n1.23\n1.24\n1.25\nRisk\n\u21e5106\n0\n2\n4\n6\n8\nRunning Time [s]\nORACLE-C\nORACLE-U\nTRAM\nN=140000\n4.5\n5.0\n5.5\n6.0\n6.5\nRisk\n0\n1\n2\nRunning Time [s]\nORACLE-C\nTRAM\nORACLE-U\nN=120000\n\u221210.3\n\u221210.4\n\u221210.5\n\u221210.6\nRisk\n10\n15\n20\n25\nRunning Time [s]\nORACLE-C\nTRAM\nORACLE-U\nN=44000000\nFigure 2: Results for SYNTHETIC, KDD2004BIO, CSN and WEBSCOPE datasets, per column from left to right. Figures in the \ufb01rst row\nshow data-time tradeoffs: best running time for \ufb01xed risk tolerance and varying data sizes (cf. Figure 1c). Tradeoffs exist: running time\ndecreases with increasing data size. Furthermore, the coreset procedure dominates uniform subsampling, and TRAM tracks the coreset\ntradeoff closely, with limited overhead. Figures in the second row show risk-time tradeoffs: best running time for \ufb01xed data size and\nvarying risk tolerance (cf. Figure 1d).\nYAHOO! WEBSCOPE R6A \u2014 45,811,883 instances in R6\nthat represent the user click log displayed on the Yahoo!\nFront Page. We \ufb01t a GMM with k = 200 components. The\nrisk here is the negative log likelihood on the hold-out data.\nParameters\nFor the k-means clustering problem we use\nthe coreset construction from Feldman and Langberg\n[2011], and a weighted variant of the k-means++ algo-\nrithm to solve the problem on the subsample. In the case\nof GMMs, we use the coreset construction from Feldman\net al. [2011] and a weighted EM for GMMs.\nWe con-\nsider summarization sizes between 100 and 20,000. For\nTRAM, we start with summarization size and truncation\nsize inversely proportional to the risk required. At every\niteration, we double the truncation size and take 1.5-fold\n(b = \u2212log2 1.5) of the summarization size. 1/5th of the\ndata is assigned to validation, with a d of 0.1.\nObservations\nThe plots in the \ufb01rst row in Figure 2 show\nthe Pareto-optimal boundary for a \ufb01xed risk as data size\nvaries. There is a data-time tradeoff as predicted from the-\nory. Furthermore, TRAM traces the solutions achieved by\nthe coreset oracle, implying that we can navigate tradeoff\ncurves without oracles. Remarkably, TRAM remains better\nthan the uniform subsampler oracle, eventhough either\noracle takes orders of magnitude more time to obtain by\nexhaustive search. The second row illustrates the existence\nof a risk-time tradeoffs also: for \ufb01xed data size, the time to\nguarantee a desired risk decreases as the risk increases. An-\nother perspective to these results is as follows. A potential\npractitioner is faced with three options: solving the prob-\nlem on the whole dataset or doing so after summarizing,\neither by truncating to a portion deemed adequate or by\nstrategically summarizing the data with a somewhat larger\nportion. The former is often out of the question (in the case\nof GMMs, it may take weeks). Summarization slashes this\ntime down (minutes instead of weeks). However, because\nthe coreset procedure can achieve a faster time even as it\naccesses a larger portion, it will be more likely to guarantee\na desired risk, as compared to the uniform subsampler, at\nleast for interesting (small) risk levels.\n8\nCONCLUSIONS\nWe explored space/time/data/risk tradeoffs achievable via\ncoreset-based data-summarization.\nOur theory predicts\nand our empirical results demonstrate the existence and\nutility of such tradeoffs.\nWe further showed how such\ntradeoffs can be practically realized via a novel algorithm,\nTRAM.\nWhile our analysis focused on k-means, our\ninsights are more generally applicable. In particular, we\nempirically demonstrated tradeoffs in learning Gaussian\nMixture Models. Approaches that optimize cost functions\nrelated to the quantization error, such as small-variance\nlimits of non-parametric Bayesian models Jiang et al.\n[2012], may also immediately bene\ufb01t from our results.\nWe thus strongly believe that our results present an\nimportant step towards understanding tradeoffs in large-\nscale unsupervised learning. Lastly,\ngiven promising\nsummarization-style techniques Pavlov et al. [2000], Bakir\net al. [2004], Tsang et al. [2005], similar results may also\nbe possible in supervised learning.\nAcknowledgements\nThis work was supported in part by ERC StG 307036, an\nETH Fellowship, a Microsoft Research Faculty Fellowship,\nand the Zurich Information Security Center. The research\nwas carried out when the second author was an MSR-Inria\npostdoctoral researcher and an ERCIM \"Alain Bensous-\nsan\" fellow, funded in part by EU FP7/2007-2013 Grant\n246016.\nLucic, Ohannessian, Karbasi and Krause\nReferences\nPankaj K Agarwal, Sariel Har-Peled, and Kasturi R\nVaradarajan.\nGeometric approximation via coresets.\nCombinatorial and computational geometry, 52:1\u201330,\n2005.\nAndr\u00e1s Antos, L\u00e1szl\u00f3 Gy\u00f6r\ufb01, and Andr\u00e1s Gy\u00f6rgy. Indi-\nvidual convergence rates in empirical vector quantizer\ndesign. Information Theory, IEEE Transactions on, 51\n(11):4013\u20134022, 2005.\nG\u00f6khan H. Bakir, L\u00e9on Bottou, and Jason Weston. Break-\ning SVM Complexity with Cross-Training.\nIn NIPS,\n2004.\nMaria-Florina Balcan, Steven Ehrlich, and Yingyu Liang.\nDistributed k-means and k-median clustering on general\ntopologies. In NIPS, pages 1995\u20132003, 2013.\nShai Ben-David.\nA framework for statistical cluster-\ning with constant time approximation algorithms for k-\nmedian and k-means clustering. Machine Learning, 66\n(2-3):243\u2013257, 2007.\nAharon Birnbaum and Shai S Shwartz. Learning halfspaces\nwith the zero-one loss: time-accuracy tradeoffs. In NIPS,\npages 935\u2013943, 2012.\nL\u00e9on Bottou and Olivier Bousquet. The Tradeoffs of Large-\nScale Learning. In NIPS, volume 20, pages 161\u2013168.\nNIPS Foundation, 2008.\nVenkat Chandrasekaran and Michael I Jordan.\nCompu-\ntational and statistical tradeoffs via convex relaxation.\nPNAS U.S.A., 110(13):E1181\u201390, March 2013.\nScott E Decatur, Oded Goldreich, and Dana Ron. Compu-\ntational sample complexity. SIAM Journal on Comput-\ning, 29(3):854\u2013879, 2000.\nMatthew Faulkner, Michael Olson, Rishi Chandy, Jonathan\nKrause, K Mani Chandy, and Andreas Krause. The next\nbig one: Detecting earthquakes and other rare events\nfrom community-based sensors. In IPSN, pages 13\u201324,\n2011.\nDan Feldman and Michael Langberg. A Uni\ufb01ed Frame-\nwork for Approximating and Clustering Data. In STOC,\npages 569\u2013578. ACM, 2011.\nDan Feldman, Morteza Monemizadeh, and Christian\nSohler. A PTAS for k-means clustering based on weak\ncoresets. In Proceedings of the 23rd Annual Symposium\non Computational Geometry, pages 11\u201318. ACM, 2007.\nDan Feldman, Andreas Krause, and Matthew Faulkner.\nScalable training of mixture models via coresets.\nIn\nNIPS, pages 2142\u20132150, 2011.\nDan Feldman, Melanie Schmidt, and Christian Sohler.\nTurning big data into tiny data: Constant-size coresets\nfor k-means, PCA and projective clustering. In SODA,\n2013.\nSiegfried Graf and Harald Luschgy. Foundations of Quan-\ntization for Probability Distributions. Springer, 2000.\nSariel Har-Peled and Soham Mazumdar. On coresets for\nk-means and k-median clustering. In STOC, pages 291\u2013\n300. ACM, 2004.\nMary Inaba, Naoki Katoh, and Hiroshi Imai.\nApplica-\ntions of weighted Voronoi diagrams and randomization\nto variance-based k-clustering.\nIn ACM SoCG, pages\n332\u2013339. ACM, 1994.\nKe Jiang, Brian Kulis, and Michael I Jordan.\nSmall-\nvariance asymptotics for exponential family Dirichlet\nprocess mixture models.\nIn NIPS, pages 3167\u20133175,\n2012.\nTapas Kanungo, David M Mount, Nathan S Netanyahu,\nChristine D Piatko, Ruth Silverman, and Angela Y Wu.\nAn ef\ufb01cient k-means clustering algorithm: Analysis and\nimplementation. Pattern Analysis and Machine Intelli-\ngence, IEEE Transactions on, 24(7):881\u2013892, 2002.\nTam\u00e1s Linder. Learning-theoretic methods in vector quan-\ntization. In Principles of nonparametric learning, pages\n163\u2013210. Springer, 2002.\nStuart Lloyd. Least squares quantization in PCM. IEEE\nTransactions on Information Theory, 28(2):129\u2013137,\n1982.\nAdam Meyerson, Liadan O\u2019Callaghan, and Serge Plotkin.\nA k-Median algorithm with running time independent of\ndata size. Machine Learning, 2004. ISSN 0885-6125.\nDmitry Pavlov, Darya Chudova, and Padhraic Smyth. To-\nwards scalable support vector machines using squashing.\nIn KDD, pages 295\u2013299, 2000.\nDavid Pollard. Strong consistency of k-means clustering.\nAnn. of Statistics, 9(1):135\u2013140, 1981.\nRocco A Servedio. Computational sample complexity and\nattribute-ef\ufb01cient learning.\nIn STOC, pages 701\u2013710.\nACM, 1999.\nShai Shalev-Shwartz and Nathan Srebro. SVM optimiza-\ntion: inverse dependence on training set size. In ICML,\npages 928\u2013935, 2008.\nMatus Telgarsky and Sanjoy Dasgupta.\nMoment-based\nUniform Deviation Bounds for k-means and Friends.\nCoRR, 2013.\nIvor W. Tsang, James T. Kwok, and Pak-Ming Cheung.\nCore vector machines: fast SVM training on very large\ndata sets. JMLR, 6:363\u2013392, 2005.\nTradeoffs for Space, Time, Data and Risk in Unsupervised Learning\nAppendix\nDetails for Proposition 2 [Modeling Error]\nThe proof consists of properly placing the centers. We direct the interested reader to Graf and Luschgy [2000]. Theorem\n4.16 in that reference illustrates the upper bound, and the examples that follow show that the bound is tight (in k) in a\nminimax sense. We provide here an intuitive sketch to the proof, one could consider a d-hypercube of side B rather than a\nsphere. We can bound the expected square-Euclidean distance with the maximal distance to a center. With a single center\ninitially in the hypercube, this maximal distance is dB2/4. We then successively split into half-sized d-hypercubes using\ncuts by d (d \u22121)-hyperplanes. This multiplies the number of centers by 2d and divides the distance from the centers by 2.\nAfter ` steps, we have k = 2`d centers, and the distance to the centers is bounded by\n1\n22`\ndB2\n4 , and thus by\ndB2\n4k2/d .\nDetails for Proposition 3 [Estimation Error]\nThe estimation error has been extensively studied in the statistics literature. This originated in the work of Pollard [1981],\nwho showed that the empirically optimal centers are consistent, in the sense of both the estimation error decaying to zero\nand the centers converging to the optimal centers. To bound the estimation error, we use a Equation (4) of Antos et al.\n[2005]. Note that we can explicitly choose s = 192. For the lower bound we use Equation (5) of Antos et al. [2005], which\nholds for any estimator based on samples, and in particular for the empirically optimal centers.\nProof of Proposition 4 [Coreset Summarization Error]\nRecall De\ufb01nition 1 of a (1+h)-approximation, Rm(\u02dccm)\u2212Rm(\u02c6cm) \uf8ffhRm(\u02c6cm). Since \u02c6cm minimizes Rm, by taking expec-\ntations we have:\n0 \uf8ffE[Rm(\u02dccm)]\u2212E[Rm(\u02c6cm] \uf8ffhE[Rm(\u02c6cm)].\n(5)\nNote that this guarantee is in terms of the empirical risk, whereas we are interested in the expected value of the true risk in\nthe de\ufb01nition of the expected summarization error in Equation (2):\nesum = |E[R(\u02dccm)]\u2212E[R(\u02c6cm)]|.\nWe can relate these quantities via the following uniform concentration. By virtue of the fact that d2(\u00b7,x) is a smooth\nfunction on C (recall C is the set of all k-centers in the ball at the origin of radius B), as well as bounded for all c 2 C\nand all x in the ball, classical concentration results Linder [2002] imply that we have the following uniform concentration\nresult, for some constant k (that depends on B , d, and k), we have that for all n:\nE\n\uf8ff\nsup\nc2C\n|Rm(c)\u2212R(c)|\n(\n\uf8ff\nk\npm.\nIn particular, this means that for any (even random) c, E[|Rm(c)\u2212R(c)|] \uf8ff\nk\npm. And therefore |E[Rm(c)]\u2212E[R(c)]| \uf8ff\nk\npm\nas well.\nE[R(\u02dcc)]\u2212E[R(\u02c6c)]\n=\n(E[R(\u02dcc)]\u2212E[Rm(\u02dcc)])+(E[Rm(\u02dcc)]\u2212E[Rm(\u02c6c)])+(E[Rm(\u02c6c)]\u2212E[R(\u02c6c)])\n(6)\n\uf8ff\n2k\npm +hE[Rm(\u02c6c)]\n\uf8ff\n2k\npm +h(E[Rm(\u02c6c)]\u2212E[R(\u02c6c)])+hE[R(\u02c6c)]\n\uf8ff\n(2+h)k\npm\n+hE[R(\u02c6c)],\n(7)\nwhere we have used the uniform concentration as well as Equation (5). Recall that R = infc2C R(c), and that we assume\nR > 0, that is the modeling error is positive, therefore we can write this result in a more convenient multiplicative form as\nfollows\nE[R(\u02dcc)]\u2212E[R(\u02c6c)] \uf8ff\n\u2713(2+h)k\nRpm\n+h\n\u25c6\nE[R(\u02c6c)].\nLucic, Ohannessian, Karbasi and Krause\nFor the other side of the inequality, by using once again the fact that \u02c6cm minimizes Rm, we have that unlike in the above the\nmiddle term of the decomposition in Equation (6) is negative and thus:\nE[R(\u02c6c)]\u2212E[R(\u02dcc)] \uf8ff2k\npm.\n(8)\nSince the bound in (7) is always larger than that of (8), we have:\n|E[R(\u02c6c)]\u2212E[R(\u02dcc)]| \uf8ff\n\u2713(2+h)k\nRpm\n+h\n\u25c6\nE[R(\u02c6c)].\nIn particular, if h > h0, then by letting m0 =\nh\u21e3\n2\nh0 +1\n\u2318\nk\nR\ni2\nwe have that for all m > m0,\nesum = |E[R(\u02dcc)]\u2212E[R(\u02c6c)]| \uf8ff2hE[R(\u02c6c)] \uf8ff2h(emodel +eest),\nas desired. As a remark, note how m0 may depend on the parameters of the problem (d,B,k,R), and the lower approxi-\nmation level h0, but not on the value of h. This would allows us to optimize over all score that keep h(score) above h0.\n\u21e4\nProof of Theorem 1 [Existence of Tradoffs]\nIn this proof, without loss of generality, we consider tsolver(\u00b7), tinit(\u00b7), tsamp(\u00b7), eest(\u00b7) and h(\u00b7) to be continuous functions\nfrom their domains to the real numbers. We also equate tsolver with its lower bound. To make the expressions concise,\nlet us rename some of these functions. For the running times, let t(x) = tsolver(x), g(x) = tsamp\ncore (x), and let h be such that\ntinit\ncore(x) = h(x). For the errors, let f(x) = eest(x), and let x = emodel.\nThe idea of the proof is as follows. Let x be a given sample size and let etotal = x + f(x). Since f(x) is decreasing by\nassumption, x represents the threshold of feasibility for a total risk of etotal. Note that we enunciate the statements of this\nproof as being for large enough x, which will then correspond to large enough etotal as stated in the theorem. For all n \u2265x,\nthe optimal behavior of the uniform subsampler given a total risk of etotal is to truncate to x samples. Therefore, we have\nt?\nsubs(n,etotal) = t(x) for all n \u2265x, and unde\ufb01ned otherwise. Given the coreset construction, if for some n \u2265x we manage to\nobtain a suboptimal coreset size s that allows the coreset\u2019s total risk to match etotal while its running time is less than t(x),\nthen the optimal running time with the optimal coreset size will only be better, implying that t?\ncore(n,etotal) < t?\nsubs(n,etotal)\nas claimed. Furthermore this remains true for all n0 > n we have t?\ncore(n0,etotal) < t?\nsubs(n0,etotal). Therefore the proof\nproceeds to show that for large enough x and some n > x such a choice of s is possible under the conditions of the theorem.\nBy the fact that t(x) is convex increasing by Condtion (d), for all a < 1 there exists b < 1 (strictly below 1) such that for\nlarge enough x we have t(ax) < bt(x). In particular, for b as given by Condition (b), de\ufb01ne d 2 (0,1) to be such that for\nlarge enough x we have:\nt(x/(1+b)) < (1\u22122d)t(x).\n(9)\nFurthermore, we can choose x large enough so that:\n\u2022 By Condition (c) and the fact that, by (d), tsolver is super-linear,\n1\u2212f(h\u22121dt(x))\nf(x)\nx + f(h\u22121dt(x)) > 1\nx \u2212a.\n(10)\n\u2022 By Condition (a),\ng(x) \uf8ffdt(x), and\n(11)\n\u2022 By Condition (b),\n2h(x/(1+b)) <\n\u27131\nx \u2212a\n\u25c6\nf(x).\n(12)\nTradeoffs for Space, Time, Data and Risk in Unsupervised Learning\nLet x be large enough so that it satis\ufb01es the above conditions and let etotal = x + f(x). Let:\ns = t\u22121((1\u22122d)t(x)),\n(13)\nand note that we have s < x by virtue of t being increasing. Let m be the truncation size of the coreset. The coreset\u2019s total\nrisk can therefore be written as (x + f(m))(1+2h(s)), based on Proposition 4. Therefore, to match a risk of etotal, we can\nset:\nm = f \u22121\n\u2713x + f(x)\n1+2h(s) \u2212x\n\u25c6\n.\n(14)\nChoose any n \u2265m, guaranteeing thus to have enough samples for the coreset construction. Since f is increasing, note that\nm \u2265x, and therefore we indeed have n \u2265x. Since with the choice of m in Equation (14) the total risk of etotal is satis\ufb01ed,\nthe only thing that remains to verify is that the coreset running time with these choices of m and s falls below the running\ntime t(x) of the uniform subsampler.\nRecall that tcore(m,s) = tsolver(s)+tinit\ncore(m)+tsamp\ncore (s), and we can write this explicitly as:\ntcore(m,s) = t(s)+h\u00b7m+g(s).\nOur suboptimal choice of s in Equation (13) is designed to carve just enough room under t(x). Indeed, by construction, we\nhave t(s) = (1\u22122d)t(x). Since s < x and since g is increasing, we have by Equation (11) that g(s) < g(x) < dt(x).\nWe are only left to verify that h\u00b7m < dt(x). By applying Equations (10), (12), (9), and (13) in that order, we have:\nf(x)\u2212f(h\u22121dt(x))\nx + f(h\u22121dt(x))\n(10)\n>\n\u27131\nx \u2212a\n\u25c6\nf(x)\n(12)\n> 2h(x/(1+b))\n(9)\n> 2h\n-\nt\u22121((1\u22122d)t(x))\n. (13)\n= 2h(s)\nIt is easy to rewrite this as:\nx + f(x)\n1+2h(s) \u2212x > f(h\u22121dt(x))\nWe can now compare this to the expression for m in Equation (14). In particular, using the fact that f \u22121 is decreasing,\nwe \ufb01nd that indeed m < h\u22121dt(x). Therefore, for such large enough x, for n \u2265m, we have t?\ncore(n,etotal) \uf8fftcore(m,s) <\n(1\u22122d)t(x)+dt(x)+dt(x) = t(x), which concludes the proof.\n\u21e4\nProof of Proposition 1 [Veri\ufb01cation of Tradeoffs]\nWe verify that Theorem 1 applies to existing coreset procedures. First, note that for a distribution for which Proposition\n3 is tight, we have that eest(x) = Q(1/px) (the constants do not matter here), which satis\ufb01es Condition (c). On the other\nhand, all generic solvers with exact guarantees have running times that increase and do so much faster than linearly, say at\nleast polynomially tsolver(x) = W(xb) for some b > 1, and Condition (d) is easily satis\ufb01ed. Furthermore, in the construction\nof Feldman and Langberg [2011] we saw that both tinit\ncore and tsamp\ncore are linear, and Condition (a) thus follows.\nWhat remains to verify is Condition (b). Using Proposition 3, let us write more explicitly (the constants do matter here)\neest(x) \u2265sB2p\nk1\u22124/d/px, for large enough x. Consider now the Feldman and Langberg [2011] coreset, with score =\nO(dk(2+h)2/h2). Note that in Feldman and Langberg [2011], this is given for k-median and in terms of the framework of\n1\u00b1e-coresets, written as O(dk/e2). The result translates to k-means, and to the (1+h)-approximation notion of De\ufb01nition\n1. Write the inverse function h(score), and also interpret the bound more explicitly, as h(x) < A\np\ndk/(px \u2212\np\ndk), for\nlarge enough x for some A > 0. Condition (b) is now satis\ufb01ed whenever emodel(k) <\ns\n2\np\ndA\nB2\nk2/d (1 \u2212\np\ndk/px) strictly. By\ncomparing to Proposition 2, we see that this is satis\ufb01ed for large enough x whenever A <\ns\n2d\np\nd . This is a very conservative\nanalysis, due to the looseness of the asymptotic constants, but it shows that even so, it is possible for coresets to have a\nleading edge on uniform subsampling.\n\u21e4\nDetails of Numerical Simulations in Section 5.1\nLet etotal be a given desired risk level. The simulations consist of setting speci\ufb01c choices of the parameters of the problem\nand then, for each procedure and for each data size n, performing an explicit grid search over data summarization to\nminimize total running time while matching the etotal risk.\nLucic, Ohannessian, Karbasi and Krause\nTo make sure the risk is satis\ufb01ed in expectation, the search is done using the upper bounds given in Section 5.2. To stay\nconservative for the running time, we let tsolver(x) = asolverdkxb with b > 1 (note that the typical dependence on d and\nk is much higher), with an explicity constant asolver. We also let tinit\ncore(m) = ainitdkm, tsamp\ncore (s) = asamps (recall that these\nare linear in their arguments), with explicit constants ainit and asamp. Lastly, we use the Feldman and Langberg [2011]\nconstruction for the coreset, with h(s) < A\np\nk/(ps \u2212\np\ndk) \u21e1A\np\nk/ps (somewhat simplifying the expressions, since dk\nis often much smaller than s) with an explicit constant A. Since B appears everywhere in the errors, we can factor it out\nsafely (set B = 1). We also factor out asolverdk by renormalizing the computation time (set asolver = 1/dk). In summary,\nthe remaining parameters are: d, k, s, ainit, asamp, b, and A. Formally, we have the following.\nFor the uniform subsampler, the numerical version of t?\nsubs(n,etotal) is:\nminimize\nmb\nsubs\nsubject to\n1 \uf8ffmsubs \uf8ffn\nd\nk2/d +\np\nkd\npmsubs \uf8ffetotal\nFor the coreset procedure, the numerical version of t?\ncore(n,etotal) is:\nminimize\nsb\ncore +ainitmcore +asampscore/(dk)\nsubject to\n1 \uf8ffmcore \uf8ffn\n1 \uf8ffscore \uf8ffn\n\u21e3\n1+2 A\np\nk\npscore\n\u2318\u21e3\nd\nk2/d +\np\nkd\npmcore\n\u2318\n\uf8ffetotal,\nwhere if the coreset size attempts to exceed n, we back off to the uniform subsampler. (In the Figure, this is indicated by\nthe fact that the coreset has no points in the initial feasile range.)\nTo imitate realistic values encountered in our experiments, we let the parameters be as follows: d = 20, k = 20 , s = 192\n(the value cited in Antos et al. [2005]), ainit = 100, asamp = 100, b = 3 and A = 5. We then plot the data-time tradeoff of\nboth the subsampler (in black) and the coreset procedure (in red) in Figure 1c. We \ufb01x etotal = 300, and vary n.\nSeveral observations are in order. First, the problem is not feasible for data sizes that are too small (the \u201cdata-bounded\u201d\nregime). The uniform subsampler immediately throws away data upon becoming feasible, and maintains a constant com-\nputation time thereafter. If the theory is used as is, then the coreset procedure becomes more expensive for an interval of\nsmall data sizes because of lack of summarization room. To re\ufb02ect what is practiced, we simply back off to the uniform\nsubsampler when the coreset becomes too large to be cost-effective (alternatively, we may think of the entire data set as a\ncoreset).\nAs more samples become available, the estimation error shrinks, which allows the coreset to pick up performance. The\noptimal behavior of the coreset procedure is to optimize its space summarization in order to smoothly drive the running\ntime down (this is the \u201cintermediate regime\u201d).\nFor very large data size n, the computation time of constructing a coreset is bound to increase. At this point, the coreset\nprocedure opts to truncate the data just like the uniform subsampler, and therefore maintains its lowest computation time.\nThis is why the running time of the coreset eventually \ufb02attens (this is the \u201cdata-laden\u201d regime).\nFinally, the same type of numerical optimization via grid search can be done to obtain other tradeoffs. To illustrate this, we\nplot the data-time tradeoff in Figure 1d, with the same parameters, for \ufb01xed n = 2,000 samples, and as etotal varies.\nProof of Theorem 2 [The TRAM Algorithm]\nThe proof idea is as follows. Using the validation test at every step, we control the errors of stopping too far before and\ntoo far after the optimal truncation and coreset sizes. If these errors are not too large, the polynomial structure of the\nrunning time of the coreset procedure compounds with the geometric incrementing scheme of the algorithm, to lead to a\ncomputational overhead that remains reasonably close to the optimal.\nRoadmap\nWe divide the proof into the following stages. We \ufb01rst analyze the stopping probabilities. We then characterize\nthe number of iterations needed for feasibility. Using both of these stages, we describe the randomness of the number of\ntotal iterations. We use this to \ufb01nd the deviation probability of the running time within the coreset procedure as well as\nTradeoffs for Space, Time, Data and Risk in Unsupervised Learning\nthat of the total running time. We conclude by establishing the risk guarantees of TRAM, and bounding the amount of\nvalidation data used.\nReferring to Equation (3) in Section 4, the optimal running time t?\ncore for data size n and risk etotal may be expressed in terms\nof an optimal truncation size m?\ncore and optimal coreset size s?\ncore. By dropping the core subscript, we write t? = am? +s?b.\nTo reduce clutter, we also write etotal \u2318e throughout.\nWe perform our analysis conditionally on the strong feasibility event of Assumption C, which we can denote by:\nF = {R(\u02dcc(m,s)) \uf8ffetotal, 8m \u2265m?,s \u2265s?}.\nWe bound the conditional probability P{E |F} of three types of events that characterize the regular behavior of TRAM:\nErisk = {R(\u02dcc[J]) \uf8ff2e},\nEtime = {T \uf8fffT(t?)}, and\nEvalidation = {a[J] \uf8fffa(t?)},\nwhere J is the total number of iterations of TRAM, \u02dcc[J] represents its output, T its total running time, a[J] the number\nof validation data points it uses, and fT(\u00b7) and fa(\u00b7) are functions to be speci\ufb01ed. For the statement of the theorem, we\nintersect these events (or equivalently, we union bound their complements), then we use:\nP{\\E } \u2265P{\\E |F}P{F} \u2265(1\u2212l)P{\\E |F}.\n(15)\nTo keep the exposition clean, we drop the |F} notation in what follows, implicitly understanding that all computed prob-\nabilities are conditional on F.\nStopping probabilities\nTo analyze the algorithm, we need to determine various stopping and not-stopping probabilities.\nFor this, we use simple Hoeffding\u2019s concentration inequalities. For any \ufb01xed set of centers c, given a sample points from\nthe distribution P, we have (with a constant b = 2B2):\nP{Ra(c) > R(c)+z} \uf8ffexp\n\u21e3\n\u2212a\nbz 2\u2318\n,\nand\nP{Ra(c) < R(c)\u2212z} \uf8ffexp\n\u21e3\n\u2212a\nbz 2\u2318\n.\nAt every iteration we are attempting to test the null hypothesis H0 = {R(\u02dcc) < e}. We can encounter two types of errors:\ntype I, the hypothesis holds yet we don\u2019t stop, and type II, the hypothesis does not hold yet we do stop. The threshold test\nhelps us control type I errors primarily:\nP{Ra[i](\u02dcc) > t;H0}\n=\nP{Ra[i](\u02dcc) > R(\u02dcc)+t \u2212R(\u02dcc);H0}\n=\nP{Ra[i](\u02dcc) > R(\u02dcc)+e/2;H0}\n\uf8ff\nP\n(\nRa[i](\u02dcc) > R(\u02dcc)+\ns\nb\na[i] log 1\nd i\n)\n\uf8ff\nd i,\n(16)\nwhere we have used Hoeffding\u2019s inequality and the fact that a[i] =\nb\n(e/2)2 log 1\nd i .\nIn the absence of an alternative hypothesis, we cannot control type II errors. A natural choice of alternative is H1 =\n{R(\u02dcc) > 2e}, which gives us the same error bound as above while incurring a factor of 2 in the potential risk. More\nprecisely we have similarly to the above:\nP{Ra[i](\u02dcc) \uf8fft;H1}\n=\nP{Ra[i](\u02dcc) \uf8ffR(\u02dcc)+t \u2212R(\u02dcc);H1}\n=\nP{Ra[i](\u02dcc) < R(\u02dcc)\u2212e/2;H1}\n\uf8ff\nP\n(\nRa[i](\u02dcc) < R(\u02dcc)\u2212\ns\nb\na[i] log 1\nd i\n)\n\uf8ff\nd i\n(17)\nLucic, Ohannessian, Karbasi and Krause\nIterations until feasibility\nUnder event F, we know that it is possible to \ufb01nd values of truncation m \uf8ffn and coreset\nsize s such that a risk of e is achieved and maintained for larger summarizations. The \ufb01rst iteration where we obtain such\nstrong feasibility may be written as:\ni(e) := min{i : R(\u02dcc[j]) \uf8ffe 8 j \u2265i}\n(18)\nAlthough Equation (18) is precisely the earliest we satisfy the risk condition, it makes it hard to explicitly compare to the\ntime-optimal m? and s? for ultimately comparing with t?. Consider instead the following iteration:\ni? = min{i : gi\nmm[0] \u2265m? and gi\nss[0] \u2265s?}\n(19)\nThis a conservative bound on the number of iterations until feasibility, since we know that m? and s? already satisfy the\nrisk condition (recall once more that we are operating under F), and therefore:\ni? \u2265i(e).\nStrictly speaking, this de\ufb01nition gives us feasibility, but it gives only an upper bound, not a lower bound on the running\ntime. Nevertheless, since i? (through bounding i(e)) represents the main transitional point in our control of stopping\nconditions, we would like to express our running time relatively to it. While it is true that either one or the other of the two\nconditions of Equation (19) will have to fail for iterations prior to i?, we need to have both of them fail to compare to the\noptimal running time. It is thus convenient to de\ufb01ne im and is to denote the steps just before m[i] and s[i] respectively reach\ntheir optimal values. That is,\nim\n=\ndlog[m?/m[0]]/loggme\u22121,\nis\n=\ndlog[s?/s[0]]/loggse\u22121.\nIn what follows, we \ufb01nd it convenient to use coarse bounds:\nim \uf8fflogm?\nloggm\n\u22121 and is \uf8fflogs?\nloggm\n\u22121.\nUsing this, we can also write i? = im _is +1 \uf8fflogm?\nloggm _ logs?\nloggm , therefore using gm = 2 and gs = 21/b we get:\ni? \uf8fflog2 m? _b log2 s? \uf8fflog2 m? +b log2 s?.\nOn the other hand, since t? = am? +s?b, we have:\nlogt? \u22651\n2 log2 m? + 1\n2b log2 s? + 1\n2 log2 a +1,\nwhere we have used the concavity of the logarithm and Jensen\u2019s inequality on log2\n\u21e3\n1\n22am? + 1\n22s?b\u2318\n. Combining these\ntwo observations, and noting that in our time units we have a \u22651 and thus log2 a \u22650, we have:\ni? \uf8ff2log2t? \u22122.\n(20)\nTotal number of iterations\nRecall that J denotes the number of iterations of the algorithm. We can split the iterations\ninto two halves, before and after the problem becomes feasible. In light of the stopping probabilities that we analyzed, we\ncan therefore determine the behavior of J.\nProposition 5. If i \u2265i? then:\nP{J > i} \uf8ffP{J > i|J \u2265i?} \uf8ffd i.\nProof. We can write P{J > i} = P{J > i|J < i?}P{J < i?}+P{J > i|J \u2265i?}P{J \u2265i?}. If i \u2265i?, the \ufb01rst product is null,\nand the second is no greater than the P{J > i|J \u2265i?} term.\nAs the validation data is independent from the samples used to generate \u02dcc[j] and since we are operating under event F, we\nhave that for all iterations j \u2265i? hypothesis H0 holds and from Equation (16):\nP{TRAM does not stop at j} = P{Ra[j](\u02dcc[j]) > t} \uf8ffd j.\nTradeoffs for Space, Time, Data and Risk in Unsupervised Learning\nUsing this, we can do an intersection bound for all i \u2265i?:\nP{J > i|J \u2265i?}\n=\nP\ni\\\nj=i?\n{TRAM does not stop at j}\n\uf8ff\ni\nmin\nj=i? P{TRAM does not stop at j}\n\uf8ff\nd i,\nwhich establishes the claim.\nTotal running time\nLet T1 denote the total running time of the coreset procedure computations. Let T2 denote the\nrunning time of the validation computations. The total computation can then be written as the sum of these two running\ntimes T = T1 + T2. As we expect, the lion\u2019s share of the computation is consumed by the coreset procedure. We now\nanalyze T1 and T2 separately.\nLet us \ufb01rst write out the explicit dependence of T1 on J:\nT1[J] := T1 =\nJ\n\u00c2\ni=0\n\u21e3\nam[i]+s[i]b\u2318\n=\nJ\n\u00c2\ni=0\n2i \u21e3\nam[0]+s[0]b\u2318\nwhere for the last expression recall that we use gm = 2 and gs = 21/b for the multiplicative increment at each iteration:\nm[i+1]  gmm[i]^n and s[i+1]  gss[i].\nOur goal is to bound the probability of the event that T1 is well behaved, and in particular to show that with high probability\nT1 \uf8ff(1 + v)2t?2 for arbitrary v \u22651. To do so, we \ufb01st show that the running time until (but excluding) i? is bounded by\n2t?2. We then show that, thanks to Proposition 5, the likelihood of stopping is so high beyond i? that we only incur the\nadditional (1+v) factor, with high probability. We can de\ufb01ne the running time before i? and bound it as follows:\nT1[i? \u22121] :=\ni?\u22121\n\u00c2\ni=0\n\u21e3\nam[i]+s[i]b\u2318\n=\ni?\u22121\n\u00c2\ni=0\n2i\u2212i?+1 \u21e3\nam[i? \u22121]+s[i? \u22121]b\u2318\n\uf8ff2\n\u21e3\nam[i? \u22121]+s[i? \u22121]b\u2318\n(21)\nBased on this, to compare the running time T1[i? \u22121] to the optimal running time t? = am? + s?b, it suf\ufb01ces to compare\nam[i? \u22121]+s[i? \u22121] to this optimum. For the moment, in order to have a clean book-keeping, let us revert to the symbols\ngm and gs of the multiplicative updates, instead of their numerical values.\nIn particular, the following peculiarity will occur: either m? will be reached \ufb01rst or s? will. Let us treat each of the following\ntwo cases separately:\n\u2022 Say m? is reached \ufb01rst, that is im \uf8ffis. In this case, i? = is + 1, and we have m[is] < gmlogs?/loggsm?. The factor in\nthe latter expression uses the fact that m[im] < m? and that m is continued to be incremented for at most is \u2212im +1 \uf8ff\nis +1 \uf8fflogs?/loggs steps, by a multiple of gm at each step. Noting also that s[is] < s?, we have:\nam[i? \u22121]+sb[i? \u22121]\n<\nagmlogs?/loggsm? +s?b\n=\nas?loggm/loggsm? +s?b.\n\u2022 Say s? is reached \ufb01rst, that is is \uf8ffim, parallel calculations give us that:\nam[i? \u22121]+sb[i? \u22121]\n<\nam? +gsb logm?/loggms?b\n=\nam? +m?b loggs/loggms?b.\nWith our choices of gm and gs we have loggm/loggs = b, therefore in either case:\nam[i? \u22121]+s[i? \u22121]b\n<\n\u21e3\nas?bm? +s?b\u2318\n_\n\u21e3\nam? +m?s?b\u2318\n<\nt?2,\n(22)\nLucic, Ohannessian, Karbasi and Krause\nwhere we have again used the fact that in our time units we have a \u22651. Of course, this bound is overly conservative. For\none, we are factoring in extra increments on both terms, whereas only holds. Also, neither m nor s can be incremented\narbitrarily many times, as they are bounded by n. Despite this conservatism, we adhere to this expression for its simplicity,\nand use it to bound the randomness of T1. Going back to Equation (21) and using Equation (22), we have:\nT1[i? \u22121] \uf8ff2\n\u21e3\nam[i? \u22121]+s[i? \u22121]b\u2318\n\uf8ff2t?2,\nChoose some v \u22650. From this bound, we can see that if J < i? we will always have T1[J] \uf8ff(1+v)2t?2, and thus P{T1 >\n(1+v)2t?2|J < i?} = 0. Therefore, by total probability, it follows that P{T1 > (1+v)2t?2} \uf8ffP{T1 > (1+v)2t?2|J \u2265i?}\n(cf. the proof of Proposition 5). Next when J \u2265i?, we have on one hand that T1 > (1+v)2t?2 implies that:\nJ\n\u00c2\ni=i?\n\u21e3\nam[i]+s[i]b\u2318\n> (1+v)2t?2 \u2212T1[i? \u22121] > 2vt?2.\nOn the other hand, using the bound in Equation (22), we have:\nJ\n\u00c2\ni=i?\n\u21e3\nam[i]+s[i]b\u2318\n\uf8ff\nJ\n\u00c2\ni=i?\n2i\u2212i?+1t?2 = 2\n\u21e3\n2J\u2212i?+1 \u22121\n\u2318\nt?2.\nTherefore when J \u2265i?, T1 > (1+v)2t?2 implies that 2J\u2212i?+1 \u22121 > v, and thus J > log2(1+v)\u22121+i?. Starting with this\nchain of implications to bound the probabilities of their respective events, and then combining with Proposition 5, we have:\nP{T1 > (1+v)2t?2}\n\uf8ff\nP{T1 > (1+v)2t?2|J \u2265i?}\n\uf8ff\nP{J > log2(1+v)\u22121+i?|J \u2265i?}\n\uf8ff\nd log2(1+v)\u22121+i?\n(23)\nNow let us move to T2, which recall denotes the running time of the validations. Per Assumption (B), we can write it\nexplicitly as a function of the number of iterations:\nT2[J] =\nJ\n\u00c2\ni=1\nka[i].\nThis is easy to account for, since:\na[i] = i 4b\ne2 log 1\nd ,\nand thus\nT2[J] = J(J +1) 2bk\ne2 log 1\nd\n|\n{z\n}\n:=g\n.\nWe can now use arguments similar to the analysis for T1 above. A useful observation in this regard is to use Equation (20)\nto get (2log2t? +w)2 \u2265(i? +w)(i? +w+1), for any given w \u22650. Then, by Proposition 5:\nP\n3\nT2 > g(2log2t? +w)2 \n\uf8ff\nP{T2 > g(i? +w)(i? +w+1)}\n=\nP{gJ(J +1) > g(i? +w)(i? +w+1)}\n=\nP{J > i? +w}\n\uf8ff\nd w+i?\nBy restricting v \u22651 and choosing w = log2(1+v)\u22121, we obtain a comparable exponent to T1:\nP\nn\nT2 > g log2\n2\n\u21e3\n1\n2(1+v)t?2\u2318o\n\uf8ffd log2(1+v)\u22121+i?\n(24)\nBy using a union bound to combine Equations (23) and (24), we have:\nP\nn\nT = T1 +T2 > (1+v)2t?2 +log2\n2\n\u21e3\n1\n2(1+v)t?2\u2318\n2bk\ne2 log 1\nd\no\n\uf8ff2d log2(1+v)\u22121+i? \uf8ff2d i? \uf8ff2d,\n(25)\nwhere we have simpli\ufb01ed from the general form for v \u22651 and using the fact that i? \u22651.\nTradeoffs for Space, Time, Data and Risk in Unsupervised Learning\nRisk guarantees\nWe would now like to use Equation (17) to say something about performance guarantees for the output\nof the algorithm. The probability of the stopping condition being satis\ufb01ed at a given iteration j when the risk is larger than\n2e (denote this event by E j) is bounded by Equation (17):\nP{E j} = P{Ra[ j](\u02dcc[j]) \uf8fft and R(\u02dcc[j]) > 2e} \uf8ffP{Ra[j](\u02dcc[j]) \uf8fft|R(\u02dcc[j]) > 2e} \uf8ffd j,\nwhere we have used the fact that the validation data is independent from the samples, and that the bound of Equation (17)\nholds for any center \u02dcc such that R(\u02dcc) > 2e.\nTherefore, the conditional probability of actually stopping at any such j is given by:\nP{R(\u02dcc[J]) > 2e} \uf8ffP\n[\nj\nEj \uf8ff\n\u2022\n\u00c2\nj=1\nd j \uf8ff\nd\n1\u2212d \uf8ff2d,\n(26)\nsince d < 1\n5 < 1\n2. Therefore, no matter how many iterations we have, the probability that we will stop at a high-risk iteration\nis bounded. Namely, with probability at least 1\u22122d we guarantee a risk of at most 2e.\nValidation data requirements\nWe conclude with showing that the number of validation data points needed remains\nsmall. Since the same points are reused from one iteration to the other, the total amount of validation data used is:\na = a[J] = J 4b\ne2 log 1\nd .\nBy Proposition 5 and Equation (20) we have that:\nP{a[J] > 2log2t? 4b\ne2 log 1\nd } \uf8ffP{a[J] > i? 4b\ne2 log 1\nd } \uf8ffP{J > i?} \uf8ffd i? \uf8ffd.\n(27)\nSynthesis\nThe theorem follows by union bounding (25) (with v = 1), (26), and (27) and using (15).\n\u21e4\n",
        "sentence": " As a solution, recent advances in learning theory introduce hierarchies of algorithmic solutions, ordered by the respective computational complexity, for several fundamental machine learning applications in (Bousquet and Bottou, 2008; Shalev-Shwartz and Srebro, 2008; Chandrasekaran and Jordan, 2013; Agarwal et al., 2012; Lucic et al., 2015).",
        "context": "Related Work.\nAn alternative direction is to investigate\ncomputational and statistical tradeoffs: using data as a\ncomputational resource when available beyond the sample\ncomplexity of the learning task.\nPioneering this effort,\nfact that as we accumulate more data, the desired risk e\nbecomes easier to reach, thus computationally cheaper but\nless accurate algorithms can be employed. This idea of\nalgorithmic weakening was explored more systematically\naba et al. [1994]). There are various popular heuristics,\nincluding Lloyd\u2019s (\u201cthe k-means\u201d) algorithm, and on typi-\ncal inputs these have polynomial running times tsolver(s) =\nW(poly(k)poly(d)poly(s)). Under further conditions they"
    },
    {
        "title": "Fast and accurate inference of plackett-luce models",
        "author": [
            "L. Maystre",
            "M. Grossglauser"
        ],
        "venue": "In Advances in Neural Information Processing Systems",
        "citeRegEx": "Maystre and Grossglauser.,? \\Q2015\\E",
        "shortCiteRegEx": "Maystre and Grossglauser.",
        "year": 2015,
        "abstract": "",
        "full_text": "",
        "sentence": " comparisons in (Ford Jr., 1957; Hunter, 2004; Negahban et al., 2014; Shah et al., 2015a; Maystre and Grossglauser, 2015). We use the following Theorem from Pr\u00e9kopa (1980). A similar technique was used to prove concavity when |T (e)| = 1 in Azari Soufiani et al.",
        "context": null
    },
    {
        "title": "Sum-of-squares lower bounds for planted clique",
        "author": [
            "R. Meka",
            "A. Potechin",
            "A. Wigderson"
        ],
        "venue": "In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of Computing,",
        "citeRegEx": "Meka et al\\.,? \\Q2015\\E",
        "shortCiteRegEx": "Meka et al\\.",
        "year": 2015,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": " planted clique problem (Deshpande and Montanari, 2015; Meka et al., 2015).",
        "context": null
    },
    {
        "title": "Rank centrality: Ranking from pair-wise comparisons",
        "author": [
            "S. Negahban",
            "S. Oh",
            "D. Shah"
        ],
        "venue": null,
        "citeRegEx": "Negahban et al\\.,? \\Q2014\\E",
        "shortCiteRegEx": "Negahban et al\\.",
        "year": 2014,
        "abstract": "",
        "full_text": "",
        "sentence": " comparisons in (Ford Jr., 1957; Hunter, 2004; Negahban et al., 2014; Shah et al., 2015a; Maystre and Grossglauser, 2015).",
        "context": null
    },
    {
        "title": "Logarithmic concave measures and related topics",
        "author": [
            "A. Pr\u00e9kopa"
        ],
        "venue": "In Stochastic programming,",
        "citeRegEx": "Pr\u00e9kopa.,? \\Q1980\\E",
        "shortCiteRegEx": "Pr\u00e9kopa.",
        "year": 1980,
        "abstract": "",
        "full_text": "",
        "sentence": " 1 (Theorem 9 in Pr\u00e9kopa (1980)).",
        "context": null
    },
    {
        "title": "Estimation from pairwise comparisons: Sharp minimax bounds with topology dependence",
        "author": [
            "N.B. Shah",
            "S. Balakrishnan",
            "J. Bradley",
            "A. Parekh",
            "K. Ramchandran",
            "M.J. Wainwright"
        ],
        "venue": null,
        "citeRegEx": "Shah et al\\.,? \\Q2015\\E",
        "shortCiteRegEx": "Shah et al\\.",
        "year": 2015,
        "abstract": "Data in the form of pairwise comparisons arises in many domains, including\npreference elicitation, sporting competitions, and peer grading among others.\nWe consider parametric ordinal models for such pairwise comparison data\ninvolving a latent vector $w^* \\in \\mathbb{R}^d$ that represents the\n\"qualities\" of the $d$ items being compared; this class of models includes the\ntwo most widely used parametric models--the Bradley-Terry-Luce (BTL) and the\nThurstone models. Working within a standard minimax framework, we provide tight\nupper and lower bounds on the optimal error in estimating the quality score\nvector $w^*$ under this class of models. The bounds depend on the topology of\nthe comparison graph induced by the subset of pairs being compared via its\nLaplacian spectrum. Thus, in settings where the subset of pairs may be chosen,\nour results provide principled guidelines for making this choice. Finally, we\ncompare these error rates to those under cardinal measurement models and show\nthat the error rates in the ordinal and cardinal settings have identical\nscalings apart from constant pre-factors.",
        "full_text": "Estimation from Pairwise Comparisons:\nSharp Minimax Bounds with Topology Dependence\nNihar B. Shah\nnihar@eecs.berkeley.edu\nSivaraman Balakrishnan\nsbalakri@berkeley.edu\nJoseph Bradley\njoseph.kurata.bradley@gmail.com\nAbhay Parekh\nparekh@berkeley.edu\nKannan Ramchandran\nkannanr@eecs.berkeley.edu\nMartin J. Wainwright\nwainwrig@berkeley.edu\nUC Berkeley\nKeywords:\nPairwise comparisons, inference, ranking, topology, crowdsourcing\nAbstract\nData in the form of pairwise comparisons arises in many domains, including preference elicitation,\nsporting competitions, and peer grading among others. We consider parametric ordinal models for\nsuch pairwise comparison data involving a latent vector w\u2217\u2208Rd that represents the \u201cqualities\u201d of the\nd items being compared; this class of models includes the two most widely used parametric models\u2013\nthe Bradley-Terry-Luce (BTL) and the Thurstone models.\nWorking within a standard minimax\nframework, we provide tight upper and lower bounds on the optimal error in estimating the quality\nscore vector w\u2217under this class of models. The bounds depend on the topology of the comparison\ngraph induced by the subset of pairs being compared via its Laplacian spectrum. Thus, in settings\nwhere the subset of pairs may be chosen, our results provide principled guidelines for making this\nchoice. Finally, we compare these error rates to those under cardinal measurement models and show\nthat the error rates in the ordinal and cardinal settings have identical scalings apart from constant\npre-factors.\n1. Introduction\nIn an increasing range of applications, it is of interest to elicit judgments from non-expert humans.\nFor instance, in marketing, elicitation of preferences of consumers about products, either directly\nor indirectly, is a common practice (Green et al., 1981). The gathering of this and related data\ntypes has been greatly facilitated by the emergence of \u201ccrowdsourcing\u201d platforms such as Amazon\nMechanical Turk: they have become powerful, low-cost tools for collecting human judgments (Khatib\net al., 2011; Lang and Rio-Ross, 2011; von Ahn et al., 2008). Crowdsourcing is employed not only for\ncollection of consumer preferences, but also for other types of data, including counting the number\nof malaria parasites in an image of a blood smear (Luengo-Oroz et al., 2012); rating responses of\nan online search engine to search queries (Kazai, 2011); or for labeling data for training machine\nlearning algorithms (Hinton et al., 2012; Raykar et al., 2010; Deng et al., 2009). In a di\ufb00erent do-\nmain, competitive sports can be understood as a mechanism for sequentially performing comparisons\nbetween individuals or teams (Ross, 2007; Herbrich et al., 2007). Finally, peer-grading in massive\nopen online courses (MOOCs) (Piech et al., 2013) can be viewed as another form of elicitation.\nA common method of elicitation is through pairwise comparisons. For instance, the decision\nof a consumer to choose one product over another constitutes a pairwise comparison between the\ntwo products. Workers in a crowdsourcing setup are often asked to compare pairs of items: for\n1\narXiv:1505.01462v1  [cs.LG]  6 May 2015\n%Which%image%is%more%relevant%\nfor%the%search%query%\u2018INTERNET\u2019?%\n!%\n!%\nHow%relevant%is%this%image%for%%\nthe%search%query%'INTERNET'?%\n/%100%\n!%\n!%\n!%\nbut sure cure\u201d \ntagline%for%a%\nare%plaMorm%\n/%10%\n(a) Asking for a pairwise comparison.\n/ 100 \nHow relevant is this image for \nthe search query 'INTERNET'? \n(b) Asking for a numeric score.\nFigure 1. An example of eliciting judgments from people: rating the relevance of the result of a search\nquery.\ninstance, they might be asked to identify the better of two possible results of a search engine, as\nshown in Figure 1a. Competitive sports such as chess or basketball also involve sequences of pairwise\ncomparisons. From a modeling point of view, we can think of pairwise comparisons as a means of\nestimating the underlying \u201cqualities\u201d or \u201cweights\u201d of the items being compared (e.g., skill levels of\nchess players, relevance of search engine results, etc.). Each pairwise comparison can be viewed as\na noisy sample of some function of the underlying pair of (real-valued) weights. Noise can arise\nfrom a variety of sources. When objective questions are posed to human subjects, noise can arise\nfrom their di\ufb00ering levels of expertise. In a sports competition, many sources of randomness can\nin\ufb02uence the outcome of any particular match between a pair of competitors. Thus, one important\ngoal is to estimate the latent qualities based on noisy data in the form of pairwise comparisons. A\nrelated problem is that of experimental design: assuming that we can choose the subset of pairs to\nbe compared (e.g., in designing a chess tournament), what choice will allow for the most accurate\nestimation? Characterizing the fundamental di\ufb03culty of estimating the weights will allow us to make\nthis choice judiciously. These tasks are the primary focus of this paper.\nIn more detail, the focus of this paper is the aggregation from pairwise comparisons in a fairly\nbroad class of parametric models. This class includes as special cases the two most popular models for\npairwise comparisons\u2014namely, the Thurstone (Case V) (Thurstone, 1927) and the Bradley-Terry-\nLuce (BTL) (Bradley and Terry, 1952; Luce, 1959) models. The Thurstone (Case V) model has been\nused in a variety of both applied (Swets, 1973; Ross, 2007; Herbrich et al., 2007) and theoretical\npapers (Bramley, 2005; Krabbe, 2008; Nosofsky, 1985). Similarly, the BTL model has been popular\nin both theory and practice (e.g., (Nosofsky, 1985; Atkinson et al., 1998; Koehler and Ridpath, 1982;\nHeldsinger and Humphry, 2010; Loewen et al., 2012; Green et al., 1981; Khairullah and Zionts,\n1987)).\n1.1 Some past work\nThere is a vast literature on the Thurstone and BTL models, and we focus on those most closely\nrelated to our own work. Negahban et al. (2012) provide minimax bounds for the BTL model in\nthe special case of comparisons chosen uniformly at random. They focus on this case in order to\ncomplement their analysis of an algorithm based on a random walk. In their analysis, there is a gap\nbetween the achievable rate of the MLE and the lower bound. In contrast, our analysis eliminates\nthis discrepancy and shows that MLE is an optimal estimator (up to constant factors) and achieves\nthe minimax rate. In independent and concurrent work, Hajek et al. (2014) consider the problem\nof estimation in the Plackett-Luce model, which extends the BTL model to comparisons of two or\nmore items. They derive bounds on the minimax error rates under this model which are tight up\n2\nto logarithmic factors. In contrast, our results are tight up to constants and, as we emphasize in\nthe following section, provide deeper insights into the role of the topology of the comparison graph.\nJagabathula and Shah (2008) design an algorithm for aggregating ordinal data when the underlying\ndistribution over the permutations is assumed to be sparse.\nAmmar and Shah (2011) employ a\ndi\ufb00erent, maximum entropy approach towards parameterization and inference from partially ranked\ndata. Rajkumar and Agarwal (2014) study the statistical convergence properties of several rank\naggregation algorithms.\nOur work assumes a \ufb01xed design setup. In this setup, the choice of which pairs to compare and\nthe number of times to compare them is chosen ahead of time in a non-adaptive fashion. There\nis a parallel line of literature on \u201csorting\u201d or \u201cactive ranking\u201d from pairwise comparisons.\nFor\ninstance, Braverman and Mossel (2008) assume a noise model where the outcome of a pairwise\ncomparison depends only on the relative ranks of the items being compared, and not on their actual\nranks or values. On the other hand, Jamieson and Nowak (2011) consider the problem of ranking\na set of items assuming that items can be embedded into a smaller-dimensional Euclidean space,\nand that the outcomes of the pairwise comparisons are based on the relative distances of these items\nfrom a \ufb01xed reference point in the Euclidean space.\nA recent line of work considers a variant of the BTL and the Thurstone models where the com-\nparisons may depend on some auxiliary unknown variable in addition to the items being compared;\nfor instance, the accuracy of the individual making the comparison in an objective task. Chen et al.\n(2013) consider a crowdsourcing setup where the outcome depends on the worker\u2019s expertise. They\npresent algorithms for inference under such a model and present empirical evaluations. Yi et al.\n(2013) consider a problem in the spirit of collaborative \ufb01ltering where certain unknown preferences\nof a certain user must be predicted based on the preferences of other users as well as of that user over\nother items. Lee et al. (2011) consider the inverse problem of measuring the expertise of individu-\nals based on the rankings submitted by them, and the proposed algorithms assume an underlying\nThurstone model.\n1.2 Our contributions\nBoth the Thurstone (Case V) and BTL models involve an unknown vector w\u2217\u2208Rd corresponding\nto the underlying qualities of d items, and in a pairwise comparison between items j and k, the\nprobability of j being ranked above k is some function F of the di\ufb00erence w\u2217\nj \u2212w\u2217\nk. The Thurstone\n(Case V) and BTL are based on di\ufb00erent choices of F, and both belong to the broader class of models\nanalyzed in this paper, in which F is required only to be strongly log-concave.\nWith this context, the main contributions of this paper are to provide some answers to the\nfollowing questions:\n\u2022 How does the minimax error for estimating the weight vector w\u2217in various norms scale with the\nproblem dimension (the number of items) and the number of observations?\n\u2013 We derive upper and lower bounds on the minimax estimation rates under the model described\nabove. Our upper/lower bounds on the estimation error agree up to constant factors: to the\nbest of our knowledge, despite the voluminous literature on these two models, this provides\nthe \ufb01rst sharp characterization of the associated minimax rates. Moreover, our error guarantees\nprovide guidance to the practitioner in assessing the number of pairwise comparisons to be made\nin order to guarantee a pre-speci\ufb01ed accuracy.\n\u2022 Given a budget of n comparisons, which pairs of items should be compared?\n\u2013 The bounds that we derive depend on the comparison graph induced by the subset of pairs that\nare compared. Our theoretical analysis reveals that the spectral gap of a certain scaled version\n3\nof the graph Laplacian plays a fundamental role, and provides guidelines for the practitioner on\nhow to choose the subset of comparisons to be made.\n\u2022 When is it better to elicit pairwise comparisons versus numeric scores?\n\u2013 When eliciting data, one often has the liberty to ask for either cardinal values (Figure 1b) or\nfor pairwise comparisons (Figure 1a) from the human subjects. One would like to adopt the\napproach that would lead to a better estimate. One may be tempted to think that cardinal\nelicitation methods are superior, since each cardinal measurement gives a real-valued number\nwhereas an ordinal measurement provides at most one bit of information. Our bounds show,\nhowever, that the scaling of the error in the cardinal and ordinal settings is identical up to\nconstant pre-factors. As we demonstrate, this result allows for a comparison of cardinal and\nordinal data elicitation methods in terms of the per-measurement noise alone, independent of\nthe number of measurements and the number of items. A priori, there is no obvious reason for\nthe relative performance to be independent of the number of measurements and items.\nNotation:\nFor any symmetric matrix M of size (m \u00d7 m), we will let \u03bb1(M) \u2264\u03bb2(M) \u2264\u00b7 \u00b7 \u00b7 \u2264\n\u03bbm(M) denote its ordered eigenvalues. We will use the notation DKL(P1\u2225P2) to denote the Kullback-\nLeibler divergence between the two distributions P1 and P2. For any integer m, we will let [m] denote\nthe set {1, . . . , m}.\n2. Problem formulation\nWe begin with some background followed by a precise formulation of the problem.\n2.1 Generative models for ranking\nGiven a collection of d items to be evaluated, we suppose that each item has a certain numeric quality\nscore, and a comparison of any pair of items is generated via a comparison of the two quality scores\nin the presence of noise. We represent the quality scores as a vector w\u2217\u2208Rd, so item j \u2208[d] has\nquality score w\u2217\nj. Now suppose that we make n pairwise comparisons: if comparison i \u2208[n] pertains\nto comparing item ai with item bi, then it can be described by a di\ufb00erencing vector xi \u2208Rd, with\nentry ai equal to one, entry bi equal to \u22121, and the remaining entries set to 0.\nWith this notation, we study the problem of estimating the weight vector w\u2217based on observing\na collection of n independent samples yi \u2208{\u22121, 1} drawn from the distribution\nP\n\u0002\nyi = 1|xi, w\u2217\u0003\n= F\n\u0010\u27e8xi, w\u2217\u27e9\n\u03c3\n\u0011\nfor i \u2208[n],\n(Ordinal)\nwhere F is a known function taking values in [0, 1]. Since the probability of item ai dominating bi\nshould be independent of the order of the two items being compared, we require throughout that\nF(x) = 1 \u2212F(\u2212x).\nIn any model of the general form (Ordinal), the parameter \u03c3 > 0, assumed to be known, plays\nthe role of a noise parameter, with a higher value of \u03c3 leading to more uncertainty in the comparisons.\nMoreover, we assume that F is strongly log-concave in a neighborhood of the origin, meaning that\nthere is some curvature parameter \u03b3 > 0 such that\nd2\ndt2 (\u2212log F(t)) \u2265\u03b3\nfor all t \u2208[\u22122B/\u03c3, 2B/\u03c3].\n(1)\nHere the known parameter B denotes a bound on the \u2113\u221e-norm of the weight vector, namely\n\u2225w\u2217\u2225\u221e\u2264B.\n4\nAs our analysis shows, a bound of this form is fundamental: the minimax error for estimating w\u2217\nwill diverge to in\ufb01nity if we are allowed to consider models in which B is arbitrarily large (see\nProposition 17 in Appendix G). Informally, this behavior is related to the di\ufb03culty of estimating\nvery small (or very large) probabilities that can arise in the two models for large \u2225w\u2217\u2225\u221e. Note that\nany model of the form (Ordinal) is invariant to shifts in w\u2217, that is, it does not di\ufb00erentiate between\nthe vector w\u2217and the shifted vector w\u2217+1, where 1 denotes the vector of all ones. Therefore, in order\nto ensure identi\ufb01ability of w\u2217, we assume throughout that \u27e81, w\u2217\u27e9= 0. We will use the notation WB\nto denote the set of permissible quality score vectors\nWB : =\n\b\nw \u2208Rd | \u2225w\u2225\u221e\u2264B,\nand\n\u27e81, w\u27e9= 0\n\t\n.\n(2)\nBoth the Thurstone (Case V) model with Gaussian noise (Thurstone, 1927) and Bradley-Terry-\nLuce (BTL) models (Bradley and Terry, 1952; Luce, 1959) are special cases of this general set-up,\nas we now describe.\nThurstone (Case V):\nThis model is is a special case of the family (Ordinal), obtained by setting\nF(t) =\nZ t\n\u2212\u221e\n1\n\u221a\n2\u03c0e\u2212u2/2du,\n(3)\ncorresponding to the CDF of the standard normal distribution. Consequently, the Thurstone model\ncan alternatively be written as making n i.i.d. observations of the form\nyi = sign\n\u001a\n\u27e8xi, w\u2217\u27e9+ \u03f5i\n\u001b\n,\nfor i \u2208[n],\n(Thurstone)\nwhere \u03f5i \u223cN(0, \u03c32) is observation noise. It can be veri\ufb01ed that the Thurstone model is strongly\nlog-concave (e.g., see (Tsukida and Gupta, 2011)).\nBradley-Terry-Luce:\nThe Bradley-Terry-Luce (BTL) model (Bradley and Terry, 1952; Luce,\n1959) is another special case in which\nF(t) =\n1\n1 + e\u2212t ,\nand hence\nP\n\u0002\nyi = 1|xi, w\u2217\u0003\n=\n1\n1 + exp\n\u0000\u2212\u27e8xi, w\u2217\u27e9\n\u03c3\n\u0001\nfor i \u2208[n].\n(BTL)\nIt can also be veri\ufb01ed that the BTL model is strongly log-concave.\nCardinal observation models:\nWhile our primary focus is on the pairwise-comparison setting,\nfor comparison purposes we also analyze analogous cardinal settings where each observation is real\nvalued. In particular, we consider the following two cardinal analogues of the Thurstone model.\nIn the Cardinal model we consider, each observation i \u2208[n] consists of a numeric evaluation yi \u2208R\nof a single item,\nyi = \u27e8ui, w\u2217\u27e9+ \u03f5i\nfor i \u2208[n],\n(Cardinal)\nwhere ui in this case is a coordinate vector with one of its entries equal to 1 and remaining entries\nequal to 0, and \u03f5i is independent Gaussian noise N(0, \u03c32). One may alternatively elicit cardinal\nvalues of the di\ufb00erences between pairs of items\nyi = \u27e8xi, w\u2217\u27e9+ \u03f5i\nfor i \u2208[n],\n(Paired Cardinal)\nwhere \u03f5i are i.i.d. N(0, \u03c32). We term this model the Paired Cardinal model.\n5\n2.2 Fixed design and the graph Laplacian\nWe analyze the estimation error when a \ufb01xed subset of pairs is chosen for comparison. Of interest\nto us will be the comparison graph de\ufb01ned by these chosen pairs, with each pair inducing an edge\nin the graph. Edge weights are determined by the fraction of times a given pair is compared. The\nanalysis in the sequel reveals the central role played by the Laplacian of this weighted graph. Note\nthat we are operating in a \ufb01xed-design setup where the graph is constructed o\ufb04ine and does not\ndepend on the observations.\nIn the ordinal models, the ith measurement is related to the di\ufb00erence between the two items\nbeing compared, as de\ufb01ned by the measurement vector xi \u2208Rd.\nWe let X \u2208Rn\u00d7d denote the\nmeasurement matrix with the vector xT\ni as its ith row. The Laplacian matrix L associated with this\ndi\ufb00erencing matrix is given by\nL : = 1\nnXT X = 1\nn\nn\nX\ni=1\nxixT\ni .\n(4)\nBy construction, for any vector v \u2208Rd, we have vT Lv = P\nj\u0338=k Ljk(vj \u2212vk)2, where Ljk is the fraction\nof the measurement vectors {xi}n\ni=1 in which items (j, k) are compared.\nThe Laplacian matrix is positive semide\ufb01nite, and has at least one zero-eigenvalue, corresponding\nto the all-ones eigenvector. The Laplacian matrix induces a graph on the vertex set {1, . . . , d}, in\nwhich a given pair (j, k) is included as an edge if and only if Ljk \u0338= 0, and the weight on an edge\n(j, k) equals Ljk. We emphasize that throughout our analysis, we assume that the comparison graph\nis connected, since otherwise, the quality score vector w\u2217is not identi\ufb01able. Note that the Laplacian\nmatrix L induces a semi-norm1 on Rd, given by\n\u2225u \u2212v\u2225L : =\nq\n(u \u2212v)T L(u \u2212v).\n(5)\nWe study optimal rates of estimation in this semi-norm, as well as the usual \u21132-norm. As will be\nclearer in the sequel the L semi-norm is a natural metric in our setup, and estimation in this induced\nmetric can be done at a topology independent rate. The estimation error in the L semi-norm is\nclosely related to the prediction risk in generalized linear models. It arises naturally when one is\ninterested in predicting the probability of a certain outcome for a new comparison.\n3. Bounds on the minimax risk\nIn this section, we state the main results of the paper, and discuss some of their consequences.\n3.1 Minimax rates in the squared L semi-norm\nOur \ufb01rst main result provides bounds on the minimax risk under the squared L semi-norm (5) in\nthe pairwise comparison models introduced earlier. In all of the statements, we use c1, c2, etc. to\ndenote positive numerical constants, independent of the sample size n, number of items d and other\nproblem-dependent parameters.\nApart from the parameter \u03b3, the bounds presented subsequently will depend on F through a\nsecond parameter \u03b6, de\ufb01ned as\n\u03b6 : =\nmax\nx\u2208[0,2B/\u03c3] F \u2032(x)\nF(2B/\u03c3)(1 \u2212F(2B/\u03c3)).\n(6)\nIn the BTL and the Thurstone models, we have \u03b6 : =\nF \u2032(0)\nF(2B/\u03c3)(1\u2212F(2B/\u03c3)).\n1. A semi-norm di\ufb00ers from a norm in that the semi-norm of a non-zero element is allowed to be zero.\n6\nTheorem 1 (Bounds on minimax rates in L semi-norm)\n(a) For a sample size n \u2265c1\u03c32tr(L\u2020)\n\u03b6B2\n,\nany estimator ew based on n samples from the Ordinal model has Laplacian squared error lower\nbounded as\nd\nsup\nw\u2217\u2208WB\nE\nh\n\u2225ew \u2212w\u2217\u22252\nL\ni\n\u2265c1\u2113\n\u03b6 \u03c32 d\nn.\n(7a)\n(b) For any instance of the Ordinal model with \u03b3-strong log-concavity and any w\u2217\u2208WB, the\nmaximum likelihood estimator satis\ufb01es the bound\nP\nh\n\u2225bwML \u2212w\u2217\u22252\nL > tc\u03b62\u03c32\n\u03b32\nd\nn\ni\n\u2264e\u2212t\nfor all t \u22651,\nand consequently\nsup\nw\u2217\u2208WB\nE\nh\n\u2225bwML \u2212w\u2217\u22252\nL\ni\n\u2264c1u\u03b6\n\u03b3 \u03c32 d\nn.\n(7b)\nThe results of Theorem 1 characterize the minimax risk in the squared L semi-norm up to\nconstant factors. The upper bounds follow from an analysis of the maximum likelihood estimator,\nwhich turns out to be a convex optimization problem. On the other hand, the lower bounds are\nbased on a combination of information-theoretic techniques and carefully constructed packings of\nthe parameter set WB. The main technical di\ufb03culty is in constructing a packing in the semi-norm\ninduced by the Laplacian L. See Appendix A for the full proof.\n3.2 Minimax rates in the squared \u21132-norm\nLet us now turn to optimizing the minimax risk under the squared Euclidean norm. Theorem 2\nbelow presents upper and lower bounds on this quantity.\nTheorem 2 (Bounds on minimax rates in \u21132-norm)\n(a) For a sample size n \u2265c2\u03c32tr(L\u2020)\n\u03b6B2\n, any\nestimator ew based on n samples from the Ordinal model has squared Euclidean error lower\nbounded as\nsup\nw\u2217\u2208WB\nE\nh\n\u2225ew \u2212w\u2217\u22252\n2\ni\n\u2265c2\u2113\n\u03c32\nn max\nn\nd2,\nmax\nd\u2032\u2208{2,...,d}\nd\u2032\nX\ni=\u230a0.99d\u2032\u230b\n1\n\u03bbi(L)\no\n.\n(8a)\n(b) For any instance of the Ordinal model with \u03b3-strong log-concavity and any w\u2217\u2208WB, the\nmaximum likelihood estimator satis\ufb01es the bound\nsup\nw\u2217\u2208WB\nE\nh\n\u2225bwML \u2212w\u2217\u22252\n2\ni\n\u2264c2u\u03b6\n\u03b3 \u03c32\nd\n\u03bb2(L)n.\n(8b)\nSee Appendix B for the proof of this theorem. As we describe in the next section, the upper and\nlower bounds on minimax risk from Theorem 2 to identify the comparison graph(s) that lead to the\nbest possible minimax risk over all possible graph topologies.\nFigure 2 depicts results from simulations under the Thurstone model, depicting the squared \u21132\nerror for the maximum likelihood estimator for various values of n and d. In the simulations, the true\nvector w\u2217is generated by \ufb01rst drawing a d-length vector uniformly at random from [\u22121, 1]d, followed\nby a scale and shift to ensure w\u2217\u2208WB.\nThe n pairs are chosen uniformly (with replacement)\nat random from the set of\n\u0000d\n2\n\u0001\npossible pairs of items.\nThe value of \u03c3 and B are both \ufb01xed to\n7\n27\n28\n29 210 211 212 213\nNumber of samples n\n2-8\n2-6\n2-4\n2-2\n20\n22\n24\nError\n ||\u02c6w\u2212w \u2217||2\n2\nd = 8\nd = 16\nd = 32\nd = 64\n(a) Error\n27\n28\n29 210 211 212 213\nNumber of samples n\n2-8\n2-6\n2-4\n2-2\n20\n22\n24\nRescaled error\n ||\u02c6w\u2212w \u2217||2\n2 n/d2\nd = 8\nd = 16\nd = 32\nd = 64\n(b) Rescaled error\nFigure 2. Simulation results under the Thurstone model. The comparison topology chosen here is\nthe complete graph.\nbe 1. Given the n samples, inference is performed via the maximum likelihood estimator for the\nThurstone model. Each point in the plots is an average of 20 such trials.\nThe error in Figure 2 reduces linearly with n, exactly as predicted by our Theorem 2. For the\ncomplete graph,\n1\n\u03bb2(L) = d\u22121\n2 . Theorem 2 thus predicts a quadratic increase in the error with d. As\npredicted, the error when normalized by\n1\nd2 in Figure 2 converges to the same curve for all values of\nd.\nBefore concluding this section, we also look at the Paired Cardinal model (Section 2.1), the\ncardinal analogue of the Thurstone model.\nTheorem 3 (Bounds on minimax rates in \u21132-norm) For the Paired Cardinal model, the\nminimax risk is sandwiched as\nc3\u2113\u03c32 tr(L\u2020)\nn\n\u2264inf\nbw\nsup\nw\u2217\u2208W\u221e\nE\nh\n\u2225bw \u2212w\u2217\u22252\n2\ni\n\u2264c3u \u03c32 tr(L\u2020)\nn\n.\n(9)\nThe proof of Theorem 3 is available in Appendix C.\nWe conjecture that the dependence of the squared \u21132 minimax risk under the Ordinal models\non the problem parameters n, d and the graph topology is identical to that derived in Theorem 3 for\nthe Paired Cardinal model, i.e., is proportional to tr(L\u2020)\nn\n.\n3.3 Extension to m-ary comparisons\nSuppose instead of eliciting pairwise comparisons, one can instead ask the workers to make compar-\nisons between more than two options. In particular, we assume that each sample is a selection of\nthe item with the largest perceived quality among some m presented items. The setting of pairwise\ncomparisons is a special case with m = 2. Recall from Theorem 2 that the minimum squared \u21132\nminimax risk in the pairwise comparison setting is of the order d2\nn . Our goal in this section is to\nbring the concept of multiple-item comparison under the same framework as the pairwise case, and\nvia a generalization of our earlier theoretical analysis, understand how the error exponent depends\non m.\n8\nConsider d items, where every item j \u2208[d] has a certain underlying quality score w\u2217\nj \u2208[\u2212B, B].\nYou obtain n samples, with each sample being a selection of the item with the largest perceived value\namong some m presented items.\nConsider (d\u00d7m) matrices E1, . . . , En such that for each i \u2208[n], the m columns of Ei are distinct\nunit vectors. The positions of the non-zero elements in the m columns of Ei represent the identities\nof the m items compared in the ith sample. One can visualize the choices of the items compared as a\nhyper-graph, with d vertices representing the d items and hyper-edge i \u2208[n] containing the m items\ncompared in observation i.\nLet R1, . . . , Rm be (m \u00d7 m) permutation matrices representing m cyclic shifts in an arbitrary\n(but \ufb01xed) direction. Consider the observation model\nP(yi = j|w\u2217, Ei) = F((w\u2217)T EiRj)\nfor all j \u2208[m], where F : [\u2212B, B]m \u2192[0, 1] represents the probability of choosing the \ufb01rst among\nthe m items presented. For every x \u2208[\u2212B, B]m, F(x) is assumed to satisfy:\n\u2022 Shift-invariance: the probabilities depend only on the di\ufb00erences in the weights of the items\npresented, i.e, F(x) depends only on {xi \u2212xj}i,j\u2208[m].\n\u2022 Strong log-concavity: \u22072(\u2212log F(x)) \u2ab0H for some (m\u00d7m) symmetric matrix H with \u03bb2(H) >\n0.\nNote that the shift-invariance assumption implies 1 \u2208nullspace(\u22072(\u2212log F(x))), thereby neces-\nsitating nullspace(H) = span(1) and \u03bb1(H) = 0. One can also verify that the model proposed here\nreduces to the Ordinal model of Section 2.1 when m = 2.\nFor any hope of inferring the true weights w\u2217, we must ensure that the comparison hyper-graph\nis \u201cconnected\u201d, i.e., for every pair of items i, j \u2208[d], there must exist a path connecting item i and\nitem j in the comparison hyper-graph. We assume this condition is satis\ufb01ed. We also continue to\nassume that w\u2217\u2208WB : = {w \u2208Rd | \u2225w\u2225\u221e\u2264B, \u27e8w, 1\u27e9= 0}.\nThe popular Plackett-Luce model falls in this class, as illustrated below.\nExample 1 (Plackett-Luce model (Plackett, 1975; Luce, 1959)) The Plackett-Luce model con-\ncerns the process of choosing an item from a given set. Speci\ufb01cally, given m items with quality scores\nw\u2217\n1, . . . , w\u2217\nm respectively, the likelihood of choosing item i \u2208[m] under this model is given by\new\u2217\ni\nPm\nj=1 ew\u2217\nj =: F([w\u2217\n1, . . . , w\u2217\nm]).\nEvery choice is made independent of all other choices.\nIt is easy to verify that the Plackett-Luce model satis\ufb01es shift invariance. We now show that it\nalso satis\ufb01es strong log-concavity. A little algebra gives\n\u22072(\u2212log F(x)) =\nex1\n(\u27e8ex, 1\u27e9)4\n\u0000\u27e8ex, 1\u27e9diag(ex) \u2212ex(ex)T \u0001\n,\nwhere ex : = [ex1 \u00b7 \u00b7 \u00b7 exm]T . We will now derive a lower bound for the expression above. An application\nof the Cauchy-Schwarz inequality yields that for any vector v \u2208Rm,\nvT (ex(ex)T )v \u2264vT diag(ex)\u27e8ex, 1\u27e9v,\nwith equality if and only if v \u2208span(1). It follows that \u03bb2(\u22072(\u2212log F(x))) > 0 for all x \u2208[\u2212B, B]m.\nDe\ufb01ning the scalar \u03b2 : = minx\u2208[\u2212B,B]m \u03bb2(\nex1\n(\u27e8ex, 1\u27e9)4\n\u0000\u27e8ex, 1\u27e9diag(ex)\u2212ex(ex)T \u0001\n), on can see that setting\nH = \u03c3(I \u221211T ) satis\ufb01es the strong log-concavity conditions.\n9\nOur goal is to capture the scaling of the minimax error with respect to the number of observations\nn, the dimension d of the problem, and the choice of the subsets compared {Ei}i\u2208[n]. It is well\nunderstood (Miller, 1956; Kiger, 1984; Shi\ufb00rin and Nosofsky, 1994; Saaty and Ozdemir, 2003) that\nhumans have a limited information storage and processing capacity, which makes it di\ufb03cult to\ncompare more than a small number of items. For instance, Saaty and Ozdemir (2003) recommend\neliciting preferences over no more than seven options. Thus in this work we will restrict our attention\nto m = O(1). Moreover, the amount of noise in the selection process also depends on the number of\nitems m presented at a time: the higher the number, the greater the noise. We will thus not use a\n\u2018noise parameter \u03c3\u2019 in this setting, and assume the noise to be incorporated in the function F which\nitself is a function of m.\nOur results involve the Laplacian of the comparison graph, de\ufb01ned for the m-wise comparison\nsetting as follows. Let L be an (d\u00d7d) matrix that depends on the choice of the comparison topology\nas\nL : = 1\nn\nn\nX\ni=1\nEi(mI \u221211T )ET\ni .\n(10)\nWe will call L the Laplacian of the comparison hyper-graph. One can verify that when applied to\nthe special case of m = 2, the matrix L de\ufb01ned in (10) reduces to the Laplacian of the pairwise-\ncomparison graph de\ufb01ned earlier in (4).\nThe following theorem presents our main results for the m-wise comparison setting.\nTheorem 4 For the m-wise model, the minimax risk is sandwiched as\nc3\u2113\ninfz F(z)\nm2\u03bbm(H) supz \u2225\u2207F(z)\u22252\nH\u2020\nd\nn \u2264inf\nbw\nsup\nw\u2217\u2208WB\nE\nh\n\u2225bw \u2212w\u2217\u22252\nL\ni\n\u2264c3u\nm2 supz \u2225\u2207log F(z)\u22252\n2\n\u03bb2(H)2\nd\nn,\nin the squared L semi-norm and as\nc4\u2113\ninfz F(z)\nm2\u03bbm(H) supz \u2225\u2207F(z)\u22252\nH\u2020\nd2\nn \u2264inf\nbw\nsup\nw\u2217\u2208WB\nE\nh\n\u2225bw \u2212w\u2217\u22252\n2\ni\n\u2264c4u\nm2 supz \u2225\u2207log F(z)\u22252\n2\n\u03bb2(H)2\nd2\n\u03bb2(L)n,\nin the squared \u21132 norm. Here we assume n \u2265c5\ntr(L\u2020) infz F(z)\nB2\u03bbm(H) supz \u2225\u2207F(z)\u22252\nH\u2020 for both the lower bounds, and\nwhere the suprema and in\ufb01ma with respect to the parameter z are taken over the set [\u2212B, B]m.\nThe proof of Theorem 4 is provided in Appendix D. Our results establish that the dependence of\nthe squared L semi-norm and squared Euclidean minimax error on m occurs only as multiplicative\npre-factors, and the error exponent is independent of m. Thus, if one follows the standard recommen-\ndation in the psychology literature Miller (1956); Kiger (1984); Shi\ufb00rin and Nosofsky (1994); Saaty\nand Ozdemir (2003)\u2014namely to choose m = O(1)\u2014then the best possible scaling of the squared\nL semi-norm minimax risk with respect to d and n is always d\nn, that of the squared Euclidean min-\nimax risk is always d2\nn , and evenly spreading the samples across all possible choices of m items is\noptimal. Nevertheless, a more re\ufb01ned modeling and analysis is required to understand the precise\ntradeo\ufb00s governing the choice of the number m of items presented to the user.\n4. Role of graph topology\nWe now return to the setting of pairwise comparisons. In certain applications, one may have the\nliberty to decide which pairs are compared. The results of the previous section demonstrated the role\nplayed by the Laplacian of the comparison graph in the estimation error. We now employ these results\n10\nto derive guidelines towards designing the comparison graph. Let us focus on the estimation error in\nthe squared \u21132 norm in the ordinal setting. As discussed earlier, we assume that the graph induced\nby the comparisons is connected. An application of Theorem 2 lets us identify good topologies for\npairwise comparisons in the \ufb01xed-design setup.\nA popular class of comparison topologies is that of evenly distributed samples on an unweighted\ngraph (e.g., (Negahban et al., 2012)). Consider any \ufb01xed, unweighted graph G = (V, E). We assume\nthat the samples are distributed evenly along the edges E of G, and that the sample size n is\nsu\ufb03ciently large. Using standard matrix concentration inequalities, it is straightforward to extend\nour analysis to the setting of random chosen comparisons from a \ufb01xed graph (see, for instance,\nOliveira (2009)). Let L\u2032 denote the Laplacian of G. We de\ufb01ne the scaled Laplacian of G as\nL : =\n1\n| E |L\u2032.\nOne can verify that the matrix L de\ufb01ned here is identical to what was de\ufb01ned in (4) in a more general\ncontext. In order to di\ufb00erentiate from L, we will term L\u2032 as the regular Laplacian of the graph G.\n4.1 Analytical results\nConsider the Ordinal model and the squared \u21132-norm as the metric of interest. We claim that\nin order to determine whether a given comparison graph achieves minimax risk (up to a constant\npre-factor), it su\ufb03ces to examine the eigen-spectrum of the scaled Laplacian matrix. In particular,\nwe claim that:\n\u2022 If the scaled Laplacian has a second smallest eigenvalue that scales as\n1\n\u03bb2(L) = \u0398(d), then the\ncomparison graph is optimal, and leads to the smallest possible minimax risk, in particular one\nthat scales as d2\nn .\n\u2022 Conversely, if the scaled Laplacian matrix has an eigen-spectrum satisfying\nd2 = o\n\uf8eb\n\uf8ed\nmax\nd\u2032\u2208{2,...,d}\nd\u2032\nX\ni=\u230a0.99d\u2032\u230b\n1\n\u03bbi(L)\n\uf8f6\n\uf8f8,\n(11)\nthen the associated estimation error is strictly larger than the minimax risk. In particular, this\nsub-optimality holds whenever d2 = o(\n1\n\u03bb2(L)).\nIn order to verify these claims, we note that by de\ufb01nition (4) of the Laplacian matrix, we have\ntr(L) = 1\nn\nn\nX\ni=1\ntr(xixT\ni ) = 2.\nIt follows that \u03bb2(L) \u2264\n2\nd\u22121, i.e., that\n1\n\u03bb2(L) = \u2126(d). As we will see shortly, several classes of graphs\nsatisfy\n1\n\u03bb2(L) = \u0398(d). Comparing the lower bound of \u2126(d2\nn ) on the minimax risk (8a) with the upper\nbound (8b) gives the su\ufb03cient condition of\n1\n\u03bb2(L) = \u0398(d) for optimality, and the smallest minimax\nrisk as \u0398( d2\nn ). The lower bound (8a) now also gives the claimed condition for strict sub-optimality.\nIn order to illustrate these claims, let us consider a few canonical classes of graphs, and study how\nthe estimation error under the squared Euclidean norm scales in the Ordinal model. The spectra\nof the regular Laplacian matrices of these graphs can be found in various standard texts on spectral\ngraph theory (e.g., Brouwer and Haemers (2011)).\n11\n\u2022 Complete graph. A complete graph has one edge between every pair of nodes. The spectrum\nof the regular Laplacian of the complete graph is 0, d, . . . , d, and hence the spectrum of the scaled\nLaplacian L is 0,\n2\nd\u22121, . . . ,\n2\nd\u22121. Substituting \u03bb2(L) =\n2\nd\u22121 in Theorem 2b gives an upper bound\nof \u0398( d2\nn ) on the minimax risk, and Theorem 2 gives a matching lower bound. The su\ufb03ciency\ncondition discussed above proves optimality.\n\u2022 Constant-degree expander. The spectrum of the regular Laplacian is 0, \u0398(d), \u2126(d), . . . , \u2126(d).\nSince the number of edges is \u0398(d), the spectrum of the scaled Laplacian equals 0, \u0398( 1\nd), \u2126( 1\nd), . . . , \u2126( 1\nd).\nThe evaluation of this class of graphs with respect to the minimax risk is identical to that of com-\nplete graphs, giving a lower and upper bound of \u0398(d2\nn ) on the minimax risk, and guaranteeing\noptimality.\n\u2022 Complete bipartite. The d nodes are partitioned into two sets comprising, say, m1 and m2\nnodes. There is an edge between every pair of nodes in di\ufb00erent sets, and there are no edges\nbetween any two nodes in the same set. The eigenvalues of the regular Laplacian of this graph are\n0, m2, . . . , m2\n|\n{z\n}\nm1\u22121\n, m1, . . . , m1\n|\n{z\n}\nm2\u22121\n, m1+m2. Since the total number of edges is m1m2, the scaled Laplacian\nL has a spectrum 0,\n1\nm1 ,..., 1\nm1\n|\n{z\n}\nm1\u22121\n,\n1\nm2 ,..., 1\nm2\n|\n{z\n}\nm2\u22121\n,\n1\nm1 +\n1\nm2 . Suppose without loss of generality that m1 \u2265m2.\nAlso suppose that m2 > 1 (the case of m2 = 1 is the star graph discussed below). Then we have\n1\nm1 \u2264\n1\nm2 \u2264\n1\nm1 +\n1\nm2 and that d > m1 \u2265d\n2. Furthermore since m2 > 1, the multiplicity of\n1\nm1\nin the spectrum of the scaled Laplacian is at least 1. Thus we have \u03bb2(L) = \u0398( 1\nd). Theorem 2\nthen gives lower and upper bounds on the minimax risk as \u0398(d2\nn ) and the su\ufb03ciency condition\ndiscussed above guarantees its optimality.\n\u2022 Star. A star graph has one central node with edges to every other node. It is a special case\nof the complete bipartite graph with m1 = d \u22121 and m2 = 1.\nThe spectrum of the regular\nLaplacian is 0, 1, . . . , 1, d. Since there are (d \u22121) edges, the spectrum of the scaled Laplacian is\n0,\n1\nd\u22121, . . . ,\n1\nd\u22121,\nd\nd\u22121. Theorem 2 and the su\ufb03ciency condition discussed above imply that this class\nof graphs is optimal and is associated to a minimax risk of \u0398(d2\nn ).\n\u2022 Path. A path graph is associated to an arbitrary ordering of the d nodes with edges between\npairs j and (j + 1) for every j \u2208{1, . . . , d \u22121}. The spectrum of the regular Laplacian is given by\n2\n\u00001 \u2212cos\n\u0000 \u03c0i\nd\n\u0001\u0001\n, i \u2208{0, . . . , d \u22121}, and that of the scaled Laplacian is thus\n2\nd\u22121\n\u00001 \u2212cos\n\u0000 \u03c0i\nd\n\u0001\u0001\n, i \u2208\n{0, . . . , d \u22121}. The relation (1 \u2212cos x) = sin2 x\n2 and the approximation sin x \u2248x for values of x\nclose to zero gives \u03bb2(L) = \u0398( 1\nd3 ). The minimax risk is thus upper bounded as O( d4\nn ) and lower\nbounded as \u2126( d3\nn ). This class of graphs is thus strictly suboptimal.\n\u2022 Cycle. A cycle is identical to a path except for an additional edge between node d and node 1.\nThe spectrum of the regular Laplacian is given by 2\n\u00001 \u2212cos\n\u0000 2\u03c0i\nd\n\u0001\u0001\n, i \u2208{0, . . . , d \u22121}, and that of\nthe scaled Laplacian is thus 2\nd\n\u00001 \u2212cos\n\u0000 2\u03c0i\nd\n\u0001\u0001\n, i \u2208{0, . . . , d \u22121}. The relation (1 \u2212cos x) = sin2 x\n2\nand the approximation sin x \u2248x for values of x close to zero gives \u03bb2(L) = \u0398( 1\nd3 ). The minimax\nrisk is thus upper bounded as O( d4\nn ) and lower bounded as \u2126(d3\nn ). This class of graphs is thus\nstrictly suboptimal.\n\u2022 Barbell. The nodes are partitioned into two sets of d\n2 nodes each, and there is an edge between\nevery pair of nodes within each set. In addition, there is exactly one edge across the sets. The spec-\ntrum of the regular Laplacian can be computed as 0, \u0398( 1\nd), \u0398(d), . . . , \u0398(d). Since there are \u0398(d2)\nedges, the spectrum of the scaled Laplacian turns out to become 0, \u0398( 1\nd3 ), \u0398( 1\nd), . . . , \u0398( 1\nd), \u2126( 1\nd).\n12\nApplying the results derived earlier in the paper, we get that a lower bound of \u2126(d3\nn ) and an upper\nbound of O( d4\nn ) on the minimax risk, thereby also establishing the sub-optimality of this class of\ngraphs.\n\u2022 2D Lattice. An (m1 \u00d7 m2) lattice has d = m1m2 vertices arranged as a (m1 \u00d7 m2) grid. Assume\nm1 = \u0398(d) and m2 = \u0398(d). This class of graphs can be written as a Cartesian product of a path\ngraph of length m1 and a second path graph of length m2. As a result, the spectrum of the scaled\nLaplacian is 2\nd\n\u00002\u2212cos\n\u0000 \u03c0i\nm1\n\u0001\n\u2212cos\n\u0000 \u03c0j\nm2\n\u0001\u0001\n,\n... i\u2208{0,...,m1\u22121},j\u2208{0,...,m2\u22121}. Again, using the small angle\napproximation of the sinusoid, one can compute an upper bound on the minimax risk as O( d3\nn )\nand a lower bound of \u2126(d2\nn ). We do not know at this point whether the 2D lattice minimizes the\nminimax risk.\n\u2022 Hypercube. Assume d = 2m for some integer m. Representing each node as a distinct m-length\nbinary vector, an edge exists between the nodes corresponding to any pair of vectors within a\nHamming distance of one. The hypercube is an m-fold Cartesian product of a path with two nodes,\nand hence the regular Laplacian has an eigenvalue of 2i with multiplicity\n\u0000m\ni\n\u0001\n, for i \u2208{0, . . . , m}.\nThe scaled Laplacian has an eigenvalue of\n2i\nd log d with multiplicity\n\u0000m\ni\n\u0001\n, for i \u2208{0, . . . , m}. A lower\nbound on the minimax risk is \u2126(d2\nn ) and an upper bound is O( d2 log d\nn\n). We do not know if the\nhypercube is optimal, our bounds do tell us that any sub-optimality is bounded by at most a\nlogarithmic factor.\nObserve that the degree-k expander requires n \u2265kd samples while the complete graph requires\nn \u2265\n\u0000d\n2\n\u0001\nsamples, so in practical applications at least for small sample sizes we should prefer a\nlow-degree expander.\nFinally, if the conjecture in Section 3.2 were true, namely that the \u21132 minimax risk scales as\n\u03c32tr(L\u2020)/n, then the condition tr(L\u2020) = \u0398(d2) would be necessary and su\ufb03cient for optimality of\na comparison graph with the scaled Laplacian L. Observe that the graphs designated as \u2018optimal\u2019\nin the discussion above indeed satisfy this condition. On the other hand, the graphs established as\nstrictly suboptimal have tr(L\u2020) = \u2126(d3).\n4.2 Experiments and simulations\nThis section evaluates the dependence of the squared \u21132-error on the topology of the comparison\ngraph. We consider the following \ufb01ve topologies: path, barbell, complete, expander and 2D-lattice.\nIn order to form an expander graph, we used the Gabber-Galil construction (Gabber and Galil,\n1981). For any chosen graph topology, the n di\ufb00erence vectors are selected as one edge each chosen\nuniformly at random (with replacement) from the comparison graph. Recall that our theory predicts\nthat the complete and expander graphs will perform the best, and that the line and dumbbell graphs\nwill fare the worst. Also recall that our theory predicts the error will scale as \u2225w\u2217\u2212bw\u22252\n2 scales with\nn as 1/n in the complete and expander topologies.\n4.2.1 Experiments on synthetic data\nThis section describes simulations using data generated synthetically from the Thurstone model.\nIn the simulations, we \ufb01rst generate a quality score vector w\u2217\u2208WB using one of the procedures\ndescribed below. Once w\u2217is chosen, the n pairwise comparisons for any given topology are generated\nas follows. An edge is selected uniformly (with replacement) at random from the underlying graph,\nand the chosen edge determines the pair of items compared. The outcome of the comparison is\ngenerated as per the Thurstone model with the chosen w\u2217as the underlying quality score. Finally,\n13\nthe maximum likelihood estimator for the Thurstone model is employed to estimate w\u2217. Every\npoint in the plots is an average across 40 trials.\nThe following six procedures are employed to generated the true quality score vector w\u2217in the\nsix respective sub\ufb01gures of Figure 3.\n(a) Gaussian: w\u2217is drawn from the standard normal distribution N(0, I).\n(b) Uniform: w\u2217is drawn uniformly at random from the set [\u22121, 1]d.\n(c) Packing set for the path graph: We \ufb01rst choose a vector z as by setting a value of 0 in the\n\ufb01rst coordinate, a value \u22121 in d\n2 of the other coordinates chosen uniformly at random, and a\nvalue 1 in the remaining coordinates. Letting L = U T \u039bU denote the eigen-decomposition of\nthe Laplacian matrix of the path graph, w\u2217is set as U T \u039b\u2020z, where \u039b\u2020 is the Moore-Penrose\npseudoinverse of \u039b. This generation process mimics a construction used to prove the lower\nbound in Theorem 2, and tailors the construction for the path graph.\n(d) Packing set for the barbell graph: The procedure is identical to that in (c), except that the\nLaplacian matrix used is that of the barbell graph.\n(e) Packing set for the complete graph: The procedure is identical to that in (c), except that the\nLaplacian matrix used is that of the complete graph.\n(f) Packing set for the star graph: The procedure is identical to that in (c), except that the\nLaplacian matrix used is that of the star graph.\nThe vector w\u2217generated in this procedure is then scaled and shifted to ensure w\u2217\u2208WB. The value\nof B and \u03c3 are set as 1.\nFigure 3 plots the estimation error under various topologies of the comparison graph. Observe\nin the \ufb01gure that the error is the lowest under the complete and the star graphs, and the highest\nunder the barbell and the path graphs. In particular, the error consistently varies as \u0398(d2/n) for the\ncomplete and star graphs \u2013 this phenomenon holds even in plots (e) and (f) where the procedure to\nchoose w\u2217forms the worst case for the complete and star graphs respectively according to the proof\nof Theorem 2. On the other hand, the minimax error varies as \u2126(d3/n) in the worst case for the\npath and the barbell graphs. Finally, observe that in the simulations, the (constant) multiplicative\nfactors to the term d2\nn in the error turn out to be rather small, in the range of 0 to 9.\n4.2.2 Experiments on MTurk\nIn this section, we describe the results of experiments conducted on the popular Amazon Mechanical\nTurk (https://www.mturk.com/; henceforth referred to as \u201cMTurk\u201d) commercial crowdsourcing\nplatform, evaluating the e\ufb00ects of the choice of the topology. MTurk is an online platform where\nindividuals or businesses can put up a task, and any individual can log in and complete the tasks\nin exchange for a payment that is speci\ufb01ed along with the task. In our experiments, each worker\nwas o\ufb00ered 20 cents per completed task. A worker was allowed to do no more than one task in an\nexperiment. Workers were required to answer all the questions in a task. Only those workers who had\n100 or more prior approved works and an approval rate of 95% or higher were allowed. Workers from\nany country were allowed to participate, except for the task of estimating distances between cities\n(for which only USA-based workers were permitted since all questions involved American cities).\nWe conducted three experiments that required the workers to make ordinal choices.\n(a) Estimating areas of circles: In each question, the worker was shown a circle in a bounding box\n(Figure 5a), and the worker was required to identify the fraction of the box\u2019s area that the\ncircle occupied.\n14\n0\n10\n20\n30\n40\n50\n60\n70\nNumber of items d\n0\n5\n10\n15\n20\n25\n30\nRescaled error\n ||\u02c6w\u2212w \u2217||2\n2 n/d2\nComplete graph\nStar graph\nPath graph\nBarbell graph\n(a) Gaussian\n0\n10\n20\n30\n40\n50\n60\n70\nNumber of items d\n0\n5\n10\n15\n20\n25\n30\nRescaled error\n ||\u02c6w\u2212w \u2217||2\n2 n/d2\nComplete graph\nStar graph\nPath graph\nBarbell graph\n(b) Uniform\n0\n10\n20\n30\n40\n50\n60\n70\nNumber of items d\n0\n5\n10\n15\n20\n25\n30\nRescaled error\n ||\u02c6w\u2212w \u2217||2\n2 n/d2\nComplete graph\nStar graph\nPath graph\nBarbell graph\n(c) Packing set for the path graph\n0\n10\n20\n30\n40\n50\n60\n70\nNumber of items d\n0\n5\n10\n15\n20\n25\n30\nRescaled error\n ||\u02c6w\u2212w \u2217||2\n2 n/d2\nComplete graph\nStar graph\nPath graph\nBarbell graph\n(d) Packing set for the barbell graph\n0\n10\n20\n30\n40\n50\n60\n70\nNumber of items d\n0\n5\n10\n15\n20\n25\n30\nRescaled error\n ||\u02c6w\u2212w \u2217||2\n2 n/d2\nComplete graph\nStar graph\nPath graph\nBarbell graph\n(e) Packing set for the complete graph\n0\n10\n20\n30\n40\n50\n60\n70\nNumber of items d\n0\n5\n10\n15\n20\n25\n30\nRescaled error\n ||\u02c6w\u2212w \u2217||2\n2 n/d2\nComplete graph\nStar graph\nPath graph\nBarbell graph\n(f) Packing set for the star graph\nFigure 3. Estimation error under di\ufb00erent topologies for di\ufb00erent generative processes in the synthetic\nsimulations.\n15\n(a) Area of circle\n(b) Age from photograph\n(c) City distances\nFigure 4: Estimation error under di\ufb00erent topologies in the experiments conducted on MTurk.\n(b) Estimating age of people from photographs: The worker was shown photographs of people\n(Figure 5b) and was asked to estimate their ages.\n(c) Estimating distances between pairs of cities: Pairs of cities were listed (Figure 5c) and for each\npair, the worker had to estimate the distance between them.\nFor each experiment, we recruited 140 workers on MTurk, and assigned them to one of the\n\ufb01ve topologies uniformly at random. In this experiment and others involving aggregation of ordi-\nnal data from MTurk, the aggregation procedure follows maximum likelihood estimation under the\nThurstone model, and the estimator is supplied the best-\ufb01tting value of \u03c3 obtained via 3-fold\ncross-validation. Each run of the estimation procedure employs the data provided by \ufb01ve randomly\nchosen workers from the pool of workers who performed that task. The entire data pertaining to\nthese experiments is available on the \ufb01rst author\u2019s website.\nFigure 4 plots the squared \u21132 estimation error for the three experiments under the \ufb01ve topologies\nconsidered. We see that the relative errors are generally consistent with our theory, with the com-\nplete graph exhibiting the best performance and the path graph faring the worst. On real datasets,\nmodel misspeci\ufb01cation can in some cases cause the outcomes to di\ufb00er from our theoretical predic-\ntions. Understanding the e\ufb00ect of model misspeci\ufb01cation, especially on topology considerations, is\nan important question we hope to address in future work.\n5. Cardinal versus ordinal measurements\nIn this section, we compare two approaches towards eliciting data: a score-based \u201ccardinal\u201d approach\nand a comparison-based \u201cordinal\u201d approach. In a cardinal approach, evaluators directly enter nu-\nmeric scores as their answers (Figure 1b), while an ordinal approach involves comparing (pairs of)\nitems (Figure 1a).\nThere are obvious advantages and disadvantages associated with either approach. On one hand,\nthe cardinal approach allows for very \ufb01ne measurements. For instance, the cardinal measurements in\nFigure 1 can take any value between 0 and 100, whereas an ordinal measurement is binary. One might\nbe tempted to go even further and argue that ordinal measurements necessarily give less information,\nfor one can always convert a set of cardinal measurements into ordinal, simply by ordering the\nmeasurements by value. If this conversion were valid, the data processing inequality (Cover and\nThomas, 2012), would then guarantee that estimators based on ordinal data can never outperform\nestimators based on cardinal data.\nHowever, this conversion assumes that cardinal and ordinal\nmeasurements su\ufb00er from the same type of statistical \ufb02uctuation. The following set of experiments\nshow this assumption is false.\n5.1 Raw data from MTurk\nWe conducted seven di\ufb00erent experiments on MTurk to investigate the possibility of a \u201cdata-\nprocessing inequality\u201d between the elicited cardinal and ordinal responses: Are responses elicited\n16\n\u00a2\uf0a2 \n\u00a2\uf0a2 \n Which circle is BIGGER?  \n(a)\nWhat%is%the%distance%between%%\nthe%following%pairs%of%ci4es?%\n%\nSan$Francisco$and$Aus.n%%%\nmiles%\nWho%do%you%think%is%OLDER?%\n!%\n!%\n%Which%image%is%more%relevant%\nfor%the%search%query%\u2018INTERNET\u2019?%\n!%\n!%\nHow%relevant%is%this%imag\nthe%search%query%'INTERN\n/%100%\np\ng\np\nwords%are%misspell\nBut that is the beginning of a new sto\nstory of the gradual reneual of a m\nstory of his gradual regeneration, of his\nfrom one world into another, of his intiat\na new unknown life. That might be the \nof a new story, but our present story is e\nWhich%tone%corresponds%to\nHIGHER%number%on%a%phone%ke\n!%\n!%\n!%\n!%\n\u201cSimple, fast but sure cure\u201d \nhealthcare%plaMorm%\n/%10%\n(b)\nbetween%these%ci.es?%\n%\nSan$Francisco$and$Aus.n\nmiles%\n!%\n!%\n%Which%image%is%more%re\nfor%the%search%query%\u2018INT\n!%\nWhich%pair%of%ci.es%is%farther%\naway%from%each%other?%\n!%\n!%\nCharlo2e$$\nand$$\nBoston$$\nSan$Francisco$$\nand$$\nAus.n%%%\n(c)\nHow many words are \nmisspelled in this paragraph?  \nwords are misspelled \nBut that is the beginning of a new story - the \nstory of the gradual reneual of a man, the \nstory of his gradual regeneration, of his pasing \nfrom one world into another, of his intiation into \na new unknown life. That might be the subject \nof a new story, but our present story is ended. \n(d)\nWhat%is%the%distance%%\nbetween%these%ci.es?%\n%\nSan$Francisco$and$Aus.n%%%\nmiles%\nOLDER?%\n!%\n%Which%image%is%more%relevant%\nfor%the%search%query%\u2018INTERNET\u2019?%\n!%\n!%\nHow%relevant%is%this%image%for%%\nthe%search%query%'INTERNET'?%\n/%100%\nHow%many%words%are%misspelled%\nin%this%paragraph?%%\nwords%are%misspelled%\nBut that is the beginning of a new story - the \nstory of the gradual reneual of a man, the \nstory of his gradual regeneration, of his pasing \nfrom one world into another, of his intiation into \na new unknown life. That might be the subject \nof a new story, but our present story is ended. \nWhich%sound%has%a%%\nHIGHER%frequency?%\n!%\n!%\n!%\n!%\n%Which%circle%is%BIGGER?%%\ne cure\u201d \nor%a%\nrm%\n(e)\nWhat%is%the%distance\nthe%following%pairs%o\n%\nSan$Francisco$and$\nmile\nWho%do%you%think%is%OLDER?%\n!%\n!%\n%Which%image%is%m\nfor%the%search%que\n!%\n!%\n%Which%circle%is%B\n\u201cSimple, fast but sure cure\u201d \nRate%this%tagline%for%a%\nhealthcare%plaMorm%\n/%10%\n(f)\nFigure 5. Screenshots of the tasks presented to the subjects. For each task, only one version (cardinal\nor ordinal) is shown here.\nin ordinal form equivalent to data obtained by \ufb01rst eliciting cardinal responses and then subtracting\npairs of items? Our experiments lead us to conclude that this is generally not the case: convert-\ning cardinally collected data into ordinal (by subtracting pairs of responses) often leads to a higher\namount of noise as compared to that in data that is elicited directly in ordinal form.\nThe tasks were selected to have a broad coverage of several important subjective judgment\nparadigms such as preference elicitation, knowledge elicitation, audio and visual perception and\nskill utilization.\nIn addition to the three experiments described in Section 4.2.2, we conducted the following four\nexperiments.\n(d) Finding spelling mistakes in text: The worker had to identify the number of words that were\nmisspelled in each paragraph shown (Figure 5d).\n(e) Identifying sounds: The worker was presented with audio clips, each of which was the sound of\na single key on a piano (which corresponds to a single frequency). The worker had to estimate\nthe frequency of the sound in each audio clip (Figure 5e).\n(f) Rating tag-lines for a product: A product was described and tag-lines for this product were\nshown (Figure 5f). The worker had to rate each of these tag-lines in terms of its originality,\nclarity and relevance to this product.\n(g) Rating relevance of the results of a search query: Results for the query \u2018Internet\u2019 for an image\nsearch were shown (Figure 1) and the worker had to rate the relevance of these results with\nrespect to the given query.\nNote that the data collected for (a)\u2013(c) here was di\ufb00erent and independent of the data collected\nfor these tasks in Section 4.2.2.\nThe number of items d in the experiments ranged from 10 to 25. For each of the seven experiments,\nwe recruited 100 workers, and assigned each worker to either the ordinal or the cardinal version of\nthe task at random. Upon obtaining the data, we \ufb01rst reduced the cardinal data obtained from the\nexperiments into ordinal form by comparing answers given by the subjects to consecutive questions.\nFor \ufb01ve of the experiments ((a) through (e)), we had access to the \u201cground truth\u201d solutions, using\n17\nTask\nCircle\nAge\nDistance\nSpelling\nAudio\nTagline\nRelevance\nError in Ordinal\n6%\n13%\n17%\n40%\n20%\n44%\n31%\nStd. dev.\n.23\n.33\n.38\n.49\n.40\n.47\n.44\nError in Cardinal\n17%\n17%\n20%\n42%\n29%\n42%\n35%\nStd. dev.\n.31\n.38\n.38\n.46\n.43\n.46\n.44\nTime in Ordinal\n98s\n31s\n84s\n316s\n66s\n251s\n105s\nStd. dev.\n21.1\n14.3\n62.1\n33.2\n11.1\n28.1\n13.1\nTime in Cardinal\n181s\n70s\n144s\n525s\n134s\n342s\n185s\nStd. dev.\n39.9\n33.1\n56.2\n46.0\n12.4\n44.6\n28.2\nTable 1. Comparison of the average amount of error when ordinal data is collected directly versus\nwhen cardinal data is collected and converted to ordinal. Also tabulated is the median time (in seconds)\ntaken to complete a task by a subject in either type of task.\nwhich we computed the fraction of answers that were incorrect in the ordinal and the cardinal-\nconverted-to-ordinal data (any tie in the latter case was counted as half an error). For the two\nremaining experiments ((f) and (g)) for which there is no ground truth, we computed the \u2018error\u2019\nas the fraction of (ordinal or cardinal-converted-to-ordinal) answers provided by the subjects that\ndisagreed with each other. It is important to note that in the experiments in this section, we did not\nrun any estimation procedure on the data: we only measured the noise in the raw responses. The\nentire data pertaining to these experiments, including the interface seen by the workers and the data\nobtained from their work, is available on the \ufb01rst author\u2019s website.\nThe results are summarized in Table 1. If the cardinal measurements could always be converted\nto ordinal ones with the same noise level as directly eliciting ordinal responses, then it would be\nunlikely for the amount of error in the ordinal setting to be smaller than that in the cardinal setting.\nTable 1 shows that converting cardinal data to an ordinal form very often results in a higher (and\nsometimes signi\ufb01cantly higher) per-sample error in the (raw) responses than direct elicitation of\nordinal evaluations. Such an outcome may be explained by the argument that the inherent evaluation\nprocess in humans is not the same in the cardinal and ordinal cases: humans do not perform an\nordinal evaluation by \ufb01rst performing cardinal evaluations and then comparing them (Barnett, 2003;\nStewart et al., 2005). One can also see from Table 1 that the amount of time required for cardinal\nevaluations was typically (much) higher than for ordinal evaluations. One can thus assume that we\nwill typically have the per-observation error in the ordinal case lower than that in the cardinal case.\nIn particular, if we consider the Thurstone and the Cardinal models (introduced in Section 2.1),\nwe can assume that \u03c3 < \u03c3c.\n5.2 Analytical comparison of Cardinal versus Ordinal\nAs discussed earlier, while cardinal measurements allow more \ufb02exibility in the range of responses,\nordinal measurements contain a lower per-sample error.\nOrdinal measurements have additional\nbene\ufb01ts in that they avoid calibration issues that are frequently encountered in cardinal measure-\nments (Tsukida and Gupta, 2011), such as the evaluators\u2019 inherent (and possibly time-varying)\nbiases, or tendencies to give in\ufb02ated or conservative evaluations. Ordinal measurements are also\nrecognized to be easier or faster for humans to make (Barnett, 2003; Stewart et al., 2005), allowing\nfor more evaluations with the same amount of time, e\ufb00ort and cost.\nThe lack of clarity regarding when to use a cardinal versus an ordinal approach forms the moti-\nvation of this section. Can we make as reliable estimates from paired comparisons as from numeric\nscores? How much lower does the noise have to be for comparative measurements to be preferred\n18\nover cardinal measurements? The answers to these questions will help in determining how responses\nshould be elicited.\nIn order to compare the cardinal and ordinal methods of data elicitation, we focus on a setting\nwith evenly budgeted measurements. In accordance with the \ufb01xed-design setup assumed throughout\nthe paper, we choose the vectors xi a priori. Suppose that n is large enough, and that in the ordinal\ncase we compare each pair n/\n\u0000d\n2\n\u0001\ntimes. In the cardinal case suppose that we evaluate the quality of\neach item n/d times. We consider the Gaussian-noise models Thurstone and Cardinal introduced\nearlier in Section 2.1. In order to capture the fact that the amount of noise is di\ufb00erent in the cardinal\nand ordinal settings, we will denote the standard deviation of the noise in the cardinal setting as \u03c3c,\nand retain our notation of \u03c3 for the noise in the ordinal setting. In order to bring the two models\non the same footing, we measure the error in terms of the squared \u21132-norm.\nLet \u03b3G and \u03b6G denote the parameters \u03b3 and \u03b6 (de\ufb01ned in (1) and (6) respectively) specialized to\nthe Gaussian distribution. De\ufb01ne b\u2113(\u03c3, B) : =\nc2\u2113\n\u03b6G(B,\u03c3), bu(\u03c3, B) : = c2u\u03b6G(B,\u03c3)\n\u03b3G(B,\u03c3)\nand b(\u03c3, B) : =\nl\nc2\u03c32\n\u03b6GB2\nm\n.\nObserve that b\u2113, bu and b are independent of the parameters n and d.\nWith these preliminaries in place, we now compare the minimax error in the estimation under\nthe cardinal and ordinal settings.\nProposition 5 Given a sample size n that is a multiple of d(d \u22121)b(\u03c3, B), suppose that we observe\neach coordinate n/d times under the Cardinal model. Then the minimax risk is given by\ninf\nbw\nsup\nw\u2217\u2208WB\nE\nh\n\u2225bw \u2212w\u2217\u22252\n2\ni\n= \u03c32\nc\nd\nn.\n(12a)\nSimilarly, if we observe each pair n/\n\u0000d\n2\n\u0001\ntimes in the Thurstone model, then the minimax risk is\nsandwiched as\n\u03c32b\u2113(\u03c3, B) d\nn \u2264inf\nbw\nsup\nw\u2217\u2208WB\nE\nh\n\u2225bw \u2212w\u2217\u22252\n2\ni\n\u2264\u03c32bu(\u03c3, B) d\nn.\n(12b)\nIn the cardinal case, when each coordinate is measured the same number of times, the Cardi-\nnal model reduces to the well-studied normal location model, for which the MLE is known to be the\nminimax estimator and its risk is straightforward to characterize (see Lehmann and Casella (1998)\nfor instance). In the ordinal case, the result follows from the general treatment in Section 3.\nLet us now return to the question deciding between the cardinal and the ordinal methods of data\nelicitation. Suppose that we believe the Gaussian-noise models to be reasonably correct, and the\nper-observation errors \u03c3 and \u03c3c under the two settings are known or can be separately measured.\nProposition 5 shows that the scaling of the minimax error in the cardinal and ordinal settings is\nidentical in terms of the problem parameters n and d. As an important consequence, our result\nthus allows for the choice to be made based only on the parameters (\u03c3, \u03c3c, B), and independent of n\nand d: the ordinal approach incurs a lower minimax error when bu(\u03c3, B)\u03c32 < \u03c32\nc while the cardinal\napproach is better o\ufb00in terms of minimax error whenever b\u2113(\u03c3, B)\u03c32 > \u03c32\nc. Establishing the exact\ndecision boundary would require tightening the constants in the bounds, a task we leave for future\nwork.\n5.3 Aggregate Estimation Error in Experiments on MTurk\nFor the sake of completeness, we also computed the estimation error in the cardinal and ordinal\nsettings. We consider data from the three experiments (c), (d) and (e).2 We normalize the true\n2. We restrict attention to these three experiments for the following reasons. There is no ground truth for experiments\n(f) and (g). In experiment (a), the size of each circle in each question is chosen independently from a continuous\ndistribution, making all questions di\ufb00erent and preventing aggregation. Experiment (b) employs a disconnected\ntopology.\n19\nvector to have \u2225w\u2217\u2225\u221e= 1 and set B = 1.\nFor each of the three experiments, we execute 100\niterations of the following procedure. Select \ufb01ve workers from the cardinal and \ufb01ve from the ordinal\npool of workers uniformly at random. (The number \ufb01ve is inspired by practical systems (Wang et al.,\n2011; Piech et al., 2013).) We run the maximum-likelihood estimator of the Cardinal model on the\ndata from the \ufb01ve workers selected from the cardinal pool, and the maximum-likelihood estimator\nof the Thurstone model on the data from the \ufb01ve workers of the ordinal pool. Note that unlike\nSection 5.1, the cardinal data here is not converted to ordinal.\nTask\nSpelling\nDistance\nAudio\n\u2225w\u2217\u2212bw\u22252\n2\nd\nin Ordinal\n0.358 \u00b1 0.035\n0.168 \u00b1 0.026\n0.444 \u00b1 0.055\n\u2225w\u2217\u2212bw\u22252\n2\nd\nin Cardinal\n0.350 \u00b1 0.045\n0.330 \u00b1 0.028\n0.508 \u00b1 0.053\nKendall-tau coe\ufb03cient in Ordinal\n0.277 \u00b1 0.049\n0.547 \u00b1 0.034\n0.513 \u00b1 0.047\nKendall-tau coe\ufb03cient in Cardinal\n0.129 \u00b1 0.046\n0.085 \u00b1 0.038\n0.304 \u00b1 0.049\nTable 2: Evaluation of the inferred solution from the data received from multiple workers.\nThe results are tabulated in Table 2. To put the results in perspective of the rest of the paper,\nlet us also recall the per-sample errors in these experiments from Table 1. Observe that among these\nthree experiments, the per-sample noise in the cardinal data was closest to that in the ordinal data\nin the experiment on identifying the number of spelling mistakes. The gap was larger in the two\nremaining experiments. This fact is re\ufb02ected in the results of Table 2 where the estimator on the\ncardinal data incurs a lower \u21132-error than the estimator on the ordinal data in the experiment on\nidentifying the number of spelling mistakes, whereas the outcome goes the other way in the two\nremaining experiments. Our theory needs to tighten the constants in order to address this regime.\n6. Conclusions\nIn this paper, we presented topology-aware minimax error bounds under a broad class of preference-\nelicitation models. We demonstrated the utility of these results in guiding the selection of comparisons\nand in guiding the choice of the elicitation paradigm (cardinal versus ordinal) when these options are\navailable. One potential direction for future work would be to investigate improved data collection\nmechanisms, for instance adaptive schemes where we focus our e\ufb00ort on the most noisy comparisons.\nA second direction would be to characterize the precise thresholds for making the choice between the\ncardinal and ordinal approaches. Finally, the Thurstone and BTL models are parametric idealizations\nthat have proved useful in a wide variety of applications. In future work we would like to investigate\nmore \ufb02exible semi-parametric and non-parametric pairwise comparison models (see, for instance,\nChatterjee (2014); Braverman and Mossel (2008)).\nAcknowledgments\nThis work was partially supported by O\ufb03ce of Naval Research MURI grant N00014-11-1-0688, MURI\ngrant 96045-23800, and National Science Foundation Grants CIF-31712-23800, DMS-1107000 and\nCIF-81652-23800.\nThe work of N.S. was also partially supported by a Microsoft Research PhD\nfellowship.\nAppendix A. Proof of Theorem 1\nThe following two sections prove the lower and upper bounds (respectively) on the minimax risk of\nOrdinal model under the squared L semi-norm.\n20\nA.1 Lower bound\nOur lower bounds are based on the Fano argument, which is a standard method in minimax analysis\n(see for instance Tsybakov (2008)). Suppose that our goal is to bound the minimax risk of estimating\na parameter w over an indexed class of distributions P = {Pw | w \u2208W} in the square of a pseudo-\nmetric \u03c1. Consider a collection of vectors {w1, . . . , wM} contained within W such that\nmin\nj,k\u2208[M]\nj\u0338=k\n\u03c1\n\u0000wj, wk\u0001\n\u2265\u03b4\nand\n1\n\u0000M\n2\n\u0001\nX\nj,k\u2208[M]\nj\u0338=k\nDKL(Pwj\u2225Pwk) \u2264\u03b2.\nWe refer to any such subset as an (\u03b4, \u03b2)-packing set.\nLemma 6 (Pairwise Fano minimax lower bound) Suppose that we can construct a (\u03b4, \u03b2)-packing\nwith cardinality M. Then the minimax risk is lower bounded as\ninf\nbw\nsup\nw\u2217\u2208W\nE\nh\n\u03c1( bw, w\u2217)2i\n\u2265\u03b42\n2\n\u0010\n1 \u2212\u03b2 + log 2\nlog M\n\u0011\n.\n(13)\nIn order to apply Lemma 6, we need to a construct a suitable packing set.\nGiven a scalar\n\u03b1 \u2208(0, 1\n4) whose value will be speci\ufb01ed later, de\ufb01ne the integer\nM(\u03b1) : =\n\u0016\nexp\nnd\n2\n\u0000log 2 + 2\u03b1 log 2\u03b1 + (1 \u22122\u03b1) log(1 \u22122\u03b1)\n\u0001o\u0017\n.\n(14)\nWe require the following two auxiliary lemmas:\nLemma 7 For any \u03b1 \u2208(0, 1\n4), there exists a set of M(\u03b1) binary vectors {z1, . . . , zM(\u03b1)} \u2282{0, 1}d\nsuch that\n\u03b1d \u2264\u2225zj \u2212zk\u22252\n2 \u2264d\nfor all j \u0338= k \u2208[M(\u03b1)], and\n(15a)\n\u27e8e1, zj\u27e9= 0\nfor all j \u2208[M(\u03b1)],\n(15b)\nwhere e1 denotes the \ufb01rst canonical basis vector.\nThis result is a straightforward consequence of the Gilbert-Varshamov bound (Gilbert, 1952; Var-\nshamov, 1957).\nLemma 8 For any pair of quality score vectors wj and wk, and for\n\u03b6 : =\nmax\nx\u2208[0,2B/\u03c3] F \u2032(x)\nF(2B/\u03c3)(1 \u2212F(2B/\u03c3)),\nwe have\nDKL(Pwj\u2225Pwk) \u2264n\u03b6\n\u03c32 (wj \u2212wk)T L(wj \u2212wk).\n(16)\nWe prove this lemma at the end of this section.\nTaking these two lemmas as given for the moment, consider the set {z1, . . . , zM(\u03b1)} of d-dimensional\nbinary vectors given by Lemma 7.\nThe Laplacian L of the comparison graph is symmetric and\n21\npositive-semide\ufb01nite, and so has a diagonalization of the form L = U T \u039bU where U \u2208Rd\u00d7d is an\northonormal matrix, and \u039b is a diagonal matrix of nonnegative eigenvalues.\nLetting \u039b\u2020 denote the Moore-Penrose pseudo-inverse of \u039b, consider the collection {w1, . . . , wM(\u03b1)}\nof vectors given by wj : =\n\u03b4\n\u221a\ndU T \u221a\n\u039b\u2020zj for each j \u2208[M(\u03b1)].\nSince 1 \u2208nullspace(L), we are\nguaranteed that \u27e81, wj\u27e9=\n\u03b4\n\u221a\nd1T U T \u221a\n\u039b\u2020zj = 0. On the other hand,\n(wj \u2212wk)T L(wj \u2212wk) \u2264\u03b42\nd (zj \u2212zk)T \u221a\n\u039b\u2020ULUT \u221a\n\u039b\u2020(zj \u2212zk)\n= \u03b42\nd (zj \u2212zk)\n\u221a\n\u039b\u2020\u039b\n\u221a\n\u039b\u2020(zj \u2212zk)\n= \u03b42\nd \u2225zj \u2212zk\u22252\n2,\nHere the last step makes use of the fact that the \ufb01rst coordinate of each vector zj and zk is zero. It\nfollows that \u03b1\u03b42 \u2264\u2225wj \u2212wk\u22252\nL \u2264\u03b42.\nSetting \u03b42 : = 0.01 \u03c32d\nn\u03b6 , we \ufb01nd that\n\u2225wj\u2225\u221e\u2264\n\u03b4\n\u221a\nd\n\u2225\n\u221a\n\u039b\u2020zj\u22252\n(i)\n\u2264\n\u03b4\n\u221a\nd\nq\ntr(\u039b\u2020)\n(ii)\n=\n\u03b4\n\u221a\nd\nq\ntr(L\u2020)\n(iii)\n\u2264\nB,\nwhere inequality (i) follows from the fact that zj has entries in {0, 1}; equation (ii) follows since\nL\u2020 = U T \u039b\u2020U by de\ufb01nition; and inequality (iii) follows from our choice of \u03b4 and our assumption\nn \u2265c\u03c32tr(L\u2020)\n\u03b6B2\non the sample size with c = 0.01.\nWe have thus veri\ufb01ed that each vector wj also\nsatis\ufb01es the boundedness constraint \u2225wj\u2225\u221e\u2264B required for membership in WB. Finally, observe\nthat\nmax\nj\u0338=k DKL(Pwj\u2225Pwk) \u2264n\u03b6\u03b42\n\u03c32 ,\nand\nmin\nj\u0338=k \u2225wj \u2212wk\u22252\nL \u2265\u03b1\u03b42.\nWe have thus constructed a suitable packing set for applying Lemma 6, which yields the lower bound\nE[\u2225bw \u2212w\u2217\u22252\nL] \u2265\u03b1\n2 \u03b42n\n1 \u2212\n\u03b42\u03b6n\n\u03c32 + log 2\nlog M(\u03b1)\no\n.\nSubstituting our choice of \u03b4 and setting \u03b1 = 0.01 proves the claim for d > 9.\nIn order to handle the case d \u22649, we consider the set of the three d-length vectors given by\nz1 = [0\n\u00b7 \u00b7 \u00b7\n0\n\u22121], z2 = [0\n\u00b7 \u00b7 \u00b7\n0 1] and z3 = [0\n\u00b7 \u00b7 \u00b7\n0 0]. Construct the packing set {w1, w2, w3}\nfrom these three vectors {z1, z2, z3} as done above for the case of d > 9. From the calculations made\nfor the general case above, we have for all pairs minj\u0338=k \u2225wj\u2212wk\u22252\nL \u2265\u03b42\n9 and maxj,k \u2225wj\u2212wk\u22252\nL \u22644\u03b42,\nand as a result maxj,k DKL(Pwj\u2225Pwk) \u22644n\u03b6\u03b42\n\u03c32 . Choosing \u03b42 = \u03c32 log 2\n8n\u03b6\nand applying Lemma 6 proves\nthe theorem.\nThe only remaining detail is to prove Lemma 8.\nProof of Lemma 8:\nFor any pair of quality score vectors wj and wk, the KL divergence between\nthe distributions Pwj and Pwk is given by\nDKL(Pwj\u2225Pwk) =\nn\nX\ni=1\nF(\u27e8wj, xi\u27e9/\u03c3) log F(\u27e8wj, xi\u27e9/\u03c3)\nF(\u27e8wk, xi\u27e9/\u03c3) + (1 \u2212F(\u27e8wj, xi\u27e9/\u03c3)) log 1 \u2212F(\u27e8wj, xi\u27e9/\u03c3)\n1 \u2212F(\u27e8wk, xi\u27e9/\u03c3).\n22\nFor any a, b \u2208(0, 1), we have the elementary inequality a log a\nb \u2264(a \u2212b) a\nb . Applying this inequality\nto our expression above gives\nDKL(Pwj\u2225Pwk) \u2264\nn\nX\ni=1\n(F(\u27e8wj, xi\u27e9/\u03c3) \u2212F(\u27e8wk, xi\u27e9/\u03c3))F(\u27e8wj, xi\u27e9/\u03c3)\nF(\u27e8wk, xi\u27e9/\u03c3)\n\u2212\nn\nF(\u27e8wj, xi\u27e9/\u03c3)) \u2212F(\u27e8wk, xi\u27e9/\u03c3)\no1 \u2212F(\u27e8wj, xi\u27e9/\u03c3)\n1 \u2212F(\u27e8wk, xi\u27e9/\u03c3)\n\u2264\nn\nX\ni=1\n(F(\u27e8wj, xi\u27e9/\u03c3) \u2212F(\u27e8wk, xi\u27e9/\u03c3))2\nF(\u27e8wk, xi\u27e9/\u03c3)(1 \u2212F(\u27e8wk, xi\u27e9/\u03c3)).\nSince max{\u2225wj\u2225\u221e, \u2225wk\u2225\u221e} \u2264B, and since F is a non-decreasing function, we have\nDKL(Pwj\u2225Pwk) \u2264\nn\nX\ni=1\n(F(\u27e8wj, xi\u27e9/\u03c3) \u2212F(\u27e8wk, xi\u27e9/\u03c3))2\nF(2B/\u03c3)(1 \u2212F(2B/\u03c3))\n.\nFinally, applying the mean value theorem and recalling the de\ufb01nition of \u03b6 (from (6)) yields\nDKL(Pwj\u2225Pwk) \u2264\nn\nX\ni=1\n\u03b6(\u27e8wj, xi\u27e9/\u03c3 \u2212\u27e8wk, xi\u27e9/\u03c3)2 = n\u03b6\n\u03c32 (wj \u2212wk)T L(wj \u2212wk),\nas claimed.\nA.2 Upper bound\nFor the Ordinal model, the MLE is given by \u02c6w \u2208arg min\nw\u2208WB \u2113(w), where\n\u2113(w) = \u22121\nn\nn\nX\ni=1\nn\n1[yi = 1] log F\n\u0000\u27e8xi, w\u27e9\n\u03c3\n\u0001\n+ 1[yi = \u22121] log\n\u0010\n1 \u2212F\n\u0000\u27e8xi, w\u27e9\n\u03c3\n\u0001\u0011o\n,\nand\n(17a)\nWB : =\n\b\nw \u2208Rd | \u27e81, w\u27e9= 0,\nand\n\u2225w\u2225\u221e\u2264B\n\t\n.\n(17b)\nOur goal is to bound the estimation error of the MLE in the squared semi-norm \u2225v\u22252\nL = vT Lv.\nFor the purposes of this proof (as well as subsequent ones), let us state and prove an auxiliary\nlemma that applies more generally to M-estimators that are based on minimizing an arbitrary convex\nand di\ufb00erentiable function over some subset W of the set W\u221e: = {w \u2208Rd | \u27e81, w\u27e9= 0}. The MLE\nunder consideration here is a special case. This lemma requires that \u2113is di\ufb00erentiable and strongly\nconvex at w\u2217with respect to the semi-norm \u2225\u00b7 \u2225L, meaning that there is some constant \u03ba > 0 such\nthat\n\u2113(w\u2217+ \u2206) \u2212\u2113(w\u2217) \u2212\u27e8\u2207\u2113(w\u2217), \u2206\u27e9\u2265\u03ba\u2225\u2206\u22252\nL\n(18)\nfor all perturbations \u2206\u2208Rd such that (w\u2217+ \u2206) \u2208W. Finally, it is also convenient to introduce the\nsemi-norm \u2225u\u2225L\u2020 =\n\u221a\nuT L\u2020u, where L\u2020 is the Moore-Penrose pseudo-inverse of L.\nLemma 9 (Upper bound for M-estimators) Consider the M-estimator\nbw \u2208arg min\nw\u2208W \u2113(w),\nwhere W is any subset of W\u221e,\n(19)\nand \u2113is a di\ufb00erentiable cost function satisfying the \u03ba-strong convexity condition (18) at some w\u2217\u2208W.\nThen\n\u2225bw \u2212w\u2217\u2225L \u22641\n\u03ba\u2225\u2207\u2113(w\u2217)\u2225L\u2020.\n(20)\n23\nProof Since bw and w\u2217are optimal and feasible, respectively, for the original optimization problem,\nwe have \u2113( bw) \u2264\u2113(w\u2217). De\ufb01ning the error vector \u2206= bw \u2212w\u2217, adding and subtracting the quantity\n\u27e8\u2207\u2113(w\u2217), \u2206\u27e9yields the bound\n\u2113(w\u2217+ \u2206) \u2212\u2113(w\u2217) \u2212\u27e8\u2207\u2113(w\u2217), \u2206\u27e9\u2264\u2212\u27e8\u2207\u2113(w\u2217), \u2206\u27e9.\nBy the \u03ba-convexity condition, the left-hand side is lower bounded by \u03ba\u2225\u2206\u22252\nL.\nAs for the right-\nhand side, note that \u2206satis\ufb01es the constraint \u27e81, \u2206\u27e9= 0, and thus is orthogonal to the nullspace\nof the Laplacian matrix L. Therefore, by Lemma 16 (in Appendix F), we have |\u27e8\u2207\u2113(w\u2217), \u2206\u27e9| \u2264\n\u2225\u2207\u2113(w\u2217)\u2225L\u2020 \u2225\u2206\u2225L. Combining the pieces yields the claimed inequality (20).\nIn order to apply Lemma 9 to the MLE for the Ordinal model, we need to verify that the\nnegative log likelihood (17a) satis\ufb01es the strong convexity condition, and we need to bound the\nrandom variable \u2225\u2207\u2113(w\u2217)\u2225L\u2020 de\ufb01ned in the dual norm \u2225\u00b7 \u2225L\u2020.\nVerifying strong convexity:\nBy chain rule, the Hessian of \u2113is given by\n\u22072\u2113(w) =\n1\nn\u03c32\nn\nX\ni=1\nn\n1[yi = 1]Ti1 + 1[yi = \u22121]Ti2\no\nxixT\ni ,\nwhere\nTi1 : = F \u2032( \u27e8w, xi\u27e9\n\u03c3\n)2 \u2212F( \u27e8w, xi\u27e9\n\u03c3\n)F \u2032\u2032( \u27e8w, xi\u27e9\n\u03c3\n)\nF( \u27e8w, xi\u27e9\n\u03c3\n)2\n,\nand\nTi2 : = F \u2032( \u27e8w, xi\u27e9\n\u03c3\n)2 + (1 \u2212F( \u27e8w, xi\u27e9\n\u03c3\n))F \u2032\u2032( \u27e8w, xi\u27e9\n\u03c3\n)\n(1 \u2212F( \u27e8w, xi\u27e9\n\u03c3\n))2\n.\nObserve that the term Ti1 is simply the second derivative of log F evaluated at \u27e8w, xi\u27e9\n\u03c3\n, and hence the\nstrong log-concavity of F implies Ti1 \u2265\u03b3. On the other hand, the term Ti2 is the second derivative\nof log(1 \u2212F). Since F(\u2212x) = 1 \u2212F(x) for all x, it follows that the function x 7\u21921 \u2212F(x) is also\nstrongly log-concave with parameter \u03b3 and hence Ti2 \u2265\u03b3. Putting together the pieces, we conclude\nthat\nvT \u22072\u2113(w)v \u2265\n\u03b3\nn\u03c32 \u2225Xv\u22252\n2\nfor all v, w \u2208WB,\nwhere X \u2208Rn\u00d7d has the di\ufb00erencing vector xi \u2208Rd as its ith row.\nThus, if we introduce the error vector \u2206: = bw \u2212w\u2217, then we may conclude that\n\u2113(w\u2217+ \u2206) \u2212\u2113(w\u2217) \u2212\u27e8\u2207\u2113(w\u2217), \u2206\u27e9\u2265\n\u03b3\nn\u03c32 \u2225X\u2206\u22252\n2 =\n\u03b3\n\u03c32 \u2225\u2206\u22252\nL,\nshowing that \u2113is strongly convex around w\u2217with parameter \u03ba =\n\u03b3\n\u03c32 . An application of Lemma 9\nthen gives \u2225\u2206\u22252\nL \u2264\u03c34\n\u03b32 \u2225\u2207\u2113(w\u2217)\u22252\nL\u2020.\nBounding the dual norm:\nIn order to obtain a concrete bound, it remains to control the quantity\n\u2207\u2113(w\u2217)T L\u2020\u2207\u2113(w\u2217). Observe that the gradient takes the form\n\u2207\u2113(w\u2217) = \u22121\nn\u03c3\nn\nX\ni=1\n\u0002\n1[yi = 1]F \u2032(\u27e8w\u2217, xi\u27e9/\u03c3)\nF(\u27e8w\u2217, xi\u27e9/\u03c3) \u22121[yi = \u22121]\nF \u2032(\u27e8w\u2217, xi\u27e9/\u03c3)\n1 \u2212F(\u27e8w\u2217, xi\u27e9/\u03c3)\n\u0003\nxi.\nDe\ufb01ne a random vector V \u2208Rn with independent components as\nVi =\n( F \u2032(\u27e8w\u2217, xi\u27e9/\u03c3)\nF(\u27e8w\u2217, xi\u27e9/\u03c3)\nw.p.\nF(\u27e8w\u2217, xi\u27e9/\u03c3)\n\u2212F \u2032(\u27e8w\u2217, xi\u27e9/\u03c3)\n1\u2212F(\u27e8w\u2217, xi\u27e9/\u03c3)\nw.p.\n1 \u2212F(\u27e8w\u2217, xi\u27e9/\u03c3).\n24\nWith this notation, we have \u2207\u2113(w\u2217) = \u22121\nn\u03c3 XT V . One can verify that E[V ] = 0 and\n|Vi| \u2264\nsup\nz\u2208[\u22122B/\u03c3,2B/\u03c3]\nmax\nnF \u2032(z)\nF(z) ,\nF \u2032(z)\n1 \u2212F(z)\no\n\u2264\nsup\nz\u2208[\u22122B/\u03c3,2B/\u03c3]\nF \u2032(z)\nF(z)(1 \u2212F(z)) \u2264\u03b6,\n(21)\nwhere \u03b6 is as de\ufb01ned in (6). De\ufb01ning the n-dimensional square matrix M : =\n\u03c32\n\u03b32n2 XL\u2020XT , our\nde\ufb01nitions and previous bounds imply that \u2225\u2206\u22252\nL \u2264V T MV .\nConsequently, our problem has been reduced to controlling the \ufb02uctuations of the quadratic form\nV T MV ; in order to do so, we apply the Hanson-Wright inequality (see Lemma 13 in Appendix E).\nA straightforward calculation yields\n|||M|||2\nfro = (d \u22121) \u03c34\n\u03b34n2\nand\n|||M|||op = \u03c32\n\u03b32n,\nwhere we have used the fact that L = 1\nnXT X. Moreover, since the components of V are independent\nand of zero mean, a straightforward calculation yields that E[V T MV ] \u2264E[\u2225V \u22252\n\u221etr(M)] \u2264\u03b62\u03c32d\n\u03b32n .\nSince |Vi| \u2264\u03b6, the variables are \u03b6-sub-Gaussian, and hence the Hanson-Wright inequality implies\nthat\nP\nh\nV T MV \u2212\u03b62\u03c32d\n\u03b32n\n> t\ni\n\u22642exp\n\u0000\u2212c min{\nt2\u03b34n2\n\u03b64(d \u22121)\u03c34 , t\u03b32n\n\u03b62\u03c32 }\n\u0001\nfor all t > 0.\nConsequently, after some simple algebra, we conclude that\nP\n\u0010\n\u2225\u2206\u22252\nL > tc\u03b62\u03c32\n\u03b32\nd\nn\n\u0011\n\u2264e\u2212t\nfor all t \u22651,\nfor some universal constant c. Integrating this tail bound yields the bound on the expectation.\nAppendix B. Proof of Theorem 2\nThe following two sections prove the upper and lower bounds (respectively) on the minimax risk in the\nsquared Euclidean norm for Ordinal model. We prove the lower bound in two parts corresponding\nto the two components of the \u201cmax\u201d in the statement of the theorem.\nB.1 Upper bound\nThe proof of the upper bound under the Euclidean norm follows directly from the upper bound\nunder the L semi-norm proved in Theorem 1. From the setting described in Section 2, we have that\nthe nullspace of the matrix L is given by the span of the all ones vector. Furthermore, we have\n\u27e8w\u2217\u2212bw, 1\u27e9= 0, and \u2225w\u2217\u2212bw\u22252\nL \u2265\u03bb2(L)\u2225w\u2217\u2212bw\u22252\n2. Substituting this inequality into the upper\nbound (7b) gives the desired result.\nB.2 Lower bound: Part I\nSince the Laplacian L of the comparison graph is symmetric and positive-semide\ufb01nite. By diagonal-\nization, we can write L = U T \u039bU where U \u2208Rd\u00d7d is an orthonormal matrix, and \u039b is a diagonal\nmatrix of nonnegative eigenvalues with \u039bjj = \u03bbj(L).\nWe \ufb01rst use the Fano method (Lemma 6) to prove that the minimax risk is lower bounded\nas c\u03c32 d2\nn .\nFor scalars \u03b1 \u2208(0, 1\n4) and \u03b4 > 0 whose values will be speci\ufb01ed later, recall the set\n{z1, . . . , zM(\u03b1)} of vectors in the Boolean hypercube {0, 1}d given by Lemma 7. We then de\ufb01ne a\n25\nsecond set {wj, j \u2208[M(\u03b1)]} via wj : =\n\u03b4\n\u221a\ndU T Pzj, where P is a permutation matrix to be speci\ufb01ed\nmomentarily. At this point, the only constraint imposed on P is that it keeps the \ufb01rst coordinate\nconstant. By construction, for each j \u0338= k, we have \u2225wj \u2212wk\u22252\n2 = \u03b42\nd \u2225zj \u2212zk\u22252\n2 \u2265\u03b1\u03b42, where the\n\ufb01nal inequality follows from the fact that the set {z1, . . . , zM(\u03b1)} comprises binary vectors with a\nminimum Hamming distance at least \u03b1d.\nConsider any distinct j, k \u2208[M(\u03b1)]. Then, for some {i1, . . . , ir} \u2286{2, . . . , d} with \u03b1d \u2264r \u2264d, it\nmust be that\n\u2225wj \u2212wk\u22252\nL = \u03b42\nd \u2225U T Pzj \u2212U T Pzk\u22252\nL = \u03b42\nd \u2225zj \u2212zk\u22252\n\u039b = \u03b42\nd\nr\nX\nm=1\n\u03bbim(L).\nIt follows that for some non-negative numbers a2, . . . , ad such that \u03b1d \u2264Pd\ni=2 ai \u2264d,\n1\n\u0000M(\u03b1)\n2\n\u0001\nX\nj\u0338=k\n\u2225wj \u2212wk\u22252\nL = \u03b42\nd\nd\nX\ni=2\nai\u03bbi(L).\nWe choose the permutation matrix P such that the last (d \u22121) coordinates are permuted to have\na2 \u2265\u00b7 \u00b7 \u00b7 \u2265ad and the dth coordinate remains \ufb01xed. With this choice, we get\n1\n\u0000M(\u03b1)\n2\n\u0001\nX\nj\u0338=k\n\u2225wj \u2212wk\u22252\nL \u2264\u03b42\nd\nd\nd \u22121tr(L) \u22642\u03b42\nd tr(L).\nLemma (14) (Appendix F) gives the trace constraint tr(L) = 2, which in turn guarantees that\n1\n(M(\u03b1)\n2 )\nP\nj\u0338=k \u2225wj \u2212wk\u22252\nL \u22644\u03b42\nd . For the choice of P speci\ufb01ed above, we have for every j \u2208[M(\u03b1)],\n\u27e81, wj\u27e9=\n\u03b4\n\u221a\nd\neT\n1 Pzj = eT\n1 zj = 0,\nwhere the \ufb01nal equation employed the property (15b).\nSetting \u03b42 = 0.01 \u03c32d2\n4n\u03b6 , we have \u2225wj\u2225\u221e\u2264\n\u03b4\n\u221a\nd\u2225zj\u22252\n(i)\n\u2264\u03b4\n(ii)\n\u2264B, where inequality (i) follows from\nthe fact that zj has entries in {0, 1}; inequality (ii) follows from our choice of \u03b4 and our assumption\nn \u2265c\u03c32tr(L\u2020)\n\u03b6B2\non the sample size with c = 0.002, where Lemma 14 guarantees n \u2265c\u03c32d2\n4\u03b6B2 . We have\nthus veri\ufb01ed that each vector wj also satis\ufb01es the boundedness constraint \u2225wj\u2225\u221e\u2264B required for\nmembership in WB.\nFrom the proof of Theorem 1, we have that for any distinct DKL(Pwj\u2225Pwk) \u2264n\u03b6\n\u03c32 \u2225wj \u2212wk\u22252\nL, and\nhence\n1\n\u0000M(\u03b1)\n2\n\u0001\nX\nj\u0338=k\nDKL(Pwj\u2225Pwk) \u2264n\u03b6\n\u03c32\n4\u03b42\nd\n= 0.01 d,\nwhere we have substituted our previous choice of \u03b4.\nApplying Lemma 6 with the packing set {w1, . . . , wM(\u03b1)} gives\nMn\n\u0000\u03b8(P); \u03c1\n\u0001\n\u2265\u03b1\u03b42\n2\n\u00001 \u22120.01d + log 2\nlog M(\u03b1)\n\u0001\n.\nSubstituting our choice of\u03b4 and setting \u03b1 = 0.01 proves the claim for d > 9.\nFor the case of d \u22649, consider the set of the three d-length vectors z1 = [0\n\u00b7 \u00b7 \u00b7\n0\n\u22121],\nz2 = [0\n\u00b7 \u00b7 \u00b7\n0 1] and z3 = [0\n\u00b7 \u00b7 \u00b7\n0 0]. Construct the packing set {w1, w2, w3} from these three\nvectors {z1, z2, z3} as done above for the case of d > 9. From the calculations made for the general\ncase above, we have for all pairs minj\u0338=k \u2225wj \u2212wk\u22252\n2 \u2265\u03b42\n9 and maxj,k \u2225wj \u2212wk\u22252\nL \u22644\u03b42, and as a\nresult maxj,k DKL(Pwj\u2225Pwk) \u22644n\u03b6\u03b42\n\u03c32 . Choosing \u03b42 = \u03c32 log 2\n8n\u03b6\nand applying Lemma 6 yields the claim.\n26\nB.3 Lower bound: Part II\nGiven an integer d\u2032 \u2208{2, . . . , d}, and scalars \u03b1 \u2208(0, 1\n4) and \u03b4 > 0, de\ufb01ne the integer\nM\u2032(\u03b1) : =\n\u0016\nexp\nnd\u2032\n2\n\u0000log 2 + 2\u03b1 log 2\u03b1 + (1 \u22122\u03b1) log(1 \u22122\u03b1)\n\u0001o\u0017\n.\n(22)\nApplying Lemma 7 with d\u2032 as the dimension yields a subset {z1, . . . , zM\u2032(\u03b1)} of the Boolean hypercube\n{0, 1}d\u2032 with the stated properties. We then de\ufb01ne a set of d-length vectors { ew1, . . . , ewM\u2032(\u03b1)} via\newj = [0 (zj)T 0 \u00b7 \u00b7 \u00b7 0]T\nfor each j \u2208[M(\u03b1)].\nFor each j \u2208[M(\u03b1)], let us de\ufb01ne wj : =\n\u03b4\n\u221a\nd\u2032 U T \u221a\n\u039b\u2020 ewj.\nNow, letting e1 \u2208Rd denote the \ufb01rst\nstandard basis vector, we have \u27e81, wj\u27e9=\n\u03b4\n\u221a\nd\u2032 1T U T \u221a\n\u039b\u2020 ewj\n= 0. where we have used the fact that\n1 \u2208nullspace(L). Furthermore, for any j \u0338= k, we have\n\u2225wj \u2212wk\u22252\n2 = \u03b42\nd\u2032 ( ewj \u2212ewk)T \u039b\u2020( ewj \u2212ewk) \u2265\u03b42\nd\u2032\nd\u2032\nX\ni=\u230a(1\u2212\u03b1)d\u2032\u230b\n1\n\u03bbi\n.\nThus, setting \u03b42 = 0.01\u03c32d\u2032\nn\u03b6\nyields\n\u2225wj\u2225\u221e\u2264\n\u03b4\n\u221a\nd\u2032 \u2225\n\u221a\n\u039b\u2020 ewj\u22252\n(i)\n\u2264\n\u03b4\n\u221a\nd\u2032\nq\ntr(\u039b\u2020)\n(ii)\n=\n\u03b4\n\u221a\nd\u2032\nq\ntr(L\u2020)\n(iii)\n\u2264\nB,\nwhere inequality (i) follows from the fact that zj has entries in {0, 1}; step (ii) follows because the\nmatrices\n\u221a\n\u039b\u2020 and\n\u221a\nL\u2020 have the same eigenvalues; and inequality (iii) follows from our choice of \u03b4\nand our assumption n \u2265c\u03c32tr(L\u2020)\n\u03b6B2\non the sample size with c = 0.01. We have thus veri\ufb01ed that each\nvector wj also satis\ufb01es the boundedness constraint \u2225wj\u2225\u221e\u2264B required for membership in WB.\nFurthermore, for any pair of distinct vectors in this set, we have\n\u2225wj \u2212wk\u22252\nL = \u03b42\nd\u2032 \u2225zj \u2212zk\u22252\n2 \u2264\u03b42.\nFrom the proof of Theorem 1, we DKL(Pwj\u2225Pwk) \u2264n\u03b6\n\u03c32 \u2225wj \u2212wk\u22252\nL \u22640.01d\u2032. Applying Lemma 6 with\nthe packing set {w1, . . . , wM(\u03b1)} gives\nMn\n\u0000w(P); \u2225\u00b7 \u22252\n2\n\u0001\n\u2265\u03b1\u03b42\n2\n\u00001 \u22120.01 + log 2\nlog M\u2032(\u03b1)\n\u0001\n.\nSubstituting our choice of \u03b4 and setting \u03b1 = 0.01 proves the claim for d\u2032 > 9.\nFor the case of d\u2032 \u22649, we will show a lower bound of c\u03c32\nn\n9\n\u03bb2(L) for a universal constant c > 0. This\nquantity is at least as large as the claimed lower bound. Consider the packing set of three d-length\nvectors w1 = \u03b4U\n\u221a\n\u039b\u2020[0 1 0\n\u00b7 \u00b7 \u00b7\n0]T , w2 = \u2212w1 and w3 = [0\n\u00b7 \u00b7 \u00b7\n0]T for some \u03b4 > 0. Then for\nevery j \u0338= k, one can verify that \u2225wj \u2212wk\u22252\nL \u22644\u03b42, \u2225wj \u2212wk\u22252\n2 \u2265\n\u03b42\n\u03bb2(L). Choosing \u03b42 = \u03c32 log 2\n8n\u03b6\nand\napplying Lemma 6 proves the claim for d\u2032 \u22649.\nFinally, taking the maximum over all values of d\u2032 \u2208{2, . . . , d} gives the claimed lower bound.\nAppendix C. Proof of Theorem 3\nWe now turn to the proof of Theorem 3 on the minimax rate for the Paired Cardinal model. Recall\nthat this observation model takes the standard linear model, y = Xw\u2217+ \u03f5, where y \u2208Rn, w \u2208Rd\nand \u03f5 \u223cN(0, \u03c32I).\n27\nC.1 Upper bound under the squared L semi-norm\nThe maximum likelihood estimate in the Paired Cardinal model is a special case of the general\nM-estimator (19) with \u2113(w) : =\n1\n2n\nPn\ni=1\n\u0000yi \u2212\u27e8xi, w\u27e9\n\u00012. For this quadratic objective function, it is\neasy to verify that the \u03b3-convexity condition holds with \u03b3 = 1. (In particular, note that the Hessian\nof \u2113is given by L = XT X/n.)\nGiven the result of Lemma 9, it remains to upper bound \u2225\u2207\u2113(w\u2217)\u2225L\u2020. A straightforward com-\nputation yields \u2225\u2207\u2113(w\u2217)\u22252\nL\u2020 = \u03b5\n\u03c3\nT Q \u03b5\n\u03c3 where Q : = \u03c32\nn2 XL\u2020XT . Consequently, the random variable\n\u2225\u2207\u2113(w\u2217)\u22252\nL\u2020is quadratic form in the standard Gaussian random vector \u03b5\n\u03c3. An application of Lemma 15\n(Appendix F) gives tr(Q) = \u03c32\nn\n\u0000d \u22121\n\u0001\nand |||Q|||op = \u03c32\nn , and then applying a known tail bound on\nGaussian quadratic forms (see Lemma 12 in Appendix E) yields\nP\n\"\n\u2225\u2207\u2113(w\u2217)\u22252\nL\u2020\n\u03c32\n\u2265\n\u0010r\nd\nn +\n\u03b4\n\u221an\n\u00112\n#\n\u2264e\u2212\u03b42\n2\nfor all \u03b4 \u22650.\nSince d \u22652, we have\n\u0000\u03c3\nq\nd\nn +\n\u03c3\n\u221an\u03b4\n\u00012 \u22642\u03c32d\u03b42\nn\nfor all \u03b4 \u22654, which yields\nP\nh\n\u2225\u2207\u2113(w\u2217)\u22252\nL\u2020 \u2265t 4\u03c32d\nn\ni\n\u2264e\u2212t\nfor all t \u22658.\nIntegrating this tail bound yields that E\nh\n\u2225\u2207\u2113(w\u2217)\u22252\nL\u2020\ni\n\u2264c\u03c32 d\nn, from which the claim follows.\nC.2 Lower bound under the squared L semi-norm\nBased on the pairwise Fano lower bound previously stated in Lemma 6, we need to construct a\nsuitable (\u03b4, \u03b2)-packing, where the semi-norm \u03c1(wj, wk) = \u2225wj \u2212wk\u2225L is de\ufb01ned by the Laplacian.\nGiven the additive Gaussian noise observation model, we also have\nDKL(Pwj\u2225Pwk) =\nn\n2\u03c32 \u2225wj \u2212wk\u22252\nL,\n(23)\nThe construction of the packing and the remainder of the proof proceeds in a manner identical to\nthe proof of the lower bound in Theorem 1, except for the absence of the requirement of \u2225wj\u2225\u221e\u2264B\non the elements {wj} of the packing set.\nC.3 Upper bound under the squared Euclidean norm\nThe upper bound follows by direct analysis of the (unconstrained) least-squares estimate, which has\nthe explicit form bw = 1\nnL\u2020XT y, and thus\nE\u2225bw \u2212w\u2217\u22252\n2 = E\u22251\nnL\u2020XT \u03f5\u22252\n2 = \u03c32tr( 1\nn2 L\u2020XT XL\u2020)\nwhere we have used the fact that \u03f5 \u223cN(0, \u03c32In). Since L = XT X/n by de\ufb01nition, we conclude that\nE\u2225bw \u2212w\u2217\u22252\n2 = \u03c32tr(L\u2020)\nn\nas claimed.\nC.4 Lower bound under the squared Euclidean norm\nWe obtain the lower bound by computing the Bayes risk with respect to a suitably de\ufb01ned (proper)\nprior distribution over the weight vector w\u2217. In particular, if we impose the prior w\u2217\u223cN(0, \u03c32\nn L\u2020),\nBayes\u2019 rule then leads to the posterior distribution\nP\n\u0000w | y; X\n\u0001\n\u221dexp\n\u0012 \u22121\n2\u03c32 \u2225y \u2212Xw\u22252\n2\n\u0013\nexp\n\u0012 \u2212n\n2\u03c32 wT Lw\n\u0013\n1{\u27e8w, 1\u27e9= 0}.\n28\nThus conditioned on y, w is distributed as N\n\u0010\n(XT X + nL)\u22121XT y, \u03c32\n2 L\u2020\u0011\n. By applying iterated\nexpectations, the Bayes risk is given by E\u2225w \u22121\n2L\u2020XT y\u22252\n2 = \u03c32\n2 tr(L\u2020), which completes the proof.\nAppendix D. Proof of Theorem 4\nThis section presents the proof of Theorem 4 for the setting of m-wise comparisons. We \ufb01rst state\nsome simple properties of the model introduced in Section 3.3, which we will use subsequently in the\nproofs of the results.\nLemma 10 The Laplacian of the underlying pairwise-comparison graph satis\ufb01es the trace constraints\nnullspace(L) = 1, \u03bb2(L) > 0 and tr(L) = m(m \u22121).\nLemma 11 For any j \u2208[m], i \u2208[n] and any vector v \u2208Rm, we have\n\u03bb2(H)\nm\nvT (mI \u221211T )v \u2264vT RjHRT\nj v \u2264\u03bbmax(H)\nm\nvT (mI \u221211T )v.\nSee Section D.2 for the proof of these auxiliary lemmas.\nD.1 Upper bound under the squared L semi-norm\nWe prove this upper bound by applying Lemma 9. In this case, the rescaled negative log likelihood\ntakes the form\n\u2113(w) = \u22121\nn\nn\nX\ni=1\nm\nX\nj=1\n1[yi = j] log F\n\u0000wT EiRj\n\u0001\n,\nand the MLE is obtained by constrained minimization over the set WB : =\n\b\nw \u2208Rd | \u27e81, w\u27e9=\n0,\nand\n\u2225w\u2225\u221e\u2264B\n\t\n. As in our proof of the upper bound in Theorem 1, we need to verify the\n\u03ba-strong convexity condition, and to control the dual norm \u2225\u2207\u2113(w\u2217)\u2225L\u2020.\nVerifying strong convexity:\nThe gradient of the negative log likelihood is\n\u2207\u2113(w) = \u22121\nn\nn\nX\ni=1\nm\nX\nj=1\n1[yi = j]EiRj\u2207log F(v)\n\f\f\nv=wT EiRj.\nThe Hessian of the negative log likelihood can be written as\n\u22072\u2113(w) = 1\nn\nn\nX\ni=1\nm\nX\nj=1\n1[yi = j]EiRj\u22072 log F(v)\n\f\f\nv=wT EiRjRT\nj ET\ni .\nUsing our strongly log-concave assumption on F, we have that for any vector z \u2208Rd,\nzT \u22072\u2113(w)z = \u22121\nn\nn\nX\ni=1\nm\nX\nj=1\n1[yi = j]zT EiRj\u22072 log F(v)\n\f\f\nv=wT EiRjRT\nj ET\ni z\n\u22651\nn\nn\nX\ni=1\nm\nX\nj=1\n1[yi = j]zT EiRjHRT\nj ET\ni z\n\u2265\u03bb2(H)\nm\n1\nn\nn\nX\ni=1\nm\nX\nj=1\n1[yi = j]zT Ei(mI \u221211T )ET\ni z,\n29\nwhere the last step follows from Lemma 11. The de\ufb01nition (10) of L implies that\nzT \u22072\u2113(w)z \u2265\u03bb2(H)\nm\nzT Lz = \u03bb2(H)\nm\n\u2225z\u22252\nL.\nConsequently, the \u03ba-convexity condition holds around w\u2217with \u03ba = \u03bb2(H)\nm\n. An application of Lemma 9\nthen yields\n\u2225bwML \u2212w\u2217\u22252\nL \u2264\nm2\n\u03bb2(H)2 \u2225\u2207\u2113(w\u2217)\u22252\nL\u2020 =\nm2\n\u03bb2(H)2 \u2207\u2113(w\u2217)T L\u2020\u2207\u2113(w\u2217).\n(24)\nControlling the dual norm:\nThe gradient of the negative log likelihood can then be rewritten\nas \u2207\u2113(w\u2217) = \u22121\nn\nPn\ni=1 EiVi, where each index i \u2208[n], the random vector vector Vi \u2208Rm is given\nby Vi : = Pm\nj=1 1[yi = j] Rj \u2207log F(\u27e8w\u2217, Ei\u27e9Rj). Now observe that the matrix M : = I \u22121\nm11T is\nsymmetric and positive semi-de\ufb01nite with rank (m\u22121), eigenvalues {1, . . . , 1, 0}, its nullspace equals\nthe span of the all-ones vector, and that M\u2020 = M. Using this matrix, we de\ufb01ne the transformed\nvector eVi : = (M\u2020)\n1\n2 Vi for each i \u2208[n].\nConsider a vector x and its shifted version x + t1, where t \u2208R and 1 denotes the vector of all\nones. By the shift invariance property, the function g(t) = F(x + t1) \u2212F(x) is constant, and hence\ng\u2032(0) = \u27e8\u2207F(x), 1\u27e9= 0,\nand\ng\u2032\u2032(0) = \u27e81,\n\u0000\u22072F(x)\n\u0001\n1\u27e9= 0,\n(25)\nwhich implies that 1 \u2208nullspace(\u22072F(x)). Furthermore, we have \u27e8\u2207log F(x), 1\u27e9=\n1\nF(x)\u27e8\u2207F(x), 1\u27e9=\n0. Consequently, \u27e8Vi, 1\u27e9= 0 = \u27e8Vi, nullspace(M)\u27e9. This allows us to write\n\u2207\u2113(w\u2217) = \u22121\nn\nn\nX\ni=1\nEiM\n1\n2 eVi,\nand\n\u2207\u2113(w\u2217)T L\u2020\u2207\u2113(w\u2217) = 1\nn2\nn\nX\ni=1\nn\nX\n\u2113=1\neV T\ni M\n1\n2 ET\ni L\u2020E\u2113M\n1\n2 eV\u2113.\nBy de\ufb01nition, for every pair i \u0338= \u2113\u2208[n], eVi is independent of eV\u2113. Moreover, for every i \u2208[n],\nE[eVi] = E[(M\u2020)\n1\n2\nm\nX\nj=1\n1[yi = j]Rj\u2207log F(v)\n\f\f\nv=(w\u2217)T EiRj]\n= (M\u2020)\n1\n2\nm\nX\nj=1\nF((w\u2217)T EiRj)Rj\u2207log F(v)\n\f\f\nv=(w\u2217)T EiRj\n= (M\u2020)\n1\n2\nm\nX\nj=1\nRj\u2207F(v)\n\f\f\nv=(w\u2217)T EiRj.\nIn order to further evaluate this expression, de\ufb01ne a function g : Rm \u2192R as g(z) = Pm\nj=1 F(zT Rj).\nThen by de\ufb01nition we have g(z) = 1. Taking derivatives, we get 0 = \u2207g(z) = Pm\nj=1 Rj\u2207F(zT Rj).\nIt follows that E[eVi] = 0, and hence that\nE[\u2207\u2113(w\u2217)T L\u2020\u2207\u2113(w\u2217)] = 1\nn2 E[\nn\nX\ni=1\nn\nX\n\u2113=1\neV T\ni M\n1\n2 ET\ni L\u2020E\u2113M\n1\n2 eV\u2113]\n= 1\nn2 E[\nn\nX\ni=1\neV T\ni M\n1\n2 ET\ni L\u2020EiM\n1\n2 eVi]\n\u22641\nnE[sup\n\u2113\u2208[n]\n\u2225eV\u2113\u22252\n2]tr( 1\nn\nn\nX\ni=1\nM\n1\n2 ET\ni L\u2020EiM\n1\n2 ).\n30\nSince L = m\nn\nPn\ni=1 EiMET\ni , we have tr( 1\nn\nPn\ni=1 M\n1\n2 ET\ni L\u2020EiM\n1\n2 ) = d\u22121\nm , as well as\n\u2225eV\u2113\u22252\n2 =\nm\nX\nj=1\n1[yi = j](\u2207log F(v)\n\f\f\nv=(w\u2217)T EiRj)T RT\nj MRj\u2207log F(v)\n\f\f\nv=(w\u2217)T EiRj.\nRecalling the previously de\ufb01ned matrix M, observe that since Rj is simply a permutation matrix, we\nhave RT\nj MRj = M for every j \u2208[m]. By chain rule, we have \u27e8\u2207log F(v), 1\u27e9=\n1\nF(v)\u27e8\u2207F(v), 1\u27e9= 0,\nwhere the last step follows from our previous calculation. It follows that\nE\n\u0002\n\u27e8\u2207\u2113(w\u2217), L\u2020\u2207\u2113(w\u2217)\u27e9\n\u0003\n\u2264d\nn\nsup\nv\u2208[\u2212B,B]m \u2225\u2207log F(v)\u22252\n2.\nSubstituting this bound into equation (24) yields the claim.\nD.1.1 Lower bound under the squared L semi-norm\nFor any pair of quality score vectors wj and wk, the KL divergence between the distributions Pwj\nand Pwk is given by\nDKL(Pwj\u2225Pwk) =\nn\nX\ni=1\nm\nX\nl=1\nF(wjT EiRl) log F(wjT EiRl)\nF(wkT EiRl)\n.\nApplying the inequality log x \u2264x \u22121, valid for x > 0, we \ufb01nd that\nDKL(Pwj\u2225Pwk) \u2264\nn\nX\ni=1\nm\nX\nl=1\nF(wjT EiRl)\n\u0010F(wjT EiRl)\nF(wkT EiRl)\n\u22121\n\u0011\n.\nNow employing the fact that Pm\nl=1 F(wjT EiRl) = Pm\nl=1 F(wkT EiRl) = 1 gives\nDKL(Pwj\u2225Pwk) \u2264\nn\nX\ni=1\nm\nX\nl=1\n\u0010F(wjT EiRl)2\nF(wkT EiRl)\n\u22122F(wjT EiRl) + F(wkT EiRl)\n\u0011\n.\n=\nn\nX\ni=1\nm\nX\nl=1\n(F(wjT EiRl) \u2212F(wkT EiRl))2\nF(wkT EiRl)\n\u2264\n1\nF(\u2212B, B, . . . , B)\nn\nX\ni=1\nm\nX\nl=1\n(F(wjT EiRl) \u2212F(wkT EiRl))2\n\u2264\n1\nF(\u2212B, B, . . . , B)\nn\nX\ni=1\nm\nX\nl=1\n(\u27e8\u2207F(zil), wjT EiRl \u2212wkT EiRl\u27e9)2,\nfor some zil \u2208[\u2212B, B]m. Letting \u03b6 =\nsupz\u2208[\u2212B,B]m \u2225\u2207F(z)\u22252\nH\u2020\nF(\u2212B,B,...,B)\nand applying Lemma 16 (noting that\n\u27e8wjT EiRl, nullspace(H)\u27e9= 0 for all i, j, l) gives\nDKL(Pwj\u2225Pwk) \u2264\nn\nX\ni=1\nm\nX\nl=1\n\u03b6\u2225wjT EiRl \u2212wkT EiRl\u22252\nH\n\u2264\u03b6(wj \u2212wk)T \u0010\nn\nX\ni=1\nm\nX\nl=1\nEiRlHRT\nl ET\ni\n\u0011\n(wj \u2212wk)\n\u2264\u03b6\u03bbm(H)n\u2225wj \u2212wk\u22252\nL,\n(26)\n31\nwhere the \ufb01nal step is a result of Lemma 11.\nConsider the pair of scalars \u03b1 \u2208(0, 1\n4) and \u03b4 > 0 whose values will be speci\ufb01ed later. Let M(\u03b1)\nbe as de\ufb01ned in (14). Consider the packing set {w1, . . . , wM(\u03b1)} constructed in Appendix A.1. Each\nof these vectors is of length d, satis\ufb01es \u27e8wj, 1\u27e9= 0, and furthermore, each pair from this set satis\ufb01es\n\u03b1\u03b42 \u2264\u2225wj \u2212wk\u22252\nL \u2264\u03b42. Setting \u03b42 = 0.01\nd\nn\u03b6\u03bbm(H) yields\nDKL(Pwj\u2225Pwk) \u22640.01d.\nEvery element from the packing set also satis\ufb01es \u2225wj\u2225\u221e\u2264B when n \u22650.01\u03c32tr(L\u2020)\n\u03b6B2\u03bbm(H) , and thus belongs\nto the class WB.\nApplying Lemma 6 yields the lower bound\n\u2225bw \u2212w\u2217\u22252\nL \u2265\u03b1\n2 0.01\nd\nn\u03b6\u03bbm(H)\nn\n1 \u22120.01d + log 2\nlog M(\u03b1)\no\n.\nSetting \u03b1 = 0.01 proves the claim for d > 9.\nFor the case of d \u22649, consider the set of the three d-length vectors z1 = [0\n\u00b7 \u00b7 \u00b7\n0\n\u22121],\nz2 = [0\n\u00b7 \u00b7 \u00b7\n0 1] and z3 = [0\n\u00b7 \u00b7 \u00b7\n0 0]. Construct the packing set {w1, w2, w3} from these three\nvectors {z1, z2, z3} as done above for the case of d > 9. From the calculations made for the general\ncase above, we have for all pairs minj\u0338=k \u2225wj \u2212wk\u22252\nL \u2265\u03b42\n9 and maxj,k \u2225wj \u2212wk\u22252\nL \u22644\u03b42, and as a\nresult maxj,k DKL(Pwj\u2225Pwk) \u22644n\u03b6\u03bbm(H)\u03b42. Choosing \u03b42 =\nlog 2\n8n\u03b6\u03bbm(H) and applying Lemma 6 proves\nthe claim.\nD.1.2 Upper bound under the squared Euclidean norm\nThe upper bound under the squared \u21132-norm follows directly from the upper bound under the squared\nL semi-norm in Theorem 4: noting that (w\u2217\u2212bw) \u22a5nullspace(L), we get that\n(w\u2217\u2212bw)T L(w\u2217\u2212bw) \u2265\u03bb2(L)\u2225w\u2217\u2212bw\u22252\n2.\nSubstituting this inequality in the upper bound on the minimax risk under the squared L semi-norm\nin Theorem 4 gives the desired result.\nD.1.3 Lower bound under the squared Euclidean norm\nDe\ufb01ne \u03b6 =\nsupz\u2208[\u2212B,B]m \u2225\u2207F(z)\u22252\nH\u2020\nF(\u2212B,B,...,B)\n.\nEquation (26) in Appendix D.1.1 shows that for any vectors\nwj, wk \u2208WB,\nDKL(Pwj\u2225Pwk) \u2264\u03b6\u03bbm(H)n\u2225wj \u2212wk\u22252\nL,\nConsider the pair of scalars \u03b1 \u2208(0, 1\n4) and \u03b4 > 0 whose values will be speci\ufb01ed later. Let M(\u03b1) be\nas de\ufb01ned in (14). In Appendix B.2 we constructed a set {w1, . . . , wM(\u03b1)} of vectors of length d that\nsatisfy \u27e8wj, 1\u27e9= 0 for every j \u2208[M(\u03b1)], and for every pair of vectors in this set, \u2225wj \u2212wk\u22252\n2 \u2265\u03b1\u03b42\nand\n1\n(M(\u03b1)\n2 )\nP\nj\u0338=k \u2225ewj \u2212ewk\u22252\nL \u22642\u03b42\nd tr(L). Applying Lemma 10 gives\n1\n\u0000M(\u03b1)\n2\n\u0001\nX\nj\u0338=k\n\u2225ewj \u2212ewk\u22252\nL \u22642\u03b42\nd m(m \u22121).\nSetting \u03b42 = 0.005\nd2\nn\u03b6\u03bbm(H)m(m\u22121) yields\nDKL(Pwj\u2225Pwk) \u22640.01d.\n32\nIn a manner similar to Lemma 14 in the pairwise comparison case, one can show that in the general\nsetting of this section, tr(L\u2020) \u2265\nd2\n4m(m\u22121). Then, every element from the packing set also satis\ufb01es\n\u2225wj\u2225\u221e\u2264B when \u03b4 \u2264B, which holds true under our assumption of n \u2265\nc\u03c32tr(L\u2020)\n\u03b6B2\u03bbm(H) \u2265\nc\u03c32d2\n4m(m\u22121)\u03b6B2\u03bbm(H)\nwith c = 0.01. Each element of our packing set thus belongs to the class WB. Applying Lemma 6\nyields the lower bound\n\u2225bw \u2212w\u2217\u22252\nL \u2265\u03b1\n2 0.01\nd2\nn\u03b6\u03bbm(H)m(m \u22121)\nn\n1 \u22120.01d + log 2\nlog M(\u03b1)\no\n.\nSetting \u03b1 = 0.01 proves the claim for d > 9.\nFor the case of d \u22649, consider the set of the three d-length vectors z1 = [0\n\u00b7 \u00b7 \u00b7\n0\n\u22121],\nz2 = [0\n\u00b7 \u00b7 \u00b7\n0 1] and z3 = [0\n\u00b7 \u00b7 \u00b7\n0 0]. Construct the packing set {w1, w2, w3} from these three\nvectors {z1, z2, z3} as done above for the case of d > 9. From the calculations made for the general\ncase above, we have for all pairs minj\u0338=k \u2225wj \u2212wk\u22252\n2 \u2265\u03b42\n9 and maxj,k \u2225wj \u2212wk\u22252\nL \u22644\u03b42, and as a\nresult maxj,k DKL(Pwj\u2225Pwk) \u22644n\u03b6\u03bbm(H)\u03b42. Choosing \u03b42 =\nlog 2\n8n\u03b6\u03bbm(H) and applying Lemma 6 proves\nthe claim.\nD.2 Some implied properties of the model\nIn this section, we prove the two auxiliary lemmas stated at the start of this appendix.\nD.2.1 Proof of Lemma 10\nFrom the de\ufb01nition (10) of L, have\nL1 = 1\nn\nn\nX\ni=1\nEi(mI \u221211T )ET\ni 1 = 1\nn\nn\nX\ni=1\nEi(mI \u221211T )1 = 0,\nshowing that 1 \u2208nullspace(L).\nNow consider any non-zero vector v : = [v1, . . . , vd]T \u2208Rd such that v /\u2208span(1). Then there\nmust exist some i, j \u2208[d] such that vi \u0338= vj. We know that there exists some path from item i to j\nin the comparison hyper-graph. Thus there must exist some hyper-edge in this path with two items,\nsay i\u2032, j\u2032, such that vi\u2032 \u0338= vj\u2032. Suppose that hyper-edge corresponds to sample \u2113\u2208[n]. Let v\u2032 : = ET\n\u2113v.\nThen v\u2032 /\u2208span(1). The Cauchy-Schwarz inequality \u27e8v\u2032, v\u2032\u27e9\u27e81, 1\u27e9> (\u27e8v\u2032, 1\u27e9)2 thus implies\nvT E\u2113(mI \u221211T )ET\n\u2113v > 0.\nFurthermore, for any v\u2032\u2032 \u2208Rm, the Cauchy-Schwarz inequality \u27e8v\u2032\u2032, v\u2032\u2032\u27e9\u27e81, 1\u27e9> (\u27e8v\u2032\u2032, 1\u27e9)2 implies\nthat for any i \u2208[n], we have vT Ei(mI \u221211T )ET\ni v \u22650. Overall we conclude that have vT Lv > 0 for\nevery v /\u2208span(1), and hence, nullspace(L) = 1 and \u03bb2(L) > 0.\nFinally, we have\ntr(L) = 1\nn\nn\nX\ni=1\ntr(Ei(mI \u221211T )ET\ni ) = 1\nn\nn\nX\ni=1\n\u0010\nmtr(EiET\ni ) \u2212tr(Ei11T ET\ni )\n\u0011\n.\n(27)\nBy the de\ufb01nition of the matrices {Ei}i\u2208[n], tr(EiET\ni ) = m and tr(Ei11T ET\ni ) = m. Substituting these\nvalues in (27) gives the desired result tr(L) = m(m \u22121).\n\u25a0\n33\nD.2.2 Proof of Lemma 11\nLet h1, . . . , hm denote the m eigenvectors of H, with h1 =\n1\n\u221am1. Then for any vector v\u2032 \u2208Rm,\nv\u2032T Hv\u2032 =\nm\nX\ni=2\n\u03bbi(H)\u27e8v\u2032, hi\u27e92 \u2265\u03bb2(H)\nm\nX\ni=2\n\u27e8v\u2032, hi\u27e92 = \u03bb2(H)\n\u0010 m\nX\ni=1\n\u27e8v\u2032, hi\u27e92 \u22121\nm\u27e8v\u2032, 1\u27e92\u0011\n= \u03bb2(H)v\u2032T (I \u22121\nm11T )v\u2032,\nwhere the \ufb01nal step employed the property Pm\ni=1 hihT\ni = I of the eigenvectors h1, . . . , hm of H. A\nsimilar argument gives\nv\u2032T Hv\u2032 =\nm\nX\ni=2\n\u03bbi(H)\u27e8v\u2032, hi\u27e92 \u2264\u03bbmax(H)\nm\nX\ni=2\n\u27e8v\u2032, hi\u27e92 = \u03bbmax(H)\n\u0010 m\nX\ni=1\n\u27e8v\u2032, hi\u27e92 \u22121\nm\u27e8v\u2032, 1\u27e92\u0011\n= \u03bbmax(H)v\u2032T (I \u22121\nm11T )v\u2032.\nSetting v\u2032 = RT\nj v gives\n\u03bb2(H)vT Rj(I \u22121\nm11T )RT\nj v \u2264vT RjHRT\nj v \u2264\u03bbmax(H)vT Rj(I \u22121\nm11T )RT\nj v.\nObserve that the matrix I \u22121\nm11T is invariant to permutation of the coordinates, and hence Rj(I \u2212\n1\nm11T )RT\nj = I \u22121\nm11T . This gives\n\u03bb2(H)\nm\nvT (mI \u221211T )v \u2264vT RjHRT\nj v \u2264\u03bbmax(H)\nm\nvT (mI \u221211T )v.\n\u25a0\nAppendix E. Some useful tail bounds\nIn this appendix, we collect a few useful tail bounds for quadratic forms in Gaussian and sub-Gaussian\nrandom variables.\nLemma 12 (Tail bound for Gaussian quadratic form) For any positive semide\ufb01nite matrix Q\nand standard Gaussian vector g \u223cN(0, Id), we have\nP\n\u0002\ngT Qg \u2265\n\u0000p\ntr(Q) +\np\n|||Q|||op \u03b4\n\u00012\u0003\n\u2264e\u2212\u03b4/2.\n(28)\nvalid for all \u03b4 \u22650.\nProof\nNote that the function g 7\u2192\u2225\u221aQg\u22252 is Lipschitz with constant |||\u221aQ|||op.\nConsequently,\nby concentration for Lipschitz functions of Gaussian vectors (Ledoux, 2001), the random variable\nZ = \u2225\u221aQg\u22252 satis\ufb01es the upper bound\nP\n\u0002\nZ \u2265E[Z] + t\n\u0003\n\u2264exp\n\u0000\u2212\nt2\n2|||\u221aQ|||2\nop\n\u0001\n= exp\n\u0000\u2212\nt2\n2|||Q|||op\n\u0001\n.\nBy Jensen\u2019s inequality, we have E[Z] = E[\u2225\u221aQg\u22252] \u2264\np\nE[gT Qg] =\np\ntr(Q). Setting t =\np\n|||Q|||op \u03b4\ncompletes the proof.\n34\nLemma 13 ((Hanson and Wright, 1971; Rudelson and Vershynin, 2013)) Let V \u2208Rd be\na random vector with independent zero-mean components that are sub-Gaussian with parameter K,\nand let M \u2208Rd\u00d7d be an arbitrary matrix. Then there is a universal constant c > 0 such that\nP\n\u0002\f\fV T MV \u2212E[V T MV ]\n\f\f > t\n\u0001\n\u22642 exp\n\u0012\n\u2212c min\n\u001a\nt2\nK4|||M|||2\nfro\n,\nt\nK2|||M|||op\n\u001b\u0013\nfor all t > 0.\n(29)\nAppendix F. Properties of Laplacian matrices\nBy construction, the Laplacian L of the comparison graph is symmetric and positive-semide\ufb01nite.\nBy the singular value decomposition, we can write L = U T \u039bU where U \u2208Rd\u00d7d is an orthonormal\nmatrix, and \u039b is a diagonal matrix of nonnegative eigenvalues with \u039bjj = \u03bbj(L) for every j \u2208[d].\nGiven our assumption of \u03bb1(L) \u2264\u00b7 \u00b7 \u00b7 \u2264\u03bbd(L), we also have \u039b11 \u2264\u00b7 \u00b7 \u00b7 \u2264\u039bdd. Also recall that L\u2020\ndenotes the Moore-Penrose pseudo-inverse of L. In terms of the notation introduced, the Moore-\nPenrose pseudo-inverse is then given by L\u2020 = U T \u039b\u2020U, where \u039b\u2020 is a diagonal matrix with entries\n\u039b\u2020\njj =\n(\n(\u039b\u22121\njj )\nif \u039bjj > 0\n0\notherwise.\nThe following pair of lemmas establish some useful properties about L.\nLemma 14 The Laplacian matrix (4) satis\ufb01es the trace constraints\ntr(L) = 2,\nand\ntr(L\u2020) \u2265d2\n4 .\nProof\nFrom the de\ufb01nition (4) of the matrix L, we have tr(L) = 1\nn\nPn\ni=1 tr(xixT\ni ) = 2. We also\nknow that \u03bb1(L) = 0, and hence Pd\nj=2 \u03bbj(L) = 2. Given the latter constraint, the sum Pd\nj=2\n1\n\u03bbj(L)\nis minimized when \u03bb2(L) = \u00b7 \u00b7 \u00b7 = \u03bbd(L). Some simple algebra now gives the claimed result.\nLemma 15 For the matrix L de\ufb01ned in (4), and for a (n \u00d7 d) matrix X with xT\ni as its ith row,\ntr( 1\nnxT L\u2020x) = d \u22121,\n||| 1\nnxT L\u2020x|||fro = d \u22121,\nand\n||| 1\nnxT L\u2020x|||op = 1.\nProof\nLet Q = 1\nnxT L\u2020x. Since L = 1\nnXT X = U T \u039bU, the diagonal entries of \u039b are the squared\nsingular values of X/\u221an.\nConsequently, there must exist an orthonormal matrix V such that\nX/\u221an = V\n\u221a\n\u039bU T , and thus we can write Q = V\n\u221a\n\u039b \u039b\u2020 \u221a\n\u039b V T . By de\ufb01nition of the Moore-Penrose\npseudo-inverse, the matrix\n\u221a\n\u039b \u039b\u2020 \u221a\n\u039b is a diagonal matrix; since the Laplacian graph is connected,\nits diagonal contains (d \u22121) ones and a single zero. Noting that V is an orthonormal matrix gives\nthe claimed result.\nFor future reference, we state and prove a lemma showing that these two semi-norms satisfy a\nrestricted form of the Cauchy-Schwarz inequality:\nLemma 16 For any two vectors u and v such that u \u22a5nullspace(L) or/and v \u22a5nullspace(L), we\nhave\n|\u27e8u, v\u27e9| \u2264\u2225u\u2225L\u2020 \u2225v\u2225L.\n(30)\n35\nProof Since L = U T \u039bU and L\u2020 = U T \u039b\u2020U, we have\n\u221a\nvT Lv\n\u221a\nuT L\u2020u =\n\u221a\nvT U T \u039bUv\n\u221a\nuT U T \u039b\u2020Uu = \u2225ev\u22252\u2225eu\u22252 \u2265|\u27e8ev, eu\u27e9|,\nwhere we have de\ufb01ned ev : =\n\u221a\n\u039bUv and eu : =\n\u221a\n\u039b\u2020Uu. Continuing on,\n\u27e8ev, eu\u27e9= vT U T \u221a\n\u039b\n\u221a\n\u039b\u2020Uu = vT UUT u,\nwhere we have used the fact that u or/and v are orthogonal to the null space of L. Since U is\northonormal, we conclude that \u27e8ev, eu\u27e9= \u27e8v, u\u27e9, which completes the proof.\nAppendix G. Minimax risk without assumptions on quality scores\nThe setting considered throughout the paper imposes two restrictions (2) on the quality score vector\nw\u2217. The \ufb01rst condition is that of shift invariance, that is, \u27e8w\u2217, 1\u27e9= 0. The necessity of this condition\nfor identi\ufb01ability under the Ordinal model is easy to verify. The second condition is that the quality\nscore vectors are B-bounded, that is, \u2225w\u2217\u2225\u221e\u2264B for some \ufb01nite B. In this section, for the sake of\ncompleteness, we show that the minimax risk is in\ufb01nite in the absence of this condition.\nProposition 17 Any estimator ew based on n samples from the Ordinal model (with unbounded\nquality score vectors) has error lower bounded as\nsup\nw\u2217\u2208W\u221e\nE\nh\n\u2225ew \u2212w\u2217\u22252\n2\ni\n=\nsup\nw\u2217\u2208W\u221e\nE\nh\n\u2225ew \u2212w\u2217\u22252\nL\ni\n= \u221e.\nThe remainder of this section is devoted to the formal proof of Proposition 17. Consider the event\nwhere for every comparison, the item with the higher quality score in w\u2217wins. For any w\u2217\u2208W\u221e\\{0},\nthis event occurs with a probability at least\n1\n2n . Under this event, the true w\u2217is indistinguishable\nfrom the quality score vector cw\u2217\u2208W\u221efor every c \u22650, and the error is also unbounded. Since the\nprobability of this event is strictly bounded away from zero, the expected error is also unbounded.\nReferences\nAmmar Ammar and Devavrat Shah. Ranking: Compare, don\u2019t score. In Allerton Conference on\nCommunication, Control, and Computing, pages 776\u2013783, 2011.\nDonald R Atkinson, Bruce E Wampold, Susana M Lowe, Linda Matthews, and Hyun-Nie Ahn. Asian\nAmerican preferences for counselor characteristics: Application of the Bradley-Terry-Luce model\nto paired comparison data. The Counseling Psychologist, 26(1):101\u2013123, 1998.\nWilliam Barnett. The modern theory of consumer behavior: Ordinal or cardinal?\nThe Quarterly\nJournal of Austrian Economics, 6(1):41\u201365, 2003.\nRalph Allan Bradley and Milton E Terry. Rank analysis of incomplete block designs: I. the method\nof paired comparisons. Biometrika, pages 324\u2013345, 1952.\nTom Bramley. A rank-ordering method for equating tests by expert judgment. Journal of Applied\nMeasurement, 6(2):202\u2013223, 2005.\nMark Braverman and Elchanan Mossel. Noisy sorting without resampling. In Symposium on Discrete\nAlgorithms, pages 268\u2013276, 2008.\n36\nAndries E Brouwer and Willem H Haemers. Spectra of graphs. Springer, 2011.\nSourav Chatterjee.\nMatrix estimation by universal singular value thresholding.\nThe Annals of\nStatistics, 43(1):177\u2013214, 2014.\nXi Chen, Paul N Bennett, Kevyn Collins-Thompson, and Eric Horvitz. Pairwise ranking aggregation\nin a crowdsourced setting. In International Conference on Web Search and Data Mining, pages\n193\u2013202, 2013.\nThomas M Cover and Joy A Thomas. Elements of information theory. John Wiley & Sons, 2012.\nJia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale\nhierarchical image database. In IEEE Conference on Computer Vision and Pattern Recognition,\npages 248\u2013255, 2009.\nOfer Gabber and Zvi Galil. Explicit constructions of linear-sized superconcentrators. Journal of\nComputer and System Sciences, 22(3):407\u2013420, 1981.\nEdgar N Gilbert.\nA comparison of signalling alphabets.\nBell System Technical Journal, 31(3):\n504\u2013522, 1952.\nPaul E Green, J Douglas Carroll, and Wayne S DeSarbo. Estimating choice probabilities in multi-\nattribute decision making. Journal of Consumer Research, pages 76\u201384, 1981.\nBruce Hajek, Sewoong Oh, and Jiaming Xu. Minimax-optimal inference from partial rankings. In\nAdvances in Neural Information Processing Systems, pages 1475\u20131483, 2014.\nDavid Lee Hanson and Farroll Tim Wright. A bound on tail probabilities for quadratic forms in\nindependent random variables. The Annals of Mathematical Statistics, pages 1079\u20131083, 1971.\nSandra Heldsinger and Stephen Humphry. Using the method of pairwise comparison to obtain reliable\nteacher assessments. The Australian Educational Researcher, 37(2):1\u201319, 2010.\nRalf Herbrich, Tom Minka, and Thore Graepel. Trueskill: A Bayesian skill rating system. In Advances\nin Neural Information Processing Systems, volume 19, page 569, 2007.\nGeo\ufb00rey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed, Navdeep Jaitly,\nAndrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N Sainath, et al. Deep neural networks\nfor acoustic modeling in speech recognition: The shared views of four research groups. Signal\nProcessing Magazine, IEEE, 29(6):82\u201397, 2012.\nSrikanth Jagabathula and Devavrat Shah. Inferring rankings under constrained sensing. In Advances\nin Neural Information Processing Systems, pages 753\u2013760, 2008.\nKevin G Jamieson and Robert Nowak. Active ranking using pairwise comparisons. In Advances in\nNeural Information Processing Systems, pages 2240\u20132248, 2011.\nGabriella Kazai. In search of quality in crowdsourcing for search engine evaluation. In Advances in\nInformation Retrieval, pages 165\u2013176. Springer, 2011.\nZahid Y Khairullah and Stanley Zionts. An approach for preference ranking of alternatives. European\njournal of operational research, 28(3):329\u2013342, 1987.\n37\nFiras Khatib, Frank DiMaio, Seth Cooper, Maciej Kazmierczyk, Miroslaw Gilski, Szymon Krzywda,\nHelena Zabranska, Iva Pichova, James Thompson, Zoran Popovi\u00b4c, Mariusz Jaskolski, and David\nBaker. Crystal structure of a monomeric retroviral protease solved by protein folding game players.\nNature structural & molecular biology, 18(10):1175\u20131177, 2011.\nJohn I Kiger. The depth/breadth trade-o\ufb00in the design of menu-driven user interfaces. International\nJournal of Man-Machine Studies, 20(2):201\u2013213, 1984.\nKenneth J Koehler and Harold Ridpath. An application of a biased version of the Bradley-Terry-Luce\nmodel to professional basketball results. Journal of Mathematical Psychology, 25(3), 1982.\nPaul FM Krabbe. Thurstone scaling as a measurement method to quantify subjective health out-\ncomes. Medical care, 46(4):357\u2013365, 2008.\nASID Lang and Joshua Rio-Ross. Using Amazon Mechanical Turk to transcribe historical handwrit-\nten documents. The Code4Lib Journal, 2011.\nM. Ledoux. The Concentration of Measure Phenomenon. Mathematical Surveys and Monographs.\nAmerican Mathematical Society, Providence, RI, 2001.\nMichael D Lee, Mark Steyvers, Mindy De Young, and Brent J Miller. A model-based approach to\nmeasuring expertise in ranking tasks. In Proceedings of the 33rd annual conference of the cognitive\nscience society, 2011.\nE.L. Lehmann and G. Casella. Theory of Point Estimation. Springer Texts in Statistics, 1998.\nPeter John Loewen, Daniel Rubenson, and Arthur Spirling.\nTesting the power of arguments in\nreferendums: A Bradley\u2013Terry approach. Electoral Studies, 31(1):212\u2013221, 2012.\nR Duncan Luce. Individual Choice Behavior: A Theoretical Analysis. New York: Wiley, 1959.\nMiguel Angel Luengo-Oroz, Asier Arranz, and John Frean. Crowdsourcing malaria parasite quan-\nti\ufb01cation: an online game for analyzing images of infected thick blood smears. Journal of medical\nInternet research, 14(6), 2012.\nGeorge A Miller. The magical number seven, plus or minus two: some limits on our capacity for\nprocessing information. Psychological review, 63(2):81, 1956.\nSahand Negahban, Sewoong Oh, and Devavrat Shah. Iterative ranking from pair-wise comparisons.\nIn Advances in Neural Information Processing Systems, pages 2474\u20132482, 2012.\nRobert M Nosofsky. Luce\u2019s choice model and Thurstone\u2019s categorical judgment model compared:\nKornbrot\u2019s data revisited. Attention, Perception, & Psychophysics, 37(1):89\u201391, 1985.\nRoberto Imbuzeiro Oliveira. Concentration of the adjacency matrix and of the laplacian in random\ngraphs with independent edges. arXiv preprint arXiv:0911.0600, 2009.\nChris Piech, Jonathan Huang, Zhenghao Chen, Chuong Do, Andrew Ng, and Daphne Koller. Tuned\nmodels of peer assessment in MOOCs. In International Conference on Educational Data Mining,\n2013.\nRobin L Plackett. The analysis of permutations. Applied Statistics, pages 193\u2013202, 1975.\n38\nArun Rajkumar and Shivani Agarwal. A statistical convergence perspective of algorithms for rank\naggregation from pairwise data. In Proceedings of the 31st International Conference on Machine\nLearning, pages 118\u2013126, 2014.\nVikas C Raykar, Shipeng Yu, Linda H Zhao, Gerardo Hermosillo Valadez, Charles Florin, Luca\nBogoni, and Linda Moy. Learning from crowds. The Journal of Machine Learning Research, 99:\n1297\u20131322, 2010.\nDaniel Ross.\nArpad Elo and the Elo rating system, 2007.\nhttp://en.chessbase.com/post/\narpad-elo-and-the-elo-rating-system.\nMark Rudelson and Roman Vershynin. Hanson-wright inequality and sub-gaussian concentration.\nElectronic Communications in Probability, 18:1\u20139, 2013.\nThomas L Saaty and Mujgan S Ozdemir. Why the magic number seven plus or minus two. Mathe-\nmatical and Computer Modelling, 38(3):233\u2013244, 2003.\nRichard M Shi\ufb00rin and Robert M Nosofsky. Seven plus or minus two: a commentary on capacity\nlimitations. Psychological Review, 1994.\nNeil Stewart, Gordon DA Brown, and Nick Chater. Absolute identi\ufb01cation by relative judgment.\nPsychological review, 112(4):881, 2005.\nJohn Swets. The relative operating characteristic in psychology. Science, 182(4116), 1973.\nLouis L Thurstone. A law of comparative judgment. Psychological Review, 34(4):273, 1927.\nKristi Tsukida and Maya R Gupta. How to analyze paired comparison data. Technical report, DTIC\nDocument, 2011.\nA.B. Tsybakov. Introduction to Nonparametric Estimation. Springer Series in Statistics, 2008.\nRR Varshamov. Estimate of the number of signals in error correcting codes. In Dokl. Akad. Nauk\nSSSR, volume 117, pages 739\u2013741, 1957.\nLuis von Ahn, Benjamin Maurer, Colin McMillen, David Abraham, and Manuel Blum. Recaptcha:\nHuman-based character recognition via web security measures.\nScience, 321(5895):1465\u20131468,\n2008.\nJing Wang, Panagiotis G Ipeirotis, and Foster Provost. Managing crowdsourcing workers. In Winter\nConference on Business Intelligence, pages 10\u201312, 2011.\nJinfeng Yi, Rong Jin, Shaili Jain, and Anil Jain. Inferring users\u2019 preferences from crowdsourced pair-\nwise comparisons: A matrix completion approach. In AAAI Conference on Human Computation\nand Crowdsourcing, 2013.\n39\n",
        "sentence": "",
        "context": "a new unknown life. That might be the \nof a new story, but our present story is e\nWhich%tone%corresponds%to\nHIGHER%number%on%a%phone%ke\n!%\n!%\n!%\n!%\n\u201cSimple, fast but sure cure\u201d \nhealthcare%plaMorm%\n/%10%\n(b)\nbetween%these%ci.es?%\n%\nSan$Francisco$and$Aus.n\nMiguel Angel Luengo-Oroz, Asier Arranz, and John Frean. Crowdsourcing malaria parasite quan-\nti\ufb01cation: an online game for analyzing images of infected thick blood smears. Journal of medical\nInternet research, 14(6), 2012.\nin both theory and practice (e.g., (Nosofsky, 1985; Atkinson et al., 1998; Koehler and Ridpath, 1982;\nHeldsinger and Humphry, 2010; Loewen et al., 2012; Green et al., 1981; Khairullah and Zionts,\n1987)).\n1.1 Some past work"
    },
    {
        "title": "Stochastically transitive models for pairwise comparisons: Statistical and computational issues",
        "author": [
            "N.B. Shah",
            "S. Balakrishnan",
            "A. Guntuboyina",
            "M.J. Wainright"
        ],
        "venue": "arXiv preprint arXiv:1510.05610,",
        "citeRegEx": "Shah et al\\.,? \\Q2015\\E",
        "shortCiteRegEx": "Shah et al\\.",
        "year": 2015,
        "abstract": "There are various parametric models for analyzing pairwise comparison data,\nincluding the Bradley-Terry-Luce (BTL) and Thurstone models, but their reliance\non strong parametric assumptions is limiting. In this work, we study a flexible\nmodel for pairwise comparisons, under which the probabilities of outcomes are\nrequired only to satisfy a natural form of stochastic transitivity. This class\nincludes parametric models including the BTL and Thurstone models as special\ncases, but is considerably more general. We provide various examples of models\nin this broader stochastically transitive class for which classical parametric\nmodels provide poor fits. Despite this greater flexibility, we show that the\nmatrix of probabilities can be estimated at the same rate as in standard\nparametric models. On the other hand, unlike in the BTL and Thurstone models,\ncomputing the minimax-optimal estimator in the stochastically transitive model\nis non-trivial, and we explore various computationally tractable alternatives.\nWe show that a simple singular value thresholding algorithm is statistically\nconsistent but does not achieve the minimax rate. We then propose and study\nalgorithms that achieve the minimax rate over interesting sub-classes of the\nfull stochastically transitive class. We complement our theoretical results\nwith thorough numerical simulations.",
        "full_text": "Stochastically Transitive Models for Pairwise\nComparisons: Statistical and Computational Issues\nNihar B. Shah\u2217, Sivaraman Balakrishnan\u266f, Adityanand Guntuboyina\u2020\nand Martin J. Wainwright\u2020\u2217\n\u2020Department of Statistics\n\u2217Department of EECS\nUniversity of California, Berkeley\nBerkeley, CA 94720\n\u266fDepartment of Statistics\nCarnegie Mellon University,\n5000 Forbes Ave, Pittsburgh, PA 15213\nAbstract\nThere are various parametric models for analyzing pairwise comparison data, including\nthe Bradley-Terry-Luce (BTL) and Thurstone models, but their reliance on strong para-\nmetric assumptions is limiting. In this work, we study a \ufb02exible model for pairwise com-\nparisons, under which the probabilities of outcomes are required only to satisfy a natural\nform of stochastic transitivity. This class includes parametric models including the BTL and\nThurstone models as special cases, but is considerably more general. We provide various ex-\namples of models in this broader stochastically transitive class for which classical parametric\nmodels provide poor \ufb01ts. Despite this greater \ufb02exibility, we show that the matrix of proba-\nbilities can be estimated at the same rate as in standard parametric models. On the other\nhand, unlike in the BTL and Thurstone models, computing the minimax-optimal estimator\nin the stochastically transitive model is non-trivial, and we explore various computation-\nally tractable alternatives. We show that a simple singular value thresholding algorithm is\nstatistically consistent but does not achieve the minimax rate. We then propose and study\nalgorithms that achieve the minimax rate over interesting sub-classes of the full stochas-\ntically transitive class.\nWe complement our theoretical results with thorough numerical\nsimulations.\n1\nIntroduction\nPairwise comparison data is ubiquitous and arises naturally in a variety of applications, includ-\ning tournament play, voting, online search rankings, and advertisement placement problems.\nIn rough terms, given a set of n objects along with a collection of possibly inconsistent com-\nparisons between pairs of these objects, the goal is to aggregate these comparisons in order to\nestimate underlying properties of the population. One property of interest is the underlying\nmatrix of pairwise comparison probabilities\u2014that is, the matrix in which entry (i, j) corre-\nsponds to the probability that object i is preferred to object j in a pairwise comparison. The\nBradley-Terry-Luce [BT52, Luc59] and Thurstone [Thu27] models are mainstays in analyzing\nthis type of pairwise comparison data. These models are parametric in nature: more speci\ufb01-\ncally, they assume the existence of an n-dimensional weight vector that measures the quality\nAuthor\nemail\naddresses:\nnihar@eecs.berkeley.edu,\nsiva@stat.cmu.edu,\naditya@stat.berkeley.edu,\nwainwrig@berkeley.edu.\n1\narXiv:1510.05610v4  [stat.ML]  28 Sep 2016\nor strength of each item. The pairwise comparison probabilities are then determined via some\n\ufb01xed function of the qualities of the pair of objects. Estimation in these models reduces to\nestimating the underlying weight vector, and a large body of prior work has focused on these\nmodels (e.g., see the papers [NOS12, HOX14, SBB+16]). However, such models enforce strong\nrelationships on the pairwise comparison probabilities that often fail to hold in real applications.\nVarious papers [DM59, ML65, Tve72, BW97] have provided experimental results in which these\nparametric modeling assumptions fail to hold.\nOur focus in this paper is on models that have their roots in social science and psychology\n(e.g., see Fishburn [Fis73] for an overview), in which the only coherence assumption imposed on\nthe pairwise comparison probabilities is that of strong stochastic transitivity, or SST for short.\nThese models include the parametric models as special cases but are considerably more general.\nThe SST model has been validated by several empirical analyses, including those in a long line\nof work [DM59, ML65, Tve72, BW97]. The conclusion of Ballinger et al. [BW97] is especially\nstrongly worded:\nAll of these parametric c.d.f.s are soundly rejected by our data. However, SST\nusually survives scrutiny.\nWe are thus provided with strong empirical motivation for studying the fundamental properties\nof pairwise comparison probabilities satisfying SST.\nIn this paper, we focus on the problem of estimating the matrix of pairwise comparison\nprobabilities\u2014that is, the probability that an item i will beat a second item j in any given\ncomparison. Estimates of these comparison probabilities are useful in various applications. For\ninstance, when the items correspond to players or teams in a sport, the predicted odds of one\nteam beating the other are central to betting and bookmaking operations. In a supermarket\nor an ad display, an accurate estimate of the probability of a customer preferring one item\nover another, along with the respective pro\ufb01ts for each item, can e\ufb00ectively guide the choice of\nwhich product to display. Accurate estimates of the pairwise comparison probabilities can also\nbe used to infer partial or full rankings of the underlying items.\nOur contributions:\nWe begin by studying the performance of optimal methods for estimat-\ning matrices in the SST class: our \ufb01rst main result (Theorem 1) characterizes the minimax rate\nin squared Frobenius norm up to logarithmic factors. This result reveals that even though the\nSST class of matrices is considerably larger than the classical parametric class, surprisingly, it is\npossible to estimate any SST matrix at nearly the same rate as the classical parametric family.\nOn the other hand, our achievability result is based on an estimator involving prohibitive com-\nputation, as a brute force approach entails an exhaustive search over permutations. Accordingly,\nwe turn to studying computationally tractable estimation procedures. Our second main result\n(Theorem 2) applies to a polynomial-time estimator based on soft-thresholding the singular\nvalues of the data matrix. An estimator based on hard-thresholding was studied previously in\nthis context by Chatterjee [Cha14]. We sharpen and generalize this previous analysis, and give\na tight characterization of the rate achieved by both hard and soft-thresholding estimators. Our\nthird contribution, formalized in Theorems 3 and 4, is to show how for certain interesting sub-\nsets of the full SST class, a combination of parametric maximum likelihood [SBB+16] and noisy\nsorting algorithms [BM08] leads to a tractable two-stage method that achieves the minimax\nrate. Our fourth contribution is to supplement our minimax lower bound with lower bounds\nfor various known estimators, including those based on thresholding singular values [Cha14],\nnoisy sorting [BM08], as well as parametric estimators [NOS12, HOX14, SBB+16]. These lower\nbounds show that none of these tractable estimators achieve the minimax rate uniformly over\n2\nthe entire class. The lower bounds also show that the minimax rates for any of these subclasses\nis no better than the full SST class.\nRelated work:\nThe literature on ranking and estimation from pairwise comparisons is vast\nand we refer the reader to various surveys [FV93, Mar96, Cat12] for a more detailed overview.\nHere we focus our literature review on those papers that are most closely related to our contri-\nbutions. Some recent work [NOS12, HOX14, SBB+16] studies procedures and minimax rates\nfor estimating the latent quality vector that underlie parametric models. Theorem 4 in this\npaper provides an extension of these results, in particular by showing that an optimal estimate\nof the latent quality vector can be used to construct an optimal estimate of the pairwise com-\nparison probabilities. Chatterjee [Cha14] analyzed matrix estimation based on singular value\nthresholding, and obtained results for the class of SST matrices. In Theorem 2, we provide a\nsharper analysis of this estimator, and show that our upper bound is\u2014in fact\u2014unimprovable.\nIn past work, various authors [KMS07, BM08] have considered the noisy sorting problem, in\nwhich the goal is to infer the underlying order under a so-called high signal-to-noise ratio (SNR)\ncondition. The high SNR condition means that each pairwise comparison has a probability of\nagreeing with the underlying order that is bounded away from 1\n2 by a \ufb01xed constant. Under\nthis high SNR condition, these authors provide polynomial-time algorithms that, with high\nprobability, return an estimate of true underlying order with a prescribed accuracy. Part of our\nanalysis leverages an algorithm from the paper [BM08]; in particular, we extend their analysis\nin order to provide guarantees for estimating pairwise comparison probabilities as opposed to\nestimating the underlying order.\nAs will be clari\ufb01ed in the sequel, the assumption of strong stochastic transitivity has close\nconnections to the statistical literature on shape constrained inference (e.g., [SS11]), particularly\nto the problem of bivariate isotonic regression. In our analysis of the least-squares estimator,\nwe leverage metric entropy bounds from past work in this area (e.g., [GW07, CGS15]).\nIn Appendix D of the present paper, we study estimation under two popular models that\nare closely related to the SST class, and make even weaker assumptions. We show that under\nthese moderate stochastic transitivity (MST) and weak stochastic transitivity (WST) models,\nthe Frobenius norm error of any estimator, measured in a uniform sense over the class, must\nbe almost as bad as that incurred by making no assumptions whatsoever. Consequently, from\na statistical point of view, these assumptions are not strong enough to yield reductions in\nestimation error. We note that the \u201clow noise model\u201d studied in the paper [RA14] is identical\nto the WST class.\nOrganization:\nThe remainder of the paper is organized as follows. We begin by providing\na background and a formal description of the problem in Section 2. In Section 3, we present\nthe main theoretical results of the paper. We then present results from numerical simulations\nin Section 4. We present proofs of our main results in Section 5. We conclude the paper in\nSection 6.\n2\nBackground and problem formulation\nGiven a collection of n \u22652 items, suppose that we have access to noisy comparisons between\nany pair i \u0338= j of distinct items.\nThe full set of all possible pairwise comparisons can be\ndescribed by a probability matrix M\u2217\u2208[0, 1]n\u00d7n, in which M\u2217\nij is the probability that item i\nis preferred to item j. The upper and lower halves of the probability matrix M\u2217are related by\n3\nthe shifted-skew-symmetry condition1 M\u2217\nji = 1 \u2212M\u2217\nij for all i, j \u2208[n]. For concreteness, we set\nM\u2217\nii = 1/2 for all i \u2208[n].\n2.1\nEstimation of pairwise comparison probabilities\nFor any matrix M\u2217\u2208[0, 1]n\u00d7n with M\u2217\nij = 1 \u2212M\u2217\nji for every (i, j), suppose that we observe a\nrandom matrix Y \u2208{0, 1}n\u00d7n with (upper-triangular) independent Bernoulli entries, in partic-\nular, with P[Yij = 1] = M\u2217\nij for every 1 \u2264i \u2264j \u2264n and Yji = 1 \u2212Yij. Based on observing Y ,\nour goal in this paper is to recover an accurate estimate, in the squared Frobenius norm, of the\nfull matrix M\u2217.\nOur primary focus in this paper will be on the setting where for n items we observe the\noutcome of a single pairwise comparison for each pair. We will subsequently (in Section 3.5) also\naddress the more general case when we have partial observations, that is, when each pairwise\ncomparison is observed with a \ufb01xed probability.\nFor future reference, note that we can always write the Bernoulli observation model in the\nlinear form\nY = M\u2217+ W,\n(1)\nwhere W \u2208[\u22121, 1]n\u00d7n is a random matrix with independent zero-mean entries for every i \u2265j\ngiven by\nWij \u223c\n(\n1 \u2212M\u2217\nij\nwith probability M\u2217\nij\n\u2212M\u2217\nij\nwith probability 1 \u2212M\u2217\nij,\n(2)\nand Wji = \u2212Wij for every i < j. This linearized form of the observation model is convenient\nfor subsequent analysis.\n2.2\nStrong stochastic transitivity\nBeyond the previously mentioned constraints on the matrix M\u2217\u2014namely that M\u2217\nij \u2208[0, 1]\nand M\u2217\nij = 1 \u2212M\u2217\nij\u2014more structured and interesting models are obtained by imposing further\nrestrictions on the entries of M\u2217. We now turn to one such condition, known as strong stochastic\ntransitivity (SST), which re\ufb02ects the natural transitivity of any complete ordering. Formally,\nsuppose that the full collection of items [n] is endowed with a complete ordering \u03c0\u2217. We use\nthe notation \u03c0\u2217(i) < \u03c0\u2217(j) to convey that item i is preferred to item j in the total ordering\n\u03c0\u2217.\nConsider some triple (i, j, k) such that \u03c0\u2217(i) < \u03c0\u2217(j).\nA matrix M\u2217satis\ufb01es the SST\ncondition if the inequality M\u2217\nik \u2265M\u2217\njk holds for every such triple. The intuition underlying this\nconstraint is the following: since i dominates j in the true underlying order, when we make\nnoisy comparisons, the probability that i is preferred to k should be at least as large as the\nprobability that j is preferred to k. The SST condition was \ufb01rst described2 in the psychology\nliterature (e.g., [Fis73, DM59]).\nThe SST condition is characterized by the existence of a permutation such that the permuted\nmatrix has entries that increase across rows and decrease down columns. More precisely, for a\ngiven permutation \u03c0\u2217, let us say that a matrix M is \u03c0\u2217-faithful if for every pair (i, j) such that\n1In other words, the shifted matrix M \u2217\u22121\n2 is skew-symmetric.\n2We note that the psychology literature has also considered what are known as weak and moderate stochastic\ntransitivity conditions. From a statistical standpoint, pairwise comparison probabilities cannot be consistently\nestimated in a minimax sense under these conditions. We establish this formally in Appendix D.\n4\n\u03c0\u2217(i) < \u03c0\u2217(j), we have Mik \u2265Mjk for all k \u2208[n]. With this notion, the set of SST matrices is\ngiven by\nCSST =\n\b\nM \u2208[0, 1]n\u00d7n | Mba = 1 \u2212Mab \u2200(a, b), and \u2203perm. \u03c0\u2217s.t. M is \u03c0\u2217-faithful\n\t\n.\n(3)\nNote that the stated inequalities also guarantee that for any pair with \u03c0\u2217(i) < \u03c0\u2217(j), we have\nMki \u2264Mkj for all k, which corresponds to a form of column ordering. The class CSST is our\nprimary focus in this paper.\n2.3\nClassical parametric models\nLet us now describe a family of classical parametric models, one which includes Bradley-Terry-\nLuce and Thurstone (Case V) models [BT52, Luc59, Thu27]. In the sequel, we show that these\nparametric models induce a relatively small subclass of the SST matrices CSST.\nIn more detail, parametric models are described by a weight vector w\u2217\u2208Rn that corresponds\nto the notional qualities of the n items. Moreover, consider any non-decreasing function F :\nR 7\u2192[0, 1] such that F(t) = 1 \u2212F(\u2212t) for all t \u2208R; we refer to any such function F as being\nvalid. Any such pair (F, w\u2217) induces a particular pairwise comparison model in which\nM\u2217\nij = F(w\u2217\ni \u2212w\u2217\nj)\nfor all pairs (i, j).\n(4)\nFor each valid choice of F, we de\ufb01ne\nCPAR(F) =\nn\nM \u2208[0, 1]n\u00d7n | M induced by Equation (4) for some w\u2217\u2208Rno\n.\n(5)\nFor any choice of F, it is straightforward to verify that CPAR(F) is a subset of CSST, meaning that\nany matrix M induced by the relation (4) satis\ufb01es all the constraints de\ufb01ning the set CSST. As\nparticular important examples, we recover the Thurstone model by setting F(t) = \u03a6(t) where \u03a6\nis the Gaussian CDF, and the Bradley-Terry-Luce model by setting F(t) =\net\n1+et , corresponding\nto the sigmoid function.\nRemark:\nOne can impose further constraints on the vector w\u2217without reducing the size of\nthe class {CPAR(F), for some valid F}. In particular, since the pairwise probabilities depend\nonly on the di\ufb00erences w\u2217\ni \u2212w\u2217\nj, we can assume without loss of generality that \u27e8w\u2217, 1\u27e9= 0.\nMoreover, since the choice of F can include rescaling its argument, we can also assume that\n\u2225w\u2217\u2225\u221e\u22641. Accordingly, we assume in our subsequent analysis that w\u2217belongs to the set\n\b\nw \u2208Rn | such that \u27e8w, 1\u27e9= 0 and \u2225w\u2225\u221e\u22641.\n\t\n.\n2.4\nInadequacies of parametric models\nAs noted in the introduction, a large body of past work (e.g., [DM59, ML65, Tve72, BW97])\nhas shown that parametric models, of the form (5) for some choice of F, often provide poor \ufb01ts\nto real-world data. What might be a reason for this phenomenon? Roughly, parametric models\nimpose the very restrictive assumption that the choice of an item depends on the value of a\nsingle latent factor (as indexed by w\u2217)\u2014e.g., that our preference for cars depends only on their\nfuel economy, or that the probability that one hockey team beats another depends only on the\nskills of the goalkeepers.\nThis intuition can be formalized to construct matrices M\u2217\u2208CSST that are far away from\nevery valid parametric approximation as summarized in the following result:\n5\nProposition 1. There exists a universal constant c > 0 such that for every n \u22654, there exist\nmatrices M\u2217\u2208CSST for which\n1\nn2\ninf\nvalid F\ninf\nM\u2208CPAR(F) |||M \u2212M\u2217|||2\nF \u2265c.\n(6)\nGiven that every entry of matrices in CSST lies in the interval [0, 1], the Frobenius norm diameter\nof the class CSST is at most n2, so that the scaling of the lower bound (6) cannot be sharpened.\nSee Appendix B for a proof of Proposition 1.\nWhat sort of matrices M\u2217are \u201cbad\u201d in the sense of satisfying a lower bound of the form (6)?\nPanel (a) of Figure 1 describes the construction of one \u201cbad\u201d matrix M\u2217. In order to provide\nsome intuition, let us return to the analogy of rating cars. A key property of any parametric\nmodel is that if we prefer car 1 to car 2 more than we prefer car 3 to car 4, then we must also\nprefer car 1 to car 3 more than we prefer car 2 to car 4.3 This condition is potentially satis\ufb01ed\nif there is a single determining factor across all cars\u2014for instance, their fuel economy.\nThis ordering condition is, however, violated by the pairwise comparison matrix M\u2217from\nFigure 1(a). In this example, we have M\u2217\n12 = 6\n8 > 5\n8 = M\u2217\n34 and M\u2217\n13 = 7\n8 < 8\n8 = M\u2217\n24. Such\nan occurrence can be explained by a simple two-factor model: suppose the fuel economies of\ncars 1, 2, 3 and 4 are 20, 18, 12 and 6 kilometers per liter respectively, and the comfort levels\nof the four cars are also ordered 1 \u227b2 \u227b3 \u227b4, with i \u227bj meaning that i is more comfortable\nthan j. Suppose that in a pairwise comparison of two cars, if one car is more fuel e\ufb03cient\nby at least 10 kilometers per liter, it is always chosen. Otherwise the choice is governed by a\nparametric choice model acting on the respective comfort levels of the two cars. Observe that\nwhile the comparisons between the pairs (1, 2), (3, 4) and (1, 3) of cars can be explained by this\nparametric model acting on their respective comfort levels, the preference between cars 1 and\n4, as well as between cars 2 and 4, is governed by their fuel economies. This two-factor model\naccounts for the said values of M\u2217\n12, M\u2217\n34, M\u2217\n24 and M\u2217\n13, which violate parametric requirements.\nWhile this was a simple hypothetical example, there is a more ubiquitous phenomenon\nunderlying our example. It is often the case that our preferences are decided by comparing\nitems on a multitude of dimensions. In any situation where a single (latent) parameter per\nitem does not adequately explain our preferences, one can expect that the class of parametric\nmodels to provide a poor \ufb01t to the pairwise preference probabilities.\nThe lower bound on approximation quality guaranteed by Proposition 1 means that any\nparametric estimator of the matrix M\u2217should perform poorly. This expectation is con\ufb01rmed\nby the simulation results in panel (b) of Figure 1. After generating observations from a \u201cbad\nmatrix\u201d over a range of n, we \ufb01t the data set using either the maximum likelihood estimate\nin the Thurstone model, or the singular value thresholding (SVT) estimator, to be discussed\nin Section 3.2. For each estimator c\nM, we plot the rescaled Frobenius norm error |||c\nM\u2212M\u2217|||2\nF\nn2\nversus the sample size. Consistent with the lower bound (6), the error in the Thurstone-based\nestimator stays bounded above a universal constant. In contrast, the SVT error goes to zero\nwith n, and as our theory in the sequel shows, the rate at which the error decays is at least as\nfast as 1/\u221an.\n3\nMain results\nThus far, we have introduced two classes of models for matrices of pairwise comparison proba-\nbilities. Our main results characterize the rates of estimation associated with di\ufb00erent subsets\n3This condition follows from the proof of Proposition 1.\n6\nM\u2217: = 1\n8\n\uf8ee\n\uf8ef\uf8ef\uf8f0\n4\n6\n7\n8\n2\n4\n7\n8\n1\n1\n4\n5\n0\n0\n3\n4\n\uf8f9\n\uf8fa\uf8fa\uf8fb\u2208Rn\u00d7n\n26\n27\n28\n29\n210\nNumber of items n\n2-8\n2-7\n2-6\n2-5\nError  ||c\nM\u2212M \u2217||2\nF /n2\nSVT\nThurstone MLE\n(a)\n(b)\nFigure 1. (a) Construction of a \u201cbad\u201d matrix: for n divisible by 4, form the matrix M \u2217\u2208Rn\u00d7n\nshown, where each block has dimensions n/4 \u00d7 n/4. (b) Estimation for a class of SST matrices\nthat are far from the parametric models.\nThe parametric model (Thurstone MLE) yields a\npoor \ufb01t, whereas \ufb01tting using the singular value thresholding (SVT) estimator, which allows for\nestimates over the full SST class, leads to consistent estimation.\nof these classes, using either optimal estimators (that we suspect are not polynomial-time com-\nputable), or more computationally e\ufb03cient estimators that can be computed in polynomial-\ntime.\n3.1\nCharacterization of the minimax risk\nWe begin by providing a result that characterizes the minimax risk in squared Frobenius norm\nover the class CSST of SST matrices. The minimax risk is de\ufb01ned by taking an in\ufb01mum over\nthe set of all possible estimators, which are measurable functions Y 7\u2192f\nM \u2208[0, 1]n\u00d7n. Here the\ndata matrix Y \u2208{0, 1}n\u00d7n is drawn from the observation model (1).\nTheorem 1. There are universal constants 0 < c\u2113< cu such that\nc\u2113\nn \u2264inf\nf\nM\nsup\nM\u2217\u2208CSST\n1\nn2 E[|||f\nM \u2212M\u2217|||2\nF] \u2264cu\nlog2(n)\nn\n,\n(7)\nwhere the in\ufb01mum ranges over all measurable functions f\nM of the observed matrix Y .\nWe prove this theorem in Section 5.1. The proof of the lower bound is based on extracting a\nparticular subset of the class CSST such that any matrix in this subset has at least n positions that\nare unconstrained, apart from having to belong to the interval [1\n2, 1]. We can thus conclude that\nestimation of the full matrix is at least as hard as estimating n Bernoulli parameters belonging\nto the interval [1\n2, 1] based on a single observation per number. This reduction leads to an\n\u2126(n\u22121) lower bound, as stated.\nProving an upper bound requires substantially more e\ufb00ort. In particular, we establish it via\ncareful analysis of the constrained least-squares estimator\nc\nM \u2208arg min\nM\u2208CSST\n|||Y \u2212M|||2\nF.\n(8a)\n7\nIn particular, we prove that there are universal constants (c0, c1, c2) such that, for any matrix\nM\u2217\u2208CSST, this estimator satis\ufb01es the high probability bound\nP\nh 1\nn2 |||c\nM \u2212M\u2217|||2\nF \u2265c0\nlog2(n)\nn\ni\n\u2264c1e\u2212c2n.\n(8b)\nSince the entries of c\nM and M\u2217all lie in the interval [0, 1], integrating this tail bound leads to\nthe stated upper bound (7) on the expected mean-squared error. Proving the high probability\nbound (8b) requires sharp control on a quantity known as the localized Gaussian complexity\nof the class CSST. We use Dudley\u2019s entropy integral (e.g., [VDVW96, Corollary 2.2.8]) in order\nto derive an upper bound that is sharp up to a logarithmic factor; doing so in turn requires\nderiving upper bounds on the metric entropy of the class CSST for which we leverage the prior\nwork of Gao and Wellner [GW07].\nWe do not know whether the constrained least-squares estimator (8a) is computable in time\npolynomial in n, but we suspect not. This complexity is a consequence of the fact that the set\nCSST is not convex, but is a union of n! convex sets. Given this issue, it becomes interesting to\nconsider the performance of alternative estimators that can be computed in polynomial-time.\n3.2\nSharp analysis of singular value thresholding (SVT)\nThe \ufb01rst polynomial-time estimator that we consider is a simple estimator based on threshold-\ning singular values of the observed matrix Y , and reconstructing its truncated singular value\ndecomposition. For the full class CSST, Chatterjee [Cha14] analyzed the performance of such\nan estimator and proved that the squared Frobenius error decays as O(n\u22121\n4 ) uniformly over\nCSST. In this section, we prove that its error decays as O(n\u22121\n2 ), again uniformly over CSST, and\nmoreover, that this upper bound is unimprovable.\nLet us begin by describing the estimator. Given the observation matrix Y \u2208Rn\u00d7n, we can\nwrite its singular value decomposition as Y = UDV T , where the (n \u00d7 n) matrix D is diagonal,\nwhereas the (n \u00d7 n) matrices U and V are orthonormal. Given a threshold level \u03bbn > 0, the\nsoft-thresholded version of a diagonal matrix D is the diagonal matrix T\u03bbn(D) with values\n[T\u03bbn(D)]jj = max{0, Djj \u2212\u03bbn}\nfor every integer j \u2208[1, n].\n(9)\nWith this notation, the soft singular-value-thresholded (soft-SVT) version of Y is given by\nT\u03bbn(Y ) = UT\u03bbn(D)V T .\nThe following theorem provides a bound on its squared Frobenius\nerror:\nTheorem 2. There are universal positive constants (cu, c0, c1) such that the soft-SVT estimator\nc\nM\u03bbn = T\u03bbn(Y ) with \u03bbn = 2.1\u221an satis\ufb01es the bound\nP\nh 1\nn2 |||c\nM\u03bbn \u2212M\u2217|||2\nF \u2265cu\n\u221an\ni\n\u2264c0e\u2212c1n\n(10a)\nfor any M\u2217\u2208CSST. Moreover, there is a universal constant c\u2113> 0 such that for any choice of\n\u03bbn, we have\nsup\nM\u2217\u2208CSST\n1\nn2 |||c\nM\u03bbn \u2212M\u2217|||2\nF \u2265c\u2113\n\u221an.\n(10b)\n8\nA few comments on this result are in order. Since the matrices c\nM\u03bbn and M\u2217have entries in\nthe unit interval [0, 1], the normalized squared error\n1\nn2 |||c\nM\u03bbn \u2212M\u2217|||2\nF is at most 1. Consequently,\nby integrating the the tail bound (10a), we \ufb01nd that\nsup\nM\u2217\u2208CSST\nE[ 1\nn2 |||c\nM\u03bbn \u2212M\u2217|||2\nF] \u2264cu\n\u221an + c0e\u2212c1n \u2264c\u2032\nu\n\u221an.\nOn the other hand, the matching lower bound (10b) holds with probability one, meaning that\nthe soft-SVT estimator has squared error of the order 1/\u221an, irrespective of the realization of\nthe noise.\nTo be clear, Chatterjee [Cha14] actually analyzed the hard-SVT estimator, which is based\non the hard-thresholding operator\n[H\u03bbn(D)]jj = Djj 1{Djj \u2265\u03bbn}.\nHere 1{\u00b7} denotes the 0-1-valued indicator function. In this setting, the hard-SVT estimator is\nsimply, H\u03bbn(Y ) = UH\u03bbn(D)V T . With essentially the same choice of \u03bbn as above, Chatterjee\nshowed that the estimate H\u03bbn(Y ) has a mean-squared error of O(n\u22121/4). One can verify that the\nproof of Theorem 2 in our paper goes through for the hard-SVT estimator as well. Consequently\nthe performance of the hard-SVT estimator is of the order \u0398(n\u22121/2), and is identical to that of\nthe soft-thresholded version up to universal constants.\nNote that the hard and soft-SVT estimators return matrices that may not lie in the SST\nclass CSST. In a companion paper [SBW16], we provide an alternative computationally-e\ufb03cient\nestimator with similar statistical guarantees that is guaranteed to return a matrix in the SST\nclass.\nTogether the upper and lower bounds of Theorem 2 provide a sharp characterization of the\nbehavior of the soft/hard SVT estimators. On the positive side, these are easily implementable\nestimators that achieve a mean-squared error bounded by O(1/\u221an) uniformly over the entire\nclass CSST. On the negative side, this rate is slower than the O(log2 n/n) rate achieved by the\nleast-squares estimator, as in Theorem 1.\nIn conjunction, Theorems 1 and 2 raise a natural open question: is there a polynomial-time\nestimator that achieves the minimax rate uniformly over the family CSST? We do not know the\nanswer to this question, but the following subsections provide some partial answers by analyzing\nsome polynomial-time estimators that (up to logarithmic factors) achieve the optimal \u02dcO(1/n)-\nrate over some interesting sub-classes of CSST. In the next two sections, we turn to results of\nthis type.\n3.3\nOptimal rates for high SNR subclass\nIn this section, we describe a multi-step polynomial-time estimator that (up to logarithmic\nfactors) can achieve the optimal \u02dcO(1/n) rate over an interesting subclass of CSST. This subset\ncorresponds to matrices M that have a relatively high signal-to-noise ratio (SNR), meaning\nthat no entries of M fall within a certain window of 1/2. More formally, for some \u03b3 \u2208(0, 1\n2),\nwe de\ufb01ne the class\nCHIGH(\u03b3) =\n\b\nM \u2208CSST | max(Mij, Mji) \u22651/2 + \u03b3 \u2200i \u0338= j\n\t\n.\n(11)\nBy construction, for any matrix CHIGH(\u03b3), the amount of information contained in each obser-\nvation is bounded away from zero uniformly in n, as opposed to matrices in which some large\nsubset of entries have values equal (or arbitrarily close) to 1\n2. In terms of estimation di\ufb03culty,\n9\nthis SNR restriction does not make the problem substantially easier: as the following theorem\nshows, the minimax mean-squared error remains lower bounded by a constant multiple of 1/n.\nMoreover, we can demonstrate a polynomial-time algorithm that achieves this optimal mean\nsquared error up to logarithmic factors.\nThe following theorem applies to any \ufb01xed \u03b3 \u2208(0, 1\n2] independent of n, and involves con-\nstants (c\u2113, cu, c) that may depend on \u03b3 but are independent of n.\nTheorem 3. There is a constant c\u2113> 0 such that\ninf\nf\nM\nsup\nM\u2217\u2208CHIGH(\u03b3)\n1\nn2 E\n\u0002\n|||f\nM \u2212M\u2217|||2\nF] \u2265c\u2113\nn ,\n(12a)\nwhere the in\ufb01mum ranges over all estimators. Moreover, there is a two-stage estimator c\nM,\ncomputable in polynomial-time, for which\nP\nh 1\nn2 |||c\nM \u2212M\u2217|||2\nF \u2265cu log2(n)\nn\ni\n\u2264c\nn2 ,\n(12b)\nvalid for any M\u2217\u2208CHIGH(\u03b3).\nAs before, since the ratio\n1\nn2 |||c\nM \u2212M\u2217|||2\nF is at most 1, so the tail bound (12b) implies that\nsup\nM\u2217\u2208CHIGH(\u03b3)\n1\nn2 E[|||c\nM \u2212M\u2217|||2\nF] \u2264cu log2(n)\nn\n+ c\nn2 \u2264c\u2032\nu log2(n)\nn\n.\n(13)\nWe provide the proof of this theorem in Section 5.3. As with our proof of the lower bound in\nTheorem 1, we prove the lower bound by considering the sub-class of matrices that are free\nonly on the two diagonals just above and below the main diagonal. We now provide a brief\nsketch for the proof of the upper bound (12b). It is based on analyzing the following two-step\nprocedure:\n1. In the \ufb01rst step of algorithm, we \ufb01nd a permutation b\u03c0FAS of the n items that minimizes\nthe total number of disagreements with the observations.\n(For a given ordering, we say\nthat any pair of items (i, j) are in disagreement with the observation if either i is rated\nhigher than j in the ordering and Yij = 0, or if i is rated lower than j in the ordering\nand Yij = 1.) The problem of \ufb01nding such a disagreement-minimizing permutation b\u03c0FAS is\ncommonly known as the minimum feedback arc set (FAS) problem. It is known to be NP-\nhard in the worst-case [ACN08, Alo06], but our set-up has additional probabilistic structure\nthat allows for polynomial-time solutions with high probability. In particular, we call upon a\npolynomial-time algorithm due to Braverman and Mossel [BM08] that, under the model (11),\nis guaranteed to \ufb01nd the exact solution to the FAS problem with high probability. Viewing\nthe FAS permutation b\u03c0FAS as an approximation to the true permutation \u03c0\u2217, the novel techni-\ncal work in this \ufb01rst step is show that b\u03c0FAS is \u201cgood enough\u201d for Frobenius norm estimation,\nin the sense that for any matrix M\u2217\u2208CHIGH(\u03b3), it satis\ufb01es the bound\n1\nn2 |||\u03c0\u2217(M\u2217) \u2212b\u03c0FAS(M\u2217)|||2\nF \u2264c log n\nn\n(14a)\nwith high probability. In this statement, for any given permutation \u03c0, we have used \u03c0(M\u2217)\nto denote the matrix obtained by permuting the rows and columns of M\u2217by \u03c0. The term\n1\nn2 |||\u03c0\u2217(M\u2217) \u2212b\u03c0FAS(M\u2217)|||2\nF can be viewed in some sense as the bias in estimation incurred\nfrom using b\u03c0FAS in place of \u03c0\u2217.\n10\n2. Next we de\ufb01ne CBISO as the class of \u201cbivariate isotonic\u201d matrices, that is, matrices M \u2208\n[0, 1]n\u00d7n that satisfy the linear constraints Mij = 1 \u2212Mji for all (i, j) \u2208[n]2, and Mk\u2113\u2265Mij\nwhenever k \u2264i and \u2113\u2265j. This class corresponds to the subset of matrices CSST that are faith-\nful with respect to the identity permutation. Letting b\u03c0FAS(CBISO) = {b\u03c0FAS(M), M \u2208CBISO}\ndenote the image of this set under b\u03c0FAS, the second step involves computing the constrained\nleast-squares estimate\nc\nM \u2208\narg min\nM\u2208b\u03c0FAS(CBISO)\n|||Y \u2212M|||2\nF.\n(14b)\nSince the set b\u03c0FAS(CBISO) is a convex polytope, with a number of facets that grows polynomi-\nally in n, the constrained quadratic program (14b) can be solved in polynomial-time. The\n\ufb01nal step in the proof of Theorem 3 is to show that the estimator c\nM also has mean-squared\nerror that is upper bounded by a constant multiple of log2(n)\nn\n.\nOur analysis shows that for any \ufb01xed \u03b3 \u2208(0, 1\n2], the proposed two-step estimator works well\nfor any matrix M\u2217\u2208CHIGH(\u03b3). Since this two-step estimator is based on \ufb01nding a minimum\nfeedback arc set (FAS) in the \ufb01rst step, it is natural to wonder whether an FAS-based estimator\nworks well over the full class CSST. Somewhat surprisingly the answer to this question turns out\nto be negative: we refer the reader to Appendix C for more intuition and details on why the\nminimal FAS estimator does not perform well over the full class.\n3.4\nOptimal rates for parametric subclasses\nLet us now return to the class of parametric models CPAR(F) introduced earlier in Section 2.3.\nAs shown previously in Proposition 1, this class is much smaller than the class CSST, in the\nsense that there are models in CSST that cannot be well-approximated by any parametric model.\nNonetheless, in terms of minimax rates of estimation, these classes di\ufb00er only by logarithmic\nfactors. An advantage of the parametric class is that it is possible to achieve the 1/n minimax\nrate by using a simple, polynomial-time estimator. In particular, for any log concave function\nF, the maximum likelihood estimate bwML can be obtained by solving a convex program. This\nMLE induces a matrix estimate M( bwML) via Equation (4), and the following result shows that\nthis estimator is minimax-optimal up to constant factors.\nTheorem 4. Suppose that F is strictly increasing, strongly log-concave and twice di\ufb00erentiable.\nThen there is a constant c\u2113> 0, depending only on F, such that the minimax risk over CPAR(F)\nis lower bounded as\ninf\nf\nM\nsup\nM\u2217\u2208CPAR(F)\n1\nn2 E[|||f\nM \u2212M\u2217|||2\nF] \u2265c\u2113\nn ,\n(15a)\nConversely, there is a constant cu \u2265c\u2113, depending only on F, such that the matrix estimate\nM( bwML) induced by the MLE satis\ufb01es the bound\nsup\nM\u2217\u2208CPAR(F)\n1\nn2 E[|||M( bwML) \u2212M\u2217|||2\nF] \u2264cu\nn .\n(15b)\nTo be clear, the constants (c\u2113, cu) in this theorem are independent of n, but they do depend\non the speci\ufb01c properties of the given function F. We note that the stated conditions on F\nare true for many popular parametric models, including (for instance) the Thurstone and BTL\nmodels.\n11\nWe provide the proof of Theorem 4 in Section 5.4.\nThe lower bound (15a) is, in fact,\nstronger than the the lower bound in Theorem 1, since the supremum is taken over a smaller\nclass. The proof of the lower bound in Theorem 1 relies on matrices that cannot be realized by\nany parametric model, so that we pursue a di\ufb00erent route to establish the bound (15a). On the\nother hand, in order to prove the upper bound (15b), we make use of bounds on the accuracy\nof the MLE bwML from our own past work (see the paper [SBB+16]).\n3.5\nExtension to partial observations\nWe now consider the extension of our results to the setting in which not all entries of Y are\nobserved. Suppose instead that every entry of Y is observed independently with probability\npobs. In other words, the set of pairs compared is the set of edges of an Erd\u02ddos-R\u00b4enyi graph\nG(n, pobs) that has the n items as its vertices.\nIn this setting, we obtain an upper bound on the minimax risk of estimation by \ufb01rst setting\nYij = 1\n2 whenever the pair (i, j) is not compared, then forming a new (n \u00d7 n) matrix Y \u2032 as\nY \u2032 : =\n1\npobs\nY \u22121 \u2212pobs\n2pobs\n11T ,\n(16a)\nand \ufb01nally computing the least squares solution\nc\nM \u2208arg min\nM\u2208CSST\n|||Y \u2032 \u2212M|||2\nF.\n(16b)\nLikewise, the computationally-e\ufb03cient singular value thresholding estimator is also obtained\nby thresholding the singular values of Y \u2032 with a threshold \u03bbn = 3\nq\nn\npobs . See our discussion\nfollowing Theorem 5 for the motivation underlying the transformed matrix Y \u2032.\nThe parametric estimators continue to operate on the original (partial) observations, \ufb01rst\ncomputing a maximum likelihood estimate bwML of M\u2217using the observed data, and then com-\nputing the associated pairwise-comparison-probability matrix M( bwML) via (4).\nTheorem 5. In the setting where each pair is observed with a probability pobs, there are positive\nuniversal constants c\u2113, cu and c0 such that:\n(a) The minimax risk is sandwiched as\nc\u2113\npobsn \u2264inf\nf\nM\nsup\nM\u2217\u2208CSST\n1\nn2 E[|||f\nM \u2212M\u2217|||2\nF] \u2264cu(log n)2\npobsn\n,\n(17a)\nwhen pobs \u2265c0\nn .\n(b) The soft-SVT estimator, c\nM\u03bbn with \u03bbn = 3\nq\nn\npobs , satis\ufb01es the bound\nsup\nM\u2217\u2208CSST\n1\nn2 E[|||c\nM\u03bbn \u2212M\u2217|||2\nF] \u2264\ncu\n\u221anpobs\n.\n(17b)\n(c) For a parametric sub-class based on a strongly log-concave and smooth F, the estimator\nM( bwML) induced by the maximum likelihood estimate bwML of the parameter vector w\u2217has\nmean-squared error upper bounded as\nsup\nM\u2217\u2208CPAR(F)\n1\nn2 E[|||M( bwML) \u2212M\u2217|||2\nF] \u2264\ncu\npobsn,\n(17c)\nwhen pobs \u2265c0(log n)2\nn\n.\n12\nThe intuition behind the transformation (16a) is that the matrix Y \u2032 can equivalently be\nwritten in a linearized form as\nY \u2032 = M\u2217+\n1\npobs\nW \u2032,\n(18a)\nwhere W \u2032 has entries that are independent on and above the diagonal, satisfy skew-symmetry,\nand are distributed as\n[W \u2032]ij =\n\uf8f1\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f3\npobs( 1\n2 \u2212[M\u2217]ij) + 1\n2\nwith probability pobs[M\u2217]ij\npobs( 1\n2 \u2212[M\u2217]ij) \u22121\n2\nwith probability pobs(1 \u2212[M\u2217]ij)\npobs( 1\n2 \u2212[M\u2217]ij)\nwith probability 1 \u2212pobs.\n(18b)\nThe proofs of the upper bounds exploit the speci\ufb01c relation (18a) between the observations Y \u2032\nand the true matrix M\u2217, and the speci\ufb01c form of the additive noise (18b).\nThe result of Theorem 5(b) yields an a\ufb03rmative answer to the question, originally posed\nby Chatterjee [Cha14], of whether or not the singular value thresholding estimator can yield a\nvanishing error when pobs \u2264\n1\n\u221an.\nWe note that we do not have an analogue of the high-SNR result in the partial observations\ncase since having partial observations reduces the SNR. In general, we are interested in scalings\nof pobs which allow pobs \u21920 as n \u2192\u221e.\nThe noisy-sorting algorithm of Braverman and\nMossel [BM08] for the high-SNR case has computational complexity scaling as e\u03b3\u22124, and hence\nis not computable in time polynomial in n when \u03b3 < (log n)\u22121\n4 . This restriction disallows most\ninteresting scalings of pobs with n.\n4\nSimulations\nIn this section, we present results from simulations to gain a further understanding of the prob-\nlem at hand, in particular to understand the rates of estimation under speci\ufb01c generative mod-\nels. We investigate the performance of the soft-SVT estimator (Section 3.2) and the maximum\nlikelihood estimator under the Thurstone model (Section 2.3).4 The output of the SVT estima-\ntor need not lie in the set [0, 1]n\u00d7n of matrices; in our implementation, we take a projection of\nthe output of the SVT estimator on this set, which gives a constant factor reduction in the error.\nIn our simulations, we generate the ground truth M\u2217in the following \ufb01ve ways:\n\u2022 Uniform: The matrix M\u2217is generated by drawing\n\u0000n\n2\n\u0001\nvalues independently and uniformly at\nrandom in [1\n2, 1] and sorting them in descending order. The values are then inserted above\nthe diagonal of an (n \u00d7 n) matrix such that the entries decrease down a column or left along\na row. We then make the matrix skew-symmetric and permute the rows and columns.\n\u2022 Thurstone: The matrix M\u2217\u2208[\u22121, 1]n is generated by \ufb01rst choosing w\u2217uniformly at random\nfrom the set satisfying \u27e8w\u2217, 1\u27e9= 0. The matrix M\u2217is then generated from w\u2217via Equation (4)\nwith F chosen as the CDF of the standard normal distribution.\n4We could not compare the algorithm that underlies Theorem 3, since it is not easily implementable. In\nparticular, it relies on the algorithm due to Braverman and Mossel [BM08] to compute the feedback arc set\nminimizer. The computational complexity of this algorithm, though polynomial in n, has a large polynomial\ndegree which precludes it from being implemented for matrices of any reasonable size.\nThe simulations in this section add to the simulation results of Section 2.4 (Figure 1) demonstrating a large\nclass of matrices in the SST class that cannot be represented by any parametric class.\n13\n26\n27\n28\n29\n210\nNumber of items n\n2-12\n2-11\n2-10\n2-9\n2-8\n2-7\n2-6\n2-5\nError  ||c\nM\u2212M \u2217||2\nF /n2\n(a) Uniform\n26\n27\n28\n29\n210\nNumber of items n\n2-12\n2-11\n2-10\n2-9\n2-8\n2-7\n2-6\n2-5\nError  ||c\nM\u2212M \u2217||2\nF /n2\n(b) Thurstone\n26\n27\n28\n29\n210\nNumber of items n\n2-12\n2-11\n2-10\n2-9\n2-8\n2-7\n2-6\nError  ||c\nM\u2212M \u2217||2\nF /n2\n(c) BTL\n26\n27\n28\n29\n210\nNumber of items n\n2-6\n2-5\n2-4\n2-3\nError  ||c\nM\u2212M \u2217||2\nF /n2\n(d) High SNR\n26\n27\n28\n29\n210\nNumber of items n\n2-5\n2-4\n2-3\nError  ||c\nM\u2212M \u2217||2\nF /n2\n(e) Independent bands\nFigure 2. Errors of singular value thresholding (SVT) estimator and the Thurstone MLE under\ndi\ufb00erent methods to generate M \u2217.\n\u2022 Bradley-Terry-Luce (BTL): Identical to the Thurstone case, except that F is given by the\nsigmoid function.\n\u2022 High SNR: A setting studied previously by Braverman and Mossel [BM08], in which the noise\nis independent of the items being compared. Some global order is \ufb01xed over the n items, and\nthe comparison matrix M\u2217takes the values M\u2217\nij = 0.9 = 1 \u2212M\u2217\nji for every pair (i, j) where i\nis ranked above j in the underlying ordering. The entries on the diagonal are 0.5.\n\u2022 Independent bands: The matrix M\u2217is chosen with diagonal entries all equal to 1\n2. Entries\non diagonal band immediately above the diagonal itself are chosen i.i.d. and uniformly at\nrandom from [1\n2, 1]. The band above is then chosen uniformly at random from the allowable\nset, and so on. The choice of any entry in this process is only constrained to be upper bounded\nby 1 and lower bounded by the entries to its left and below. The entries below the diagonal\nare chosen to make the matrix skew-symmetric.\nFigure 2 depicts the results of the simulations based on observations of the entire matrix Y .\nEach point is an average across 20 trials. The error bars in most cases are too small and hence\nnot visible. We see that the uniform case (Figure 2a) is favorable for both estimators, with\nthe error scaling as O( 1\n\u221an). With data generated from the Thurstone model, both estimators\ncontinue to perform well, and the Thurstone MLE yields an error of the order 1\nn (Figure 2b).\n14\nInterestingly, the Thurstone model also \ufb01ts relatively well when data is generated via the BTL\nmodel (Figure 2c). This behavior is likely a result of operating in the near-linear regime of\nthe logistic and the Gaussian CDF where the two curves are similar. In these two parametric\nsettings, the SVT estimator has squared error strictly worse than order 1\nn but better than\n1\n\u221an.\nThe Thurstone model, however, yields a poor \ufb01t for the model in the high-SNR (Figure 2d) and\nthe independent bands (Figure 2e) cases, incurring a constant error as compared to an error\nscaling as O( 1\n\u221an) for the SVT estimator. We recall that the poor performance of the Thurstone\nestimator was also described previously in Proposition 1 and Figure 1.\nIn summary, we see that while the Thurstone MLE estimator gives minimax optimal rates\nof estimation when the underlying model is parametric, it can be inconsistent when the para-\nmetric assumptions are violated. On the other hand, the SVT estimator is robust to violations\nof parametric assumptions, and while it does not necessarily give minimax-optimal rates, it\nremains consistent across the entire SST class. Finally, we remark that our theory predicts that\nthe least squares estimator, if implementable, would outperform both these estimators in terms\nof statistical error.\n5\nProofs of main results\nThis section is devoted to the proofs of our main results\u2013namely, Theorems 1 through 5.\nThroughout these and other proofs, we use the notation {c, c\u2032, c0, C, C\u2032} and so on to denote\npositive constants whose values may change from line to line. In addition, we assume through-\nout that n is lower bounded by a universal constant so as to avoid degeneracies. For any square\nmatrix A \u2208Rn\u00d7n, we let {\u03c31(A), . . . , \u03c3n(A)} denote its singular values (ordered from largest\nto smallest), and similarly, for any symmetric matrix M \u2208Rn\u00d7n, we let {\u03bb1(M), . . . , \u03bbn(M)}\ndenote its ordered eigenvalues. The identity permutation is one where item i is the ith most\npreferred item, for every i \u2208[n].\n5.1\nProof of Theorem 1\nThis section is devoted to the proof of Theorem 1, including both the upper and lower bounds\non the minimax risk in squared Frobenius norm.\n5.1.1\nProof of upper bound\nDe\ufb01ne the di\ufb00erence matrix b\u2206: =c\nM- M\u2217between M\u2217and the optimal solution c\nM to the\nconstrained least-squares problem.\nSince c\nM is optimal and M\u2217is feasible, we must have\n|||Y \u2212c\nM|||2\nF \u2264|||Y \u2212M\u2217|||2\nF, and hence following some algebra, we arrive at the basic inequality\n1\n2|||b\u2206|||2\nF \u2264\u27e8\u27e8b\u2206, W\u27e9\u27e9,\n(19)\nwhere W \u2208Rn\u00d7n is the noise matrix in the observation model (1), and \u27e8\u27e8A, B\u27e9\u27e9: = trace(AT B)\ndenotes the trace inner product.\nWe introduce some additional objects that are useful in our analysis. The class of bivariate\nisotonic matrices CBISO is de\ufb01ned as\nCBISO : =\n\b\nM \u2208[0, 1]n\u00d7n | Mk\u2113\u2265Mij whenever k \u2264i and \u2113\u2265j\n\t\n.\n(20)\n15\nFor a given permutation \u03c0 and matrix M, we let \u03c0(M) denote the matrix obtained by applying\n\u03c0 to its rows and columns. We then de\ufb01ne the set\nCDIFF : =\nn\n\u03c01(M1) \u2212\u03c02(M2) | for some M1, M2 \u2208CBISO, and perm. \u03c01 and \u03c02\no\n.\n(21)\ncorresponding to the set of di\ufb00erence matrices. Note that CDIFF \u2282[\u22121, 1]n\u00d7n by construction.\nOne can verify that for any M\u2217\u2208CSST, we are guaranteed the inclusion\n{M \u2212M\u2217| M \u2208CSST, |||M \u2212M\u2217|||F \u2264t} \u2282CDIFF \u2229{|||D|||F \u2264t}.\nConsequently, the error matrix b\u2206must belong to CDIFF, and so must satisfy the properties\nde\ufb01ning this set. Moreover, as we discuss below, the set CDIFF is star-shaped, and this property\nplays an important role in our analysis.\nFor each choice of radius t > 0, de\ufb01ne the random variable\nZ(t) : =\nsup\nD\u2208CDIFF,|||D|||F\u2264t\n\u27e8\u27e8D, W\u27e9\u27e9.\n(22)\nUsing our earlier basic inequality (19), the Frobenius norm error |||b\u2206|||F then satis\ufb01es the bound\n1\n2|||b\u2206|||2\nF \u2264\u27e8\u27e8b\u2206, W\u27e9\u27e9\u2264Z\n\u0000|||b\u2206|||F\n\u0001\n.\n(23)\nThus, in order to obtain a high probability bound, we need to understand the behavior of the\nrandom quantity Z(\u03b4).\nOne can verify that the set CDIFF is star-shaped, meaning that \u03b1D \u2208CDIFF for every \u03b1 \u2208[0, 1]\nand every D \u2208CDIFF. Using this star-shaped property, we are guaranteed that there is a non-\nempty set of scalars \u03b4n > 0 satisfying the critical inequality\nE[Z(\u03b4n)] \u2264\u03b42\nn\n2 .\n(24)\nOur interest is in the smallest (strictly) positive solution \u03b4n to the critical inequality (24), and\nmoreover, our goal is to show that for every t \u2265\u03b4n, we have |||b\u2206|||F \u2264c\u221at\u03b4n with probability at\nleast 1 \u2212c1e\u2212c2nt\u03b4n.\nFor each t > 0, de\ufb01ne the \u201cbad\u201d event At as\nAt =\n\b\n\u2203\u2206\u2208CDIFF | |||\u2206|||F \u2265\np\nt\u03b4n\nand\n\u27e8\u27e8\u2206, W\u27e9\u27e9\u22652|||\u2206|||F\np\nt\u03b4n\n\t\n.\n(25)\nUsing the star-shaped property of CDIFF, it follows by a rescaling argument that\nP[At] \u2264P\n\u0002\nZ(\u03b4n) \u22652\u03b4n\np\nt\u03b4n\n\u0003\nfor all t \u2265\u03b4n.\nThe entries of W lie in [\u22121, 1], are i.i.d. on and above the diagonal, are zero-mean, and satisfy\nskew-symmetry. Moreover, the function W 7\u2192Z(t) is convex and Lipschitz with parameter\nt. Consequently, from known concentration bounds(e.g., [Led01, Theorem 5.9], [Sam00]) for\nconvex Lipschitz functions, we have\nP\n\u0002\nZ(\u03b4n) \u2265E[Z(\u03b4n)] +\np\nt\u03b4n\u03b4n\n\u0003\n\u22642e\u2212c1t\u03b4n\nfor all t \u2265\u03b4n.\nBy the de\ufb01nition of \u03b4n, we have E[Z(\u03b4n)] \u2264\u03b42\nn \u2264\u03b4n\n\u221at\u03b4n for any t \u2265\u03b4n, and consequently\nP[At] \u2264P[Z(\u03b4n) \u22652\u03b4n\np\nt\u03b4n\n\u0003\n\u22642e\u2212c1t\u03b4n\nfor all t \u2265\u03b4n.\n16\nConsequently, either |||b\u2206|||F \u2264\u221at\u03b4n, or we have |||b\u2206|||F > \u221at\u03b4n. In the latter case, conditioning\non the complement Ac\nt, our basic inequality implies that 1\n2|||b\u2206|||2\nF \u22642|||b\u2206|||F\n\u221at\u03b4n, and hence\n|||b\u2206|||F \u22644\u221at\u03b4n with probability at least 1 \u22122e\u2212c1t\u03b4n. Putting together the pieces yields that\n|||b\u2206|||F \u2264c0\np\nt\u03b4n\n(26)\nwith probability at least 1 \u22122e\u2212c1t\u03b4n for every t \u2265\u03b4n.\nIn order to determine a feasible \u03b4n satisfying the critical inequality (24), we need to bound\nthe expectation E[Z(\u03b4n)].\nWe do using Dudley\u2019s entropy integral and bounding the metric\nentropies of certain sub-classes of matrices.\nIn particular, the remainder of this section is\ndevoted to proving the following claim:\nLemma 1. There is a universal constant C such that\nE[Z(t)] \u2264C\nn\nn log2(n) + t\np\nn log n\no\n,\n(27)\nfor all t \u2208[0, 2n].\nGiven this lemma, we see that the critical inequality (24) is satis\ufb01ed with \u03b4n = C\u2032\u221an log n.\nConsequently, from our bound (26), there are universal positive constants C\u2032\u2032 and c1 such that\n|||b\u2206|||2\nF\nn2\n\u2264C\u2032\u2032 log2(n)\nn\n,\nwith probability at least 1 \u22122e\u2212c1n(log n)2, which completes the proof.\nProof of Lemma 1: It remains to prove Lemma 1, and we do so by using Dudley\u2019s entropy\nintegral, as well as some auxiliary results on metric entropy. We use the notation log N(\u03f5, C, \u03c1)\nto denote the \u03f5 metric entropy of the class C in the metric \u03c1. Our proof requires the following\nauxiliary lemma:\nLemma 2. For every \u03f5 > 0, we have the metric entropy bound\nlog N(\u03f5, CDIFF, |||.|||F) \u22649n2\n\u03f52\n\u0000log n\n\u03f5\n\u00012 + 9n log n.\nSee the end of this section for the proof of this claim. Letting BF (t) denote the Frobenius norm\nball of radius t, the truncated form of Dudley\u2019s entropy integral inequality (e.g., [VDVW96,\nCorollary 2.2.8]) yields that the mean E[Z(t)] is upper bounded as\nE[Z(t)]] \u2264c\ninf\n\u03b4\u2208[0,n]\nn\nn\u03b4 +\nZ t\n\u03b4\n2\np\nlog N(\u03f5, CDIFF \u2229BF (t), |||.|||F)d\u03f5\no\n\u2264c\nn\nn\u22128 +\nZ t\n1\n2 n\u22129\np\nlog N(\u03f5, CDIFF, |||.|||F)d\u03f5\no\n,\n(28)\nwhere the second step follows by setting \u03b4 = n\u22129, and making use of the set inclusion (CDIFF \u2229BF (t)) \u2286CDIFF.\nFor any \u03f5 \u22651\n2n\u22129, applying Lemma 2 yields the upper bound\np\nlog N(\u03f5, CDIFF, |||.|||F) \u2264c\nnn\n\u03f5 log n\n\u03f5 +\np\nn log n\no\n.\n17\nOver the range \u03f5 \u2265n\u22129/2, we have log n\n\u03f5 \u2264c log n, and hence\np\nlog N(\u03f5, CDIFF, |||.|||F) \u2264c\nnn\n\u03f5 log n +\np\nn log n\no\n.\nSubstituting this bound into our earlier inequality (28) yields\nE[Z(t)] \u2264c\nn\nn\u22128 +\n\u0000n log n\n\u0001\nlog(nt) + t\np\nn log n\no\n(i)\n\u2264c\nn\u0000n log n\n\u0001\nlog(n2) + t\np\nn log n\no\n\u2264c\nn\nn log2(n) + t\np\nn log n\no\n,\nwhere step (i) uses the upper bound t \u22642n.\nThe only remaining detail is to prove Lemma 2.\nProof of Lemma 2:\nWe \ufb01rst derive an upper bound on the metric entropy of the class CBISO\nde\ufb01ned previously in equation (20).\nIn particular, we do so by relating it to the set of all\nbivariate monotonic functions on the square [0, 1] \u00d7 [0, 1]. Denoting this function class by F,\nfor any matrix M \u2208CBISO, we de\ufb01ne a function gM \u2208F via\ngM(x, y) = M\u2308n(1\u2212x)\u2309,\u2308ny\u2309.\nIn order to handle corner conditions, we set M0,i = M1,i and Mi,0 = Mi,1 for all i. With this\nde\ufb01nition, we have\n\u2225gM\u22252\n2 =\nZ 1\nx=0\nZ 1\ny=0\n(gM(x, y))2dxdy = 1\nn2\nn\nX\ni=1\nn\nX\nj=1\nM2\ni,j = 1\nn2 |||M|||2\nF.\nAs a consequence, the metric entropy can be upper bounded as\nlog N(\u03f5, CBISO, |||.|||F) \u2264log N\n\u0010 \u03f5\nn, F, \u2225.\u22252\n\u0011\n(i)\n\u2264n2\n\u03f52\n\u0000log n\n\u03f5\n\u00012,\n(29)\nwhere inequality (i) follows from Theorem 1.1 of Gao and Wellner [GW07].\nWe now bound the metric entropy of CDIFF in terms of the metric entropy of CBISO. For any\n\u03f5 > 0, let C\u03f5\nBISO denote an \u03f5-covering set in CBISO that satis\ufb01es the inequality (29). Consider the\nset\nC\u03f5\nDIFF : = {\u03c01(M1) \u2212\u03c02(M2) | for some permutations \u03c01, \u03c02 and some M1, M2 \u2208C\u03f5/2\nBISO}.\nFor any D \u2208CDIFF, we can write D = \u03c01(M\u2032\n1)\u2212\u03c02(M\u2032\n2) for some permutations \u03c01 and \u03c02 and some\nmatrices M\u2032\n1 and M\u2032\n2 \u2208CBISO. We know there exist matrices M1, M2 \u2208C\u03f5/2\nBISO such that |||M\u2032\n1 \u2212\nM1|||F \u2264\u03f5/2 and |||M\u2032\n2 \u2212M2|||F \u2264\u03f5/2. With these choices, we have \u03c01(M1) \u2212\u03c02(M2) \u2208C\u03f5\nDIFF,\nand moreover\n|||D \u2212(\u03c01(M1) \u2212\u03c02(M2))|||2\nF \u22642|||\u03c01(M1) \u2212\u03c01(M\u2032\n1)|||2\nF + 2|||\u03c02(M2) \u2212\u03c01(M\u2032\n2)|||2\nF\n\u2264\u03f52.\n18\nThus the set C\u03f5\nDIFF forms an \u03f5-covering set for the class CDIFF. One can now count the number of\nelements in this set to \ufb01nd that\nN(\u03f5, CDIFF, |||.|||F) \u2264\n\u0000n!N(\u03f5/2, CBISO, |||.|||F)\n\u00012.\nSome straightforward algebraic manipulations yield the claimed result.\n5.1.2\nProof of lower bound\nWe now turn to the proof of the lower bound in Theorem 1. We may assume that the correct\nrow/column ordering is \ufb01xed and known to be the identity permutation. Here we are using\nthe fact that revealing the knowledge of this ordering cannot make the estimation problem any\nharder. Recalling the de\ufb01nition (20) of the bivariate isotonic class CBISO, consider the subclass\nC\u2032\nSST : = {M \u2208CBISO | Mi,j = 1 when j > i + 1 and Mi,j = 1 \u2212Mj,i when j \u2264i}\nAny matrix M is this subclass can be identi\ufb01ed with the vector q = q(M) \u2208Rn\u22121 with elements\nqi : = Mi,i+1. The only constraint imposed on q(M) by the inclusion M \u2208CSST is that qi \u2208[ 1\n2, 1]\nfor all i = 1, . . . , n \u22121.\nIn this way, we have shown that the di\ufb03culty of estimating M\u2217\u2208C\u2032\nSST is at least as\nhard as that of estimating a vector q \u2208[ 1\n2, 1]n\u22121 based on observing the random vector\nY = {Y1,2, . . . , Yn\u22121,n} with independent coordinates, and such that each Yi,i+1 \u223cBer(qi).\nFor this problem, it is easy to show that there is a universal constant c\u2113> 0 such that\ninf\nbq\nsup\nq\u2208[ 1\n2 ,1]n\u22121\nE\nh\n\u2225bq \u2212q\u22252\n2\ni\n\u2265c\u2113\n2 n,\nwhere the in\ufb01mum is taken over all measurable functions Y 7\u2192bq. Putting together the pieces,\nwe have shown that\ninf\nc\nM\nsup\nM\u2217\u2208CSST\n1\nn2 E[||| \u02c6\nM \u2212M\u2217|||2\nF] \u22652\nn2 inf\nbq\nsup\nq\u2208[0.5,1]n\u22121 E[\u2225bq \u2212q\u22252\n2] \u2265c\u2113\nn ,\nas claimed.\n5.2\nProof of Theorem 2\nRecall from equation (1) that we can write our observation model as Y = M\u2217+ W, where\nW \u2208Rn\u00d7n is a zero-mean matrix with entries that are drawn independently (except for the\nskew-symmetry condition) from the interval [\u22121, 1].\n5.2.1\nProof of upper bound\nOur proof of the upper bound hinges upon the following two lemmas.\nLemma 3. If \u03bbn \u22651.01|||W|||op, then\n|||T\u03bbn(Y ) \u2212M\u2217|||2\nF \u2264c\nn\nX\nj=1\nmin\n\b\n\u03bb2\nn, \u03c32\nj (M\u2217)\n\t\n,\nwhere c is a positive universal constant.\n19\nOur second lemma is an approximation-theoretic result:\nLemma 4. For any matrix M\u2217\u2208CSST and any s \u2208{1, 2, . . . , n \u22121}, we have\n1\nn2\nn\nX\nj=s+1\n\u03c32\nj (M\u2217) \u22641\ns.\nSee the end of this section for the proofs of these two auxiliary results.5\nBased on these two lemmas, it is easy to complete the proof of the theorem. The entries of\nW are zero-mean with entries in the interval [\u22121, 1], are i.i.d. on and above the diagonal, and\nsatisfy skew-symmetry. Consequently, we may apply Theorem 3.4 of Chatterjee [Cha14], which\nguarantees that\nP\nh\n|||W|||op > (2 + t)\u221an\ni\n\u2264ce\u2212f(t)n,\nwhere c is a universal constant, and the quantity f(t) is strictly positive for each t > 0. Thus,\nthe choice \u03bbn = 2.1\u221an guarantees that \u03bbn \u22651.01|||W|||op with probability at least 1 \u2212ce\u2212cn, as\nis required for applying Lemma 3. Applying this lemma guarantees that the upper bound\n|||T\u03bbn(Y ) \u2212M\u2217|||2\nF \u2264c\nn\nX\nj=1\nmin\n\b\nn, \u03c32\nj (M\u2217)\n\t\nhold with probability at least 1\u2212c1e\u2212c2n. From Lemma 4, with probability at least 1\u2212c1e\u2212c2n,\nwe have\n1\nn2 |||T\u03bbn(Y ) \u2212M\u2217|||2\nF \u2264c\nn s\nn + 1\ns\no\nfor all s \u2208{1, . . . , n}. Setting s = \u2308\u221an\u2309and performing some algebra shows that\nP\nh 1\nn2 |||T\u03bbn(Y ) \u2212M\u2217|||2\nF > cu\n\u221an\ni\n\u2264c1e\u2212c2n,\nas claimed. Since\n1\nn2 |||T\u03bbn(Y ) \u2212M\u2217|||2\nF \u22641, we are also guaranteed that\n1\nn2 E[|||T\u03bbn(Y ) \u2212M\u2217|||2\nF] \u2264cu\n\u221an + c1e\u2212c2n \u2264c\u2032\nu\n\u221an.\nProof of Lemma 3\nFix \u03b4 = 0.01. Let b be the number of singular values of M\u2217above\n\u03b4\n1+\u03b4\u03bbn,\nand let M\u2217\nb be the version of M\u2217truncated to its top b singular values. We then have\n|||T\u03bbn(Y ) \u2212M\u2217|||2\nF \u22642|||T\u03bbn(Y ) \u2212M\u2217\nb |||2\nF + 2|||M\u2217\nb \u2212M\u2217|||2\nF\n\u22642 rank(T\u03bbn(Y ) \u2212M\u2217\nb )|||T\u03bbn(Y ) \u2212M\u2217\nb |||2\nop + 2\nn\nX\nj=b+1\n\u03c32\nj (M\u2217).\nWe claim that T\u03bbn(Y ) has rank at most b. Indeed, for any j \u2265b + 1, we have\n\u03c3j(Y ) \u2264\u03c3j(M\u2217) + |||W|||op \u2264\u03bbn,\n5As a side note, in Section 5.2.2 we present a construction of a matrix M \u2217\u2208CSST using which we show that\nthe bound of Lemma 4 is sharp up to a constant factor when s = o(n); this result is essential in proving the\nsharpness of the result of Theorem 2.\n20\nwhere we have used the facts that \u03c3j(M\u2217) \u2264\n\u03b4\n1+\u03b4\u03bbn for every j \u2265b + 1 and \u03bbn \u2265(1 + \u03b4)|||W|||op.\nAs a consequence we have \u03c3j(T\u03bbn(Y )) = 0, and hence rank(T\u03bbn(Y ) \u2212M\u2217\nb ) \u22642b. Moreover, we\nhave\n|||T\u03bbn(Y ) \u2212M\u2217\nb |||op \u2264|||T\u03bbn(Y ) \u2212Y |||op + |||Y \u2212M\u2217|||op + |||M\u2217\u2212M\u2217\nb |||op\n\u2264\u03bbn + |||W|||op +\n\u03b4\n1 + \u03b4\u03bbn\n\u22642\u03bbn.\nPutting together the pieces, we conclude that\n|||T\u03bbn(Y ) \u2212M\u2217|||2\nF \u226416b\u03bb2\nn + 2\nn\nX\nj=b+1\n\u03c32\nj (M\u2217)\n(i)\n\u2264C\nn\nX\nj=1\nmin{\u03c32\nj (M\u2217), \u03bb2\nn},\nfor some constant6 C. Here inequality (i) follows since \u03c3j(M\u2217) \u2264\n\u03b4\n1+\u03b4\u03bbn whenever j \u2265b + 1\nand \u03c3j(M\u2217) >\n\u03b4\n1+\u03b4\u03bbn whenever j \u2264b.\nProof of Lemma 4\nIn this proof, we make use of a construction due to Chatterjee [Cha14].\nFor a given matrix M\u2217, we can de\ufb01ne the vector t \u2208Rn of row sums\u2014namely, with entries\nti = Pn\nj=1 M\u2217\nij for i \u2208[n]. Using this vector, we can de\ufb01ne a rank s approximation M to the\noriginal matrix M\u2217by grouping the rows according to the vector t according to the following\nprocedure:\n\u2022 Observing that each ti \u2208[0, n], let us divide the full interval [0, n] into s groups\u2014say of the\nform [0, n/s), [n/s, 2n/s), . . . [(s \u22121)n/s, n]. If ti falls into the interval \u03b1 for some \u03b1 \u2208[s], we\nthen map row i to the group G\u03b1 of indices.\n\u2022 For each group G\u03b1, we choose a particular row index k = k(\u03b1) \u2208G\u03b1 in an arbitrary fashion.\nFor every other row index i \u2208G\u03b1, we set Mij = Mkj for all j \u2208[n].\nBy construction, the matrix M has at most s distinct rows, and hence rank at most s. Let\nus now bound the Frobenius norm error in this rank s approximation. Fixing an arbitrary\ngroup index \u03b1 \u2208[s] and an arbitrary row in i \u2208G\u03b1, we then have\nn\nX\nj=1\n(M\u2217\nij \u2212Mij)2 \u2264\nn\nX\nj=1\n|M\u2217\nij \u2212Mij|.\nBy construction, we either have M\u2217\nij \u2265Mij for every j \u2208[n], or M\u2217\nij \u2264Mij for every j \u2208[n].\nThus, letting k \u2208G\u03b1 denote the chosen row, we are guaranteed that\nn\nX\nj=1\n|M\u2217\nij \u2212Mij| \u2264|ti \u2212tk| \u2264n\ns ,\nwhere we have used the fact the pair (ti, tk) must lie in an interval of length at most n/s.\nPutting together the pieces yields the claim.\n5.2.2\nProof of lower bound\nWe now turn to the proof of the lower bound in Theorem 2. We split our analysis into two\ncases, depending on the magnitude of \u03bbn.\n6To be clear, the precise value of the constant C is determined by \u03b4, which has been \ufb01xed as \u03b4 = 0.01.\n21\nCase 1:\nFirst suppose that \u03bbn \u2264\n\u221an\n3 . In this case, we consider the matrix M\u2217: = 1\n211T in\nwhich all items are equally good, so any comparison is simply a fair coin \ufb02ip. Let the observation\nmatrix Y \u2208{0, 1}n\u00d7n be arbitrary. By de\ufb01nition of the singular value thresholding operation,\nwe have |||Y \u2212T\u03bbn(Y )|||op \u2264\u03bbn, and hence the SVT estimator c\nM\u03bbn = T\u03bbn(Y ) has Frobenius\nnorm at most\n|||Y \u2212c\nM\u03bbn|||2\nF \u2264n\u03bb2\nn \u2264n2\n9 .\nSince M\u2217\u2208{1\n2}n\u00d7n and Y \u2208{0, 1}n\u00d7n, we are guaranteed that |||M\u2217\u2212Y |||F = n\n2 . Applying the\ntriangle inequality yields the lower bound\n|||c\nM\u03bbn \u2212M\u2217|||F \u2265|||M\u2217\u2212Y |||F \u2212|||c\nM\u03bbn \u2212Y |||F \u2265n\n2 \u2212n\n3 = n\n6 .\nCase 2:\nOtherwise, we may assume that \u03bbn >\n\u221an\n3 . Consider the matrix M\u2217\u2208Rn\u00d7n with\nentries\n[M\u2217]ij =\n\uf8f1\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f3\n1\nif i > j\n1\n2\nif i = j\n0\nif i < j.\n(30)\nBy construction, the matrix M\u2217corresponds to the degenerate case of noiseless comparisons.\nConsider the matrix Y \u2208Rn\u00d7n generated according to the observation model (1). (To be\nclear, all of its o\ufb00-diagonal entries are deterministic, whereas the diagonal is population with\ni.i.d. Bernoulli variates.) Our proof requires the following auxiliary result regarding the singular\nvalues of Y :\nLemma 5. The singular values of the observation matrix Y \u2208Rn\u00d7n generated by the noiseless\ncomparison matrix M\u2217satisfy the bounds\nn\n4\u03c0(i + 1) \u22121\n2 \u2264\u03c3n\u2212i\u22121(Y ) \u2264\nn\n\u03c0(i \u22121) + 1\n2\nfor all integers i \u2208[1, n\n6 \u22121].\nWe prove this lemma at the end of this section.\nTaking it as given, we get that \u03c3n\u2212i\u22121(Y ) \u2264\n\u221an\n3 for every integer i \u22652\u221an, and \u03c3n\u2212i(Y ) \u2265\nn\n50i\nfor every integer i \u2208[1, n\n25]. It follows that\nn\nX\ni=1\n(\u03c3i(Y ))21{\u03c3i(Y ) \u2264\n\u221an\n3 } \u2265\nn2\n2500\nn\n25\nX\ni=2\u221an\n1\ni2 \u2265cn\n3\n2 ,\nfor some universal constant c > 0.\nRecalling that \u03bbn \u2265\n\u221an\n3 , we have the lower bound\n|||Y \u2212c\nM\u03bbn|||2\nF \u2265cn\n3\n2 . Furthermore, since the observations (apart from the diagonal entries)\nare noiseless, we have |||Y \u2212M\u2217|||2\nF \u2264n\n4 . Putting the pieces together yields the lower bound\n|||c\nM\u03bbn \u2212M\u2217|||F \u2265|||c\nM\u03bbn \u2212Y |||F \u2212|||M\u2217\u2212Y |||F \u2265cn\n3\n4 \u2212\n\u221an\n2\n\u2265c\u2032n\n3\n4 ,\nwhere the \ufb01nal step holds when n is large enough (i.e., larger than a universal constant).\n22\nProof of Lemma 5:\nInstead of working with the original observation matrix Y , it is conve-\nnient to work with a transformed version. De\ufb01ne the matrix \u00afY : = Y \u2212diag(Y ) + In, so that\nthe matrix \u00afY is identical to Y except that all its diagonal entries are set to 1.\nUsing this\nintermediate object, de\ufb01ne the (n \u00d7 n) matrix\neY : = ( \u00afY ( \u00afY )T )\u22121 \u2212eneT\nn,\n(31)\nwhere en denotes the nth standard basis vector. One can verify that this matrix has entries\n[eY ]ij =\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f4\n\uf8f3\n1\nif i = j = 1 or i = j = n\n2\nif 1 < i = j < n\n\u22121\nif i = j + 1 or i = j \u22121\n0\notherwise.\nConsequently, it is equal to the graph Laplacian7 of an undirected chain graph on n nodes.\nConsequently, from standard results in spectral graph theory [BH11], the eigenvalues of eY are\ngiven by {4 sin2( \u03c0i\nn )}n\u22121\ni=0 . Recall the elementary sandwich relationship x\n2 \u2264sin x \u2264x, valid for\nevery x \u2208[0, \u03c0\n6 ]. Using this fact, we are guaranteed that\n\u03c02i2\nn2\n\u2264\u03bbi+1(eY ) \u22644\u03c02i2\nn2\nfor all integers i \u2208[1, n\n6 ].\n(32)\nWe now use this intermediate result to establish the claimed bounds on the singular values\nof Y . Observe that the matrices eY and ( \u00afY ( \u00afY )T )\u22121 di\ufb00er only by the rank one matrix eneT\nn.\nStandard results in matrix perturbation theory [Tho76] guarantee that a rank-one perturba-\ntion can shift the position (in the large-to-small ordering) of any eigenvalue by at most one.\nConsequently, the eigenvalues of the matrix ( \u00afY ( \u00afY )T )\u22121 must be sandwiched as\n\u03c02(i \u22121)2\nn2\n\u2264\u03bbi+1(( \u00afY ( \u00afY )T )\u22121) \u22644\u03c02(i + 1)2\nn2\nfor all integers i \u2208[1, n\n6 \u22121].\nIt follows that the singular values of \u00afY are sandwiched as\nn\n4\u03c0(i + 1) \u2264\u03c3n\u2212i\u22121( \u00afY ) \u2264\nn\n\u03c0(i \u22121)\nfor all integers i \u2208[1, n\n6 \u22121].\nObserve that \u00afY \u2212Y is a {0, 1\n2}-valued diagonal matrix, and hence ||| \u00afY \u2212Y |||op \u22641\n2. Conse-\nquently, we have maxi=1,...,n |\u03c3i(Y ) \u2212\u03c3i( \u00afY )| \u22641\n2, from which it follows that\nn\n4\u03c0(i + 1) \u22121\n2 \u2264\u03c3n\u2212i\u22121(Y ) \u2264\nn\n\u03c0(i \u22121) + 1\n2\nas claimed.\n5.3\nProof of Theorem 3\nWe now prove our results on the high SNR subclass of CSST, in particular establishing a lower\nbound and then analyzing the two-stage estimator described in Section 3.3 so as to obtain the\nupper bound.\n7In particular, the Laplacian of a graph is given by L = D \u2212A, where A is the graph adjacency matrix, and\nD is the diagonal degree matrix.\n23\n5.3.1\nProof of lower bound\nIn order to prove the lower bound, we follow the proof of the lower bound of Theorem 1, with\nthe only di\ufb00erence being that the vector q \u2208Rn\u22121 is restricted to lie in the interval [1\n2 +\u03b3, 1]n\u22121.\n5.3.2\nProof of upper bound\nWithout loss of generality, assume that the true matrix M\u2217is associated to the identity permu-\ntation. Recall that the second step of our procedure involves performing constrained regression\nover the set CBISO(b\u03c0FAS). The error in such an estimate is necessarily of two types: the usual esti-\nmation error induced by the noise in our samples, and in addition, some form of approximation\nerror that is induced by the di\ufb00erence between b\u03c0FAS and the correct identity permutation.\nIn order to formalize this notion, for any \ufb01xed permutation \u03c0, consider the constrained\nleast-squares estimator\nc\nM\u03c0 \u2208arg min\nM\u2208CBISO(\u03c0)\n|||Y \u2212M|||2\nF.\n(33)\nOur \ufb01rst result provides an upper bound on the error matrix c\nM\u03c0 \u2212M\u2217that involves both\napproximation and estimation error terms.\nLemma 6. There is a universal constant c0 > 0 such that error in the constrained LS esti-\nmate (33) satis\ufb01es the upper bound\n|||c\nM\u03c0 \u2212M\u2217|||2\nF\nc0\n\u2264|||M\u2217\u2212\u03c0(M\u2217)|||2\nF\n|\n{z\n}\nApprox. error\n+\nn log2(n)\n|\n{z\n}\nEstimation error\n(34)\nwith probability at least 1 \u2212c1e\u2212c2n.\nThere are two remaining challenges in the proof. Since the second step of our estimator\ninvolves the FAS-minimizing permutation b\u03c0FAS, we cannot simply apply Lemma 6 to it directly.\n(The permutation b\u03c0FAS is random, whereas this lemma applies to any \ufb01xed permutation). Con-\nsequently, we \ufb01rst need to extend the bound (34) to one that is uniform over a set that includes\nb\u03c0FAS with high probability. Our second challenge is to upper bound the approximation error\nterm |||M\u2217\u2212b\u03c0FAS(M\u2217)|||2\nF that is induced by using the permutation b\u03c0FAS instead of the correct\nidentity permutation.\nIn order to address these challenges, for any constant c > 0, de\ufb01ne the set\nb\u03a0(c) : = {\u03c0 | max\ni\u2208[n] |i \u2212\u03c0(i)| \u2264c log n}.\nThis set corresponds to permutations that are relatively close to the identity permutation in\nthe sup-norm sense. Our second lemma shows that any permutation in b\u03a0(c) is \u201cgood enough\u201d\nin the sense that the approximation error term in the upper bound (34) is well-controlled:\nLemma 7. For any M\u2217\u2208CBISO and any permutation \u03c0 \u2208b\u03a0(c), we have\n|||M\u2217\u2212\u03c0(M\u2217)|||2\nF \u22642c\u2032\u2032n log n,\n(35)\nwhere c\u2032\u2032 is a positive constant that may depend only on c.\n24\nTaking these two lemmas as given, let us now complete the proof of Theorem 3. (We return\nto prove these lemmas at the end of this section.) Braverman and Mossel [BM08] showed that\nfor the class CHIGH(\u03b3), there exists a positive constant c\u2014depending on \u03b3 but independent of\nn\u2014such that\nP\nh\nb\u03c0FAS \u2208b\u03a0(c)\ni\n\u22651 \u2212c3\nn2 .\n(36)\nFrom the de\ufb01nition of class b\u03a0(c), there is a positive constant c\u2032 (whose value may depend only\non c) such that its cardinality is upper bounded as\ncard(b\u03a0(c)) \u2264n2c\u2032 log n (i)\n\u2264e.5c2n,\nwhere the inequality (i) is valid once the number of items n is larger than some universal\nconstant. Consequently, by combining the union bound with Lemma 6 we conclude that, with\nprobability at least 1 \u2212c\u2032\n1e\u2212c\u2032\n2n \u2212c3\nn2 , the error matrix b\u2206FAS : = c\nMb\u03c0FAS \u2212M\u2217satis\ufb01es the upper\nbound (34). Combined with the approximation-theoretic guarantee from Lemma 7, we \ufb01nd\nthat\n|||b\u2206FAS|||2\nF\nc0\n\u2264|||M\u2217\u2212b\u03c0FAS(M\u2217)|||2\nF + n log2(n)\n\u2264c\u2032\u2032n log n + +n log2(n),\nfrom which the claim follows.\nIt remains to prove the two auxiliary lemmas, and we do so in the following subsections.\nProof of Lemma 6:\nThe proof of this lemma involves a slight generalization of the proof of\nthe upper bound in Theorem 1 (see Section 5.1.1 for this proof). From the optimality of c\nM\u03c0\nand feasibility of \u03c0(M\u2217) for the constrained least-squares program (33), we are guaranteed that\n|||Y \u2212c\nM\u03c0|||2\nF \u2264|||Y \u2212\u03c0(M\u2217)|||2\nF. Introducing the error matrix b\u2206\u03c0 : = c\nM\u03c0 \u2212M\u2217, some algebraic\nmanipulations yield the modi\ufb01ed basic inequality\n|||b\u2206\u03c0|||2\nF \u2264|||M\u2217\u2212\u03c0(M\u2217)|||2\nF + 2\u27e8\u27e8W, c\nM\u03c0 \u2212\u03c0(M\u2217)\u27e9\u27e9.\nLet us de\ufb01ne b\u2206: = c\nM\u03c0 \u2212\u03c0(M\u2217). Further, for each choice of radius t > 0, recall the de\ufb01nitions\nof the random variable Z(t) and event At from equations (22) and (25), respectively. With\nthese de\ufb01nitions, we have the upper bound\n|||b\u2206\u03c0|||2\nF \u2264|||M\u2217\u2212\u03c0(M\u2217)|||2\nF + 2Z\n\u0000|||b\u2206|||F\n\u0001\n.\n(37)\nLemma 2 proved earlier shows that the inequality E[Z(\u03b4n)] \u2264\u03b42\nn\n2 is satis\ufb01ed by \u03b4n = c\u221an log n.\nIn a manner identical to the proof in Section 5.1.1, one can show that\nP[At] \u2264P[Z(\u03b4n) \u22652\u03b4n\np\nt\u03b4n\n\u0003\n\u22642e\u2212c1t\u03b4n\nfor all t \u2265\u03b4n.\nGiven these results, we break the next step into two cases depending on the magnitude of b\u2206.\nCase I: Suppose |||b\u2206|||F \u2264\u221at\u03b4n. In this case, we have\n|||b\u2206\u03c0|||2\nF \u22642|||M\u2217\u2212\u03c0(M\u2217)|||2\nF + 2|||b\u2206|||2\nF\n\u22642|||M\u2217\u2212\u03c0(M\u2217)|||2\nF + t\u03b4n.\n25\nCase II: Otherwise, we must have |||b\u2206|||F > \u221at\u03b4n. Conditioning on the complement Ac\nt, our basic\ninequality (37) implies that\n|||b\u2206\u03c0|||2\nF \u2264|||M\u2217\u2212\u03c0(M\u2217)|||2\nF + 4|||b\u2206|||F\np\nt\u03b4n\n\u2264|||M\u2217\u2212\u03c0(M\u2217)|||2\nF + |||b\u2206|||2\nF\n8\n+ 32t\u03b4n,\n\u2264|||M\u2217\u2212\u03c0(M\u2217)|||2\nF + 2|||b\u2206\u03c0|||2\nF + 2|||M\u2217\u2212\u03c0(M\u2217)|||2\nF\n8\n+ 32t\u03b4n,\nwith probability at least 1 \u22122e\u2212c1t\u03b4n.\nFinally, setting t = \u03b4n = c\u221an log(n) in either case and re-arranging yields the bound (34).\nProof of Lemma 7:\nFor any matrix M and any value i, let Mi denote its ith row. Also\nde\ufb01ne the clipping function b : Z \u2192[n] via b(x) = min{max{1, x}, n}. Using this notation, we\nhave\n|||M\u2217\u2212\u03c0(M\u2217)|||2\nF =\nn\nX\ni=1\n\u2225M\u2217\ni \u2212M\u2217\n\u03c0\u22121(i)\u22252\n2\n\u2264\nn\nX\ni=1\nmax\n0\u2264j\u2264c log n{\u2225M\u2217\ni \u2212M\u2217\nb(i\u2212j)\u22252\n2, \u2225M\u2217\ni \u2212M\u2217\nb(i+j)\u22252\n2},\nwhere we have used the de\ufb01nition of the set b\u03a0(c) to obtain the \ufb01nal inequality. Since M\u2217\ncorresponds to the identity permutation, we have M\u2217\n1 \u2265M\u2217\n2 \u2265\u00b7 \u00b7 \u00b7 \u2265M\u2217\nn, where the inequalities\nare in the pointwise sense. Consequently, we have\n|||M\u2217\u2212\u03c0(M\u2217)|||2\nF \u2264\nn\nX\ni=1\nmax\nn\n\u2225M\u2217\ni \u2212M\u2217\nb(i\u2212c log n)\u22252\n2, \u2225M\u2217\ni \u2212M\u2217\nb(i+c log n)\u22252\n2\no\n\u22642\nn\u2212c log n\nX\ni=1\n\u2225M\u2217\ni \u2212M\u2217\ni+c log n\u22252\n2.\nOne can verify that the inequality Pk\u22121\ni=1 (ai \u2212ai+1)2 \u2264(a1 \u2212ak)2 holds for all ordered sequences\nof real numbers a1 \u2265a2 \u2265\u00b7 \u00b7 \u00b7 \u2265ak. As stated earlier, the rows of M\u2217dominate each other\npointwise, and hence we conclude that\n|||M\u2217\u2212\u03c0(M\u2217)|||2\nF \u22642c log n\u2225M\u2217\n1 \u2212M\u2217\nn\u22252\n2 \u22642cn log n,\nwhich establishes the claim (35).\n5.4\nProof of Theorem 4\nWe now turn to our theorem giving upper and lower bounds on estimating pairwise probability\nmatrices for parametric models. Let us begin with a proof of the claimed lower bound.\n5.4.1\nLower bound\nWe prove our lower bound by constructing a set of matrices that are well-separated in Frobenius\nnorm. Using this set, we then use an argument based on Fano\u2019s inequality to lower bound the\nminimax risk. Underlying our construction of the matrix collection is a collection of Boolean\nvectors. For any two Boolean vectors b, b\u2032 \u2208{0, 1}n, let dH(b, b\u2032) = Pn\nj=1 1[bj \u0338= b\u2032\nj] denote the\nHamming distance between them.\n26\nLemma 8. For any \ufb01xed \u03b1 \u2208(0, 1/4), there is a collection of Boolean vectors {b1, . . . , bT } such\nthat\nmin\n\b\ndH(bj, bk), dH(bj, 0)\n\t\n\u2265\u2308\u03b1n\u2309\nfor all distinct j \u0338= k \u2208{1, . . . , T}, and\n(38a)\nT \u2261T(\u03b1) \u2265exp\nn\n(n \u22121) DKL(2\u03b1\u22251\n2)\no\n\u22121.\n(38b)\nGiven the collection {bj, j \u2208[T(\u03b1)]} guaranteed by this lemma, we then de\ufb01ne the collection\nof real vectors {wj, j \u2208[T(\u03b1)]} via\nwj = \u03b4\n\u0010\nI \u22121\nn11T \u0011\nbj\nfor each j \u2208[T(\u03b1)],\nwhere \u03b4 \u2208(0, 1) is a parameter to be speci\ufb01ed later in the proof. By construction, for each\nindex j \u2208[T(\u03b1)], we have \u27e81, wj\u27e9= 0 and \u2225wj\u2225\u221e\u2264\u03b4. Based on these vectors, we then de\ufb01ne\nthe collection of matrices\n\b\nMj, j \u2208[T(\u03b1)]\n\t\nvia\n[Mk]ij : = F([wk]i \u2212[wk]j).\nBy construction, this collection of matrices is contained within our parametric family. We also\nclaim that they are well-separated in Frobenius norm:\nLemma 9. For any distinct pair j, k \u2208[T(\u03b1)], we have\n|||Mj \u2212Mk|||2\nF\nn2\n\u2265\u03b12\n4 (F(\u03b4) \u2212F(0))2.\n(39)\nIn order to apply Fano\u2019s inequality, our second requirement is an upper bound on the\nmutual information I(Y ; J), where J is a random index uniformly distributed over the index\nset [T] = {1, . . . , T}. By Jensen\u2019s inequality, we have I(Y ; J) \u2264\n1\n(T\n2)\nP\nj\u0338=k DKL(Pj\u2225Pk), where\nPj denotes the distribution of Y when the true underlying matrix is Mj. Let us upper bound\nthese KL divergences.\nFor any pair of distinct indices u, v \u2208[n]2, let xuv be a di\ufb00erencing vector\u2014that is, a vector\nwhose components u and v are set as 1 and \u22121, respectively, with all remaining components\nequal to 0. We are then guaranteed that\n\u27e8xuv, wj\u27e9= \u03b4\u27e8xuv, bj\u27e9,\nand\nF(\u27e8xuv, wj\u27e9) \u2208\n\b\nF(\u2212\u03b4), F(0), F(\u03b4)\n\t\n,\nwhere F(\u03b4) \u2265F(0) \u2265F(\u2212\u03b4) by construction. Using these facts, we have\nDKL(Pj\u2225Pk)\n(i)\n\u22642\nX\nu,v\u2208[n]\n\u0000F(\u27e8xuv, wj\u27e9) \u2212F(\u27e8xuv, wk\u27e9)\n\u00012\nmin{F(\u27e8xuv, wk\u27e9), 1 \u2212F(\u27e8xuv, wk\u27e9)}\n\u22642n2 (F(\u03b4) \u2212F(\u2212\u03b4))2\nF(\u2212\u03b4)\n\u22648n2 (F(\u03b4) \u2212F(0))2\nF(\u2212\u03b4)\n,\n(40)\nwhere the bound (i) follows from the elementary inequality a log a\nb \u2264(a \u2212b) a\nb for any two\nnumbers a, b \u2208(0, 1).\n27\nThis upper bound on the KL divergence (40) and lower bound on the Frobenius norm (39),\nwhen combined with Fano\u2019s inequality, imply that any estimator c\nM has its worst-case risk over\nour family lower bounded as\nsup\nj\u2208[T(\u03b1)]\n1\nn2 E\n\u0002\n|||c\nM \u2212M(wj)|||2\nF\n\u0003\n\u22651\n8\u03b12(F(\u03b4) \u2212F(0))2\u0010\n1 \u2212\n8\nF(\u2212\u03b4)n2(F(\u03b4) \u2212F(0))2 + log 2\nn\n\u0011\n.\nChoosing a value of \u03b4 > 0 such that (F(\u03b4) \u2212F(0))2 = F(\u2212\u03b4)\n80n\ngives the claimed result. (Such a\nvalue of \u03b4 is guaranteed to exist with F(\u2212\u03b4) \u2208[ 1\n4, 1\n2] given our assumption that F is continuous\nand strictly increasing.)\nThe only remaining details are to prove Lemmas 8 and 9.\nProof of Lemma 8:\nThe Gilbert-Varshamov bound [Gil52, Var57] guarantees the existence\nof a collection of vectors {b0, . . . , b \u00afT\u22121} contained with the Boolean hypercube {0, 1}n such that\n\u00afT \u22652n\u22121 \u0000 \u2308\u03b1n\u2309\u22121\nX\n\u2113=0\n\u0012n \u22121\n\u2113\n\u0013\u0001\u22121,\nand\ndH(bj, bk) \u2265\u2308\u03b1n\u2309\nfor all j \u0338= k, j, k \u2208[ \u00afT \u22121].\nMoreover, their construction allows loss of generality that the all-zeros vector is a member of\nthe set\u2014say b0 = 0. We are thus guaranteed that dH(bj, 0) \u2265\u2308\u03b1n\u2309for all j \u2208{1, . . . , \u00afT \u22121}.\nSince n \u22652 and \u03b1 \u2208(0, 1\n4), we have \u2308\u03b1n\u2309\u22121\nn\u22121\n\u22642\u03b1 \u22641\n2. Applying standard bounds on the\ntail of the binomial distribution yields\n1\n2n\u22121\n\u2308\u03b1n\u2309\u22121\nX\n\u2113=0\n\u0012n \u22121\n\u2113\n\u0013\n\u2264exp\n\u0010\n\u2212(n \u22121)DKL(\u2308\u03b1n\u2309\u22121\nn \u22121\n\u22251\n2)\n\u0011\n\u2264exp\n\u0010\n\u2212(n \u22121)DKL(2\u03b1\u22251\n2)\n\u0011\n.\nConsequently, the number of non-zero code words T : = \u00afT \u22121 is at least\nT(\u03b1) : = exp\n\u0010\n(n \u22121)DKL(2\u03b1\u22251\n2)\n\u0011\n\u22121.\nThus, the collection {b1, . . . , bT } has the desired properties.\nProof of Lemma 9:\nBy de\ufb01nition of the matrix ensemble, we have\n|||M(wj) \u2212M(wk)|||2\nF =\nX\nu,v\u2208[n]\n(F(\u27e8xuv, wj\u27e9) \u2212F(\u27e8xuv, wk\u27e9))2.\n(41)\nBy construction, the Hamming distances between the triplet of vectors {wj, wk, 0} are lower\nbounded dH(wj, 0) \u2265\u03b1n, dH(wk, 0) \u2265\u03b1n and dH(wj, wk) \u2265\u03b1n. We claim that this implies that\ncard\nn\nu \u0338= v \u2208[n]2 | \u27e8xuv, wj\u27e9\u0338= \u27e8xuv, wk\u27e9\no\n\u2265\u03b12\n4 n2.\n(42)\nTaking this auxiliary claim as given for the moment, applying it to Equation (41) yields the\nlower bound |||M(w1) \u2212M(w2)|||2\nF \u2265\n1\n4\u03b12n2(F(\u03b4) \u2212F(0))2, as claimed.\n28\nIt remains to prove the auxiliary claim (42). We relabel j = 1 and k = 2 for simplicity in\nnotation. For (y, z) \u2208{0, 1} \u00d7 {0, 1}, let set Iyz \u2286[n] denote the set of indices on which w1\ntakes value y and w2 takes value z. We then split the proof into two cases:\nCase 1: Suppose | I00 \u222aI11 |\u2265\u03b1n\n2 . The minimum distance condition dH(w1, w2) \u2265\u03b1n im-\nplies that | I01 \u222aI10 |\u2265\u03b1n. For any i \u2208I00 \u222aI11 and any j \u2208I01 \u222aI10, it must be that\n\u27e8xuv, w1\u27e9\u0338= \u27e8xuv, w2\u27e9. Thus there are at least \u03b12\n2 n2 such pairs of indices.\nCase 2: Otherwise, we may assume that | I00 \u222aI11 |< \u03b1n\n2 . This condition, along with the\nminimum Hamming weight conditions dH(w1, 0) \u2265\u03b1n and dH(w2, 0) \u2265\u03b1n, gives I10 \u2265\u03b1n\n2 and\nI01 \u2265\u03b1n\n2 . For any i \u2208I01 and any j \u2208I10, it must be that \u27e8xuv, w1\u27e9\u0338= \u27e8xuv, w2\u27e9. Thus there\nare at least \u03b12\n4 n2 such pairs of indices.\n5.4.2\nUpper bound\nIn our earlier work [SBB+16, Theorem 2b] we prove that when F is strongly log-concave and\ntwice di\ufb00erentiable, then there is a universal constant cu such that the maximum likelihood\nestimator bwML has mean squared error at most\nsup\nw\u2217\u2208[\u22121,1]n,\u27e8w\u2217, 1\u27e9=0\nE[\u2225bwML \u2212w\u2217\u22252\n2] \u2264cu.\n(43)\nMoreover, given the log-concavity assumption, the MLE is computable in polynomial-time. Let\nM( bwML) and M(w\u2217) denote the pairwise comparison matrices induced, via Equation (4), by\nbwML and w\u2217. It su\ufb03ces to bound the Frobenius norm |||M( bwML) \u2212M(w\u2217)|||F.\nConsider any pair of vectors w1 and w2 that lie in the hypercube [\u22121, 1]n. For any pair of\nindices (i, j) \u2208[n]2, we have\n((M(w1))ij \u2212(M(w2))ij)2 = (F(w1\ni \u2212w1\nj) \u2212F(w2\ni \u2212w2\nj))2 \u2264\u03b62((w1\ni \u2212w1\nj) \u2212(w2\ni \u2212w2\nj))2,\nwhere we have de\ufb01ned \u03b6 : =\nmax\nz\u2208[\u22121,1] F \u2032(z). Putting together the pieces yields\n|||M(w1) \u2212M(w2)|||2\nF \u2264\u03b62(w1 \u2212w2)T (nI \u221211T )(w1 \u2212w2) = n\u03b62\u2225w1 \u2212w2\u22252\n2.\n(44)\nApplying this bound with w1 = bwML and w2 = w\u2217and combining with the bound (43) yields\nthe claim.\n5.5\nProof of Theorem 5\nWe now turn to the proof of Theorem 5, which characterizes the behavior of di\ufb00erent estimators\nfor the partially observed case.\n5.5.1\nProof of part (a)\nIn this section, we prove the lower and upper bounds stated in part (a).\nProof of lower bound:\nWe begin by proving the lower bound in equation (17a). The Gilbert-\nVarshamov bound [Gil52, Var57] guarantees the existence of a set of vectors {b1, . . . , bT } in the\nBoolean cube {0, 1}\nn\n2 with cardinality at least T : = 2cn such that\ndH(bj, bk) \u2265\u23080.1n\u2309\nfor all distinct pairs j, k \u2208[T] : = {1, . . . , T}.\n29\nFixing some \u03b4 \u2208(0, 1\n4) whose value is to be speci\ufb01ed later, for each k \u2208[T], we de\ufb01ne a matrix\nMk \u2208CSST with entries\n[Mk]uv =\n(\n1\n2 + \u03b4\nif u \u2264n\n2 , [bk]u = 1 and v \u2265n\n2\n1\n2\notherwise,\nfor every pair of indices u \u2264v. We complete the matrix by setting [Mk]vu = 1 \u2212[Mk]uv for all\nindices u > v.\nBy construction, for each distinct pair j, k \u2208[T], we have the lower bound\n|||Mj \u2212Mk|||2\nF = n\u03b42\u2225bj \u2212bk\u22252\n2 \u2265c0n2\u03b42.\nLet Pj and Pj\nuv denote (respectively) the distributions of the matrix Y and entry Yuv when\nthe underlying matrix is Mj.\nSince the entries of Y are generated independently, we have\nDKL(Pj\u2225Pk) =\nP\n1\u2264u<v\u2264n\nDKL(Pj\nuv\u2225Pk\nuv). The matrix entry Yuv is generated according to the\nmodel\nYuv =\n\uf8f1\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f3\n1\nw.p. pobsM\u2217\nuv\n0\nw.p. pobs(1 \u2212M\u2217\nuv)\nnot observed\nw.p. 1 \u2212pobs.\nConsequently, the KL divergence can be upper bounded as\nDKL(Pj\nuv\u2225Pk\nuv)\n= pobs\n\u0010\nMj\nuv log Mj\nuv\nMkuv\n+ (1 \u2212Mj\nuv) log (1 \u2212Mj\nuv)\n(1 \u2212Mkuv)\n\u0011\n\u2264pobs\nn\nMj\nuv\n\u0000Mj\nuv \u2212Mk\nuv\nMkuv\n\u0001\n+ (1 \u2212Mj\nuv)\n\u0000Mk\nuv \u2212Mj\nuv\n1 \u2212Mkuv\n\u0001o\n(45a)\n= pobs\n(Mj\nuv \u2212Mk\nuv)2\nMkuv(1 \u2212Mkuv)\n(45b)\n\u226416pobs (Mj\nuv \u2212Mk\nuv)2,\n(45c)\nwhere inequality (45a) follows from the fact that log(t) \u2264t\u22121 for all t > 0; and inequality (45c)\nfollows since the numbers {Mj\nuv, Mk\nuv} both lie in the interval [1\n4, 3\n4]. Putting together the pieces,\nwe conclude that\nDKL(Pj\u2225Pk) \u2264c1pobs|||Mj \u2212Mk|||2\nF \u2264c\u2032\n1pobsn2\u03b42.\nThus, applying Fano\u2019s inequality to the packing set {M1, . . . , MT } yields that any estimator\nc\nM has mean squared error lower bounded by\nsup\nk\u2208[T]\n1\nn2 E[|||c\nM \u2212Mk|||2\nF] \u2265c0\u03b42\u0010\n1 \u2212c\u2032\n1pobsn2\u03b42 + log 2\ncn\n\u0011\n.\nFinally, choosing \u03b42 =\nc2\n2c1pobsn yields the lower bound supk\u2208[T]\n1\nn2 E[|||c\nM \u2212Mk|||2\nF] \u2265c3\n1\nnpobs . Note\nthat in order to satisfy the condition \u03b4 \u22641\n4, we must have pobs \u226516c2\n2c1n.\n30\nProof of upper bound:\nFor this proof, recall the linearized form of the observation model\ngiven in equations (16a), (18a), and (18b). We begin by introducing some additional notation.\nLetting \u03a0 denote the set of all permutations of n items. For each \u03c0 \u2208\u03a0, we de\ufb01ne the set\n\u03c0(CBISO) : =\n\b\nM \u2208[0, 1]n\u00d7n | Mk\u2113\u2265Mij whenever \u03c0(k) \u2264\u03c0(i) and \u03c0(\u2113) \u2265\u03c0(j)\n\t\n,\ncorresponding to the subset of SST matrices that are faithful to the permutation \u03c0. We then\nde\ufb01ne the estimator M\u03c0 \u2208arg min\nM\u2208\u03c0(CBISO)\n|||Y \u2032 \u2212M|||2\nF, in terms of which the least squares estima-\ntor (16b) can be rewritten as\nc\nM \u2208arg min\n\u03c0\u2208\u03a0\n|||Y \u2032 \u2212M\u03c0|||2\nF.\nDe\ufb01ne a set of permutations \u03a0\u2032 \u2286\u03a0 as\n\u03a0\u2032 : = {\u03c0 \u2208\u03a0 | |||Y \u2032 \u2212M\u03c0|||2\nF \u2264|||Y \u2032 \u2212M\u2217|||2\nF}.\nNote that the set \u03a0\u2032 is guaranteed to be non-empty since the permutation corresponding to c\nM\nalways lies in \u03a0\u2032. We claim that for any \u03c0 \u2208\u03a0\u2032, we have\nP\n\u0000|||M\u03c0 \u2212M\u2217|||2\nF \u2264cu\nn\npobs\nlog2 n\n\u0001\n\u22651 \u2212e\u22123n log n,\n(46)\nfor some positive universal constant cu.\nGiven this bound, since there are at most en log n\npermutations in the set \u03a0\u2032, a union bound over all these permutations applied to (46) yields\nP\n\u0010\nmax\n\u03c0\u2208\u03a0\u2032 |||M\u03c0 \u2212M\u2217|||2\nF > cu\nn\npobs\nlog2 n\n\u0011\n\u2264e\u22122n log n.\nSince c\nM is equal to M\u03c0 for some \u03c0 \u2208\u03a0\u2032, this tail bound yields the claimed result.\nThe remainder of our proof is devoted to proving the bound (46).\nBy de\ufb01nition, any\npermutation \u03c0 \u2208\u03a0\u2032 must satisfy the inequality\n|||Y \u2212M\u03c0|||2\nF \u2264|||Y \u2212M\u2217|||2\nF.\nLetting b\u2206\u03c0 : = M\u03c0 \u2212M\u2217denote the error matrix, and using the linearized form (18a) of the\nobservation model, some algebraic manipulations yield the basic inequality\n1\n2|||b\u2206\u03c0|||2\nF \u2264\n1\npobs\n\u27e8\u27e8W \u2032, b\u2206\u03c0\u27e9\u27e9.\n(47)\nNow consider the set of matrices\nCDIFF(\u03c0) : =\nn\n\u03b1(M \u2212M\u2217) | M \u2208\u03c0(CBISO), \u03b1 \u2208[0, 1]\no\n,\n(48)\nand note that CDIFF(\u03c0) \u2286[\u22121, 1]n\u00d7n. (To be clear, the set CDIFF(\u03c0) also depends on the value of\nM\u2217, but considering M\u2217as \ufb01xed, we omit this dependence from the notation for brevity.) For\neach choice of radius t > 0, de\ufb01ne the random variable\nZ\u03c0(t) : =\nsup\nD\u2208CDIFF(\u03c0),\n|||D|||F\u2264t\n1\npobs\n\u27e8\u27e8D, W \u2032\u27e9\u27e9.\n(49)\n31\nUsing the basic inequality (47), the Frobenius norm error |||b\u2206\u03c0|||F then satis\ufb01es the bound\n1\n2|||b\u2206\u03c0|||2\nF \u2264\n1\npobs\n\u27e8\u27e8W \u2032, b\u2206\u03c0\u27e9\u27e9\u2264Z\u03c0\n\u0000|||b\u2206\u03c0|||F\n\u0001\n.\n(50)\nThus, in order to obtain a high probability bound, we need to understand the behavior of the\nrandom quantity Z\u03c0(t).\nOne can verify that the set CDIFF(\u03c0) is star-shaped, meaning that \u03b1D \u2208CDIFF(\u03c0) for every\n\u03b1 \u2208[0, 1] and every D \u2208CDIFF(\u03c0). Using this star-shaped property, we are guaranteed that\nthere is a non-empty set of scalars \u03b4n > 0 satisfying the critical inequality\nE[Z\u03c0(\u03b4n)] \u2264\u03b42\nn\n2 .\n(51)\nOur interest is in an upper bound to the smallest (strictly) positive solution \u03b4n to the critical\ninequality (51), and moreover, our goal is to show that for every t \u2265\u03b4n, we have |||b\u2206|||F \u2264c\u221at\u03b4n\nwith high probability.\nFor each t > 0, de\ufb01ne the \u201cbad\u201d event\nAt =\n\b\n\u2203\u2206\u2208CDIFF(\u03c0) | |||\u2206|||F \u2265\np\nt\u03b4n\nand\n1\npobs\n\u27e8\u27e8\u2206, W \u2032\u27e9\u27e9\u22652|||\u2206|||F\np\nt\u03b4n\n\t\n.\n(52)\nUsing the star-shaped property of CDIFF(\u03c0), it follows by a rescaling argument that\nP[At] \u2264P[Z\u03c0(\u03b4n) \u22652\u03b4n\np\nt\u03b4n]\nfor all t \u2265\u03b4n.\nThe following lemma helps control the behavior of the random variable Z\u03c0(\u03b4n).\nLemma 10. For any \u03b4 > 0, the mean of Z\u03c0(\u03b4) is bounded as\nE[Z\u03c0(\u03b4)] \u2264cu\nn\npobs\nlog2 n,\nand for every u > 0, its tail probability is bounded as\nP\n\u0010\nZ\u03c0(\u03b4) > E[Z\u03c0(\u03b4)] + u\n\u0011\n\u2264exp\n\u0010\n\u2212cu2pobs\n\u03b42 + E[Z\u03c0(\u03b4)] + u\n\u0011\n,\nwhere cu and c are positive universal constants.\nFrom this lemma, we have the tail bound\nP\n\u0010\nZ\u03c0(\u03b4n) > E[Z\u03c0(\u03b4n)] + \u03b4n\np\nt\u03b4n\n\u0011\n\u2264exp\n\u0010\n\u2212c(\u03b4n\n\u221at\u03b4n)2pobs\n\u03b42n + E[Z\u03c0(\u03b4n)] + (\u03b4n\n\u221at\u03b4n)\n\u0011\n,\nfor all t \u2265\u03b4n.\nBy the de\ufb01nition of \u03b4n in equation (51), we have E[Z(\u03b4n)] \u2264\u03b42\nn \u2264\u03b4n\n\u221at\u03b4n for any t \u2265\u03b4n, and\nconsequently\nP[At] \u2264P[Z(\u03b4n) \u22652\u03b4n\np\nt\u03b4n\n\u0003\n\u2264exp\n\u0010\u2212c(\u03b4n\n\u221at\u03b4n)2pobs\n3\u03b4n\n\u221at\u03b4n\n\u0011\n,\nfor all t \u2265\u03b4n.\nConsequently, either |||b\u2206\u03c0|||F \u2264\u221at\u03b4n, or we have |||b\u2206\u03c0|||F > \u221at\u03b4n. In the latter case, conditioning\non the complement Ac\nt, our basic inequality implies that 1\n2|||b\u2206\u03c0|||2\nF \u22642|||b\u2206\u03c0|||F\n\u221at\u03b4n and hence\n|||b\u2206\u03c0|||F \u22644\u221at\u03b4n. Putting together the pieces yields that\nP\n\u0000|||b\u2206\u03c0|||F \u22644\np\nt\u03b4n\n\u0001\n\u22651 \u2212exp\n\u0000\u2212c\u2032\u03b4n\np\nt\u03b4npobs\n\u0001\n,\nfor all t \u2265\u03b4n.\n(53)\n32\nFinally, from the bound on the expected value of Z\u03c0(t) in Lemma 10, we see that the critical\ninequality (51) is satis\ufb01ed for \u03b4n =\nq\ncun\npobs log n. Setting t = \u03b4n =\nq\ncun\npobs log n in (53) yields\nP\n\u0010\n|||b\u2206\u03c0|||F \u22644 cun\npobs\nlog2 n\n\u0011\n\u22651 \u2212exp\n\u0010\n\u22123n log n\n\u0011\n,\n(54)\nfor some universal constant cu > 0, thus proving the bound (46).\nIt remains to prove Lemma 10.\nProof of Lemma 10\nBounding E[Z\u03c0(\u03b4)]: We establish an upper bound on E[Z\u03c0(\u03b4)] by\nusing Dudley\u2019s entropy integral, as well as some auxiliary results on metric entropy. We use the\nnotation log N(\u03f5, C, \u03c1) to denote the \u03f5 metric entropy of the class C in the metric \u03c1. Introducing\nthe random variable eZ\u03c0 : =\nsup\nD\u2208CDIFF(\u03c0)\n\u27e8\u27e8D, W \u2032\u27e9\u27e9, note that we have E[Z\u03c0(\u03b4)] \u2264\n1\npobs E[ eZ\u03c0]. The\ntruncated form of Dudley\u2019s entropy integral inequality yields\nE[ eZ\u03c0] \u2264c\nn\nn\u22128 +\nZ 2n\n1\n2 n\u22129\np\nlog N(\u03f5, CDIFF(\u03c0), |||.|||F)d\u03f5\no\n,\n(55)\nwhere we have used the fact that the diameter of the set CDIFF(\u03c0) is at most 2n in the Frobenius\nnorm.\nFrom our earlier bound (29), we are guaranteed that for each \u03f5 > 0, the metric entropy is\nupper bounded as\nlog N\n\u0010\n\u03f5, {\u03b1M | M \u2208CBISO, \u03b1 \u2208[0, 1]}, ||| \u00b7 |||F\n\u0011\n\u22648n2\n\u03f52\n\u0000log n\n\u03f5\n\u00012.\nConsequently, we have\nlog N(\u03f5, CDIFF(\u03c0), |||.|||F) \u226416n2\n\u03f52\n\u0000log n\n\u03f5\n\u00012.\nSubstituting this bound on the metric entropy of CDIFF(\u03c0) and the inequality \u03f5 \u22651\n2n\u22129 into the\nDudley bound (55) yields\nE[ eZ\u03c0] \u2264cn(log n)2.\nThe inequality E[Z\u03c0(\u03b4)] \u2264\n1\npobs E[ eZ\u03c0] then yields the claimed result.\nBounding the tail probability of Z\u03c0(\u03b4): In order to establish the claimed tail bound, we use\na Bernstein-type bound on the supremum of empirical processes due to Klein and Rio [KR05,\nTheorem 1.1c], which we state in a simpli\ufb01ed form here.\nLemma 11. Let X : = (X1, . . . , Xm) be any sequence of zero-mean, independent random vari-\nables, each taking values in [\u22121, 1]. Let V \u2282[\u22121, 1]m be any measurable set of m-length vectors.\nThen for any u > 0, the supremum X\u2020 = supv\u2208V\u27e8X, v\u27e9satis\ufb01es the upper tail bound\nP\n\u0000X\u2020 > E[X\u2020] + u\n\u0001\n\u2264exp\n\u0010\n\u2212u2\n2 supv\u2208V E[\u27e8v, X\u27e92] + 4E[X\u2020] + 3u\n\u0011\n.\n33\nWe now invoke Lemma 11 with the choices V = CDIFF(\u03c0) \u2229B(\u03b4), m = (n \u00d7 n), X = W \u2032, and\nX\u2020 = pobsZ\u03c0(\u03b4). The matrix W \u2032 has zero-mean entries belonging to the interval [\u22121, +1], and\nare independent on and above the diagonal (with the entries below determined by the skew-\nsymmetry condition). Then we have E[X\u2020] \u2264pobsE[Z\u03c0(\u03b4)] and E[\u27e8\u27e8D, W \u2032\u27e9\u27e92] \u22644pobs|||D|||2\nF \u22644pobs\u03b42\nfor every D \u2208V. With these assignments, and some algebraic manipulations, we obtain that\nfor every u > 0,\nP\nh\nZ\u03c0(\u03b4) > E[Z\u03c0(\u03b4)] + u\ni\n\u2264exp\n\u0010\n\u2212u2pobs\n8\u03b42 + 4E[Z\u03c0(\u03b4)] + 3u\n\u0011\n,\nas claimed.\n5.5.2\nProof of part (b)\nIn order to prove the bound (17b), we analyze the SVT estimator T\u03bbn(Y \u2032) with the threshold\n\u03bbn = 3\nq\nn\npobs . Naturally then, our analysis is similar to that of complete observations case\nfrom Section 5.2. Recall our formulation of the problem in terms of the observation matrix Y \u2032\nalong with the noise matrix W \u2032 from equations (16a), (18a) and (18b). The result of Lemma 3\ncontinues to hold in this case of partial observations, translated to this setting. In particular,\nif \u03bbn \u22651.01\npobs |||W \u2032|||op, then\n|||T\u03bbn(Y \u2032) \u2212M\u2217|||2\nF \u2264c1\nn\nX\nj=1\nmin\n\b\n\u03bb2\nn, \u03c32\nj (M\u2217)\n\t\n,\nwhere c1 > 0 is a universal constant.\nWe now upper bound the operator norm of the noise matrix W \u2032. De\ufb01ne a (2n \u00d7 2n) matrix\nW \u2032\u2032 =\n\u0014\n0\nW \u2032\n(W \u2032)T\n0\n\u0015\n.\nFrom equation (18b) and the construction above, we have that the matrix W \u2032\u2032 is symmetric,\nwith mutually independent entries above the diagonal that have a mean of zero and are bounded\nin absolute value by 1. Consequently, known results in random matrix theory (e.g., see [Tao12,\nTheorem 2.3.21]) yield the bound |||W \u2032\u2032|||op \u22642.01\n\u221a\n2n with probability at least 1 \u2212n\u2212c2, for\nsome universal constant c2 > 1. One can also verify that |||W \u2032\u2032|||op = |||W \u2032|||op, thereby yielding\nthe bound\nP\nh\n|||W \u2032|||op > 2.01\np\n2npobs\ni\n\u2264n\u2212c2.\nWith our choice \u03bbn = 3\nq\nn\npobs , the event {\u03bbn \u22651.01\npobs |||W \u2032|||op} holds with probability at least\n1 \u2212n\u2212c2. Conditioned on this event, the approximation-theoretic result from Lemma 4 gives\n1\nn2 |||T\u03bbn(Y \u2032) \u2212M\u2217|||2\nF \u2264c\n\u0010s\u03bb2\nn\nn2 + 1\ns\n\u0011\nwith probability at least 1 \u2212n\u2212c2. Substituting \u03bbn = 3\nq\nn\npobs in this bound and setting s =\n\u221apobsn yields the claimed result.\n34\n5.5.3\nProof of part (c)\nAs in our of proof of the fully observed case from Section 5.4.2, we consider the two-stage\nestimator based on \ufb01rst computing the MLE bwML of w\u2217from the observed data, and then\nconstructing the matrix estimate M( bwML) via Equation (4).\nLet us now upper bound the\nmean-squared error associated with this estimator.\nOur observation model can be (re)described in the following way. Consider an Erd\u02ddos-R\u00b4enyi\ngraph on n vertices with each edge drawn independently with a probability pobs. For each edge\nin this graph, we obtain one observation of the pair of vertices at the end-points of that edge.\nLet L be the (random) Laplacian matrix of this graph, that is, L = D\u2212A where D is an (n\u00d7n)\ndiagonal matrix with [D]ii being the degree of item i in the graph (equivalently, the number of\npairwise comparison observations that involve item i) and A is the (n \u00d7 n) adjacency matrix\nof the graph. Let \u03bb2(L) denote the second largest eigenvalue of L. From Theorem 2(b) of our\npaper [SBB+16] on estimating parametric models,8 for this graph, there is a universal constant\nc1 such that the maximum likelihood estimator bwML has mean squared error upper bounded as\nE[\u2225bwML \u2212w\u2217\u22252\n2 | L] \u2264c1\nn\n\u03bb2(L).\nThe estimator bwML is computable in a time polynomial in n.\nSince pobs \u2265c0\n(log n)2\nn\n, known results on the eigenvalues of random graphs [Oli09, CR11,\nKOVB14] imply that\nP\nh\n\u03bb2(L) \u2265c2npobs\ni\n\u22651 \u22121\nn4\n(56)\nfor a universal constant c2 (that may depend on c0).\nAs shown earlier in Equation (44),\nfor any valid score vectors w1, w2, we have |||M(w1) \u2212M(w2)|||2\nF \u2264n\u03b62\u2225w1 \u2212w2\u22252\n2 where\n\u03b6 : = maxz\u2208[\u22121,1] F \u2032(z) is a constant independent of n and pobs. Putting these results together\nand performing some simple algebraic manipulations leads to the upper bound\n1\nn2 E\nh\n|||M( bwML) \u2212M\u2217|||2\nF\ni\n\u2264c3\u03b62\nnpobs\n,\nwhich establishes the claim.\n6\nDiscussion\nIn this paper, we analyzed a \ufb02exible model for pairwise comparison data that includes various\nparametric models, including the BTL and Thurstone models, as special cases. We analyzed\nvarious estimators for this broader matrix family, ranging from optimal estimators to various\npolynomial-time estimators, including forms of singular value thresholding, as well as a multi-\nstage method based on a noisy sorting routine. We show that this SST model permits far more\nrobust estimation as compared to popular parametric models, while surprisingly, incurring little\npenalty for this signi\ufb01cant generality.9 Our results thus present a strong motivation towards\nthe use of such general stochastic transitivity based models.\n8Note that the Laplacian matrix used in the statement of [SBB+16, Theorem 2(b)] is a scaled version of the\nmatrix L introduced here, with each entry of L divided by the total number of observations.\n9In Appendix D.1 we show that under weaker notions of stochastic transitivity, the pairwise-comparison\nprobabilities are unestimable.\n35\nAll of the results in this paper focused on estimation of the matrix of pairwise comparison\nprobabilities in the Frobenius norm. Estimation of probabilities in other metrics, such as the\nKL divergence or estimation of the ranking in the Spearman\u2019s footrule or Kemeny distance,\nfollow as corollaries of our results (see Appendix A). Establishing the best possible rates for\npolynomial-time algorithms over the full class CSST is a challenging open problem.\nWe evaluated a computationally e\ufb03cient estimator based on thresholding the singular values\nof the observation matrix that is consistent, but achieves a suboptimal rate. In our analysis of\nthis estimator, we have so far been conservative in our choice of the regularization parameter,\nin that it is a \ufb01xed choice. Such a \ufb01xed choice has been prescribed in various theoretical works\non the soft or hard-thresholded singular values (see, for instance, the papers [Cha14, GD14]).\nIn practice, the entries of the e\ufb00ective noise matrix W have variances that depend on the\nunknown matrix, and the regularization parameter may be obtained via cross-validation. The\ne\ufb00ect of allowing a data-dependent choice of the regularization parameter remains to be studied,\nalthough we suspect it may improve the minimax risk by a constant factor at best.\nFinally, in some applications, choices can be systematically intransitive, for instance when\nobjects have multiple features and di\ufb00erent features dominate di\ufb00erent pairwise comparisons.\nIn these situations, the SST assumption may be weakened to one where the underlying pairwise\ncomparison matrix is a mixture of a small number of SST matrices. The results of this work\nmay form building blocks to address this general setting; we defer a detailed analysis to future\nwork.\nAcknowledgments:\nThis work was partially supported by ONR-MURI grant DOD-002888,\nAFOSR grant FA9550-14-1-0016, NSF grant CIF-31712-23800, and ONR MURI grant N00014-\n11-1-0688. The work of NBS was also supported in part by a Microsoft Research PhD fellowship.\nReferences\n[ACN08]\nN. Ailon, M. Charikar, and A. Newman. Aggregating inconsistent information:\nranking and clustering. Journal of the ACM (JACM), 55(5):23, 2008.\n[Alo06]\nN. Alon. Ranking tournaments. SIAM Journal on Discrete Mathematics, 20(1):137\u2013\n142, 2006.\n[BH11]\nA. E. Brouwer and W. H. Haemers. Spectra of graphs. Springer, 2011.\n[BM08]\nM. Braverman and E. Mossel. Noisy sorting without resampling. In Proc. ACM-\nSIAM symposium on Discrete algorithms, pages 268\u2013276, 2008.\n[BT52]\nR. A. Bradley and M. E. Terry. Rank analysis of incomplete block designs: I. The\nmethod of paired comparisons. Biometrika, pages 324\u2013345, 1952.\n[BW97]\nT. P. Ballinger and N. T. Wilcox. Decisions, error and heterogeneity. The Economic\nJournal, 107(443):1090\u20131105, 1997.\n[Cat12]\nM. Cattelan.\nModels for paired comparison data: A review with emphasis on\ndependent data. Statistical Science, 27(3):412\u2013433, 2012.\n[CGS15]\nS. Chatterjee, A. Guntuboyina, and B. Sen. On matrix estimation under mono-\ntonicity constraints. arXiv:1506.03430, 2015.\n[Cha14]\nS. Chatterjee. Matrix estimation by universal singular value thresholding. The\nAnnals of Statistics, 43(1):177\u2013214, 2014.\n36\n[CR11]\nF. Chung and M. Radcli\ufb00e. On the spectra of general random graphs. The electronic\njournal of combinatorics, 18(1):P215, 2011.\n[CS15]\nY. Chen and C. Suh. Spectral MLE: Top-k rank aggregation from pairwise com-\nparisons. In International Conference on Machine Learning, 2015.\n[DG77]\nP. Diaconis and R. L. Graham.\nSpearman\u2019s footrule as a measure of disarray.\nJournal of the Royal Statistical Society. Series B (Methodological), pages 262\u2013268,\n1977.\n[Dia89]\nP. Diaconis. A generalization of spectral analysis with application to ranked data.\nThe Annals of Statistics, 17(3):949\u2013979, 1989.\n[DIS15]\nW. Ding, P. Ishwar, and V. Saligrama. A topic modeling approach to ranking.\nInternational Conference on Arti\ufb01cial Intelligence and Statistics, 2015.\n[DM59]\nD. Davidson and J. Marschak. Experimental tests of a stochastic decision theory.\nMeasurement: De\ufb01nitions and theories, pages 233\u201369, 1959.\n[Fis73]\nP. C. Fishburn. Binary choice probabilities: on the varieties of stochastic transitiv-\nity. Journal of Mathematical psychology, 10(4):327\u2013352, 1973.\n[FJS13]\nV. F. Farias, S. Jagabathula, and D. Shah. A nonparametric approach to modeling\nchoice with limited data. Management Science, 59(2):305\u2013322, 2013.\n[FV93]\nM. A. Fligner and J. S. Verducci. Probability models and statistical analyses for\nranking data, volume 80. Springer, 1993.\n[GD14]\nM. Gavish and D. L. Donoho. The optimal hard threshold for singular values is.\nIEEE Transactions on Information Theory, 60(8):5040\u20135053, 2014.\n[Gil52]\nE. N. Gilbert. A comparison of signalling alphabets. Bell System Technical Journal,\n31(3):504\u2013522, 1952.\n[GW07]\nF. Gao and J. A. Wellner. Entropy estimate for high-dimensional monotonic func-\ntions. Journal of Multivariate Analysis, 98(9):1751\u20131764, 2007.\n[HOX14]\nB. Hajek, S. Oh, and J. Xu. Minimax-optimal inference from partial rankings. In\nAdvances in Neural Information Processing Systems, pages 1475\u20131483, 2014.\n[KMS07]\nC. Kenyon-Mathieu and W. Schudy. How to rank with few errors. In Symposium\non Theory of computing (STOC), pages 95\u2013103. ACM, 2007.\n[KOVB14]\nT. Kolokolnikov,\nB. Osting,\nand J. Von Brecht.\nAlgebraic connectivity\nof Erd\u00a8os-R\u00b4enyi graphs near the connectivity threshold.\nAvailable online\nhttp://www.mathstat.dal.ca/ tkolokol/papers/braxton-james.pdf, 2014.\n[KR05]\nT. Klein and E. Rio.\nConcentration around the mean for maxima of empirical\nprocesses. The Annals of Probability, 33(3):1060\u20131077, 2005.\n[Led01]\nM. Ledoux. The Concentration of Measure Phenomenon. Mathematical Surveys\nand Monographs. American Mathematical Society, Providence, RI, 2001.\n[Luc59]\nR. D. Luce. Individual choice behavior: A theoretical analysis. New York: Wiley,\n1959.\n[Mar96]\nJ. I. Marden. Analyzing and modeling rank data. CRC Press, 1996.\n[ML65]\nD. H. McLaughlin and R. D. Luce.\nStochastic transitivity and cancellation of\npreferences between bitter-sweet solutions. Psychonomic Science, 2(1-12):89\u201390,\n1965.\n37\n[NOS12]\nS. Negahban, S. Oh, and D. Shah. Iterative ranking from pair-wise comparisons.\nIn Advances in Neural Information Processing Systems, pages 2474\u20132482, 2012.\n[Oli09]\nR. I. Oliveira.\nConcentration of the adjacency matrix and of the Laplacian in\nrandom graphs with independent edges. arXiv preprint:0911.0600, 2009.\n[RA14]\nA. Rajkumar and S. Agarwal. A statistical convergence perspective of algorithms\nfor rank aggregation from pairwise data. In International Conference on Machine\nLearning, pages 118\u2013126, 2014.\n[Sam00]\nP.-M. Samson. Concentration of measure inequalities for Markov chains and \u03c6-\nmixing processes. Annals of Probability, pages 416\u2013461, 2000.\n[SBB+16]\nN. B. Shah, S. Balakrishnan, J. Bradley, A. Parekh, K. Ramchandran, and M. J.\nWainwright. Estimation from pairwise comparisons: Sharp minimax bounds with\ntopology dependence. Journal of Machine Learning Research, 17(58):1\u201347, 2016.\n[SBW16]\nN. B. Shah, S. Balakrishnan, and M. J. Wainwright.\nFeeling the Bern: Adap-\ntive estimators for Bernoulli probabilities of pairwise comparisons. arXiv preprint\narXiv:1603.06881, 2016.\n[SS11]\nM. J. Silvapulle and P. K. Sen. Constrained statistical inference: Order, inequality,\nand shape constraints, volume 912. John Wiley & Sons, 2011.\n[Tao12]\nT. Tao. Topics in random matrix theory, volume 132. American Mathematical\nSociety Providence, RI, 2012.\n[Tho76]\nR. Thompson. The behavior of eigenvalues and singular values under perturbations\nof restricted rank. Linear Algebra and its Applications, 13(1):69\u201378, 1976.\n[Thu27]\nL. L. Thurstone. A law of comparative judgment. Psychological Review, 34(4):273,\n1927.\n[Tve72]\nA. Tversky.\nElimination by aspects: A theory of choice.\nPsychological review,\n79(4):281, 1972.\n[Var57]\nR. Varshamov. Estimate of the number of signals in error correcting codes. In Dokl.\nAkad. Nauk SSSR, volume 117, pages 739\u2013741, 1957.\n[VDVW96] A. Van Der Vaart and J. Wellner. Weak convergence. In Weak Convergence and\nEmpirical Processes, pages 16\u201328. Springer, 1996.\n[WJJ13]\nF. L. Wauthier, M. I. Jordan, and N. Jojic. E\ufb03cient ranking from pairwise com-\nparisons. In Proceedings of the 30th International Conference on Machine Learning\n(ICML), 2013.\nAPPENDICES\nA\nRelation to other error metrics\nIn this section, we show how estimation of the pairwise-comparison-probability matrix M\u2217\nunder the squared Frobenius norm implies estimates and bounds under other error metrics. In\nparticular, we investigate relations between estimation of the true underlying ordering under\nthe Spearman\u2019s footrule and the Kemeny metrics, and estimation of the matrix M\u2217under the\nKullback-Leibler divergence metric.\n38\nA.1\nRecovering the true ordering\nRecall that the SST class assumes the existence of some true ordering of the n items. The\npairwise-comparison probabilities are then assumed to be faithful to this ordering.\nIn this\nsection, we investigate the problem of estimating this underlying ordering.\nIn order to simplify notation, we assume without loss of generality that this true underlying\nordering is the identity permutation of the n items, and denote the identity permutation as \u03c0id.\nRecall the set CBISO of bivariate isotonic matrices, that is, SST matrices that are faithful to the\nidentity permutation:\nCBISO = {M \u2208[0, 1]n\u00d7n | Mij = 1 \u2212Mji for all (i, j) \u2208[n]2, and Mi\u2113\u2265Mj\u2113whenever i < j.}\nThen we have that M\u2217\u2208CBISO. Let \u03c0 be any permutation of the n items. For any matrix\nM \u2208Rn\u00d7n and any integer i \u2208[n] we let Mi denote the ith row of M.\nTwo of the most popular metrics of measuring the error between two such orderings are the\nSpearman\u2019s footrule and the Kemeny (or Kendall tau) distance, de\ufb01ned as follows. Spearman\u2019s\nfootrule measures the total displacement of all items in \u03c0 as compared to \u03c0id, namely\nSpearman\u2019s footrule(\u03c0, \u03c0id) : =\nn\nX\ni=1\n| \u03c0(i) \u2212i | .\nOn the other hand, the Kemeny distance equals the total number of pairs whose relative posi-\ntions are di\ufb00erent in the two orderings, namely,\nKemeny(\u03c0, \u03c0id) : =\nX\n1\u2264i<j\u2264n\n1{sign(\u03c0(i) \u2212\u03c0(j)) \u0338= sign(i \u2212j)},\nwhere \u201csign\u201d denotes the sign function, that is, sign(x) = 1 if x > 0, sign(x) = \u22121 if x < 0 and\nsign(x) = 0 if x = 0. The Kemeny distance is also known as the Kendall tau metric.\nBefore investigating the two aforementioned metrics, we remark on one important aspect of\nthe problem of estimating the order of the items. Observe that if the rows of M\u2217corresponding\nto some pair of items (i, j) are very close to each other (say, in a pointwise sense), then it is\nhard to estimate the relative position of item i with respect to item j. On the other hand, if the\ntwo rows are far apart then di\ufb00erentiating between the two items is easier. Consequently, it is\nreasonable to consider a metric that penalizes errors in the inferred permutation based on the\nrelative values of the rows of M\u2217. To this end, we de\ufb01ne a reweighted version of Spearman\u2019s\nfootrule as\nMatrix-reweighted Spearman\u2019s footruleM\u2217(\u03c0, \u03c0id) : = |||\u03c0(M\u2217) \u2212M\u2217|||2\nF =\nn\nX\ni=1\n|||M\u2217\n\u03c0(i) \u2212M\u2217\ni |||2\n2.\nGiven these de\ufb01nitions, the following proposition now relates the squared Frobenius norm\nmetric to the other aforementioned metrics.\nProposition 2.A. Any two matrices M\u2217\u2208CBISO, and M \u2208CSST with \u03c0 as its underlying\npermutation, must satisfy the following bound on the matrix-reweighted Spearman\u2019s footrule:\n|||M\u2217\u2212\u03c0(M\u2217)|||2\nF \u22644|||M\u2217\u2212M|||2\nF.\n39\nProposition 2.B. Consider any matrix M\u2217\u2208CBISO that satis\ufb01es |||M\u2217\ni \u2212M\u2217\ni+1|||2\n2 \u2265\u03b32 for some\nconstant \u03b3 > 0 and for every i \u2208[n \u22121]. Then for any permutation \u03c0, the Spearman\u2019s footrule\ndistance from the identity permutation is upper bounded as\nn\nX\ni=1\n| i \u2212\u03c0(i) |\u22641\n\u03b32 |||M\u2217\u2212\u03c0(M\u2217)|||2\nF.\nConversely, there exists a matrix M\u2217\u2208CBISO that satis\ufb01es |||M\u2217\ni \u2212M\u2217\ni+1|||2\n2 = \u03b32 for every\ni \u2208[n\u22121] such that for every permutation \u03c0, the Spearman\u2019s footrule distance from the identity\npermutation is lower bounded as\nn\nX\ni=1\n| i \u2212\u03c0(i) |\u2265\n1\n4\u03b32 |||M\u2217\u2212\u03c0(M\u2217)|||2\nF.\nProposition 2.C ([DG77]). The Kemeny distance of any permutation \u03c0 from the identity\npermutation \u03c0id is sandwiched as\n1\n2\nn\nX\ni=1\n| i \u2212\u03c0(i) |\u2264\nX\n1\u2264i<j\u2264n\n1{sign(\u03c0(i) \u2212\u03c0(j)) \u0338= sign(i \u2212j)} \u2264\nn\nX\ni=1\n| i \u2212\u03c0(i) | .\nAs a consequence of this proposition, an upper bound on the error in estimation of M\u2217\nunder the squared Frobenius norm yields identical upper bounds (with some constant factors)\nunder the other three metrics.\nA few remarks are in order:\n(a) Treating M\u2217as the true pairwise comparison probability matrix and M as its estimate,\nProposition 2.A assumes that M also lies in the matrix class CSST. This set-up is known as\nproper learning in some of the machine learning literature.\n(b) The \u03b3-separation condition of Proposition 2.B is satis\ufb01ed in the models assumed in several\nearlier works [BM08, WJJ13].\nThe remainder of this subsection is devoted to the proof of these claims.\nA.1.1\nProof of Proposition 2.A\nFor any matrix M and any permutation \u03c0 of n items, let \u03c0(M) denote the matrix resulting\nfrom permuting the rows of M by \u03c0. With this notation, we have\n|||\u03c0(M\u2217) \u2212M\u2217|||2\nF \u22642|||\u03c0(M\u2217) \u2212M|||2\nF + 2|||M \u2212M\u2217|||2\nF = 2|||M\u2217\u2212\u03c0\u22121(M)|||2\nF + 2|||M \u2212M\u2217|||2\nF.\nWe now show that\n|||M\u2217\u2212\u03c0\u22121(M)|||2\nF \u2264|||M\u2217\u2212M|||2\nF,\n(57)\nwhich would then imply the claimed result. As shown below, the inequality (57) is a consequence\nof the fact that M\u2217and \u03c0\u22121(c\nM) both lie in the SST class and have the same underlying ordering\nof the rows. More generally, we claim that for any two matrices M \u2208CBISO and M\u2032 \u2208CBISO,\n\u03c0id \u2208arg min\ne\u03c0\n|||M \u2212e\u03c0(M\u2032)|||2\nF,\n(58)\n40\nwhere the minimization is carried out over all permutations of n items. To see this, consider\nany two matrices M and M\u2032 in CBISO and let \u03c0\u2032 be a minimizer of |||M \u2212\u03c0(M\u2032)|||2\nF. If \u03c0\u2032 \u0338= \u03c0id,\nthen there must exist some item i \u2208[n \u22121] such that item (i + 1) is ranked higher than item i\nin \u03c0\u2032. Consequently,\n|||Mi \u2212M\u2032\ni+1|||2\n2 + |||Mi+1 \u2212M\u2032\ni|||2\n2 \u2212|||Mi \u2212M\u2032\ni|||2\n2 \u2212|||Mi+1 \u2212M\u2032\ni+1|||2\n2\n= 2\u27e8\u27e8Mi \u2212Mi+1, M\u2032\ni \u2212M\u2032\ni+1\u27e9\u27e9\u22650,\nwhere the \ufb01nal inequality follows from the fact that M \u2208CBISO and M\u2032 \u2208CBISO. It follows that\nthe new permutation obtained by swapping the positions of items i and (i + 1) in \u03c0\u2032 (which\nnow ranks item i higher than item (i + 1)) is also a minimizer of |||M \u2212\u03c0(M\u2032)|||2\nF. A recursive\napplication of this argument yields that \u03c0id is also a minimizer of |||M \u2212\u03c0(M\u2032)|||2\nF.\nA.1.2\nProof of Proposition 2.B\nWe \ufb01rst prove the upper bound on the Spearman\u2019s footrule metric. Due to the monotonicity\nof the rows and the columns of M\u2217, we have the lower bound\n|||M\u2217\u2212\u03c0(M\u2217)|||2\nF \u2265\nn\nX\n\u2113=1\n|||M\u2217\n\u2113\u2212M\u2217\n\u03c0(\u2113)|||2\n2.\nNow consider any \u2113\u2208[n] such that \u03c0(\u2113) > \u2113. Then we have\n|||M\u2217\n\u2113\u2212M\u2217\n\u03c0(\u2113)|||2\n2 = |||\n\u03c0(\u2113)\u22121\nX\ni=\u2113\n(M\u2217\ni \u2212M\u2217\ni+1)|||2\n2\n(i)\n\u2265\n\u03c0(\u2113)\u22121\nX\ni=\u2113\n|||M\u2217\ni \u2212M\u2217\ni+1|||2\n2\n(ii)\n\u2265\u03b32|\u03c0(i) \u2212i|,\nwhere the inequality (i) is a consequence of the fact that for every i \u2208[n \u22121], every entry\nof the vector (M\u2217\ni \u2212M\u2217\ni+1) is non-negative, and the inequality (ii) results from the assumed\n\u03b3-separation condition on the rows of M\u2217. An identical argument holds when \u03c0(\u2113) < \u2113. This\nargument completes the proof of the upper bound.\nWe now move on to the lower bound on Spearman\u2019s footrule. To this end, consider the\nmatrix M\u2217\u2208CBISO with its entries given as:\n[M\u2217]ij =\n\uf8f1\n\uf8f4\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f4\n\uf8f3\n1\n2 +\n\u03b3\n\u221a\n2\nif i < j\n1\n2\nif i = j\n1\n2 \u2212\n\u03b3\n\u221a\n2\nif i > j.\nOne can verify that this matrix M\u2217satis\ufb01es the required condition |||M\u2217\ni \u2212M\u2217\ni+1|||2\n2 = \u03b32 for every\ni \u2208[n\u22121]. One can also compute that this matrix also satis\ufb01es the condition |||M\u2217\u2212\u03c0(M\u2217)|||F =\n4\u03b32 Pn\n\u2113=1 |\u2113\u2212\u03c0(\u2113)|, thereby yielding the claim.\nA.1.3\nProof of Proposition 2.C\nIt is well known [DG77] that the Kemeny distance and Spearman\u2019s footrule distance between\ntwo permutation lie within a factor of 2 of each other.\n41\nA.2\nEstimating comparison probabilities under Kullback-Leibler divergence\nLet PM denote the probability distribution of the observation matrix Y \u223c{0, 1}n\u00d7n obtained\nby independently sampling entry Yij from a Bernoulli distribution with parameter Mij. The\nKullback-Leibler (KL) divergence between PM and PM\u2032 is given by\nDKL(PM\u2225PM\u2032) = Mij log Mij\nM\u2032\nij\n+ (1 \u2212Mij) log 1 \u2212Mij\n1 \u2212M\u2032\nij\n.\nBefore we establish the connection with the squared Frobenius norm, we make one assump-\ntion on the pairwise comparison probabilities that is standard in the literature on estimation\nfrom pairwise comparisons [NOS12, HOX14, SBB+16, CS15]. We assume that every entry of\nM\u2217is bounded away from {0, 1}. In other words, we assume the existence of some known\nconstant-valued parameter \u03f5 \u2208(0, 1\n2] whose value is independent of n, such that M\u2217\nij \u2208(\u03f5, 1 \u2212\u03f5)\nfor every pair (i, j). Given this assumption, for any estimator M of M\u2217, we clip each of its\nentries and force them to lie in the interval (\u03f5, 1 \u2212\u03f5).10 The following proposition then relates\nthe Kullback-Leibler divergence metric to estimation under the squared Frobenius norm.\nProposition 3. The probability distributions induced by any two probability matrices M\u2217and\nM must satisfy the sandwich inequalities:\n|||M \u2212M\u2217|||2\nF \u2264DKL(PM\u2225PM\u2217) \u2264\n1\n\u03f5(1 \u2212\u03f5)|||M \u2212M\u2217|||2\nF,\nwhere for the upper bound we have assumed that every entry of the matrices lies in (\u03f5, 1 \u2212\u03f5).\nThe proof of the proposition follows from standard upper and lower bounds on the natural\nlogarithm (45b). As a consequence of this result, any upper or lower bound on |||M \u2212M\u2217|||2\nF\ntherefore automatically implies an identical upper or lower bound on DKL(PM\u2225PM\u2217) up to\nconstant factors.\nB\nProof of Proposition 1\nWe show that the matrix M\u2217speci\ufb01ed in Figure 1a satis\ufb01es the conditions required by the\nproposition. It is easy to verify that M\u2217\u2208CSST, so that it remains to prove the approximation-\ntheoretic lower bound (6). In order to do so, we require the following auxiliary result:\nLemma 12. Consider any matrix M that belongs to CPAR(F) for a valid function F. Suppose\nfor some collection of four distinct items {i1, . . . , i4}, the matrix M satis\ufb01es the inequality\nMi1i2 > Mi3i4. Then it must also satisfy the inequality Mi1i3 \u2265Mi2i4.\nWe return to prove this lemma at the end of this section. Taking it as given, let us now\nproceed to prove the lower bound (6). For any valid F, \ufb01x an arbitrary member M of a class\nCPAR(F), and let w \u2208Rn be the underlying weight vector (see the de\ufb01nition (4)).\nPick any item in the set of \ufb01rst n\n4 items (corresponding to the \ufb01rst n\n4 rows of M\u2217) and call\nthis item as \u201c1\u201d; pick an item from the next set of n\n4 items (rows) and call it item \u201c2\u201d; item \u201c3\u201d\nfrom the next set and item \u201c4\u201d from the \ufb01nal set. Our analysis proceeds by developing some\nrelations between the pairwise comparison probabilities for these four items that must hold for\nevery parametric model, that are strongly violated by M\u2217. We divide our analysis into two\npossible relations between the entries of M.\n10This clipping step does not increase the estimation error.\n42\nCase I: First suppose that M12 \u2264M34. Since M\u2217\n12 = 6/8 and M\u2217\n34 = 5/8 in our construction, it\nfollows that\n(M12 \u2212M\u2217\n12)2 + (M34 \u2212M\u2217\n34)2 \u2265\n1\n256.\nCase II: Otherwise, we may assume that M12 > M34. Then Lemma 12 implies that M13 \u2265M24.\nMoreover, since M\u2217\n13 = 7/8 and M\u2217\n24 = 1 in our construction, it follows that\n(M13 \u2212M\u2217\n13)2 + (M24 \u2212M\u2217\n24)2 \u2265\n1\n256.\nAggregating across these two exhaustive cases, we \ufb01nd that\nX\n(u,v)\u2208{1,2,3,4}\n(Muv \u2212M\u2217\nuv)2 \u2265\n1\n256.\nSince this bound holds for any arbitrary selection of items from the four sets, we conclude that\n1\nn2 |||M \u2212M\u2217|||2\nF is lower bounded by a universal constant c > 0 as claimed.\nFinally, it is easy to see that upon perturbation of any of the entries of M\u2217by at most\n1\n32\u2014\nwhile still ensuring that the resulting matrix lies in CSST\u2014the aforementioned results continue\nto hold, albeit with a worse constant. Every matrix in this class satis\ufb01es the claim of this\nproposition.\nProof of Lemma 12:\nIt remains to prove Lemma 12. Since M belongs to the parametric\nfamily, there must exist some valid function F and some vector w that induce M (see Equa-\ntion (4)). Since F is non-decreasing, the condition Mi1i2 > Mi3i4 implies that\nwi1 \u2212wi2 > wi3 \u2212wi4.\nAdding wi2 \u2212wi3 to both sides of this inequality yields wi1 \u2212wi3 > wi2 \u2212wi4. Finally, applying\nthe non-decreasing function F to both sides of this inequality gives yields Mi1i3 \u2265Mi2i4 as\nclaimed, thereby completing the proof.\nC\nMinimizing feedback arc set over entire SST class\nOur analysis in Theorem 3 shows that the two-step estimator proposed in Section 3.3 works\nwell under the stated bounds on the entries of M\u2217, i.e., for M\u2217\u2208CHIGH(\u03b3) for a \ufb01xed \u03b3. This\ntwo-step estimator is based on \ufb01nding a minimum feedback arc set (FAS) in the \ufb01rst step. In\nthis section, we investigate the e\ufb03cacy of estimators based on minimum FAS over the full class\nCSST. We show that minimizing the FAS does not work well over CSST.\nThe intuition is that although minimizing the feedback arc set appears to minimize dis-\nagreements at a global scale, it makes only local decisions: if it is known that items i and j are\nin adjacent positions, the order among these two items is decided based solely on the outcome\nof the comparison between items i and j, and is independent of the outcome of the comparisons\nof i and j with all other items.\nHere is a concrete example to illustrate this property. Suppose n is divisible by 3, and\nconsider the following (n \u00d7 n) block matrix M \u2208CSST:\nM =\n\uf8ee\n\uf8ef\uf8f0\n1\n2\n1\n2\n1\n1\n2\n1\n2\n3\n4\n0\n1\n4\n1\n2\n\uf8f9\n\uf8fa\uf8fb,\n43\nwhere each block is of size ( n\n3 \u00d7 n\n3 ). Let \u03c01 be the identity permutation, and let \u03c02 be the\npermutation [n\n3 +1, . . . , 2n\n3 , 1, . . . , n\n3 , 2n\n3 +1, . . . , n], that is, \u03c02 swaps the second block of n\n3 items\nwith the \ufb01rst block. For any permutation \u03c0 of the n items and any M \u2208CSST, let \u03c0(M) denote\nthe (n \u00d7 n) matrix resulting from permuting both the rows and the columns by \u03c0.\nOne can verify that |||\u03c01(M) \u2212\u03c02(M)|||2\nF \u2265cn2, for some universal constant c > 0. Now\nsuppose an observation Y is generated from \u03c01(M) as per the model (1). Then the distribution\nof the size of the feedback arc set of \u03c01 is identical to the distribution of the size of the feedback\narc set of \u03c02. Minimizing FAS cannot distinguish between \u03c01(M) and \u03c02(M) at least 50% of\nthe time, and consequently, any estimator based on the minimum FAS output cannot perform\nwell over the SST class.\nD\nRelation to other models\nWe put things in perspective to the other models considered in the literature. We begin with\ntwo weaker versions of stochastic transitivity that are also investigated in the literature on\npsychology and social science.\nD.1\nModerate and weak stochastic transitivity\nThe model CSST that we consider is called strong stochastic transitivity in the literature on\npsychology and social science [Fis73, DM59]. The two other popular (and weaker) models are\nthose of moderate stochastic transitivity CMST de\ufb01ned as\nCMST : =\n\b\nM \u2208[0, 1]n\u00d7n | Mik \u2265min{Mij, Mjk} for every (i, j, k) satisfying Mij \u22651\n2 and Mjk \u22651\n2\n\t\n,\nand weak stochastic transitivity CWST de\ufb01ned as\nCWST : =\n\b\nM \u2208[0, 1]n\u00d7n | Mik \u22651\n2 for every (i, j, k) satisfying Mij \u22651\n2 and Mjk \u22651\n2\n\t\n.\nClearly, we have the inclusions CSST \u2286CMST \u2286CWST.\nIn Theorem 1, we prove that the minimax rates of estimation under the strong stochastic\ntransitivity assumption are \u02dc\u0398(n\u22121). It turns out, however, that the two weaker transitivity\nconditions do not permit meaningful estimation.\nProposition 4. There exists a universal constant c > 0 such that under the moderate CMST\nstochastic transitivity model,\ninf\nf\nM\nsup\nM\u2217\u2208CMST\n1\nn2 E[|||f\nM \u2212M\u2217|||2\nF] > c.\nwhere the in\ufb01mum is taken over all measurable mappings from the observations Y to [0, 1]n\u00d7n.\nConsequently, for the weak stochastic transitivity model CWST, we also have\ninf\nf\nM\nsup\nM\u2217\u2208CWST\n1\nn2 E[|||f\nM \u2212M\u2217|||2\nF] > c,\nThe minimax risk over these two classes is clearly the worst possible (up to a universal\nconstant) since for any two arbitrary matrices M and M\u2032 in [0, 1]n\u00d7n, we have\n1\nn2 |||M \u2212M\u2032|||2\nF \u2264\n1. For this reason, in the paper we restrict our analysis to the strong stochastic transitivity\ncondition.\n44\nall-half matrix \nconstruction 4 \nconstruction 1 \nconstruction 3 \nconstruction 2 \nCPAR \nCSST \nCFULL \nFigure 3. Relations between various models of pairwise comparisons. The constructions proving\nthese relations are presented as a part of the proof of Proposition 5.\nD.2\nComparison with statistical models\nLet us now investigate relationship of the strong stochastic transitivity model considered in this\npaper with two other popular models in the literature on statistical learning from comparative\ndata. Perhaps the most popular model in this regard is the class of parametric models CPAR:\nrecall that this class is de\ufb01ned as\nCPAR : = {M | Mij = F(w\u2217\ni \u2212w\u2217\nj) for some non-decreasing function F : R \u2192[0, 1],\nand vector w\u2217\u2208Rn}.\nThe parametric class of models assumes that the function F is \ufb01xed and known. Statistical\nestimation under the parametric class is studied in several recent papers [NOS12, HOX14,\nSBB+16]. The setting where the function F is \ufb01xed, but unknown leads to a semi-parametric\nvariant. The results presented in this section also readily apply to the semi-parametric class.\nThe second class is that generated from distributions over complete rankings [Dia89, FJS13,\nDIS15]. Speci\ufb01cally, every element in this class is generated as the pairwise marginal of an\narbitrary probability distribution over all possible permutations of the n items. We denote this\nclass as CFULL.\nThe following result characterizes the relation between the classes.\nProposition 5. Consider any value of n > 10. The parametric class CPAR is a strict subset of\nthe strong stochastic transitivity class CSST. The class CFULL of marginals of a distribution on\ntotal rankings is neither a subset nor a superset of either of the classes CSST, CPAR, and CSST\\CPAR.\nThe various relationships in Proposition 5 are depicted pictorially in Figure 3. These rela-\ntions are derived by \ufb01rst establishing certain conditions that matrices in the classes considered\nmust satisfy, and then constructing matrices that satisfy or violate one or more of these con-\nditions. The conditions on CFULL arise from the observation that the class is the convex hull of\nall SST matrices that have their non-diagonal elements in {0, 1}; we derive conditions on this\nconvex hull that leads to properties of the CFULL class. To handle the parametric class CPAR, we\nemploy a necessary condition discussed earlier in Section 2.4 and de\ufb01ned formally in Lemma 12.\nThe SST class CSST is characterized using the insights derived throughout the paper.\nD.3\nProof of Proposition 4\nWe will derive an order one lower bound under the moderate stochastic transitivity condition.\nThis result automatically implies the order one lower bound for weak stochastic transitivity.\n45\nThe proof imposes a certain structure on a subset of the entries of M\u2217in a manner that\n\u0398(n2) remaining entries are free to take arbitrary values within the interval [1\n2, 1]. This \ufb02exibility\nthen establishes a minimax error of \u0398(1) as claimed.\nLet us suppose M\u2217corresponds to the identity permutation of the n items, and that this\ninformation is public knowledge. Set the entries of M\u2217above the diagonal in the following\nmanner. For every i \u2208[n] and every odd j \u2208[n], set M\u2217\nij = 1\n2. For every i \u2208[n] and every even\nj \u2208[n], set M\u2217\nji = 1\n2. This information is also assumed to be public knowledge. Let S \u2282[n]2\ndenote the set of all entries of M\u2217above the diagonal whose values were not assigned in the\nprevious step. Let |S| denote the size of set S. The entries below the diagonal are governed by\nthe skew-symmetry constraints.\nWe \ufb01rst argue that every entry in S can take arbitrary values in the interval [1\n2, 1], and are\nnot constrained by each other under the moderate stochastic transitivity condition. To this\nend, consider any entry (i, k) \u2208S. Recall that the moderate stochastic transitivity condition\nimposes the following set of restrictions in M\u2217\nik: for every j, M\u2217\nik \u2265min{M\u2217\nij, M\u2217\njk}. From our\nearlier construction we have that for every odd value of j, M\u2217\nij = 1\n2 and hence the restriction\nsimply reduces to M\u2217\nik \u22651\n2. On the other hand, for every even value of j, our construction\ngives M\u2217\njk = 1\n2, and hence the restriction again reduces to M\u2217\nik \u22651\n2. Given the absence of any\nadditional restrictions, the error E[|||c\nM \u2212M\u2217|||2\nF] \u2265c|S|. Finally, observe that every entry (i, k)\nwhere i < k, i is odd and k is even belongs to the set S. It follows that |S| \u2265n2\n8 , thus proving\nour claim.\nD.4\nProof of Proposition 5\nThe constructions governing the claimed relations are enumerated in Figure 3 and the details\nare provided below.\nIt is easy to see that since F is non-decreasing, the parametric class CPAR is contained in the\nstrong stochastic transitivity class CSST. We provide a formal proof of this statement for the\nsake of completeness. Suppose without loss of generality that w1 \u2265\u00b7 \u00b7 \u00b7 \u2265wn. Then we claim\nthat the distribution of pairwise comparisons generated through this model result in a matrix,\nsay M, that lies in the SST model with the ordering following the identity permutation. This\nis because for any i > j > k,\nwi \u2212wk \u2265wi \u2212wj\nF(wi \u2212wk) \u2265F(wi \u2212wj)\nMik \u2265Mij.\nWe now show the remaining relations with the four constructions indicated in Figure 3.\nWhile these constructions target some speci\ufb01c value of n, the results hold for any value n\ngreater than that speci\ufb01c value. To see this, suppose we construct a matrix M for some n = n0,\nand show that it lies inside (or outside) one of these classes. Consider any n > n0, and de\ufb01ne\na (n \u00d7 n) matrix M\u2032 as having M as the top-left (n0 \u00d7 n0) block, 1\n2 on the remaining diagonal\nentries, 1 on the remaining entries above the diagonal and 0 on the remaining entries below the\ndiagonal. This matrix M\u2032 will retain the properties of M in terms of lying inside (or outside,\nrespectively) the claimed class.\nIn this proof, we use the notation i \u227bj to represent a greater preference for i as compared\nto j.\n46\nD.4.1\nConstruction 1\nWe construct a matrix M such that M \u2208CFULL but M /\u2208CSST. Let n = 3. Consider the following\ndistribution over permutations of 3 items (1, 2, 3):\nP(1 \u227b2 \u227b3)\n= 2\n5,\nP(3 \u227b1 \u227b2)\n= 1\n5,\nP(2 \u227b3 \u227b1)\n= 2\n5.\nThis distribution induces the pairwise marginals\nP(1 \u227b2)\n= 3\n5,\nP(2 \u227b3)\n= 4\n5,\nP(3 \u227b1)\n= 3\n5.\nSet Mij = P(i \u227bj) for every pair. By de\ufb01nition of the class CFULL, we have M \u2208CFULL.\nA necessary condition for a matrix M to belong to the class CSST is that there must exist at\nleast one item, say item i, such that Mij \u22651\n2 for every item j. One can verify that the pairwise\nmarginals enumerated above do not satisfy this condition, and hence M /\u2208CSST.\nD.4.2\nConstruction 2\nWe construct a matrix M such that M \u2208CSST \u2229CFULL but M /\u2208CPAR. Let n = 4 and consider\nthe following distribution over permutations of 4 items (1, 2, 3, 4):\nP(3 \u227b1 \u227b2 \u227b4) = 1\n8,\nP(1 \u227b2 \u227b4 \u227b3) = 1\n8\nP(2 \u227b1 \u227b4 \u227b3) = 2\n8\nand\nP(1 \u227b2 \u227b3 \u227b4) = 4\n8.\nOne can verify that this distribution leads to the following pairwise comparison matrix M (with\nthe ordering of the rows and columns respecting the permutation 1 \u227b2 \u227b3 \u227b4):\nM : = 1\n8\n\uf8ee\n\uf8ef\uf8ef\uf8f0\n4\n6\n7\n8\n2\n4\n7\n8\n1\n1\n4\n5\n0\n0\n3\n4\n\uf8f9\n\uf8fa\uf8fa\uf8fb.\nIt is easy to see that this matrix M \u2208CSST, and by construction M \u2208CFULL. Finally, the proof\nof Proposition 4 shows that M /\u2208CPAR, thereby completing the proof.\nD.4.3\nConstruction 3\nWe construct a matrix M such that M \u2208CPAR (and hence M \u2208CSST) but M /\u2208CFULL. First\nobserve that any total ordering on n items can be represented as an (n \u00d7 n) matrix in the SST\nclass such that all its o\ufb00-diagonal entries take values in {0, 1}. The class CFULL is precisely the\nconvex hull of all such binary SST matrices.\nLet B1, . . . , Bn! denote all (n\u00d7n) matrices in CSST whose o\ufb00-diagonal elements are restricted\nto take values in the set {0, 1}. The following lemma derives a property that any matrix in the\nconvex hull of B1, . . . , Bn! must satisfy.\n47\nLemma 13. Consider any M \u2208CSST, and consider three items i, j, k \u2208[n] such that M respects\nthe ordering i \u227bj \u227bk. Suppose Mij = Mjk = 1\n2 and Mik = 1. Further suppose that M can be\nwritten as\nM =\nX\n\u2113\u2208[n!]\n\u03b1\u2113B\u2113,\n(59)\nwhere \u03b1\u2113\u22650 \u2200\u2113and Pn!\n\u2113=1 \u03b1\u2113= 1. Then for any \u2113\u2208[n!] such that \u03b1\u2113> 0, it must be that\nB\u2113\nij \u0338= B\u2113\njk.\nThe proof of the lemma is provided at the end of this section.\nNow consider the following (7 \u00d7 7) matrix M \u2208CSST:\nM : =\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n1\n2\n1\n2\n1\n1\n1\n1\n1\n1\n2\n1\n2\n1\n2\n1\n2\n1\n1\n1\n0\n1\n2\n1\n2\n1\n2\n1\n2\n1\n1\n0\n1\n2\n1\n2\n1\n2\n1\n2\n1\n2\n1\n0\n0\n1\n2\n1\n2\n1\n2\n1\n2\n1\n0\n0\n0\n1\n2\n1\n2\n1\n2\n1\n2\n0\n0\n0\n0\n0\n1\n2\n1\n2\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n.\n(60)\nWe will now show via proof by contradiction that M cannot be represented as a convex com-\nbination of the matrices B1, . . . , Bn!. We will then show that M \u2208CPAR.\nSuppose one can represent M as a convex combination M = P\n\u2113\u2208[n!] \u03b1\u2113B\u2113, where \u03b11, . . . , \u03b1n!\nare non-negative scalars that sum to one. Consider any \u2113such that \u03b1\u2113\u0338= 0. Let B\u2113\n12 = b \u2208{0, 1}.\nLet us derive some more constraints on B\u2113. Successively applying Lemma 13 for the following\nvalues of i, j, k implies that B\u2113must necessarily have the form (61) shown below. Here \u00afb : = 1\u2212b\nand \u2018\u2217\u2019 denotes some arbitrary value that is irrelevant to the discussion at hand.\n\u2022 i = 1, j = 2, k = 3 gives B\u2113\n23 = \u00afb\n\u2022 i = 1, j = 2, k = 4 gives B\u2113\n24 = \u00afb\n\u2022 i = 2, j = 3, k = 5 gives B\u2113\n35 = b\n\u2022 i = 2, j = 4, k = 6 gives B\u2113\n46 = b\n\u2022 i = 3, j = 5, k = 6 gives B\u2113\n56 = \u00afb\n\u2022 i = 4, j = 6, k = 7 gives B\u2113\n67 = \u00afb.\nThus B\u2113must be of the form\nB\u2113=\n\uf8ee\n\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n1\n2\nb\n1\n1\n1\n1\n1\n1\n2\n1\n2\n\u00afb\n\u00afb\n1\n1\n1\n0\nb\n1\n2\n\u2217\nb\n1\n1\n0\nb\n\u2217\n1\n2\n\u2217\nb\n1\n0\n0\n\u00afb\n\u2217\n1\n2\n\u00afb\n1\n0\n0\n0\n\u00afb\nb\n1\n2\n\u00afb\n0\n0\n0\n0\n0\nb\n1\n2\n\uf8f9\n\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n.\n(61)\n48\nFinally, applying Lemma 13 with i = 5, j = 6 and k = 7 implies that B\u2113\n67 = b, which contradicts\nthe necessary condition in equation (61). We have thus shown that M /\u2208CFULL.\nWe now show that the matrix M constructed in equation (60) is contained in the class CPAR.\nConsider the following function F : [\u22121, 1] \u2192[0, 1] in the de\ufb01nition of a parametric class:\nF(x) =\n\uf8f1\n\uf8f4\n\uf8f2\n\uf8f4\n\uf8f3\n0\nif x < \u22120.25\n1\n2\nif \u22120.25 \u2264x \u22640.25\n1\nif x > 0.25.\nLet n = 7 with w1 = .9, w2 = .7, w3 = .6, w4 = .5, w5 = .4, w6 = .3 and w7 = .1. One can\nverify that under this construction, the matrix of pairwise comparisons is identical to that in\nequation (60).\nProof of Lemma 13\nIn what follows, we show that P\n\u2113:B\u2113\nij=1,B\u2113\njk=1 \u03b1\u2113= P\n\u2113:B\u2113\nij=1,B\u2113\njk=1 \u03b1\u2113=\n0. The result then follows immediately.\nConsider some \u2113\u2032 \u2208[n!] such that \u03b1\u2113\u2032 > 0 and B\u2113\u2032\nij = 0. Since Mik = 1, we must have\nB\u2113\u2032\nik = 1. Given that B\u2113\u2032 represents a total ordering of the n items, that is, B\u2113\u2032 is an SST matrix\nwith boolean-valued its o\ufb00-diagonal elements, B\u2113\u2032\nij = 0 and B\u2113\u2032\nik = 1 imply that B\u2113\u2032\njk = 1. We\nhave thus shown that B\u2113\u2032\njk = 1 whenever B\u2113\u2032\nij = 0. This result has two consequences. The \ufb01rst\nconsequence is that P\n\u2113:B\u2113\nij=0,B\u2113\njk=0 \u03b1\u2113= 0. The second consequence employs the additional fact\nthat Mij = 1\n2 and hence P\n\u2113:B\u2113\nij=0 \u03b1\u2113= 1\n2, and then gives P\n\u2113:B\u2113\nij=0,B\u2113\njk=1 \u03b1\u2113= 1\n2. Building on,\nwe have\n1\n2 = Mjk =\nX\n\u2113:B\u2113\nij=0,B\u2113\njk=1\n\u03b1\u2113+\nX\n\u2113:B\u2113\nij=1,B\u2113\njk=1\n\u03b1\u2113,\nand hence we have P\n\u2113:B\u2113\nij=1,B\u2113\njk=1 \u03b1\u2113= 0, thus completing the proof.\nD.4.4\nConstruction 4\nWe construct a matrix M such that M \u2208CSST but M /\u2208CFULL and M /\u2208CPAR. Consider n = 11.\nLet M2 denote the (4 \u00d7 4) matrix of Construction 2 and let M3 denote the (7 \u00d7 7) matrix of\nconstruction 3. Consider the (11 \u00d7 11) matrix M of the form\nM : =\n\u0014M2\n1\n0\nM3\n\u0015\n.\nSince M2 \u2208CSST and M3 \u2208CSST, it is easy to see that M \u2208CSST. Since M2 /\u2208CPAR and M /\u2208CFULL,\nit follows that M /\u2208CPAR and M /\u2208CFULL. This construction completes the proof of Proposition 5.\n49\n",
        "sentence": "",
        "context": "work.\nAcknowledgments:\nThis work was partially supported by ONR-MURI grant DOD-002888,\nAFOSR grant FA9550-14-1-0016, NSF grant CIF-31712-23800, and ONR MURI grant N00014-\n\u2217Department of EECS\nUniversity of California, Berkeley\nBerkeley, CA 94720\n\u266fDepartment of Statistics\nCarnegie Mellon University,\n5000 Forbes Ave, Pittsburgh, PA 15213\nAbstract\n13 = 7\n8 < 8\n8 = M\u2217\n24. Such\nan occurrence can be explained by a simple two-factor model: suppose the fuel economies of\ncars 1, 2, 3 and 4 are 20, 18, 12 and 6 kilometers per liter respectively, and the comfort levels"
    },
    {
        "title": "Svm optimization: inverse dependence on training set size",
        "author": [
            "S. Shalev-Shwartz",
            "N. Srebro"
        ],
        "venue": "In Proceedings of the 25th international conference on Machine learning,",
        "citeRegEx": "Shalev.Shwartz and Srebro.,? \\Q2008\\E",
        "shortCiteRegEx": "Shalev.Shwartz and Srebro.",
        "year": 2008,
        "abstract": "",
        "full_text": "",
        "sentence": " As a solution, recent advances in learning theory introduce hierarchies of algorithmic solutions, ordered by the respective computational complexity, for several fundamental machine learning applications in (Bousquet and Bottou, 2008; Shalev-Shwartz and Srebro, 2008; Chandrasekaran and Jordan, 2013; Agarwal et al., 2012; Lucic et al., 2015).",
        "context": null
    },
    {
        "title": "Asymptotics when the number of parameters tends to infinity in the bradley-terry model for paired comparisons",
        "author": [
            "G. Simons",
            "Y. Yao"
        ],
        "venue": "The Annals of Statistics,",
        "citeRegEx": "Simons and Yao.,? \\Q1999\\E",
        "shortCiteRegEx": "Simons and Yao.",
        "year": 1999,
        "abstract": "Abstract n\u00e3o dispon\u00edvel",
        "full_text": "",
        "sentence": "",
        "context": null
    }
]