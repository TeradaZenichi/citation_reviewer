,abstract,faithfulness,precision,recall,semantic_similarity,pdf,pdf-faithfulness,pdf-precision,pdf-recall,pdf-semantic_similarity,pdf-precision_recall,precision_recall
Dapple: A pipelined data parallel approach for training large models,arxiv Library,0.0,0.5789473684210527,0.09821428571428571,0.8165094641118904,arxiv Library,0.5,0.42105263157894735,0.10256410256410256,0.8630978776452551,,
Beyond data and model parallelism for deep neural networks,arxiv Library,0.0,0.3684210526315789,0.06086956521739131,0.8416937485468842,arxiv Library,0.0,0.3684210526315789,0.0958904109589041,0.8666693442608611,,
Pytorch fsdp: experiences on scaling fully sharded data parallel,arxiv Library,0.0,0.42105263157894735,0.064,0.7797165120685619,arxiv Library,0.7,0.2631578947368421,0.05952380952380952,0.8568693615357268,,
A survey of quantization methods for efficient neural network inference,arxiv Library,1.0,0.47368421052631576,0.06040268456375839,0.8700222206921524,arxiv Library,0.8,0.42105263157894735,0.1,0.9032757790991779,,
Hawq: Hessian aware quantization of neural networks with mixed-precision,crossref,0.0,0.0,0.0,0.7193153825212139,,,,,,,
Noisyquant: Noisy bias-enhanced post-training activation quantization for vision transformers,crossref,0.0,0.0,0.0,0.7193153825212139,,,,,,,
Wide & deep learning for recommender systems,arxiv Library,0.0,0.35,0.06542056074766354,0.8166261012793598,arxiv Library,0.5,0.4,0.12698412698412698,0.8631761040621125,,
Analysis of quantization on mlp-based vision models,,,,,,,,,,,,
Deep learning recommendation model for personalization and recommendation systems,arxiv Library,0.0,0.24242424242424243,0.08333333333333333,0.8253943292932115,arxiv Library,0.6,0.21212121212121213,0.1111111111111111,0.8677674276451768,,
Post-training 4-bit quantization on embedding tables,,,,,,,,,,,,
Dqrm: Deep quantized recommendation models,arxiv Library,0.9,0.3939393939393939,0.08843537414965986,0.8906133363226514,arxiv Library,0.8,0.21212121212121213,0.08974358974358974,0.898365392250414,,
Tt-rec: Tensor train compression for deep learning recommendation models,arxiv Library,0.5,0.3939393939393939,0.0962962962962963,0.8756576208900493,arxiv Library,0.7,0.2727272727272727,0.11392405063291139,0.8882672133465341,,
Embedding compression in recommender systems: A survey,arxiv Library,0.5,0.2,0.0449438202247191,0.8382836662279713,arxiv Library,0.7,0.25,0.06944444444444445,0.8749615236142135,,
Reversible vision transformers,arxiv Library,0.7,0.2972972972972973,0.10091743119266056,0.8062370603816982,arxiv Library,0.5,0.2702702702702703,0.125,0.8431584522953358,,
Checkmate: Breaking the memory wall with optimal tensor rematerialization,arxiv Library,0.8,0.2702702702702703,0.1111111111111111,0.843470315547761,arxiv Library,0.7,0.35135135135135137,0.16049382716049382,0.8814846359695354,,
Pb-llm: Partially binarized large language models,arxiv Library,0.0,0.34615384615384615,0.06923076923076923,0.7602909005119327,arxiv Library,0.5,0.2692307692307692,0.10606060606060606,0.8585121973681265,,
Qft: Quantized full-parameter tuning of llms with affordable resources,,,,,,,,,,,,
Megatron-lm: Training multi-billion parameter language models using model parallelism,,,,,,,,,,,,
Bagpipe: Accelerating deep recommendation model training,arxiv Library,1.0,0.43243243243243246,0.10666666666666667,0.816777947729262,arxiv Library,1.0,0.3783783783783784,0.21212121212121213,0.8987708762470791,,
Distributed hierarchical gpu parameter server for massive scale deep learning ads systems,arxiv Library,0.0,0.25,0.048,0.7625409531463652,arxiv Library,0.5,0.2916666666666667,0.09210526315789473,0.8463607643667166,,
Time-based sequence model for personalization and recommendation systems,,,,,,,,,,,,
